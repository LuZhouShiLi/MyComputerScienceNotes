{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35.7000, 55.9000, 58.2000, 81.9000, 56.3000, 48.9000, 33.9000, 21.8000,\n",
      "        48.4000, 60.4000, 68.4000])\n"
     ]
    }
   ],
   "source": [
    "# 定义模型\n",
    "def model(t_u,w,b):\n",
    "    return w * t_u + b\n",
    "\n",
    "## 定义损失函数\n",
    "def loss_fun(t_p,t_c):\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean() ## 对损失误差的标量求平均值    得到标量损失函数\n",
    "\n",
    "\n",
    "## 初始化参数 调用模型\n",
    "w = torch.ones(1)\n",
    "b = torch.zeros(1)\n",
    "\n",
    "t_p = model(t_u,w,b)  ## 计算预测值\n",
    "print(t_p)  ## 张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1763.8848)\n"
     ]
    }
   ],
   "source": [
    "## 计算损失函数的值\n",
    "\n",
    "loss = loss_fun(t_p,t_c)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2567.5269])\n"
     ]
    }
   ],
   "source": [
    "delta = 0.1  ## 变化幅度\n",
    "loss_rate_of_change_w = (loss_fun(model(t_u,w + delta,b),t_c) - loss_fun(model(t_u,w - delta,b),t_c)) / (2.0 * delta)\n",
    "\n",
    "## 定义学习率\n",
    "learning_rate = 1e-2\n",
    "w = w - loss_rate_of_change_w * learning_rate  ## 更新参数w\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2560.])\n"
     ]
    }
   ],
   "source": [
    "loss_rate_of_change_b = (loss_fun(model(t_u,w,b + delta),t_c) - loss_fun(model(t_u,w,b - delta),t_c)) / (2.0 * delta)\n",
    "\n",
    "b = b - learning_rate * loss_rate_of_change_b\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 计算损失函数对模型的输出的偏导数\n",
    "def dloss_fun(t_p,t_c):\n",
    "    dsq_diffs = 2 * (t_p - t_c)\n",
    "    return dsq_diffs\n",
    "\n",
    "## 计算输出对参数w的偏导数\n",
    "def dmodel_dw(t_u,w,b):\n",
    "    return t_u\n",
    "\n",
    "## 计算输出对参数b的偏导数\n",
    "def dmodel_db(t_u,w,b):\n",
    "    return 1.0\n",
    "\n",
    "## 计算梯度\n",
    "def grad_fn(t_u,t_c,t_p,w,b):\n",
    "    dloss_dw = dloss_fun(t_p,t_c) * dmodel_dw(t_u,w,b)\n",
    "    dloss_db = dloss_fun(t_p,t_c) * dmodel_db(t_u,w,b)\n",
    "\n",
    "\n",
    "\n",
    "    return torch.stack([dloss_dw.mean(),dloss_db.mean()])  ## 计算均值 将梯度张量 转换成梯度标量\n",
    "\n",
    "\n",
    "\n",
    "## 从参数的固定值开始 迭代地对其应用更新以进行固定次数的迭代或者直到w和b停止改变为止\n",
    "## 所有训练样本上的一次参数更新迭代称之为一个epoch\n",
    "\n",
    "\n",
    "## 这里指定了参数更新的迭代次数\n",
    "def training_loop(n_epochs,learning_rate,params,t_u,t_c,print_params = True,verbose = 1):\n",
    "    for epoch in range(1,n_epochs + 1):\n",
    "        w,b = params## 获取参数\n",
    "\n",
    "        # 计算预测值\n",
    "        t_p = model(t_u,w,b)  # 前向传播\n",
    "        loss = loss_fun(t_p,t_c)  ## 计算损失\n",
    "\n",
    "        grad = grad_fn(t_u,t_c,t_p,w,b)  # 反向传播\n",
    "\n",
    "        params = params - learning_rate * grad  ## 参数更新\n",
    "\n",
    "        ## \n",
    "        if epoch % verbose == 0:\n",
    "            print('Epoch %d,Loss %f' % (epoch,float(loss)))\n",
    "\n",
    "          \n",
    "            if epoch % verbose == 0:\n",
    "                print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "                if print_params:\n",
    "                    print('    Params: ', params)\n",
    "                    print('    Grad  : ', grad)\n",
    "\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1,Loss 1763.884766\n",
      "Epoch 1, Loss 1763.884766\n",
      "    Params:  tensor([ 0.5483, -0.0083])\n",
      "    Grad  :  tensor([4517.2964,   82.6000])\n",
      "Epoch 2,Loss 323.090515\n",
      "Epoch 2, Loss 323.090515\n",
      "    Params:  tensor([ 0.3623, -0.0118])\n",
      "    Grad  :  tensor([1859.5492,   35.7843])\n",
      "Epoch 3,Loss 78.929634\n",
      "Epoch 3, Loss 78.929634\n",
      "    Params:  tensor([ 0.2858, -0.0135])\n",
      "    Grad  :  tensor([765.4666,  16.5122])\n",
      "Epoch 4,Loss 37.552845\n",
      "Epoch 4, Loss 37.552845\n",
      "    Params:  tensor([ 0.2543, -0.0143])\n",
      "    Grad  :  tensor([315.0790,   8.5787])\n",
      "Epoch 5,Loss 30.540283\n",
      "Epoch 5, Loss 30.540283\n",
      "    Params:  tensor([ 0.2413, -0.0149])\n",
      "    Grad  :  tensor([129.6733,   5.3127])\n",
      "Epoch 6,Loss 29.351154\n",
      "Epoch 6, Loss 29.351154\n",
      "    Params:  tensor([ 0.2360, -0.0153])\n",
      "    Grad  :  tensor([53.3496,  3.9682])\n",
      "Epoch 7,Loss 29.148884\n",
      "Epoch 7, Loss 29.148884\n",
      "    Params:  tensor([ 0.2338, -0.0156])\n",
      "    Grad  :  tensor([21.9304,  3.4148])\n",
      "Epoch 8,Loss 29.113848\n",
      "Epoch 8, Loss 29.113848\n",
      "    Params:  tensor([ 0.2329, -0.0159])\n",
      "    Grad  :  tensor([8.9965, 3.1869])\n",
      "Epoch 9,Loss 29.107145\n",
      "Epoch 9, Loss 29.107145\n",
      "    Params:  tensor([ 0.2325, -0.0162])\n",
      "    Grad  :  tensor([3.6721, 3.0930])\n",
      "Epoch 10,Loss 29.105247\n",
      "Epoch 10, Loss 29.105247\n",
      "    Params:  tensor([ 0.2324, -0.0166])\n",
      "    Grad  :  tensor([1.4803, 3.0544])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2324, -0.0166])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(n_epochs=10,learning_rate=1e-4,params=torch.tensor([1.0,0.0]),t_u = t_u,t_c = t_c)\n",
    "\n",
    "## 权重w和b 的梯度差别太大，因此权重和偏差存在于不同的比例空间 学习率只能更新一个 不能满足另一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1,Loss 80.364342\n",
      "Epoch 1, Loss 80.364342\n",
      "    Params:  tensor([1.7761, 0.1064])\n",
      "    Grad  :  tensor([-77.6140, -10.6400])\n",
      "Epoch 2,Loss 37.574917\n",
      "Epoch 2, Loss 37.574917\n",
      "    Params:  tensor([2.0848, 0.1303])\n",
      "    Grad  :  tensor([-30.8623,  -2.3864])\n",
      "Epoch 3,Loss 30.871077\n",
      "Epoch 3, Loss 30.871077\n",
      "    Params:  tensor([2.2094, 0.1217])\n",
      "    Grad  :  tensor([-12.4631,   0.8587])\n",
      "Epoch 4,Loss 29.756193\n",
      "Epoch 4, Loss 29.756193\n",
      "    Params:  tensor([2.2616, 0.1004])\n",
      "    Grad  :  tensor([-5.2218,  2.1327])\n",
      "Epoch 5,Loss 29.507153\n",
      "Epoch 5, Loss 29.507153\n",
      "    Params:  tensor([2.2853, 0.0740])\n",
      "    Grad  :  tensor([-2.3715,  2.6310])\n",
      "Epoch 6,Loss 29.392456\n",
      "Epoch 6, Loss 29.392456\n",
      "    Params:  tensor([2.2978, 0.0458])\n",
      "    Grad  :  tensor([-1.2492,  2.8241])\n",
      "Epoch 7,Loss 29.298828\n",
      "Epoch 7, Loss 29.298828\n",
      "    Params:  tensor([2.3059, 0.0168])\n",
      "    Grad  :  tensor([-0.8071,  2.8970])\n",
      "Epoch 8,Loss 29.208717\n",
      "Epoch 8, Loss 29.208717\n",
      "    Params:  tensor([ 2.3122, -0.0124])\n",
      "    Grad  :  tensor([-0.6325,  2.9227])\n",
      "Epoch 9,Loss 29.119415\n",
      "Epoch 9, Loss 29.119415\n",
      "    Params:  tensor([ 2.3178, -0.0417])\n",
      "    Grad  :  tensor([-0.5633,  2.9298])\n",
      "Epoch 10,Loss 29.030489\n",
      "Epoch 10, Loss 29.030489\n",
      "    Params:  tensor([ 2.3232, -0.0710])\n",
      "    Grad  :  tensor([-0.5355,  2.9295])\n",
      "Epoch 11,Loss 28.941877\n",
      "Epoch 11, Loss 28.941877\n",
      "    Params:  tensor([ 2.3284, -0.1003])\n",
      "    Grad  :  tensor([-0.5240,  2.9264])\n",
      "Epoch 12,Loss 28.853565\n",
      "Epoch 12, Loss 28.853565\n",
      "    Params:  tensor([ 2.3336, -0.1295])\n",
      "    Grad  :  tensor([-0.5190,  2.9222])\n",
      "Epoch 13,Loss 28.765553\n",
      "Epoch 13, Loss 28.765553\n",
      "    Params:  tensor([ 2.3388, -0.1587])\n",
      "    Grad  :  tensor([-0.5165,  2.9175])\n",
      "Epoch 14,Loss 28.677851\n",
      "Epoch 14, Loss 28.677851\n",
      "    Params:  tensor([ 2.3439, -0.1878])\n",
      "    Grad  :  tensor([-0.5150,  2.9126])\n",
      "Epoch 15,Loss 28.590431\n",
      "Epoch 15, Loss 28.590431\n",
      "    Params:  tensor([ 2.3491, -0.2169])\n",
      "    Grad  :  tensor([-0.5138,  2.9077])\n",
      "Epoch 16,Loss 28.503319\n",
      "Epoch 16, Loss 28.503319\n",
      "    Params:  tensor([ 2.3542, -0.2459])\n",
      "    Grad  :  tensor([-0.5129,  2.9028])\n",
      "Epoch 17,Loss 28.416498\n",
      "Epoch 17, Loss 28.416498\n",
      "    Params:  tensor([ 2.3593, -0.2749])\n",
      "    Grad  :  tensor([-0.5120,  2.8979])\n",
      "Epoch 18,Loss 28.329975\n",
      "Epoch 18, Loss 28.329975\n",
      "    Params:  tensor([ 2.3644, -0.3038])\n",
      "    Grad  :  tensor([-0.5111,  2.8930])\n",
      "Epoch 19,Loss 28.243742\n",
      "Epoch 19, Loss 28.243742\n",
      "    Params:  tensor([ 2.3695, -0.3327])\n",
      "    Grad  :  tensor([-0.5102,  2.8881])\n",
      "Epoch 20,Loss 28.157804\n",
      "Epoch 20, Loss 28.157804\n",
      "    Params:  tensor([ 2.3746, -0.3615])\n",
      "    Grad  :  tensor([-0.5093,  2.8832])\n",
      "Epoch 21,Loss 28.072151\n",
      "Epoch 21, Loss 28.072151\n",
      "    Params:  tensor([ 2.3797, -0.3903])\n",
      "    Grad  :  tensor([-0.5084,  2.8783])\n",
      "Epoch 22,Loss 27.986797\n",
      "Epoch 22, Loss 27.986797\n",
      "    Params:  tensor([ 2.3848, -0.4190])\n",
      "    Grad  :  tensor([-0.5076,  2.8734])\n",
      "Epoch 23,Loss 27.901728\n",
      "Epoch 23, Loss 27.901728\n",
      "    Params:  tensor([ 2.3899, -0.4477])\n",
      "    Grad  :  tensor([-0.5067,  2.8685])\n",
      "Epoch 24,Loss 27.816950\n",
      "Epoch 24, Loss 27.816950\n",
      "    Params:  tensor([ 2.3949, -0.4763])\n",
      "    Grad  :  tensor([-0.5059,  2.8636])\n",
      "Epoch 25,Loss 27.732464\n",
      "Epoch 25, Loss 27.732464\n",
      "    Params:  tensor([ 2.4000, -0.5049])\n",
      "    Grad  :  tensor([-0.5050,  2.8588])\n",
      "Epoch 26,Loss 27.648256\n",
      "Epoch 26, Loss 27.648256\n",
      "    Params:  tensor([ 2.4050, -0.5335])\n",
      "    Grad  :  tensor([-0.5042,  2.8539])\n",
      "Epoch 27,Loss 27.564344\n",
      "Epoch 27, Loss 27.564344\n",
      "    Params:  tensor([ 2.4101, -0.5620])\n",
      "    Grad  :  tensor([-0.5033,  2.8490])\n",
      "Epoch 28,Loss 27.480707\n",
      "Epoch 28, Loss 27.480707\n",
      "    Params:  tensor([ 2.4151, -0.5904])\n",
      "    Grad  :  tensor([-0.5024,  2.8442])\n",
      "Epoch 29,Loss 27.397362\n",
      "Epoch 29, Loss 27.397362\n",
      "    Params:  tensor([ 2.4201, -0.6188])\n",
      "    Grad  :  tensor([-0.5016,  2.8394])\n",
      "Epoch 30,Loss 27.314299\n",
      "Epoch 30, Loss 27.314299\n",
      "    Params:  tensor([ 2.4251, -0.6471])\n",
      "    Grad  :  tensor([-0.5007,  2.8346])\n",
      "Epoch 31,Loss 27.231512\n",
      "Epoch 31, Loss 27.231512\n",
      "    Params:  tensor([ 2.4301, -0.6754])\n",
      "    Grad  :  tensor([-0.4999,  2.8297])\n",
      "Epoch 32,Loss 27.149010\n",
      "Epoch 32, Loss 27.149010\n",
      "    Params:  tensor([ 2.4351, -0.7037])\n",
      "    Grad  :  tensor([-0.4990,  2.8249])\n",
      "Epoch 33,Loss 27.066790\n",
      "Epoch 33, Loss 27.066790\n",
      "    Params:  tensor([ 2.4401, -0.7319])\n",
      "    Grad  :  tensor([-0.4982,  2.8201])\n",
      "Epoch 34,Loss 26.984844\n",
      "Epoch 34, Loss 26.984844\n",
      "    Params:  tensor([ 2.4450, -0.7600])\n",
      "    Grad  :  tensor([-0.4973,  2.8153])\n",
      "Epoch 35,Loss 26.903175\n",
      "Epoch 35, Loss 26.903175\n",
      "    Params:  tensor([ 2.4500, -0.7881])\n",
      "    Grad  :  tensor([-0.4965,  2.8106])\n",
      "Epoch 36,Loss 26.821791\n",
      "Epoch 36, Loss 26.821791\n",
      "    Params:  tensor([ 2.4550, -0.8162])\n",
      "    Grad  :  tensor([-0.4957,  2.8058])\n",
      "Epoch 37,Loss 26.740679\n",
      "Epoch 37, Loss 26.740679\n",
      "    Params:  tensor([ 2.4599, -0.8442])\n",
      "    Grad  :  tensor([-0.4948,  2.8010])\n",
      "Epoch 38,Loss 26.659838\n",
      "Epoch 38, Loss 26.659838\n",
      "    Params:  tensor([ 2.4649, -0.8722])\n",
      "    Grad  :  tensor([-0.4940,  2.7963])\n",
      "Epoch 39,Loss 26.579279\n",
      "Epoch 39, Loss 26.579279\n",
      "    Params:  tensor([ 2.4698, -0.9001])\n",
      "    Grad  :  tensor([-0.4931,  2.7915])\n",
      "Epoch 40,Loss 26.498987\n",
      "Epoch 40, Loss 26.498987\n",
      "    Params:  tensor([ 2.4747, -0.9280])\n",
      "    Grad  :  tensor([-0.4923,  2.7868])\n",
      "Epoch 41,Loss 26.418974\n",
      "Epoch 41, Loss 26.418974\n",
      "    Params:  tensor([ 2.4796, -0.9558])\n",
      "    Grad  :  tensor([-0.4915,  2.7820])\n",
      "Epoch 42,Loss 26.339228\n",
      "Epoch 42, Loss 26.339228\n",
      "    Params:  tensor([ 2.4845, -0.9836])\n",
      "    Grad  :  tensor([-0.4906,  2.7773])\n",
      "Epoch 43,Loss 26.259754\n",
      "Epoch 43, Loss 26.259754\n",
      "    Params:  tensor([ 2.4894, -1.0113])\n",
      "    Grad  :  tensor([-0.4898,  2.7726])\n",
      "Epoch 44,Loss 26.180548\n",
      "Epoch 44, Loss 26.180548\n",
      "    Params:  tensor([ 2.4943, -1.0390])\n",
      "    Grad  :  tensor([-0.4890,  2.7679])\n",
      "Epoch 45,Loss 26.101616\n",
      "Epoch 45, Loss 26.101616\n",
      "    Params:  tensor([ 2.4992, -1.0666])\n",
      "    Grad  :  tensor([-0.4881,  2.7632])\n",
      "Epoch 46,Loss 26.022947\n",
      "Epoch 46, Loss 26.022947\n",
      "    Params:  tensor([ 2.5041, -1.0942])\n",
      "    Grad  :  tensor([-0.4873,  2.7585])\n",
      "Epoch 47,Loss 25.944544\n",
      "Epoch 47, Loss 25.944544\n",
      "    Params:  tensor([ 2.5089, -1.1217])\n",
      "    Grad  :  tensor([-0.4865,  2.7538])\n",
      "Epoch 48,Loss 25.866417\n",
      "Epoch 48, Loss 25.866417\n",
      "    Params:  tensor([ 2.5138, -1.1492])\n",
      "    Grad  :  tensor([-0.4856,  2.7491])\n",
      "Epoch 49,Loss 25.788549\n",
      "Epoch 49, Loss 25.788549\n",
      "    Params:  tensor([ 2.5186, -1.1766])\n",
      "    Grad  :  tensor([-0.4848,  2.7444])\n",
      "Epoch 50,Loss 25.710938\n",
      "Epoch 50, Loss 25.710938\n",
      "    Params:  tensor([ 2.5235, -1.2040])\n",
      "    Grad  :  tensor([-0.4840,  2.7398])\n",
      "Epoch 51,Loss 25.633600\n",
      "Epoch 51, Loss 25.633600\n",
      "    Params:  tensor([ 2.5283, -1.2314])\n",
      "    Grad  :  tensor([-0.4832,  2.7351])\n",
      "Epoch 52,Loss 25.556524\n",
      "Epoch 52, Loss 25.556524\n",
      "    Params:  tensor([ 2.5331, -1.2587])\n",
      "    Grad  :  tensor([-0.4823,  2.7305])\n",
      "Epoch 53,Loss 25.479700\n",
      "Epoch 53, Loss 25.479700\n",
      "    Params:  tensor([ 2.5379, -1.2860])\n",
      "    Grad  :  tensor([-0.4815,  2.7258])\n",
      "Epoch 54,Loss 25.403149\n",
      "Epoch 54, Loss 25.403149\n",
      "    Params:  tensor([ 2.5428, -1.3132])\n",
      "    Grad  :  tensor([-0.4807,  2.7212])\n",
      "Epoch 55,Loss 25.326851\n",
      "Epoch 55, Loss 25.326851\n",
      "    Params:  tensor([ 2.5476, -1.3403])\n",
      "    Grad  :  tensor([-0.4799,  2.7166])\n",
      "Epoch 56,Loss 25.250811\n",
      "Epoch 56, Loss 25.250811\n",
      "    Params:  tensor([ 2.5523, -1.3675])\n",
      "    Grad  :  tensor([-0.4791,  2.7120])\n",
      "Epoch 57,Loss 25.175035\n",
      "Epoch 57, Loss 25.175035\n",
      "    Params:  tensor([ 2.5571, -1.3945])\n",
      "    Grad  :  tensor([-0.4783,  2.7074])\n",
      "Epoch 58,Loss 25.099512\n",
      "Epoch 58, Loss 25.099512\n",
      "    Params:  tensor([ 2.5619, -1.4216])\n",
      "    Grad  :  tensor([-0.4775,  2.7028])\n",
      "Epoch 59,Loss 25.024248\n",
      "Epoch 59, Loss 25.024248\n",
      "    Params:  tensor([ 2.5667, -1.4485])\n",
      "    Grad  :  tensor([-0.4766,  2.6982])\n",
      "Epoch 60,Loss 24.949236\n",
      "Epoch 60, Loss 24.949236\n",
      "    Params:  tensor([ 2.5714, -1.4755])\n",
      "    Grad  :  tensor([-0.4758,  2.6936])\n",
      "Epoch 61,Loss 24.874483\n",
      "Epoch 61, Loss 24.874483\n",
      "    Params:  tensor([ 2.5762, -1.5024])\n",
      "    Grad  :  tensor([-0.4750,  2.6890])\n",
      "Epoch 62,Loss 24.799976\n",
      "Epoch 62, Loss 24.799976\n",
      "    Params:  tensor([ 2.5809, -1.5292])\n",
      "    Grad  :  tensor([-0.4742,  2.6845])\n",
      "Epoch 63,Loss 24.725737\n",
      "Epoch 63, Loss 24.725737\n",
      "    Params:  tensor([ 2.5857, -1.5560])\n",
      "    Grad  :  tensor([-0.4734,  2.6799])\n",
      "Epoch 64,Loss 24.651739\n",
      "Epoch 64, Loss 24.651739\n",
      "    Params:  tensor([ 2.5904, -1.5828])\n",
      "    Grad  :  tensor([-0.4726,  2.6753])\n",
      "Epoch 65,Loss 24.577986\n",
      "Epoch 65, Loss 24.577986\n",
      "    Params:  tensor([ 2.5951, -1.6095])\n",
      "    Grad  :  tensor([-0.4718,  2.6708])\n",
      "Epoch 66,Loss 24.504494\n",
      "Epoch 66, Loss 24.504494\n",
      "    Params:  tensor([ 2.5998, -1.6361])\n",
      "    Grad  :  tensor([-0.4710,  2.6663])\n",
      "Epoch 67,Loss 24.431252\n",
      "Epoch 67, Loss 24.431252\n",
      "    Params:  tensor([ 2.6045, -1.6628])\n",
      "    Grad  :  tensor([-0.4702,  2.6617])\n",
      "Epoch 68,Loss 24.358257\n",
      "Epoch 68, Loss 24.358257\n",
      "    Params:  tensor([ 2.6092, -1.6893])\n",
      "    Grad  :  tensor([-0.4694,  2.6572])\n",
      "Epoch 69,Loss 24.285505\n",
      "Epoch 69, Loss 24.285505\n",
      "    Params:  tensor([ 2.6139, -1.7159])\n",
      "    Grad  :  tensor([-0.4686,  2.6527])\n",
      "Epoch 70,Loss 24.212999\n",
      "Epoch 70, Loss 24.212999\n",
      "    Params:  tensor([ 2.6186, -1.7423])\n",
      "    Grad  :  tensor([-0.4678,  2.6482])\n",
      "Epoch 71,Loss 24.140741\n",
      "Epoch 71, Loss 24.140741\n",
      "    Params:  tensor([ 2.6232, -1.7688])\n",
      "    Grad  :  tensor([-0.4670,  2.6437])\n",
      "Epoch 72,Loss 24.068733\n",
      "Epoch 72, Loss 24.068733\n",
      "    Params:  tensor([ 2.6279, -1.7952])\n",
      "    Grad  :  tensor([-0.4662,  2.6392])\n",
      "Epoch 73,Loss 23.996971\n",
      "Epoch 73, Loss 23.996971\n",
      "    Params:  tensor([ 2.6326, -1.8215])\n",
      "    Grad  :  tensor([-0.4654,  2.6347])\n",
      "Epoch 74,Loss 23.925446\n",
      "Epoch 74, Loss 23.925446\n",
      "    Params:  tensor([ 2.6372, -1.8478])\n",
      "    Grad  :  tensor([-0.4646,  2.6302])\n",
      "Epoch 75,Loss 23.854168\n",
      "Epoch 75, Loss 23.854168\n",
      "    Params:  tensor([ 2.6418, -1.8741])\n",
      "    Grad  :  tensor([-0.4638,  2.6258])\n",
      "Epoch 76,Loss 23.783125\n",
      "Epoch 76, Loss 23.783125\n",
      "    Params:  tensor([ 2.6465, -1.9003])\n",
      "    Grad  :  tensor([-0.4631,  2.6213])\n",
      "Epoch 77,Loss 23.712328\n",
      "Epoch 77, Loss 23.712328\n",
      "    Params:  tensor([ 2.6511, -1.9265])\n",
      "    Grad  :  tensor([-0.4623,  2.6169])\n",
      "Epoch 78,Loss 23.641773\n",
      "Epoch 78, Loss 23.641773\n",
      "    Params:  tensor([ 2.6557, -1.9526])\n",
      "    Grad  :  tensor([-0.4615,  2.6124])\n",
      "Epoch 79,Loss 23.571455\n",
      "Epoch 79, Loss 23.571455\n",
      "    Params:  tensor([ 2.6603, -1.9787])\n",
      "    Grad  :  tensor([-0.4607,  2.6080])\n",
      "Epoch 80,Loss 23.501379\n",
      "Epoch 80, Loss 23.501379\n",
      "    Params:  tensor([ 2.6649, -2.0047])\n",
      "    Grad  :  tensor([-0.4599,  2.6035])\n",
      "Epoch 81,Loss 23.431538\n",
      "Epoch 81, Loss 23.431538\n",
      "    Params:  tensor([ 2.6695, -2.0307])\n",
      "    Grad  :  tensor([-0.4591,  2.5991])\n",
      "Epoch 82,Loss 23.361937\n",
      "Epoch 82, Loss 23.361937\n",
      "    Params:  tensor([ 2.6741, -2.0566])\n",
      "    Grad  :  tensor([-0.4584,  2.5947])\n",
      "Epoch 83,Loss 23.292570\n",
      "Epoch 83, Loss 23.292570\n",
      "    Params:  tensor([ 2.6787, -2.0825])\n",
      "    Grad  :  tensor([-0.4576,  2.5903])\n",
      "Epoch 84,Loss 23.223436\n",
      "Epoch 84, Loss 23.223436\n",
      "    Params:  tensor([ 2.6832, -2.1084])\n",
      "    Grad  :  tensor([-0.4568,  2.5859])\n",
      "Epoch 85,Loss 23.154541\n",
      "Epoch 85, Loss 23.154541\n",
      "    Params:  tensor([ 2.6878, -2.1342])\n",
      "    Grad  :  tensor([-0.4560,  2.5815])\n",
      "Epoch 86,Loss 23.085882\n",
      "Epoch 86, Loss 23.085882\n",
      "    Params:  tensor([ 2.6923, -2.1600])\n",
      "    Grad  :  tensor([-0.4553,  2.5771])\n",
      "Epoch 87,Loss 23.017447\n",
      "Epoch 87, Loss 23.017447\n",
      "    Params:  tensor([ 2.6969, -2.1857])\n",
      "    Grad  :  tensor([-0.4545,  2.5727])\n",
      "Epoch 88,Loss 22.949251\n",
      "Epoch 88, Loss 22.949251\n",
      "    Params:  tensor([ 2.7014, -2.2114])\n",
      "    Grad  :  tensor([-0.4537,  2.5684])\n",
      "Epoch 89,Loss 22.881283\n",
      "Epoch 89, Loss 22.881283\n",
      "    Params:  tensor([ 2.7060, -2.2370])\n",
      "    Grad  :  tensor([-0.4529,  2.5640])\n",
      "Epoch 90,Loss 22.813549\n",
      "Epoch 90, Loss 22.813549\n",
      "    Params:  tensor([ 2.7105, -2.2626])\n",
      "    Grad  :  tensor([-0.4522,  2.5597])\n",
      "Epoch 91,Loss 22.746044\n",
      "Epoch 91, Loss 22.746044\n",
      "    Params:  tensor([ 2.7150, -2.2882])\n",
      "    Grad  :  tensor([-0.4514,  2.5553])\n",
      "Epoch 92,Loss 22.678766\n",
      "Epoch 92, Loss 22.678766\n",
      "    Params:  tensor([ 2.7195, -2.3137])\n",
      "    Grad  :  tensor([-0.4506,  2.5510])\n",
      "Epoch 93,Loss 22.611717\n",
      "Epoch 93, Loss 22.611717\n",
      "    Params:  tensor([ 2.7240, -2.3392])\n",
      "    Grad  :  tensor([-0.4499,  2.5466])\n",
      "Epoch 94,Loss 22.544899\n",
      "Epoch 94, Loss 22.544899\n",
      "    Params:  tensor([ 2.7285, -2.3646])\n",
      "    Grad  :  tensor([-0.4491,  2.5423])\n",
      "Epoch 95,Loss 22.478306\n",
      "Epoch 95, Loss 22.478306\n",
      "    Params:  tensor([ 2.7330, -2.3900])\n",
      "    Grad  :  tensor([-0.4483,  2.5380])\n",
      "Epoch 96,Loss 22.411934\n",
      "Epoch 96, Loss 22.411934\n",
      "    Params:  tensor([ 2.7374, -2.4153])\n",
      "    Grad  :  tensor([-0.4476,  2.5337])\n",
      "Epoch 97,Loss 22.345793\n",
      "Epoch 97, Loss 22.345793\n",
      "    Params:  tensor([ 2.7419, -2.4406])\n",
      "    Grad  :  tensor([-0.4468,  2.5294])\n",
      "Epoch 98,Loss 22.279875\n",
      "Epoch 98, Loss 22.279875\n",
      "    Params:  tensor([ 2.7464, -2.4658])\n",
      "    Grad  :  tensor([-0.4461,  2.5251])\n",
      "Epoch 99,Loss 22.214186\n",
      "Epoch 99, Loss 22.214186\n",
      "    Params:  tensor([ 2.7508, -2.4910])\n",
      "    Grad  :  tensor([-0.4453,  2.5208])\n",
      "Epoch 100,Loss 22.148710\n",
      "Epoch 100, Loss 22.148710\n",
      "    Params:  tensor([ 2.7553, -2.5162])\n",
      "    Grad  :  tensor([-0.4445,  2.5165])\n",
      "Epoch 101,Loss 22.083464\n",
      "Epoch 101, Loss 22.083464\n",
      "    Params:  tensor([ 2.7597, -2.5413])\n",
      "    Grad  :  tensor([-0.4438,  2.5122])\n",
      "Epoch 102,Loss 22.018436\n",
      "Epoch 102, Loss 22.018436\n",
      "    Params:  tensor([ 2.7641, -2.5664])\n",
      "    Grad  :  tensor([-0.4430,  2.5080])\n",
      "Epoch 103,Loss 21.953632\n",
      "Epoch 103, Loss 21.953632\n",
      "    Params:  tensor([ 2.7686, -2.5914])\n",
      "    Grad  :  tensor([-0.4423,  2.5037])\n",
      "Epoch 104,Loss 21.889046\n",
      "Epoch 104, Loss 21.889046\n",
      "    Params:  tensor([ 2.7730, -2.6164])\n",
      "    Grad  :  tensor([-0.4415,  2.4994])\n",
      "Epoch 105,Loss 21.824677\n",
      "Epoch 105, Loss 21.824677\n",
      "    Params:  tensor([ 2.7774, -2.6414])\n",
      "    Grad  :  tensor([-0.4408,  2.4952])\n",
      "Epoch 106,Loss 21.760529\n",
      "Epoch 106, Loss 21.760529\n",
      "    Params:  tensor([ 2.7818, -2.6663])\n",
      "    Grad  :  tensor([-0.4400,  2.4910])\n",
      "Epoch 107,Loss 21.696600\n",
      "Epoch 107, Loss 21.696600\n",
      "    Params:  tensor([ 2.7862, -2.6912])\n",
      "    Grad  :  tensor([-0.4393,  2.4867])\n",
      "Epoch 108,Loss 21.632883\n",
      "Epoch 108, Loss 21.632883\n",
      "    Params:  tensor([ 2.7906, -2.7160])\n",
      "    Grad  :  tensor([-0.4385,  2.4825])\n",
      "Epoch 109,Loss 21.569389\n",
      "Epoch 109, Loss 21.569389\n",
      "    Params:  tensor([ 2.7949, -2.7408])\n",
      "    Grad  :  tensor([-0.4378,  2.4783])\n",
      "Epoch 110,Loss 21.506102\n",
      "Epoch 110, Loss 21.506102\n",
      "    Params:  tensor([ 2.7993, -2.7655])\n",
      "    Grad  :  tensor([-0.4370,  2.4741])\n",
      "Epoch 111,Loss 21.443037\n",
      "Epoch 111, Loss 21.443037\n",
      "    Params:  tensor([ 2.8037, -2.7902])\n",
      "    Grad  :  tensor([-0.4363,  2.4699])\n",
      "Epoch 112,Loss 21.380186\n",
      "Epoch 112, Loss 21.380186\n",
      "    Params:  tensor([ 2.8080, -2.8149])\n",
      "    Grad  :  tensor([-0.4356,  2.4657])\n",
      "Epoch 113,Loss 21.317549\n",
      "Epoch 113, Loss 21.317549\n",
      "    Params:  tensor([ 2.8124, -2.8395])\n",
      "    Grad  :  tensor([-0.4348,  2.4615])\n",
      "Epoch 114,Loss 21.255117\n",
      "Epoch 114, Loss 21.255117\n",
      "    Params:  tensor([ 2.8167, -2.8641])\n",
      "    Grad  :  tensor([-0.4341,  2.4573])\n",
      "Epoch 115,Loss 21.192907\n",
      "Epoch 115, Loss 21.192907\n",
      "    Params:  tensor([ 2.8211, -2.8886])\n",
      "    Grad  :  tensor([-0.4334,  2.4531])\n",
      "Epoch 116,Loss 21.130898\n",
      "Epoch 116, Loss 21.130898\n",
      "    Params:  tensor([ 2.8254, -2.9131])\n",
      "    Grad  :  tensor([-0.4326,  2.4490])\n",
      "Epoch 117,Loss 21.069105\n",
      "Epoch 117, Loss 21.069105\n",
      "    Params:  tensor([ 2.8297, -2.9375])\n",
      "    Grad  :  tensor([-0.4319,  2.4448])\n",
      "Epoch 118,Loss 21.007526\n",
      "Epoch 118, Loss 21.007526\n",
      "    Params:  tensor([ 2.8340, -2.9619])\n",
      "    Grad  :  tensor([-0.4311,  2.4407])\n",
      "Epoch 119,Loss 20.946152\n",
      "Epoch 119, Loss 20.946152\n",
      "    Params:  tensor([ 2.8383, -2.9863])\n",
      "    Grad  :  tensor([-0.4304,  2.4365])\n",
      "Epoch 120,Loss 20.884983\n",
      "Epoch 120, Loss 20.884983\n",
      "    Params:  tensor([ 2.8426, -3.0106])\n",
      "    Grad  :  tensor([-0.4297,  2.4324])\n",
      "Epoch 121,Loss 20.824026\n",
      "Epoch 121, Loss 20.824026\n",
      "    Params:  tensor([ 2.8469, -3.0349])\n",
      "    Grad  :  tensor([-0.4290,  2.4282])\n",
      "Epoch 122,Loss 20.763273\n",
      "Epoch 122, Loss 20.763273\n",
      "    Params:  tensor([ 2.8512, -3.0592])\n",
      "    Grad  :  tensor([-0.4282,  2.4241])\n",
      "Epoch 123,Loss 20.702726\n",
      "Epoch 123, Loss 20.702726\n",
      "    Params:  tensor([ 2.8555, -3.0834])\n",
      "    Grad  :  tensor([-0.4275,  2.4200])\n",
      "Epoch 124,Loss 20.642384\n",
      "Epoch 124, Loss 20.642384\n",
      "    Params:  tensor([ 2.8597, -3.1075])\n",
      "    Grad  :  tensor([-0.4268,  2.4159])\n",
      "Epoch 125,Loss 20.582249\n",
      "Epoch 125, Loss 20.582249\n",
      "    Params:  tensor([ 2.8640, -3.1316])\n",
      "    Grad  :  tensor([-0.4261,  2.4118])\n",
      "Epoch 126,Loss 20.522322\n",
      "Epoch 126, Loss 20.522322\n",
      "    Params:  tensor([ 2.8682, -3.1557])\n",
      "    Grad  :  tensor([-0.4253,  2.4077])\n",
      "Epoch 127,Loss 20.462593\n",
      "Epoch 127, Loss 20.462593\n",
      "    Params:  tensor([ 2.8725, -3.1797])\n",
      "    Grad  :  tensor([-0.4246,  2.4036])\n",
      "Epoch 128,Loss 20.403069\n",
      "Epoch 128, Loss 20.403069\n",
      "    Params:  tensor([ 2.8767, -3.2037])\n",
      "    Grad  :  tensor([-0.4239,  2.3995])\n",
      "Epoch 129,Loss 20.343742\n",
      "Epoch 129, Loss 20.343742\n",
      "    Params:  tensor([ 2.8810, -3.2277])\n",
      "    Grad  :  tensor([-0.4232,  2.3954])\n",
      "Epoch 130,Loss 20.284624\n",
      "Epoch 130, Loss 20.284624\n",
      "    Params:  tensor([ 2.8852, -3.2516])\n",
      "    Grad  :  tensor([-0.4224,  2.3914])\n",
      "Epoch 131,Loss 20.225702\n",
      "Epoch 131, Loss 20.225702\n",
      "    Params:  tensor([ 2.8894, -3.2755])\n",
      "    Grad  :  tensor([-0.4217,  2.3873])\n",
      "Epoch 132,Loss 20.166981\n",
      "Epoch 132, Loss 20.166981\n",
      "    Params:  tensor([ 2.8936, -3.2993])\n",
      "    Grad  :  tensor([-0.4210,  2.3832])\n",
      "Epoch 133,Loss 20.108461\n",
      "Epoch 133, Loss 20.108461\n",
      "    Params:  tensor([ 2.8978, -3.3231])\n",
      "    Grad  :  tensor([-0.4203,  2.3792])\n",
      "Epoch 134,Loss 20.050137\n",
      "Epoch 134, Loss 20.050137\n",
      "    Params:  tensor([ 2.9020, -3.3469])\n",
      "    Grad  :  tensor([-0.4196,  2.3752])\n",
      "Epoch 135,Loss 19.992016\n",
      "Epoch 135, Loss 19.992016\n",
      "    Params:  tensor([ 2.9062, -3.3706])\n",
      "    Grad  :  tensor([-0.4189,  2.3711])\n",
      "Epoch 136,Loss 19.934086\n",
      "Epoch 136, Loss 19.934086\n",
      "    Params:  tensor([ 2.9104, -3.3942])\n",
      "    Grad  :  tensor([-0.4182,  2.3671])\n",
      "Epoch 137,Loss 19.876352\n",
      "Epoch 137, Loss 19.876352\n",
      "    Params:  tensor([ 2.9146, -3.4179])\n",
      "    Grad  :  tensor([-0.4174,  2.3631])\n",
      "Epoch 138,Loss 19.818823\n",
      "Epoch 138, Loss 19.818823\n",
      "    Params:  tensor([ 2.9187, -3.4415])\n",
      "    Grad  :  tensor([-0.4167,  2.3591])\n",
      "Epoch 139,Loss 19.761480\n",
      "Epoch 139, Loss 19.761480\n",
      "    Params:  tensor([ 2.9229, -3.4650])\n",
      "    Grad  :  tensor([-0.4160,  2.3550])\n",
      "Epoch 140,Loss 19.704336\n",
      "Epoch 140, Loss 19.704336\n",
      "    Params:  tensor([ 2.9270, -3.4885])\n",
      "    Grad  :  tensor([-0.4153,  2.3510])\n",
      "Epoch 141,Loss 19.647385\n",
      "Epoch 141, Loss 19.647385\n",
      "    Params:  tensor([ 2.9312, -3.5120])\n",
      "    Grad  :  tensor([-0.4146,  2.3471])\n",
      "Epoch 142,Loss 19.590626\n",
      "Epoch 142, Loss 19.590626\n",
      "    Params:  tensor([ 2.9353, -3.5354])\n",
      "    Grad  :  tensor([-0.4139,  2.3431])\n",
      "Epoch 143,Loss 19.534061\n",
      "Epoch 143, Loss 19.534061\n",
      "    Params:  tensor([ 2.9395, -3.5588])\n",
      "    Grad  :  tensor([-0.4132,  2.3391])\n",
      "Epoch 144,Loss 19.477690\n",
      "Epoch 144, Loss 19.477690\n",
      "    Params:  tensor([ 2.9436, -3.5822])\n",
      "    Grad  :  tensor([-0.4125,  2.3351])\n",
      "Epoch 145,Loss 19.421507\n",
      "Epoch 145, Loss 19.421507\n",
      "    Params:  tensor([ 2.9477, -3.6055])\n",
      "    Grad  :  tensor([-0.4118,  2.3311])\n",
      "Epoch 146,Loss 19.365515\n",
      "Epoch 146, Loss 19.365515\n",
      "    Params:  tensor([ 2.9518, -3.6287])\n",
      "    Grad  :  tensor([-0.4111,  2.3272])\n",
      "Epoch 147,Loss 19.309715\n",
      "Epoch 147, Loss 19.309715\n",
      "    Params:  tensor([ 2.9559, -3.6520])\n",
      "    Grad  :  tensor([-0.4104,  2.3232])\n",
      "Epoch 148,Loss 19.254107\n",
      "Epoch 148, Loss 19.254107\n",
      "    Params:  tensor([ 2.9600, -3.6752])\n",
      "    Grad  :  tensor([-0.4097,  2.3193])\n",
      "Epoch 149,Loss 19.198685\n",
      "Epoch 149, Loss 19.198685\n",
      "    Params:  tensor([ 2.9641, -3.6983])\n",
      "    Grad  :  tensor([-0.4090,  2.3153])\n",
      "Epoch 150,Loss 19.143446\n",
      "Epoch 150, Loss 19.143446\n",
      "    Params:  tensor([ 2.9682, -3.7214])\n",
      "    Grad  :  tensor([-0.4083,  2.3114])\n",
      "Epoch 151,Loss 19.088402\n",
      "Epoch 151, Loss 19.088402\n",
      "    Params:  tensor([ 2.9723, -3.7445])\n",
      "    Grad  :  tensor([-0.4076,  2.3075])\n",
      "Epoch 152,Loss 19.033543\n",
      "Epoch 152, Loss 19.033543\n",
      "    Params:  tensor([ 2.9763, -3.7675])\n",
      "    Grad  :  tensor([-0.4069,  2.3036])\n",
      "Epoch 153,Loss 18.978868\n",
      "Epoch 153, Loss 18.978868\n",
      "    Params:  tensor([ 2.9804, -3.7905])\n",
      "    Grad  :  tensor([-0.4062,  2.2997])\n",
      "Epoch 154,Loss 18.924377\n",
      "Epoch 154, Loss 18.924377\n",
      "    Params:  tensor([ 2.9844, -3.8135])\n",
      "    Grad  :  tensor([-0.4056,  2.2957])\n",
      "Epoch 155,Loss 18.870081\n",
      "Epoch 155, Loss 18.870081\n",
      "    Params:  tensor([ 2.9885, -3.8364])\n",
      "    Grad  :  tensor([-0.4049,  2.2918])\n",
      "Epoch 156,Loss 18.815960\n",
      "Epoch 156, Loss 18.815960\n",
      "    Params:  tensor([ 2.9925, -3.8593])\n",
      "    Grad  :  tensor([-0.4042,  2.2880])\n",
      "Epoch 157,Loss 18.762022\n",
      "Epoch 157, Loss 18.762022\n",
      "    Params:  tensor([ 2.9966, -3.8821])\n",
      "    Grad  :  tensor([-0.4035,  2.2841])\n",
      "Epoch 158,Loss 18.708271\n",
      "Epoch 158, Loss 18.708271\n",
      "    Params:  tensor([ 3.0006, -3.9049])\n",
      "    Grad  :  tensor([-0.4028,  2.2802])\n",
      "Epoch 159,Loss 18.654699\n",
      "Epoch 159, Loss 18.654699\n",
      "    Params:  tensor([ 3.0046, -3.9277])\n",
      "    Grad  :  tensor([-0.4021,  2.2763])\n",
      "Epoch 160,Loss 18.601313\n",
      "Epoch 160, Loss 18.601313\n",
      "    Params:  tensor([ 3.0086, -3.9504])\n",
      "    Grad  :  tensor([-0.4014,  2.2724])\n",
      "Epoch 161,Loss 18.548109\n",
      "Epoch 161, Loss 18.548109\n",
      "    Params:  tensor([ 3.0126, -3.9731])\n",
      "    Grad  :  tensor([-0.4007,  2.2686])\n",
      "Epoch 162,Loss 18.495085\n",
      "Epoch 162, Loss 18.495085\n",
      "    Params:  tensor([ 3.0166, -3.9958])\n",
      "    Grad  :  tensor([-0.4001,  2.2647])\n",
      "Epoch 163,Loss 18.442236\n",
      "Epoch 163, Loss 18.442236\n",
      "    Params:  tensor([ 3.0206, -4.0184])\n",
      "    Grad  :  tensor([-0.3994,  2.2609])\n",
      "Epoch 164,Loss 18.389570\n",
      "Epoch 164, Loss 18.389570\n",
      "    Params:  tensor([ 3.0246, -4.0409])\n",
      "    Grad  :  tensor([-0.3987,  2.2570])\n",
      "Epoch 165,Loss 18.337080\n",
      "Epoch 165, Loss 18.337080\n",
      "    Params:  tensor([ 3.0286, -4.0635])\n",
      "    Grad  :  tensor([-0.3980,  2.2532])\n",
      "Epoch 166,Loss 18.284777\n",
      "Epoch 166, Loss 18.284777\n",
      "    Params:  tensor([ 3.0326, -4.0860])\n",
      "    Grad  :  tensor([-0.3974,  2.2494])\n",
      "Epoch 167,Loss 18.232641\n",
      "Epoch 167, Loss 18.232641\n",
      "    Params:  tensor([ 3.0365, -4.1084])\n",
      "    Grad  :  tensor([-0.3967,  2.2456])\n",
      "Epoch 168,Loss 18.180685\n",
      "Epoch 168, Loss 18.180685\n",
      "    Params:  tensor([ 3.0405, -4.1308])\n",
      "    Grad  :  tensor([-0.3960,  2.2417])\n",
      "Epoch 169,Loss 18.128906\n",
      "Epoch 169, Loss 18.128906\n",
      "    Params:  tensor([ 3.0445, -4.1532])\n",
      "    Grad  :  tensor([-0.3953,  2.2379])\n",
      "Epoch 170,Loss 18.077301\n",
      "Epoch 170, Loss 18.077301\n",
      "    Params:  tensor([ 3.0484, -4.1756])\n",
      "    Grad  :  tensor([-0.3947,  2.2341])\n",
      "Epoch 171,Loss 18.025877\n",
      "Epoch 171, Loss 18.025877\n",
      "    Params:  tensor([ 3.0523, -4.1979])\n",
      "    Grad  :  tensor([-0.3940,  2.2303])\n",
      "Epoch 172,Loss 17.974623\n",
      "Epoch 172, Loss 17.974623\n",
      "    Params:  tensor([ 3.0563, -4.2201])\n",
      "    Grad  :  tensor([-0.3933,  2.2266])\n",
      "Epoch 173,Loss 17.923546\n",
      "Epoch 173, Loss 17.923546\n",
      "    Params:  tensor([ 3.0602, -4.2424])\n",
      "    Grad  :  tensor([-0.3927,  2.2228])\n",
      "Epoch 174,Loss 17.872643\n",
      "Epoch 174, Loss 17.872643\n",
      "    Params:  tensor([ 3.0641, -4.2646])\n",
      "    Grad  :  tensor([-0.3920,  2.2190])\n",
      "Epoch 175,Loss 17.821909\n",
      "Epoch 175, Loss 17.821909\n",
      "    Params:  tensor([ 3.0680, -4.2867])\n",
      "    Grad  :  tensor([-0.3913,  2.2152])\n",
      "Epoch 176,Loss 17.771345\n",
      "Epoch 176, Loss 17.771345\n",
      "    Params:  tensor([ 3.0719, -4.3088])\n",
      "    Grad  :  tensor([-0.3907,  2.2115])\n",
      "Epoch 177,Loss 17.720955\n",
      "Epoch 177, Loss 17.720955\n",
      "    Params:  tensor([ 3.0758, -4.3309])\n",
      "    Grad  :  tensor([-0.3900,  2.2077])\n",
      "Epoch 178,Loss 17.670738\n",
      "Epoch 178, Loss 17.670738\n",
      "    Params:  tensor([ 3.0797, -4.3529])\n",
      "    Grad  :  tensor([-0.3893,  2.2040])\n",
      "Epoch 179,Loss 17.620689\n",
      "Epoch 179, Loss 17.620689\n",
      "    Params:  tensor([ 3.0836, -4.3749])\n",
      "    Grad  :  tensor([-0.3887,  2.2002])\n",
      "Epoch 180,Loss 17.570814\n",
      "Epoch 180, Loss 17.570814\n",
      "    Params:  tensor([ 3.0875, -4.3969])\n",
      "    Grad  :  tensor([-0.3880,  2.1965])\n",
      "Epoch 181,Loss 17.521103\n",
      "Epoch 181, Loss 17.521103\n",
      "    Params:  tensor([ 3.0914, -4.4188])\n",
      "    Grad  :  tensor([-0.3873,  2.1927])\n",
      "Epoch 182,Loss 17.471565\n",
      "Epoch 182, Loss 17.471565\n",
      "    Params:  tensor([ 3.0952, -4.4407])\n",
      "    Grad  :  tensor([-0.3867,  2.1890])\n",
      "Epoch 183,Loss 17.422192\n",
      "Epoch 183, Loss 17.422192\n",
      "    Params:  tensor([ 3.0991, -4.4626])\n",
      "    Grad  :  tensor([-0.3860,  2.1853])\n",
      "Epoch 184,Loss 17.372993\n",
      "Epoch 184, Loss 17.372993\n",
      "    Params:  tensor([ 3.1030, -4.4844])\n",
      "    Grad  :  tensor([-0.3854,  2.1816])\n",
      "Epoch 185,Loss 17.323954\n",
      "Epoch 185, Loss 17.323954\n",
      "    Params:  tensor([ 3.1068, -4.5062])\n",
      "    Grad  :  tensor([-0.3847,  2.1779])\n",
      "Epoch 186,Loss 17.275084\n",
      "Epoch 186, Loss 17.275084\n",
      "    Params:  tensor([ 3.1106, -4.5279])\n",
      "    Grad  :  tensor([-0.3841,  2.1742])\n",
      "Epoch 187,Loss 17.226379\n",
      "Epoch 187, Loss 17.226379\n",
      "    Params:  tensor([ 3.1145, -4.5496])\n",
      "    Grad  :  tensor([-0.3834,  2.1705])\n",
      "Epoch 188,Loss 17.177839\n",
      "Epoch 188, Loss 17.177839\n",
      "    Params:  tensor([ 3.1183, -4.5713])\n",
      "    Grad  :  tensor([-0.3828,  2.1668])\n",
      "Epoch 189,Loss 17.129463\n",
      "Epoch 189, Loss 17.129463\n",
      "    Params:  tensor([ 3.1221, -4.5929])\n",
      "    Grad  :  tensor([-0.3821,  2.1631])\n",
      "Epoch 190,Loss 17.081255\n",
      "Epoch 190, Loss 17.081255\n",
      "    Params:  tensor([ 3.1259, -4.6145])\n",
      "    Grad  :  tensor([-0.3815,  2.1594])\n",
      "Epoch 191,Loss 17.033209\n",
      "Epoch 191, Loss 17.033209\n",
      "    Params:  tensor([ 3.1298, -4.6361])\n",
      "    Grad  :  tensor([-0.3808,  2.1558])\n",
      "Epoch 192,Loss 16.985327\n",
      "Epoch 192, Loss 16.985327\n",
      "    Params:  tensor([ 3.1336, -4.6576])\n",
      "    Grad  :  tensor([-0.3802,  2.1521])\n",
      "Epoch 193,Loss 16.937605\n",
      "Epoch 193, Loss 16.937605\n",
      "    Params:  tensor([ 3.1374, -4.6791])\n",
      "    Grad  :  tensor([-0.3795,  2.1485])\n",
      "Epoch 194,Loss 16.890047\n",
      "Epoch 194, Loss 16.890047\n",
      "    Params:  tensor([ 3.1411, -4.7005])\n",
      "    Grad  :  tensor([-0.3789,  2.1448])\n",
      "Epoch 195,Loss 16.842649\n",
      "Epoch 195, Loss 16.842649\n",
      "    Params:  tensor([ 3.1449, -4.7219])\n",
      "    Grad  :  tensor([-0.3783,  2.1412])\n",
      "Epoch 196,Loss 16.795414\n",
      "Epoch 196, Loss 16.795414\n",
      "    Params:  tensor([ 3.1487, -4.7433])\n",
      "    Grad  :  tensor([-0.3776,  2.1375])\n",
      "Epoch 197,Loss 16.748339\n",
      "Epoch 197, Loss 16.748339\n",
      "    Params:  tensor([ 3.1525, -4.7646])\n",
      "    Grad  :  tensor([-0.3770,  2.1339])\n",
      "Epoch 198,Loss 16.701420\n",
      "Epoch 198, Loss 16.701420\n",
      "    Params:  tensor([ 3.1562, -4.7859])\n",
      "    Grad  :  tensor([-0.3763,  2.1303])\n",
      "Epoch 199,Loss 16.654665\n",
      "Epoch 199, Loss 16.654665\n",
      "    Params:  tensor([ 3.1600, -4.8072])\n",
      "    Grad  :  tensor([-0.3757,  2.1267])\n",
      "Epoch 200,Loss 16.608068\n",
      "Epoch 200, Loss 16.608068\n",
      "    Params:  tensor([ 3.1637, -4.8284])\n",
      "    Grad  :  tensor([-0.3751,  2.1230])\n",
      "Epoch 201,Loss 16.561625\n",
      "Epoch 201, Loss 16.561625\n",
      "    Params:  tensor([ 3.1675, -4.8496])\n",
      "    Grad  :  tensor([-0.3744,  2.1194])\n",
      "Epoch 202,Loss 16.515343\n",
      "Epoch 202, Loss 16.515343\n",
      "    Params:  tensor([ 3.1712, -4.8708])\n",
      "    Grad  :  tensor([-0.3738,  2.1158])\n",
      "Epoch 203,Loss 16.469215\n",
      "Epoch 203, Loss 16.469215\n",
      "    Params:  tensor([ 3.1750, -4.8919])\n",
      "    Grad  :  tensor([-0.3731,  2.1122])\n",
      "Epoch 204,Loss 16.423250\n",
      "Epoch 204, Loss 16.423250\n",
      "    Params:  tensor([ 3.1787, -4.9130])\n",
      "    Grad  :  tensor([-0.3725,  2.1086])\n",
      "Epoch 205,Loss 16.377438\n",
      "Epoch 205, Loss 16.377438\n",
      "    Params:  tensor([ 3.1824, -4.9341])\n",
      "    Grad  :  tensor([-0.3719,  2.1051])\n",
      "Epoch 206,Loss 16.331781\n",
      "Epoch 206, Loss 16.331781\n",
      "    Params:  tensor([ 3.1861, -4.9551])\n",
      "    Grad  :  tensor([-0.3712,  2.1015])\n",
      "Epoch 207,Loss 16.286280\n",
      "Epoch 207, Loss 16.286280\n",
      "    Params:  tensor([ 3.1898, -4.9760])\n",
      "    Grad  :  tensor([-0.3706,  2.0979])\n",
      "Epoch 208,Loss 16.240932\n",
      "Epoch 208, Loss 16.240932\n",
      "    Params:  tensor([ 3.1935, -4.9970])\n",
      "    Grad  :  tensor([-0.3700,  2.0944])\n",
      "Epoch 209,Loss 16.195736\n",
      "Epoch 209, Loss 16.195736\n",
      "    Params:  tensor([ 3.1972, -5.0179])\n",
      "    Grad  :  tensor([-0.3693,  2.0908])\n",
      "Epoch 210,Loss 16.150698\n",
      "Epoch 210, Loss 16.150698\n",
      "    Params:  tensor([ 3.2009, -5.0388])\n",
      "    Grad  :  tensor([-0.3687,  2.0872])\n",
      "Epoch 211,Loss 16.105808\n",
      "Epoch 211, Loss 16.105808\n",
      "    Params:  tensor([ 3.2046, -5.0596])\n",
      "    Grad  :  tensor([-0.3681,  2.0837])\n",
      "Epoch 212,Loss 16.061073\n",
      "Epoch 212, Loss 16.061073\n",
      "    Params:  tensor([ 3.2082, -5.0804])\n",
      "    Grad  :  tensor([-0.3675,  2.0802])\n",
      "Epoch 213,Loss 16.016491\n",
      "Epoch 213, Loss 16.016491\n",
      "    Params:  tensor([ 3.2119, -5.1012])\n",
      "    Grad  :  tensor([-0.3668,  2.0766])\n",
      "Epoch 214,Loss 15.972060\n",
      "Epoch 214, Loss 15.972060\n",
      "    Params:  tensor([ 3.2156, -5.1219])\n",
      "    Grad  :  tensor([-0.3662,  2.0731])\n",
      "Epoch 215,Loss 15.927777\n",
      "Epoch 215, Loss 15.927777\n",
      "    Params:  tensor([ 3.2192, -5.1426])\n",
      "    Grad  :  tensor([-0.3656,  2.0696])\n",
      "Epoch 216,Loss 15.883649\n",
      "Epoch 216, Loss 15.883649\n",
      "    Params:  tensor([ 3.2229, -5.1633])\n",
      "    Grad  :  tensor([-0.3650,  2.0661])\n",
      "Epoch 217,Loss 15.839667\n",
      "Epoch 217, Loss 15.839667\n",
      "    Params:  tensor([ 3.2265, -5.1839])\n",
      "    Grad  :  tensor([-0.3644,  2.0626])\n",
      "Epoch 218,Loss 15.795835\n",
      "Epoch 218, Loss 15.795835\n",
      "    Params:  tensor([ 3.2302, -5.2045])\n",
      "    Grad  :  tensor([-0.3637,  2.0591])\n",
      "Epoch 219,Loss 15.752155\n",
      "Epoch 219, Loss 15.752155\n",
      "    Params:  tensor([ 3.2338, -5.2250])\n",
      "    Grad  :  tensor([-0.3631,  2.0556])\n",
      "Epoch 220,Loss 15.708619\n",
      "Epoch 220, Loss 15.708619\n",
      "    Params:  tensor([ 3.2374, -5.2456])\n",
      "    Grad  :  tensor([-0.3625,  2.0521])\n",
      "Epoch 221,Loss 15.665232\n",
      "Epoch 221, Loss 15.665232\n",
      "    Params:  tensor([ 3.2410, -5.2660])\n",
      "    Grad  :  tensor([-0.3619,  2.0486])\n",
      "Epoch 222,Loss 15.621993\n",
      "Epoch 222, Loss 15.621993\n",
      "    Params:  tensor([ 3.2447, -5.2865])\n",
      "    Grad  :  tensor([-0.3613,  2.0451])\n",
      "Epoch 223,Loss 15.578900\n",
      "Epoch 223, Loss 15.578900\n",
      "    Params:  tensor([ 3.2483, -5.3069])\n",
      "    Grad  :  tensor([-0.3607,  2.0416])\n",
      "Epoch 224,Loss 15.535951\n",
      "Epoch 224, Loss 15.535951\n",
      "    Params:  tensor([ 3.2519, -5.3273])\n",
      "    Grad  :  tensor([-0.3601,  2.0382])\n",
      "Epoch 225,Loss 15.493153\n",
      "Epoch 225, Loss 15.493153\n",
      "    Params:  tensor([ 3.2555, -5.3476])\n",
      "    Grad  :  tensor([-0.3594,  2.0347])\n",
      "Epoch 226,Loss 15.450500\n",
      "Epoch 226, Loss 15.450500\n",
      "    Params:  tensor([ 3.2590, -5.3680])\n",
      "    Grad  :  tensor([-0.3588,  2.0312])\n",
      "Epoch 227,Loss 15.407983\n",
      "Epoch 227, Loss 15.407983\n",
      "    Params:  tensor([ 3.2626, -5.3882])\n",
      "    Grad  :  tensor([-0.3582,  2.0278])\n",
      "Epoch 228,Loss 15.365620\n",
      "Epoch 228, Loss 15.365620\n",
      "    Params:  tensor([ 3.2662, -5.4085])\n",
      "    Grad  :  tensor([-0.3576,  2.0243])\n",
      "Epoch 229,Loss 15.323398\n",
      "Epoch 229, Loss 15.323398\n",
      "    Params:  tensor([ 3.2698, -5.4287])\n",
      "    Grad  :  tensor([-0.3570,  2.0209])\n",
      "Epoch 230,Loss 15.281318\n",
      "Epoch 230, Loss 15.281318\n",
      "    Params:  tensor([ 3.2733, -5.4489])\n",
      "    Grad  :  tensor([-0.3564,  2.0175])\n",
      "Epoch 231,Loss 15.239383\n",
      "Epoch 231, Loss 15.239383\n",
      "    Params:  tensor([ 3.2769, -5.4690])\n",
      "    Grad  :  tensor([-0.3558,  2.0140])\n",
      "Epoch 232,Loss 15.197587\n",
      "Epoch 232, Loss 15.197587\n",
      "    Params:  tensor([ 3.2804, -5.4891])\n",
      "    Grad  :  tensor([-0.3552,  2.0106])\n",
      "Epoch 233,Loss 15.155939\n",
      "Epoch 233, Loss 15.155939\n",
      "    Params:  tensor([ 3.2840, -5.5092])\n",
      "    Grad  :  tensor([-0.3546,  2.0072])\n",
      "Epoch 234,Loss 15.114426\n",
      "Epoch 234, Loss 15.114426\n",
      "    Params:  tensor([ 3.2875, -5.5292])\n",
      "    Grad  :  tensor([-0.3540,  2.0038])\n",
      "Epoch 235,Loss 15.073058\n",
      "Epoch 235, Loss 15.073058\n",
      "    Params:  tensor([ 3.2911, -5.5492])\n",
      "    Grad  :  tensor([-0.3534,  2.0004])\n",
      "Epoch 236,Loss 15.031829\n",
      "Epoch 236, Loss 15.031829\n",
      "    Params:  tensor([ 3.2946, -5.5692])\n",
      "    Grad  :  tensor([-0.3528,  1.9970])\n",
      "Epoch 237,Loss 14.990739\n",
      "Epoch 237, Loss 14.990739\n",
      "    Params:  tensor([ 3.2981, -5.5891])\n",
      "    Grad  :  tensor([-0.3522,  1.9936])\n",
      "Epoch 238,Loss 14.949786\n",
      "Epoch 238, Loss 14.949786\n",
      "    Params:  tensor([ 3.3016, -5.6090])\n",
      "    Grad  :  tensor([-0.3516,  1.9902])\n",
      "Epoch 239,Loss 14.908976\n",
      "Epoch 239, Loss 14.908976\n",
      "    Params:  tensor([ 3.3051, -5.6289])\n",
      "    Grad  :  tensor([-0.3510,  1.9868])\n",
      "Epoch 240,Loss 14.868305\n",
      "Epoch 240, Loss 14.868305\n",
      "    Params:  tensor([ 3.3086, -5.6487])\n",
      "    Grad  :  tensor([-0.3504,  1.9835])\n",
      "Epoch 241,Loss 14.827770\n",
      "Epoch 241, Loss 14.827770\n",
      "    Params:  tensor([ 3.3121, -5.6685])\n",
      "    Grad  :  tensor([-0.3498,  1.9801])\n",
      "Epoch 242,Loss 14.787373\n",
      "Epoch 242, Loss 14.787373\n",
      "    Params:  tensor([ 3.3156, -5.6883])\n",
      "    Grad  :  tensor([-0.3492,  1.9767])\n",
      "Epoch 243,Loss 14.747115\n",
      "Epoch 243, Loss 14.747115\n",
      "    Params:  tensor([ 3.3191, -5.7080])\n",
      "    Grad  :  tensor([-0.3486,  1.9734])\n",
      "Epoch 244,Loss 14.706991\n",
      "Epoch 244, Loss 14.706991\n",
      "    Params:  tensor([ 3.3226, -5.7277])\n",
      "    Grad  :  tensor([-0.3480,  1.9700])\n",
      "Epoch 245,Loss 14.667005\n",
      "Epoch 245, Loss 14.667005\n",
      "    Params:  tensor([ 3.3261, -5.7474])\n",
      "    Grad  :  tensor([-0.3474,  1.9667])\n",
      "Epoch 246,Loss 14.627151\n",
      "Epoch 246, Loss 14.627151\n",
      "    Params:  tensor([ 3.3295, -5.7670])\n",
      "    Grad  :  tensor([-0.3468,  1.9633])\n",
      "Epoch 247,Loss 14.587439\n",
      "Epoch 247, Loss 14.587439\n",
      "    Params:  tensor([ 3.3330, -5.7866])\n",
      "    Grad  :  tensor([-0.3462,  1.9600])\n",
      "Epoch 248,Loss 14.547854\n",
      "Epoch 248, Loss 14.547854\n",
      "    Params:  tensor([ 3.3365, -5.8062])\n",
      "    Grad  :  tensor([-0.3457,  1.9567])\n",
      "Epoch 249,Loss 14.508411\n",
      "Epoch 249, Loss 14.508411\n",
      "    Params:  tensor([ 3.3399, -5.8257])\n",
      "    Grad  :  tensor([-0.3451,  1.9533])\n",
      "Epoch 250,Loss 14.469102\n",
      "Epoch 250, Loss 14.469102\n",
      "    Params:  tensor([ 3.3434, -5.8452])\n",
      "    Grad  :  tensor([-0.3445,  1.9500])\n",
      "Epoch 251,Loss 14.429920\n",
      "Epoch 251, Loss 14.429920\n",
      "    Params:  tensor([ 3.3468, -5.8647])\n",
      "    Grad  :  tensor([-0.3439,  1.9467])\n",
      "Epoch 252,Loss 14.390876\n",
      "Epoch 252, Loss 14.390876\n",
      "    Params:  tensor([ 3.3502, -5.8841])\n",
      "    Grad  :  tensor([-0.3433,  1.9434])\n",
      "Epoch 253,Loss 14.351962\n",
      "Epoch 253, Loss 14.351962\n",
      "    Params:  tensor([ 3.3537, -5.9035])\n",
      "    Grad  :  tensor([-0.3427,  1.9401])\n",
      "Epoch 254,Loss 14.313181\n",
      "Epoch 254, Loss 14.313181\n",
      "    Params:  tensor([ 3.3571, -5.9229])\n",
      "    Grad  :  tensor([-0.3421,  1.9368])\n",
      "Epoch 255,Loss 14.274528\n",
      "Epoch 255, Loss 14.274528\n",
      "    Params:  tensor([ 3.3605, -5.9422])\n",
      "    Grad  :  tensor([-0.3416,  1.9335])\n",
      "Epoch 256,Loss 14.236009\n",
      "Epoch 256, Loss 14.236009\n",
      "    Params:  tensor([ 3.3639, -5.9615])\n",
      "    Grad  :  tensor([-0.3410,  1.9302])\n",
      "Epoch 257,Loss 14.197623\n",
      "Epoch 257, Loss 14.197623\n",
      "    Params:  tensor([ 3.3673, -5.9808])\n",
      "    Grad  :  tensor([-0.3404,  1.9269])\n",
      "Epoch 258,Loss 14.159367\n",
      "Epoch 258, Loss 14.159367\n",
      "    Params:  tensor([ 3.3707, -6.0000])\n",
      "    Grad  :  tensor([-0.3398,  1.9237])\n",
      "Epoch 259,Loss 14.121238\n",
      "Epoch 259, Loss 14.121238\n",
      "    Params:  tensor([ 3.3741, -6.0192])\n",
      "    Grad  :  tensor([-0.3392,  1.9204])\n",
      "Epoch 260,Loss 14.083240\n",
      "Epoch 260, Loss 14.083240\n",
      "    Params:  tensor([ 3.3775, -6.0384])\n",
      "    Grad  :  tensor([-0.3387,  1.9171])\n",
      "Epoch 261,Loss 14.045368\n",
      "Epoch 261, Loss 14.045368\n",
      "    Params:  tensor([ 3.3809, -6.0576])\n",
      "    Grad  :  tensor([-0.3381,  1.9139])\n",
      "Epoch 262,Loss 14.007629\n",
      "Epoch 262, Loss 14.007629\n",
      "    Params:  tensor([ 3.3842, -6.0767])\n",
      "    Grad  :  tensor([-0.3375,  1.9106])\n",
      "Epoch 263,Loss 13.970016\n",
      "Epoch 263, Loss 13.970016\n",
      "    Params:  tensor([ 3.3876, -6.0957])\n",
      "    Grad  :  tensor([-0.3369,  1.9074])\n",
      "Epoch 264,Loss 13.932531\n",
      "Epoch 264, Loss 13.932531\n",
      "    Params:  tensor([ 3.3910, -6.1148])\n",
      "    Grad  :  tensor([-0.3364,  1.9041])\n",
      "Epoch 265,Loss 13.895175\n",
      "Epoch 265, Loss 13.895175\n",
      "    Params:  tensor([ 3.3943, -6.1338])\n",
      "    Grad  :  tensor([-0.3358,  1.9009])\n",
      "Epoch 266,Loss 13.857944\n",
      "Epoch 266, Loss 13.857944\n",
      "    Params:  tensor([ 3.3977, -6.1528])\n",
      "    Grad  :  tensor([-0.3352,  1.8977])\n",
      "Epoch 267,Loss 13.820841\n",
      "Epoch 267, Loss 13.820841\n",
      "    Params:  tensor([ 3.4010, -6.1717])\n",
      "    Grad  :  tensor([-0.3347,  1.8945])\n",
      "Epoch 268,Loss 13.783858\n",
      "Epoch 268, Loss 13.783858\n",
      "    Params:  tensor([ 3.4044, -6.1906])\n",
      "    Grad  :  tensor([-0.3341,  1.8912])\n",
      "Epoch 269,Loss 13.747009\n",
      "Epoch 269, Loss 13.747009\n",
      "    Params:  tensor([ 3.4077, -6.2095])\n",
      "    Grad  :  tensor([-0.3335,  1.8880])\n",
      "Epoch 270,Loss 13.710280\n",
      "Epoch 270, Loss 13.710280\n",
      "    Params:  tensor([ 3.4110, -6.2284])\n",
      "    Grad  :  tensor([-0.3330,  1.8848])\n",
      "Epoch 271,Loss 13.673678\n",
      "Epoch 271, Loss 13.673678\n",
      "    Params:  tensor([ 3.4144, -6.2472])\n",
      "    Grad  :  tensor([-0.3324,  1.8816])\n",
      "Epoch 272,Loss 13.637198\n",
      "Epoch 272, Loss 13.637198\n",
      "    Params:  tensor([ 3.4177, -6.2660])\n",
      "    Grad  :  tensor([-0.3318,  1.8784])\n",
      "Epoch 273,Loss 13.600844\n",
      "Epoch 273, Loss 13.600844\n",
      "    Params:  tensor([ 3.4210, -6.2847])\n",
      "    Grad  :  tensor([-0.3313,  1.8752])\n",
      "Epoch 274,Loss 13.564611\n",
      "Epoch 274, Loss 13.564611\n",
      "    Params:  tensor([ 3.4243, -6.3034])\n",
      "    Grad  :  tensor([-0.3307,  1.8720])\n",
      "Epoch 275,Loss 13.528503\n",
      "Epoch 275, Loss 13.528503\n",
      "    Params:  tensor([ 3.4276, -6.3221])\n",
      "    Grad  :  tensor([-0.3301,  1.8689])\n",
      "Epoch 276,Loss 13.492517\n",
      "Epoch 276, Loss 13.492517\n",
      "    Params:  tensor([ 3.4309, -6.3408])\n",
      "    Grad  :  tensor([-0.3296,  1.8657])\n",
      "Epoch 277,Loss 13.456653\n",
      "Epoch 277, Loss 13.456653\n",
      "    Params:  tensor([ 3.4342, -6.3594])\n",
      "    Grad  :  tensor([-0.3290,  1.8625])\n",
      "Epoch 278,Loss 13.420913\n",
      "Epoch 278, Loss 13.420913\n",
      "    Params:  tensor([ 3.4375, -6.3780])\n",
      "    Grad  :  tensor([-0.3285,  1.8594])\n",
      "Epoch 279,Loss 13.385290\n",
      "Epoch 279, Loss 13.385290\n",
      "    Params:  tensor([ 3.4407, -6.3965])\n",
      "    Grad  :  tensor([-0.3279,  1.8562])\n",
      "Epoch 280,Loss 13.349792\n",
      "Epoch 280, Loss 13.349792\n",
      "    Params:  tensor([ 3.4440, -6.4151])\n",
      "    Grad  :  tensor([-0.3273,  1.8530])\n",
      "Epoch 281,Loss 13.314414\n",
      "Epoch 281, Loss 13.314414\n",
      "    Params:  tensor([ 3.4473, -6.4336])\n",
      "    Grad  :  tensor([-0.3268,  1.8499])\n",
      "Epoch 282,Loss 13.279153\n",
      "Epoch 282, Loss 13.279153\n",
      "    Params:  tensor([ 3.4506, -6.4520])\n",
      "    Grad  :  tensor([-0.3262,  1.8468])\n",
      "Epoch 283,Loss 13.244012\n",
      "Epoch 283, Loss 13.244012\n",
      "    Params:  tensor([ 3.4538, -6.4705])\n",
      "    Grad  :  tensor([-0.3257,  1.8436])\n",
      "Epoch 284,Loss 13.208990\n",
      "Epoch 284, Loss 13.208990\n",
      "    Params:  tensor([ 3.4571, -6.4889])\n",
      "    Grad  :  tensor([-0.3251,  1.8405])\n",
      "Epoch 285,Loss 13.174091\n",
      "Epoch 285, Loss 13.174091\n",
      "    Params:  tensor([ 3.4603, -6.5073])\n",
      "    Grad  :  tensor([-0.3246,  1.8374])\n",
      "Epoch 286,Loss 13.139309\n",
      "Epoch 286, Loss 13.139309\n",
      "    Params:  tensor([ 3.4635, -6.5256])\n",
      "    Grad  :  tensor([-0.3240,  1.8342])\n",
      "Epoch 287,Loss 13.104645\n",
      "Epoch 287, Loss 13.104645\n",
      "    Params:  tensor([ 3.4668, -6.5439])\n",
      "    Grad  :  tensor([-0.3235,  1.8311])\n",
      "Epoch 288,Loss 13.070098\n",
      "Epoch 288, Loss 13.070098\n",
      "    Params:  tensor([ 3.4700, -6.5622])\n",
      "    Grad  :  tensor([-0.3229,  1.8280])\n",
      "Epoch 289,Loss 13.035666\n",
      "Epoch 289, Loss 13.035666\n",
      "    Params:  tensor([ 3.4732, -6.5804])\n",
      "    Grad  :  tensor([-0.3224,  1.8249])\n",
      "Epoch 290,Loss 13.001354\n",
      "Epoch 290, Loss 13.001354\n",
      "    Params:  tensor([ 3.4765, -6.5987])\n",
      "    Grad  :  tensor([-0.3218,  1.8218])\n",
      "Epoch 291,Loss 12.967156\n",
      "Epoch 291, Loss 12.967156\n",
      "    Params:  tensor([ 3.4797, -6.6168])\n",
      "    Grad  :  tensor([-0.3213,  1.8187])\n",
      "Epoch 292,Loss 12.933078\n",
      "Epoch 292, Loss 12.933078\n",
      "    Params:  tensor([ 3.4829, -6.6350])\n",
      "    Grad  :  tensor([-0.3207,  1.8156])\n",
      "Epoch 293,Loss 12.899112\n",
      "Epoch 293, Loss 12.899112\n",
      "    Params:  tensor([ 3.4861, -6.6531])\n",
      "    Grad  :  tensor([-0.3202,  1.8125])\n",
      "Epoch 294,Loss 12.865265\n",
      "Epoch 294, Loss 12.865265\n",
      "    Params:  tensor([ 3.4893, -6.6712])\n",
      "    Grad  :  tensor([-0.3197,  1.8095])\n",
      "Epoch 295,Loss 12.831527\n",
      "Epoch 295, Loss 12.831527\n",
      "    Params:  tensor([ 3.4925, -6.6893])\n",
      "    Grad  :  tensor([-0.3191,  1.8064])\n",
      "Epoch 296,Loss 12.797907\n",
      "Epoch 296, Loss 12.797907\n",
      "    Params:  tensor([ 3.4956, -6.7073])\n",
      "    Grad  :  tensor([-0.3186,  1.8033])\n",
      "Epoch 297,Loss 12.764400\n",
      "Epoch 297, Loss 12.764400\n",
      "    Params:  tensor([ 3.4988, -6.7253])\n",
      "    Grad  :  tensor([-0.3180,  1.8003])\n",
      "Epoch 298,Loss 12.731009\n",
      "Epoch 298, Loss 12.731009\n",
      "    Params:  tensor([ 3.5020, -6.7433])\n",
      "    Grad  :  tensor([-0.3175,  1.7972])\n",
      "Epoch 299,Loss 12.697727\n",
      "Epoch 299, Loss 12.697727\n",
      "    Params:  tensor([ 3.5052, -6.7612])\n",
      "    Grad  :  tensor([-0.3169,  1.7941])\n",
      "Epoch 300,Loss 12.664563\n",
      "Epoch 300, Loss 12.664563\n",
      "    Params:  tensor([ 3.5083, -6.7791])\n",
      "    Grad  :  tensor([-0.3164,  1.7911])\n",
      "Epoch 301,Loss 12.631515\n",
      "Epoch 301, Loss 12.631515\n",
      "    Params:  tensor([ 3.5115, -6.7970])\n",
      "    Grad  :  tensor([-0.3159,  1.7881])\n",
      "Epoch 302,Loss 12.598572\n",
      "Epoch 302, Loss 12.598572\n",
      "    Params:  tensor([ 3.5146, -6.8149])\n",
      "    Grad  :  tensor([-0.3153,  1.7850])\n",
      "Epoch 303,Loss 12.565742\n",
      "Epoch 303, Loss 12.565742\n",
      "    Params:  tensor([ 3.5178, -6.8327])\n",
      "    Grad  :  tensor([-0.3148,  1.7820])\n",
      "Epoch 304,Loss 12.533026\n",
      "Epoch 304, Loss 12.533026\n",
      "    Params:  tensor([ 3.5209, -6.8505])\n",
      "    Grad  :  tensor([-0.3143,  1.7790])\n",
      "Epoch 305,Loss 12.500416\n",
      "Epoch 305, Loss 12.500416\n",
      "    Params:  tensor([ 3.5241, -6.8682])\n",
      "    Grad  :  tensor([-0.3137,  1.7759])\n",
      "Epoch 306,Loss 12.467920\n",
      "Epoch 306, Loss 12.467920\n",
      "    Params:  tensor([ 3.5272, -6.8860])\n",
      "    Grad  :  tensor([-0.3132,  1.7729])\n",
      "Epoch 307,Loss 12.435534\n",
      "Epoch 307, Loss 12.435534\n",
      "    Params:  tensor([ 3.5303, -6.9037])\n",
      "    Grad  :  tensor([-0.3127,  1.7699])\n",
      "Epoch 308,Loss 12.403258\n",
      "Epoch 308, Loss 12.403258\n",
      "    Params:  tensor([ 3.5335, -6.9213])\n",
      "    Grad  :  tensor([-0.3121,  1.7669])\n",
      "Epoch 309,Loss 12.371094\n",
      "Epoch 309, Loss 12.371094\n",
      "    Params:  tensor([ 3.5366, -6.9390])\n",
      "    Grad  :  tensor([-0.3116,  1.7639])\n",
      "Epoch 310,Loss 12.339035\n",
      "Epoch 310, Loss 12.339035\n",
      "    Params:  tensor([ 3.5397, -6.9566])\n",
      "    Grad  :  tensor([-0.3111,  1.7609])\n",
      "Epoch 311,Loss 12.307087\n",
      "Epoch 311, Loss 12.307087\n",
      "    Params:  tensor([ 3.5428, -6.9742])\n",
      "    Grad  :  tensor([-0.3105,  1.7579])\n",
      "Epoch 312,Loss 12.275248\n",
      "Epoch 312, Loss 12.275248\n",
      "    Params:  tensor([ 3.5459, -6.9917])\n",
      "    Grad  :  tensor([-0.3100,  1.7549])\n",
      "Epoch 313,Loss 12.243515\n",
      "Epoch 313, Loss 12.243515\n",
      "    Params:  tensor([ 3.5490, -7.0092])\n",
      "    Grad  :  tensor([-0.3095,  1.7519])\n",
      "Epoch 314,Loss 12.211892\n",
      "Epoch 314, Loss 12.211892\n",
      "    Params:  tensor([ 3.5521, -7.0267])\n",
      "    Grad  :  tensor([-0.3090,  1.7490])\n",
      "Epoch 315,Loss 12.180374\n",
      "Epoch 315, Loss 12.180374\n",
      "    Params:  tensor([ 3.5552, -7.0442])\n",
      "    Grad  :  tensor([-0.3084,  1.7460])\n",
      "Epoch 316,Loss 12.148965\n",
      "Epoch 316, Loss 12.148965\n",
      "    Params:  tensor([ 3.5582, -7.0616])\n",
      "    Grad  :  tensor([-0.3079,  1.7430])\n",
      "Epoch 317,Loss 12.117663\n",
      "Epoch 317, Loss 12.117663\n",
      "    Params:  tensor([ 3.5613, -7.0790])\n",
      "    Grad  :  tensor([-0.3074,  1.7401])\n",
      "Epoch 318,Loss 12.086465\n",
      "Epoch 318, Loss 12.086465\n",
      "    Params:  tensor([ 3.5644, -7.0964])\n",
      "    Grad  :  tensor([-0.3069,  1.7371])\n",
      "Epoch 319,Loss 12.055375\n",
      "Epoch 319, Loss 12.055375\n",
      "    Params:  tensor([ 3.5674, -7.1137])\n",
      "    Grad  :  tensor([-0.3063,  1.7342])\n",
      "Epoch 320,Loss 12.024390\n",
      "Epoch 320, Loss 12.024390\n",
      "    Params:  tensor([ 3.5705, -7.1310])\n",
      "    Grad  :  tensor([-0.3058,  1.7312])\n",
      "Epoch 321,Loss 11.993514\n",
      "Epoch 321, Loss 11.993514\n",
      "    Params:  tensor([ 3.5736, -7.1483])\n",
      "    Grad  :  tensor([-0.3053,  1.7283])\n",
      "Epoch 322,Loss 11.962735\n",
      "Epoch 322, Loss 11.962735\n",
      "    Params:  tensor([ 3.5766, -7.1656])\n",
      "    Grad  :  tensor([-0.3048,  1.7253])\n",
      "Epoch 323,Loss 11.932062\n",
      "Epoch 323, Loss 11.932062\n",
      "    Params:  tensor([ 3.5796, -7.1828])\n",
      "    Grad  :  tensor([-0.3043,  1.7224])\n",
      "Epoch 324,Loss 11.901496\n",
      "Epoch 324, Loss 11.901496\n",
      "    Params:  tensor([ 3.5827, -7.2000])\n",
      "    Grad  :  tensor([-0.3038,  1.7195])\n",
      "Epoch 325,Loss 11.871033\n",
      "Epoch 325, Loss 11.871033\n",
      "    Params:  tensor([ 3.5857, -7.2172])\n",
      "    Grad  :  tensor([-0.3032,  1.7166])\n",
      "Epoch 326,Loss 11.840673\n",
      "Epoch 326, Loss 11.840673\n",
      "    Params:  tensor([ 3.5887, -7.2343])\n",
      "    Grad  :  tensor([-0.3027,  1.7136])\n",
      "Epoch 327,Loss 11.810418\n",
      "Epoch 327, Loss 11.810418\n",
      "    Params:  tensor([ 3.5918, -7.2514])\n",
      "    Grad  :  tensor([-0.3022,  1.7107])\n",
      "Epoch 328,Loss 11.780264\n",
      "Epoch 328, Loss 11.780264\n",
      "    Params:  tensor([ 3.5948, -7.2685])\n",
      "    Grad  :  tensor([-0.3017,  1.7078])\n",
      "Epoch 329,Loss 11.750211\n",
      "Epoch 329, Loss 11.750211\n",
      "    Params:  tensor([ 3.5978, -7.2855])\n",
      "    Grad  :  tensor([-0.3012,  1.7049])\n",
      "Epoch 330,Loss 11.720262\n",
      "Epoch 330, Loss 11.720262\n",
      "    Params:  tensor([ 3.6008, -7.3026])\n",
      "    Grad  :  tensor([-0.3007,  1.7020])\n",
      "Epoch 331,Loss 11.690415\n",
      "Epoch 331, Loss 11.690415\n",
      "    Params:  tensor([ 3.6038, -7.3196])\n",
      "    Grad  :  tensor([-0.3002,  1.6991])\n",
      "Epoch 332,Loss 11.660668\n",
      "Epoch 332, Loss 11.660668\n",
      "    Params:  tensor([ 3.6068, -7.3365])\n",
      "    Grad  :  tensor([-0.2996,  1.6963])\n",
      "Epoch 333,Loss 11.631023\n",
      "Epoch 333, Loss 11.631023\n",
      "    Params:  tensor([ 3.6098, -7.3534])\n",
      "    Grad  :  tensor([-0.2991,  1.6934])\n",
      "Epoch 334,Loss 11.601478\n",
      "Epoch 334, Loss 11.601478\n",
      "    Params:  tensor([ 3.6128, -7.3704])\n",
      "    Grad  :  tensor([-0.2986,  1.6905])\n",
      "Epoch 335,Loss 11.572034\n",
      "Epoch 335, Loss 11.572034\n",
      "    Params:  tensor([ 3.6158, -7.3872])\n",
      "    Grad  :  tensor([-0.2981,  1.6876])\n",
      "Epoch 336,Loss 11.542689\n",
      "Epoch 336, Loss 11.542689\n",
      "    Params:  tensor([ 3.6187, -7.4041])\n",
      "    Grad  :  tensor([-0.2976,  1.6848])\n",
      "Epoch 337,Loss 11.513443\n",
      "Epoch 337, Loss 11.513443\n",
      "    Params:  tensor([ 3.6217, -7.4209])\n",
      "    Grad  :  tensor([-0.2971,  1.6819])\n",
      "Epoch 338,Loss 11.484297\n",
      "Epoch 338, Loss 11.484297\n",
      "    Params:  tensor([ 3.6247, -7.4377])\n",
      "    Grad  :  tensor([-0.2966,  1.6790])\n",
      "Epoch 339,Loss 11.455251\n",
      "Epoch 339, Loss 11.455251\n",
      "    Params:  tensor([ 3.6276, -7.4544])\n",
      "    Grad  :  tensor([-0.2961,  1.6762])\n",
      "Epoch 340,Loss 11.426302\n",
      "Epoch 340, Loss 11.426302\n",
      "    Params:  tensor([ 3.6306, -7.4712])\n",
      "    Grad  :  tensor([-0.2956,  1.6733])\n",
      "Epoch 341,Loss 11.397452\n",
      "Epoch 341, Loss 11.397452\n",
      "    Params:  tensor([ 3.6335, -7.4879])\n",
      "    Grad  :  tensor([-0.2951,  1.6705])\n",
      "Epoch 342,Loss 11.368700\n",
      "Epoch 342, Loss 11.368700\n",
      "    Params:  tensor([ 3.6365, -7.5046])\n",
      "    Grad  :  tensor([-0.2946,  1.6677])\n",
      "Epoch 343,Loss 11.340046\n",
      "Epoch 343, Loss 11.340046\n",
      "    Params:  tensor([ 3.6394, -7.5212])\n",
      "    Grad  :  tensor([-0.2941,  1.6648])\n",
      "Epoch 344,Loss 11.311490\n",
      "Epoch 344, Loss 11.311490\n",
      "    Params:  tensor([ 3.6424, -7.5378])\n",
      "    Grad  :  tensor([-0.2936,  1.6620])\n",
      "Epoch 345,Loss 11.283029\n",
      "Epoch 345, Loss 11.283029\n",
      "    Params:  tensor([ 3.6453, -7.5544])\n",
      "    Grad  :  tensor([-0.2931,  1.6592])\n",
      "Epoch 346,Loss 11.254665\n",
      "Epoch 346, Loss 11.254665\n",
      "    Params:  tensor([ 3.6482, -7.5710])\n",
      "    Grad  :  tensor([-0.2926,  1.6564])\n",
      "Epoch 347,Loss 11.226396\n",
      "Epoch 347, Loss 11.226396\n",
      "    Params:  tensor([ 3.6511, -7.5875])\n",
      "    Grad  :  tensor([-0.2921,  1.6535])\n",
      "Epoch 348,Loss 11.198226\n",
      "Epoch 348, Loss 11.198226\n",
      "    Params:  tensor([ 3.6541, -7.6040])\n",
      "    Grad  :  tensor([-0.2916,  1.6507])\n",
      "Epoch 349,Loss 11.170155\n",
      "Epoch 349, Loss 11.170155\n",
      "    Params:  tensor([ 3.6570, -7.6205])\n",
      "    Grad  :  tensor([-0.2911,  1.6479])\n",
      "Epoch 350,Loss 11.142174\n",
      "Epoch 350, Loss 11.142174\n",
      "    Params:  tensor([ 3.6599, -7.6370])\n",
      "    Grad  :  tensor([-0.2906,  1.6451])\n",
      "Epoch 351,Loss 11.114287\n",
      "Epoch 351, Loss 11.114287\n",
      "    Params:  tensor([ 3.6628, -7.6534])\n",
      "    Grad  :  tensor([-0.2901,  1.6423])\n",
      "Epoch 352,Loss 11.086495\n",
      "Epoch 352, Loss 11.086495\n",
      "    Params:  tensor([ 3.6657, -7.6698])\n",
      "    Grad  :  tensor([-0.2896,  1.6395])\n",
      "Epoch 353,Loss 11.058801\n",
      "Epoch 353, Loss 11.058801\n",
      "    Params:  tensor([ 3.6686, -7.6861])\n",
      "    Grad  :  tensor([-0.2891,  1.6368])\n",
      "Epoch 354,Loss 11.031198\n",
      "Epoch 354, Loss 11.031198\n",
      "    Params:  tensor([ 3.6714, -7.7025])\n",
      "    Grad  :  tensor([-0.2886,  1.6340])\n",
      "Epoch 355,Loss 11.003687\n",
      "Epoch 355, Loss 11.003687\n",
      "    Params:  tensor([ 3.6743, -7.7188])\n",
      "    Grad  :  tensor([-0.2882,  1.6312])\n",
      "Epoch 356,Loss 10.976272\n",
      "Epoch 356, Loss 10.976272\n",
      "    Params:  tensor([ 3.6772, -7.7351])\n",
      "    Grad  :  tensor([-0.2877,  1.6284])\n",
      "Epoch 357,Loss 10.948951\n",
      "Epoch 357, Loss 10.948951\n",
      "    Params:  tensor([ 3.6801, -7.7513])\n",
      "    Grad  :  tensor([-0.2872,  1.6257])\n",
      "Epoch 358,Loss 10.921721\n",
      "Epoch 358, Loss 10.921721\n",
      "    Params:  tensor([ 3.6829, -7.7676])\n",
      "    Grad  :  tensor([-0.2867,  1.6229])\n",
      "Epoch 359,Loss 10.894585\n",
      "Epoch 359, Loss 10.894585\n",
      "    Params:  tensor([ 3.6858, -7.7838])\n",
      "    Grad  :  tensor([-0.2862,  1.6201])\n",
      "Epoch 360,Loss 10.867539\n",
      "Epoch 360, Loss 10.867539\n",
      "    Params:  tensor([ 3.6887, -7.7999])\n",
      "    Grad  :  tensor([-0.2857,  1.6174])\n",
      "Epoch 361,Loss 10.840586\n",
      "Epoch 361, Loss 10.840586\n",
      "    Params:  tensor([ 3.6915, -7.8161])\n",
      "    Grad  :  tensor([-0.2852,  1.6146])\n",
      "Epoch 362,Loss 10.813725\n",
      "Epoch 362, Loss 10.813725\n",
      "    Params:  tensor([ 3.6944, -7.8322])\n",
      "    Grad  :  tensor([-0.2847,  1.6119])\n",
      "Epoch 363,Loss 10.786952\n",
      "Epoch 363, Loss 10.786952\n",
      "    Params:  tensor([ 3.6972, -7.8483])\n",
      "    Grad  :  tensor([-0.2843,  1.6092])\n",
      "Epoch 364,Loss 10.760273\n",
      "Epoch 364, Loss 10.760273\n",
      "    Params:  tensor([ 3.7000, -7.8644])\n",
      "    Grad  :  tensor([-0.2838,  1.6064])\n",
      "Epoch 365,Loss 10.733685\n",
      "Epoch 365, Loss 10.733685\n",
      "    Params:  tensor([ 3.7029, -7.8804])\n",
      "    Grad  :  tensor([-0.2833,  1.6037])\n",
      "Epoch 366,Loss 10.707185\n",
      "Epoch 366, Loss 10.707185\n",
      "    Params:  tensor([ 3.7057, -7.8964])\n",
      "    Grad  :  tensor([-0.2828,  1.6010])\n",
      "Epoch 367,Loss 10.680777\n",
      "Epoch 367, Loss 10.680777\n",
      "    Params:  tensor([ 3.7085, -7.9124])\n",
      "    Grad  :  tensor([-0.2823,  1.5983])\n",
      "Epoch 368,Loss 10.654456\n",
      "Epoch 368, Loss 10.654456\n",
      "    Params:  tensor([ 3.7113, -7.9283])\n",
      "    Grad  :  tensor([-0.2819,  1.5955])\n",
      "Epoch 369,Loss 10.628228\n",
      "Epoch 369, Loss 10.628228\n",
      "    Params:  tensor([ 3.7142, -7.9443])\n",
      "    Grad  :  tensor([-0.2814,  1.5928])\n",
      "Epoch 370,Loss 10.602089\n",
      "Epoch 370, Loss 10.602089\n",
      "    Params:  tensor([ 3.7170, -7.9602])\n",
      "    Grad  :  tensor([-0.2809,  1.5901])\n",
      "Epoch 371,Loss 10.576035\n",
      "Epoch 371, Loss 10.576035\n",
      "    Params:  tensor([ 3.7198, -7.9761])\n",
      "    Grad  :  tensor([-0.2804,  1.5874])\n",
      "Epoch 372,Loss 10.550074\n",
      "Epoch 372, Loss 10.550074\n",
      "    Params:  tensor([ 3.7226, -7.9919])\n",
      "    Grad  :  tensor([-0.2799,  1.5847])\n",
      "Epoch 373,Loss 10.524198\n",
      "Epoch 373, Loss 10.524198\n",
      "    Params:  tensor([ 3.7254, -8.0077])\n",
      "    Grad  :  tensor([-0.2795,  1.5820])\n",
      "Epoch 374,Loss 10.498412\n",
      "Epoch 374, Loss 10.498412\n",
      "    Params:  tensor([ 3.7282, -8.0235])\n",
      "    Grad  :  tensor([-0.2790,  1.5793])\n",
      "Epoch 375,Loss 10.472711\n",
      "Epoch 375, Loss 10.472711\n",
      "    Params:  tensor([ 3.7309, -8.0393])\n",
      "    Grad  :  tensor([-0.2785,  1.5767])\n",
      "Epoch 376,Loss 10.447094\n",
      "Epoch 376, Loss 10.447094\n",
      "    Params:  tensor([ 3.7337, -8.0550])\n",
      "    Grad  :  tensor([-0.2781,  1.5740])\n",
      "Epoch 377,Loss 10.421571\n",
      "Epoch 377, Loss 10.421571\n",
      "    Params:  tensor([ 3.7365, -8.0707])\n",
      "    Grad  :  tensor([-0.2776,  1.5713])\n",
      "Epoch 378,Loss 10.396134\n",
      "Epoch 378, Loss 10.396134\n",
      "    Params:  tensor([ 3.7393, -8.0864])\n",
      "    Grad  :  tensor([-0.2771,  1.5686])\n",
      "Epoch 379,Loss 10.370782\n",
      "Epoch 379, Loss 10.370782\n",
      "    Params:  tensor([ 3.7420, -8.1021])\n",
      "    Grad  :  tensor([-0.2766,  1.5660])\n",
      "Epoch 380,Loss 10.345513\n",
      "Epoch 380, Loss 10.345513\n",
      "    Params:  tensor([ 3.7448, -8.1177])\n",
      "    Grad  :  tensor([-0.2762,  1.5633])\n",
      "Epoch 381,Loss 10.320332\n",
      "Epoch 381, Loss 10.320332\n",
      "    Params:  tensor([ 3.7476, -8.1333])\n",
      "    Grad  :  tensor([-0.2757,  1.5607])\n",
      "Epoch 382,Loss 10.295237\n",
      "Epoch 382, Loss 10.295237\n",
      "    Params:  tensor([ 3.7503, -8.1489])\n",
      "    Grad  :  tensor([-0.2752,  1.5580])\n",
      "Epoch 383,Loss 10.270224\n",
      "Epoch 383, Loss 10.270224\n",
      "    Params:  tensor([ 3.7531, -8.1645])\n",
      "    Grad  :  tensor([-0.2748,  1.5554])\n",
      "Epoch 384,Loss 10.245301\n",
      "Epoch 384, Loss 10.245301\n",
      "    Params:  tensor([ 3.7558, -8.1800])\n",
      "    Grad  :  tensor([-0.2743,  1.5527])\n",
      "Epoch 385,Loss 10.220461\n",
      "Epoch 385, Loss 10.220461\n",
      "    Params:  tensor([ 3.7585, -8.1955])\n",
      "    Grad  :  tensor([-0.2738,  1.5501])\n",
      "Epoch 386,Loss 10.195705\n",
      "Epoch 386, Loss 10.195705\n",
      "    Params:  tensor([ 3.7613, -8.2110])\n",
      "    Grad  :  tensor([-0.2734,  1.5475])\n",
      "Epoch 387,Loss 10.171030\n",
      "Epoch 387, Loss 10.171030\n",
      "    Params:  tensor([ 3.7640, -8.2264])\n",
      "    Grad  :  tensor([-0.2729,  1.5448])\n",
      "Epoch 388,Loss 10.146440\n",
      "Epoch 388, Loss 10.146440\n",
      "    Params:  tensor([ 3.7667, -8.2418])\n",
      "    Grad  :  tensor([-0.2724,  1.5422])\n",
      "Epoch 389,Loss 10.121937\n",
      "Epoch 389, Loss 10.121937\n",
      "    Params:  tensor([ 3.7694, -8.2572])\n",
      "    Grad  :  tensor([-0.2720,  1.5396])\n",
      "Epoch 390,Loss 10.097513\n",
      "Epoch 390, Loss 10.097513\n",
      "    Params:  tensor([ 3.7722, -8.2726])\n",
      "    Grad  :  tensor([-0.2715,  1.5370])\n",
      "Epoch 391,Loss 10.073175\n",
      "Epoch 391, Loss 10.073175\n",
      "    Params:  tensor([ 3.7749, -8.2879])\n",
      "    Grad  :  tensor([-0.2710,  1.5344])\n",
      "Epoch 392,Loss 10.048921\n",
      "Epoch 392, Loss 10.048921\n",
      "    Params:  tensor([ 3.7776, -8.3033])\n",
      "    Grad  :  tensor([-0.2706,  1.5317])\n",
      "Epoch 393,Loss 10.024746\n",
      "Epoch 393, Loss 10.024746\n",
      "    Params:  tensor([ 3.7803, -8.3185])\n",
      "    Grad  :  tensor([-0.2701,  1.5291])\n",
      "Epoch 394,Loss 10.000654\n",
      "Epoch 394, Loss 10.000654\n",
      "    Params:  tensor([ 3.7830, -8.3338])\n",
      "    Grad  :  tensor([-0.2697,  1.5265])\n",
      "Epoch 395,Loss 9.976643\n",
      "Epoch 395, Loss 9.976643\n",
      "    Params:  tensor([ 3.7857, -8.3491])\n",
      "    Grad  :  tensor([-0.2692,  1.5240])\n",
      "Epoch 396,Loss 9.952714\n",
      "Epoch 396, Loss 9.952714\n",
      "    Params:  tensor([ 3.7884, -8.3643])\n",
      "    Grad  :  tensor([-0.2688,  1.5214])\n",
      "Epoch 397,Loss 9.928867\n",
      "Epoch 397, Loss 9.928867\n",
      "    Params:  tensor([ 3.7910, -8.3795])\n",
      "    Grad  :  tensor([-0.2683,  1.5188])\n",
      "Epoch 398,Loss 9.905097\n",
      "Epoch 398, Loss 9.905097\n",
      "    Params:  tensor([ 3.7937, -8.3946])\n",
      "    Grad  :  tensor([-0.2678,  1.5162])\n",
      "Epoch 399,Loss 9.881411\n",
      "Epoch 399, Loss 9.881411\n",
      "    Params:  tensor([ 3.7964, -8.4098])\n",
      "    Grad  :  tensor([-0.2674,  1.5136])\n",
      "Epoch 400,Loss 9.857809\n",
      "Epoch 400, Loss 9.857809\n",
      "    Params:  tensor([ 3.7991, -8.4249])\n",
      "    Grad  :  tensor([-0.2669,  1.5111])\n",
      "Epoch 401,Loss 9.834280\n",
      "Epoch 401, Loss 9.834280\n",
      "    Params:  tensor([ 3.8017, -8.4399])\n",
      "    Grad  :  tensor([-0.2665,  1.5085])\n",
      "Epoch 402,Loss 9.810836\n",
      "Epoch 402, Loss 9.810836\n",
      "    Params:  tensor([ 3.8044, -8.4550])\n",
      "    Grad  :  tensor([-0.2660,  1.5059])\n",
      "Epoch 403,Loss 9.787472\n",
      "Epoch 403, Loss 9.787472\n",
      "    Params:  tensor([ 3.8070, -8.4700])\n",
      "    Grad  :  tensor([-0.2656,  1.5034])\n",
      "Epoch 404,Loss 9.764179\n",
      "Epoch 404, Loss 9.764179\n",
      "    Params:  tensor([ 3.8097, -8.4850])\n",
      "    Grad  :  tensor([-0.2651,  1.5008])\n",
      "Epoch 405,Loss 9.740975\n",
      "Epoch 405, Loss 9.740975\n",
      "    Params:  tensor([ 3.8123, -8.5000])\n",
      "    Grad  :  tensor([-0.2647,  1.4983])\n",
      "Epoch 406,Loss 9.717844\n",
      "Epoch 406, Loss 9.717844\n",
      "    Params:  tensor([ 3.8150, -8.5150])\n",
      "    Grad  :  tensor([-0.2642,  1.4957])\n",
      "Epoch 407,Loss 9.694795\n",
      "Epoch 407, Loss 9.694795\n",
      "    Params:  tensor([ 3.8176, -8.5299])\n",
      "    Grad  :  tensor([-0.2638,  1.4932])\n",
      "Epoch 408,Loss 9.671824\n",
      "Epoch 408, Loss 9.671824\n",
      "    Params:  tensor([ 3.8202, -8.5448])\n",
      "    Grad  :  tensor([-0.2633,  1.4906])\n",
      "Epoch 409,Loss 9.648930\n",
      "Epoch 409, Loss 9.648930\n",
      "    Params:  tensor([ 3.8229, -8.5597])\n",
      "    Grad  :  tensor([-0.2629,  1.4881])\n",
      "Epoch 410,Loss 9.626113\n",
      "Epoch 410, Loss 9.626113\n",
      "    Params:  tensor([ 3.8255, -8.5746])\n",
      "    Grad  :  tensor([-0.2624,  1.4856])\n",
      "Epoch 411,Loss 9.603375\n",
      "Epoch 411, Loss 9.603375\n",
      "    Params:  tensor([ 3.8281, -8.5894])\n",
      "    Grad  :  tensor([-0.2620,  1.4831])\n",
      "Epoch 412,Loss 9.580713\n",
      "Epoch 412, Loss 9.580713\n",
      "    Params:  tensor([ 3.8307, -8.6042])\n",
      "    Grad  :  tensor([-0.2615,  1.4805])\n",
      "Epoch 413,Loss 9.558125\n",
      "Epoch 413, Loss 9.558125\n",
      "    Params:  tensor([ 3.8333, -8.6190])\n",
      "    Grad  :  tensor([-0.2611,  1.4780])\n",
      "Epoch 414,Loss 9.535619\n",
      "Epoch 414, Loss 9.535619\n",
      "    Params:  tensor([ 3.8360, -8.6337])\n",
      "    Grad  :  tensor([-0.2607,  1.4755])\n",
      "Epoch 415,Loss 9.513188\n",
      "Epoch 415, Loss 9.513188\n",
      "    Params:  tensor([ 3.8386, -8.6485])\n",
      "    Grad  :  tensor([-0.2602,  1.4730])\n",
      "Epoch 416,Loss 9.490830\n",
      "Epoch 416, Loss 9.490830\n",
      "    Params:  tensor([ 3.8412, -8.6632])\n",
      "    Grad  :  tensor([-0.2598,  1.4705])\n",
      "Epoch 417,Loss 9.468553\n",
      "Epoch 417, Loss 9.468553\n",
      "    Params:  tensor([ 3.8437, -8.6778])\n",
      "    Grad  :  tensor([-0.2593,  1.4680])\n",
      "Epoch 418,Loss 9.446349\n",
      "Epoch 418, Loss 9.446349\n",
      "    Params:  tensor([ 3.8463, -8.6925])\n",
      "    Grad  :  tensor([-0.2589,  1.4655])\n",
      "Epoch 419,Loss 9.424221\n",
      "Epoch 419, Loss 9.424221\n",
      "    Params:  tensor([ 3.8489, -8.7071])\n",
      "    Grad  :  tensor([-0.2584,  1.4630])\n",
      "Epoch 420,Loss 9.402166\n",
      "Epoch 420, Loss 9.402166\n",
      "    Params:  tensor([ 3.8515, -8.7217])\n",
      "    Grad  :  tensor([-0.2580,  1.4605])\n",
      "Epoch 421,Loss 9.380188\n",
      "Epoch 421, Loss 9.380188\n",
      "    Params:  tensor([ 3.8541, -8.7363])\n",
      "    Grad  :  tensor([-0.2576,  1.4581])\n",
      "Epoch 422,Loss 9.358285\n",
      "Epoch 422, Loss 9.358285\n",
      "    Params:  tensor([ 3.8566, -8.7509])\n",
      "    Grad  :  tensor([-0.2571,  1.4556])\n",
      "Epoch 423,Loss 9.336452\n",
      "Epoch 423, Loss 9.336452\n",
      "    Params:  tensor([ 3.8592, -8.7654])\n",
      "    Grad  :  tensor([-0.2567,  1.4531])\n",
      "Epoch 424,Loss 9.314696\n",
      "Epoch 424, Loss 9.314696\n",
      "    Params:  tensor([ 3.8618, -8.7799])\n",
      "    Grad  :  tensor([-0.2563,  1.4506])\n",
      "Epoch 425,Loss 9.293014\n",
      "Epoch 425, Loss 9.293014\n",
      "    Params:  tensor([ 3.8643, -8.7944])\n",
      "    Grad  :  tensor([-0.2558,  1.4482])\n",
      "Epoch 426,Loss 9.271410\n",
      "Epoch 426, Loss 9.271410\n",
      "    Params:  tensor([ 3.8669, -8.8089])\n",
      "    Grad  :  tensor([-0.2554,  1.4457])\n",
      "Epoch 427,Loss 9.249873\n",
      "Epoch 427, Loss 9.249873\n",
      "    Params:  tensor([ 3.8694, -8.8233])\n",
      "    Grad  :  tensor([-0.2549,  1.4433])\n",
      "Epoch 428,Loss 9.228411\n",
      "Epoch 428, Loss 9.228411\n",
      "    Params:  tensor([ 3.8720, -8.8377])\n",
      "    Grad  :  tensor([-0.2545,  1.4408])\n",
      "Epoch 429,Loss 9.207022\n",
      "Epoch 429, Loss 9.207022\n",
      "    Params:  tensor([ 3.8745, -8.8521])\n",
      "    Grad  :  tensor([-0.2541,  1.4384])\n",
      "Epoch 430,Loss 9.185708\n",
      "Epoch 430, Loss 9.185708\n",
      "    Params:  tensor([ 3.8771, -8.8664])\n",
      "    Grad  :  tensor([-0.2537,  1.4359])\n",
      "Epoch 431,Loss 9.164463\n",
      "Epoch 431, Loss 9.164463\n",
      "    Params:  tensor([ 3.8796, -8.8808])\n",
      "    Grad  :  tensor([-0.2532,  1.4335])\n",
      "Epoch 432,Loss 9.143290\n",
      "Epoch 432, Loss 9.143290\n",
      "    Params:  tensor([ 3.8821, -8.8951])\n",
      "    Grad  :  tensor([-0.2528,  1.4310])\n",
      "Epoch 433,Loss 9.122191\n",
      "Epoch 433, Loss 9.122191\n",
      "    Params:  tensor([ 3.8846, -8.9094])\n",
      "    Grad  :  tensor([-0.2524,  1.4286])\n",
      "Epoch 434,Loss 9.101161\n",
      "Epoch 434, Loss 9.101161\n",
      "    Params:  tensor([ 3.8872, -8.9236])\n",
      "    Grad  :  tensor([-0.2519,  1.4262])\n",
      "Epoch 435,Loss 9.080206\n",
      "Epoch 435, Loss 9.080206\n",
      "    Params:  tensor([ 3.8897, -8.9379])\n",
      "    Grad  :  tensor([-0.2515,  1.4238])\n",
      "Epoch 436,Loss 9.059319\n",
      "Epoch 436, Loss 9.059319\n",
      "    Params:  tensor([ 3.8922, -8.9521])\n",
      "    Grad  :  tensor([-0.2511,  1.4213])\n",
      "Epoch 437,Loss 9.038504\n",
      "Epoch 437, Loss 9.038504\n",
      "    Params:  tensor([ 3.8947, -8.9663])\n",
      "    Grad  :  tensor([-0.2507,  1.4189])\n",
      "Epoch 438,Loss 9.017760\n",
      "Epoch 438, Loss 9.017760\n",
      "    Params:  tensor([ 3.8972, -8.9804])\n",
      "    Grad  :  tensor([-0.2502,  1.4165])\n",
      "Epoch 439,Loss 8.997087\n",
      "Epoch 439, Loss 8.997087\n",
      "    Params:  tensor([ 3.8997, -8.9946])\n",
      "    Grad  :  tensor([-0.2498,  1.4141])\n",
      "Epoch 440,Loss 8.976482\n",
      "Epoch 440, Loss 8.976482\n",
      "    Params:  tensor([ 3.9022, -9.0087])\n",
      "    Grad  :  tensor([-0.2494,  1.4117])\n",
      "Epoch 441,Loss 8.955950\n",
      "Epoch 441, Loss 8.955950\n",
      "    Params:  tensor([ 3.9047, -9.0228])\n",
      "    Grad  :  tensor([-0.2490,  1.4093])\n",
      "Epoch 442,Loss 8.935481\n",
      "Epoch 442, Loss 8.935481\n",
      "    Params:  tensor([ 3.9072, -9.0369])\n",
      "    Grad  :  tensor([-0.2485,  1.4069])\n",
      "Epoch 443,Loss 8.915091\n",
      "Epoch 443, Loss 8.915091\n",
      "    Params:  tensor([ 3.9096, -9.0509])\n",
      "    Grad  :  tensor([-0.2481,  1.4045])\n",
      "Epoch 444,Loss 8.894761\n",
      "Epoch 444, Loss 8.894761\n",
      "    Params:  tensor([ 3.9121, -9.0649])\n",
      "    Grad  :  tensor([-0.2477,  1.4021])\n",
      "Epoch 445,Loss 8.874506\n",
      "Epoch 445, Loss 8.874506\n",
      "    Params:  tensor([ 3.9146, -9.0789])\n",
      "    Grad  :  tensor([-0.2473,  1.3998])\n",
      "Epoch 446,Loss 8.854321\n",
      "Epoch 446, Loss 8.854321\n",
      "    Params:  tensor([ 3.9171, -9.0929])\n",
      "    Grad  :  tensor([-0.2469,  1.3974])\n",
      "Epoch 447,Loss 8.834200\n",
      "Epoch 447, Loss 8.834200\n",
      "    Params:  tensor([ 3.9195, -9.1068])\n",
      "    Grad  :  tensor([-0.2464,  1.3950])\n",
      "Epoch 448,Loss 8.814148\n",
      "Epoch 448, Loss 8.814148\n",
      "    Params:  tensor([ 3.9220, -9.1208])\n",
      "    Grad  :  tensor([-0.2460,  1.3926])\n",
      "Epoch 449,Loss 8.794167\n",
      "Epoch 449, Loss 8.794167\n",
      "    Params:  tensor([ 3.9244, -9.1347])\n",
      "    Grad  :  tensor([-0.2456,  1.3903])\n",
      "Epoch 450,Loss 8.774253\n",
      "Epoch 450, Loss 8.774253\n",
      "    Params:  tensor([ 3.9269, -9.1486])\n",
      "    Grad  :  tensor([-0.2452,  1.3879])\n",
      "Epoch 451,Loss 8.754406\n",
      "Epoch 451, Loss 8.754406\n",
      "    Params:  tensor([ 3.9293, -9.1624])\n",
      "    Grad  :  tensor([-0.2448,  1.3856])\n",
      "Epoch 452,Loss 8.734623\n",
      "Epoch 452, Loss 8.734623\n",
      "    Params:  tensor([ 3.9318, -9.1762])\n",
      "    Grad  :  tensor([-0.2443,  1.3832])\n",
      "Epoch 453,Loss 8.714913\n",
      "Epoch 453, Loss 8.714913\n",
      "    Params:  tensor([ 3.9342, -9.1901])\n",
      "    Grad  :  tensor([-0.2439,  1.3808])\n",
      "Epoch 454,Loss 8.695268\n",
      "Epoch 454, Loss 8.695268\n",
      "    Params:  tensor([ 3.9367, -9.2038])\n",
      "    Grad  :  tensor([-0.2435,  1.3785])\n",
      "Epoch 455,Loss 8.675688\n",
      "Epoch 455, Loss 8.675688\n",
      "    Params:  tensor([ 3.9391, -9.2176])\n",
      "    Grad  :  tensor([-0.2431,  1.3762])\n",
      "Epoch 456,Loss 8.656175\n",
      "Epoch 456, Loss 8.656175\n",
      "    Params:  tensor([ 3.9415, -9.2313])\n",
      "    Grad  :  tensor([-0.2427,  1.3738])\n",
      "Epoch 457,Loss 8.636725\n",
      "Epoch 457, Loss 8.636725\n",
      "    Params:  tensor([ 3.9439, -9.2451])\n",
      "    Grad  :  tensor([-0.2423,  1.3715])\n",
      "Epoch 458,Loss 8.617349\n",
      "Epoch 458, Loss 8.617349\n",
      "    Params:  tensor([ 3.9464, -9.2587])\n",
      "    Grad  :  tensor([-0.2419,  1.3692])\n",
      "Epoch 459,Loss 8.598033\n",
      "Epoch 459, Loss 8.598033\n",
      "    Params:  tensor([ 3.9488, -9.2724])\n",
      "    Grad  :  tensor([-0.2415,  1.3668])\n",
      "Epoch 460,Loss 8.578784\n",
      "Epoch 460, Loss 8.578784\n",
      "    Params:  tensor([ 3.9512, -9.2861])\n",
      "    Grad  :  tensor([-0.2410,  1.3645])\n",
      "Epoch 461,Loss 8.559600\n",
      "Epoch 461, Loss 8.559600\n",
      "    Params:  tensor([ 3.9536, -9.2997])\n",
      "    Grad  :  tensor([-0.2406,  1.3622])\n",
      "Epoch 462,Loss 8.540482\n",
      "Epoch 462, Loss 8.540482\n",
      "    Params:  tensor([ 3.9560, -9.3133])\n",
      "    Grad  :  tensor([-0.2402,  1.3599])\n",
      "Epoch 463,Loss 8.521428\n",
      "Epoch 463, Loss 8.521428\n",
      "    Params:  tensor([ 3.9584, -9.3269])\n",
      "    Grad  :  tensor([-0.2398,  1.3576])\n",
      "Epoch 464,Loss 8.502439\n",
      "Epoch 464, Loss 8.502439\n",
      "    Params:  tensor([ 3.9608, -9.3404])\n",
      "    Grad  :  tensor([-0.2394,  1.3553])\n",
      "Epoch 465,Loss 8.483517\n",
      "Epoch 465, Loss 8.483517\n",
      "    Params:  tensor([ 3.9632, -9.3539])\n",
      "    Grad  :  tensor([-0.2390,  1.3530])\n",
      "Epoch 466,Loss 8.464654\n",
      "Epoch 466, Loss 8.464654\n",
      "    Params:  tensor([ 3.9656, -9.3674])\n",
      "    Grad  :  tensor([-0.2386,  1.3507])\n",
      "Epoch 467,Loss 8.445861\n",
      "Epoch 467, Loss 8.445861\n",
      "    Params:  tensor([ 3.9679, -9.3809])\n",
      "    Grad  :  tensor([-0.2382,  1.3484])\n",
      "Epoch 468,Loss 8.427127\n",
      "Epoch 468, Loss 8.427127\n",
      "    Params:  tensor([ 3.9703, -9.3944])\n",
      "    Grad  :  tensor([-0.2378,  1.3461])\n",
      "Epoch 469,Loss 8.408456\n",
      "Epoch 469, Loss 8.408456\n",
      "    Params:  tensor([ 3.9727, -9.4078])\n",
      "    Grad  :  tensor([-0.2374,  1.3438])\n",
      "Epoch 470,Loss 8.389850\n",
      "Epoch 470, Loss 8.389850\n",
      "    Params:  tensor([ 3.9751, -9.4212])\n",
      "    Grad  :  tensor([-0.2370,  1.3415])\n",
      "Epoch 471,Loss 8.371307\n",
      "Epoch 471, Loss 8.371307\n",
      "    Params:  tensor([ 3.9774, -9.4346])\n",
      "    Grad  :  tensor([-0.2366,  1.3392])\n",
      "Epoch 472,Loss 8.352828\n",
      "Epoch 472, Loss 8.352828\n",
      "    Params:  tensor([ 3.9798, -9.4480])\n",
      "    Grad  :  tensor([-0.2362,  1.3370])\n",
      "Epoch 473,Loss 8.334412\n",
      "Epoch 473, Loss 8.334412\n",
      "    Params:  tensor([ 3.9822, -9.4613])\n",
      "    Grad  :  tensor([-0.2358,  1.3347])\n",
      "Epoch 474,Loss 8.316056\n",
      "Epoch 474, Loss 8.316056\n",
      "    Params:  tensor([ 3.9845, -9.4747])\n",
      "    Grad  :  tensor([-0.2354,  1.3324])\n",
      "Epoch 475,Loss 8.297765\n",
      "Epoch 475, Loss 8.297765\n",
      "    Params:  tensor([ 3.9869, -9.4880])\n",
      "    Grad  :  tensor([-0.2350,  1.3302])\n",
      "Epoch 476,Loss 8.279537\n",
      "Epoch 476, Loss 8.279537\n",
      "    Params:  tensor([ 3.9892, -9.5013])\n",
      "    Grad  :  tensor([-0.2346,  1.3279])\n",
      "Epoch 477,Loss 8.261367\n",
      "Epoch 477, Loss 8.261367\n",
      "    Params:  tensor([ 3.9915, -9.5145])\n",
      "    Grad  :  tensor([-0.2342,  1.3256])\n",
      "Epoch 478,Loss 8.243265\n",
      "Epoch 478, Loss 8.243265\n",
      "    Params:  tensor([ 3.9939, -9.5277])\n",
      "    Grad  :  tensor([-0.2338,  1.3234])\n",
      "Epoch 479,Loss 8.225218\n",
      "Epoch 479, Loss 8.225218\n",
      "    Params:  tensor([ 3.9962, -9.5410])\n",
      "    Grad  :  tensor([-0.2334,  1.3211])\n",
      "Epoch 480,Loss 8.207233\n",
      "Epoch 480, Loss 8.207233\n",
      "    Params:  tensor([ 3.9985, -9.5541])\n",
      "    Grad  :  tensor([-0.2330,  1.3189])\n",
      "Epoch 481,Loss 8.189313\n",
      "Epoch 481, Loss 8.189313\n",
      "    Params:  tensor([ 4.0009, -9.5673])\n",
      "    Grad  :  tensor([-0.2326,  1.3166])\n",
      "Epoch 482,Loss 8.171450\n",
      "Epoch 482, Loss 8.171450\n",
      "    Params:  tensor([ 4.0032, -9.5805])\n",
      "    Grad  :  tensor([-0.2322,  1.3144])\n",
      "Epoch 483,Loss 8.153648\n",
      "Epoch 483, Loss 8.153648\n",
      "    Params:  tensor([ 4.0055, -9.5936])\n",
      "    Grad  :  tensor([-0.2318,  1.3122])\n",
      "Epoch 484,Loss 8.135907\n",
      "Epoch 484, Loss 8.135907\n",
      "    Params:  tensor([ 4.0078, -9.6067])\n",
      "    Grad  :  tensor([-0.2314,  1.3099])\n",
      "Epoch 485,Loss 8.118229\n",
      "Epoch 485, Loss 8.118229\n",
      "    Params:  tensor([ 4.0101, -9.6198])\n",
      "    Grad  :  tensor([-0.2310,  1.3077])\n",
      "Epoch 486,Loss 8.100609\n",
      "Epoch 486, Loss 8.100609\n",
      "    Params:  tensor([ 4.0124, -9.6328])\n",
      "    Grad  :  tensor([-0.2306,  1.3055])\n",
      "Epoch 487,Loss 8.083050\n",
      "Epoch 487, Loss 8.083050\n",
      "    Params:  tensor([ 4.0147, -9.6458])\n",
      "    Grad  :  tensor([-0.2302,  1.3033])\n",
      "Epoch 488,Loss 8.065549\n",
      "Epoch 488, Loss 8.065549\n",
      "    Params:  tensor([ 4.0170, -9.6589])\n",
      "    Grad  :  tensor([-0.2299,  1.3011])\n",
      "Epoch 489,Loss 8.048107\n",
      "Epoch 489, Loss 8.048107\n",
      "    Params:  tensor([ 4.0193, -9.6718])\n",
      "    Grad  :  tensor([-0.2295,  1.2989])\n",
      "Epoch 490,Loss 8.030723\n",
      "Epoch 490, Loss 8.030723\n",
      "    Params:  tensor([ 4.0216, -9.6848])\n",
      "    Grad  :  tensor([-0.2291,  1.2967])\n",
      "Epoch 491,Loss 8.013401\n",
      "Epoch 491, Loss 8.013401\n",
      "    Params:  tensor([ 4.0239, -9.6978])\n",
      "    Grad  :  tensor([-0.2287,  1.2945])\n",
      "Epoch 492,Loss 7.996138\n",
      "Epoch 492, Loss 7.996138\n",
      "    Params:  tensor([ 4.0262, -9.7107])\n",
      "    Grad  :  tensor([-0.2283,  1.2923])\n",
      "Epoch 493,Loss 7.978930\n",
      "Epoch 493, Loss 7.978930\n",
      "    Params:  tensor([ 4.0285, -9.7236])\n",
      "    Grad  :  tensor([-0.2279,  1.2901])\n",
      "Epoch 494,Loss 7.961786\n",
      "Epoch 494, Loss 7.961786\n",
      "    Params:  tensor([ 4.0308, -9.7365])\n",
      "    Grad  :  tensor([-0.2275,  1.2879])\n",
      "Epoch 495,Loss 7.944697\n",
      "Epoch 495, Loss 7.944697\n",
      "    Params:  tensor([ 4.0330, -9.7493])\n",
      "    Grad  :  tensor([-0.2271,  1.2857])\n",
      "Epoch 496,Loss 7.927665\n",
      "Epoch 496, Loss 7.927665\n",
      "    Params:  tensor([ 4.0353, -9.7621])\n",
      "    Grad  :  tensor([-0.2267,  1.2835])\n",
      "Epoch 497,Loss 7.910693\n",
      "Epoch 497, Loss 7.910693\n",
      "    Params:  tensor([ 4.0376, -9.7750])\n",
      "    Grad  :  tensor([-0.2263,  1.2813])\n",
      "Epoch 498,Loss 7.893779\n",
      "Epoch 498, Loss 7.893779\n",
      "    Params:  tensor([ 4.0398, -9.7877])\n",
      "    Grad  :  tensor([-0.2260,  1.2791])\n",
      "Epoch 499,Loss 7.876918\n",
      "Epoch 499, Loss 7.876918\n",
      "    Params:  tensor([ 4.0421, -9.8005])\n",
      "    Grad  :  tensor([-0.2256,  1.2770])\n",
      "Epoch 500,Loss 7.860117\n",
      "Epoch 500, Loss 7.860117\n",
      "    Params:  tensor([ 4.0443, -9.8133])\n",
      "    Grad  :  tensor([-0.2252,  1.2748])\n",
      "Epoch 501,Loss 7.843373\n",
      "Epoch 501, Loss 7.843373\n",
      "    Params:  tensor([ 4.0466, -9.8260])\n",
      "    Grad  :  tensor([-0.2248,  1.2726])\n",
      "Epoch 502,Loss 7.826686\n",
      "Epoch 502, Loss 7.826686\n",
      "    Params:  tensor([ 4.0488, -9.8387])\n",
      "    Grad  :  tensor([-0.2244,  1.2705])\n",
      "Epoch 503,Loss 7.810054\n",
      "Epoch 503, Loss 7.810054\n",
      "    Params:  tensor([ 4.0511, -9.8514])\n",
      "    Grad  :  tensor([-0.2240,  1.2683])\n",
      "Epoch 504,Loss 7.793480\n",
      "Epoch 504, Loss 7.793480\n",
      "    Params:  tensor([ 4.0533, -9.8640])\n",
      "    Grad  :  tensor([-0.2237,  1.2662])\n",
      "Epoch 505,Loss 7.776964\n",
      "Epoch 505, Loss 7.776964\n",
      "    Params:  tensor([ 4.0555, -9.8767])\n",
      "    Grad  :  tensor([-0.2233,  1.2640])\n",
      "Epoch 506,Loss 7.760502\n",
      "Epoch 506, Loss 7.760502\n",
      "    Params:  tensor([ 4.0578, -9.8893])\n",
      "    Grad  :  tensor([-0.2229,  1.2619])\n",
      "Epoch 507,Loss 7.744092\n",
      "Epoch 507, Loss 7.744092\n",
      "    Params:  tensor([ 4.0600, -9.9019])\n",
      "    Grad  :  tensor([-0.2225,  1.2597])\n",
      "Epoch 508,Loss 7.727746\n",
      "Epoch 508, Loss 7.727746\n",
      "    Params:  tensor([ 4.0622, -9.9145])\n",
      "    Grad  :  tensor([-0.2221,  1.2576])\n",
      "Epoch 509,Loss 7.711448\n",
      "Epoch 509, Loss 7.711448\n",
      "    Params:  tensor([ 4.0644, -9.9270])\n",
      "    Grad  :  tensor([-0.2218,  1.2554])\n",
      "Epoch 510,Loss 7.695211\n",
      "Epoch 510, Loss 7.695211\n",
      "    Params:  tensor([ 4.0666, -9.9396])\n",
      "    Grad  :  tensor([-0.2214,  1.2533])\n",
      "Epoch 511,Loss 7.679026\n",
      "Epoch 511, Loss 7.679026\n",
      "    Params:  tensor([ 4.0688, -9.9521])\n",
      "    Grad  :  tensor([-0.2210,  1.2512])\n",
      "Epoch 512,Loss 7.662897\n",
      "Epoch 512, Loss 7.662897\n",
      "    Params:  tensor([ 4.0710, -9.9646])\n",
      "    Grad  :  tensor([-0.2207,  1.2490])\n",
      "Epoch 513,Loss 7.646822\n",
      "Epoch 513, Loss 7.646822\n",
      "    Params:  tensor([ 4.0733, -9.9770])\n",
      "    Grad  :  tensor([-0.2203,  1.2469])\n",
      "Epoch 514,Loss 7.630805\n",
      "Epoch 514, Loss 7.630805\n",
      "    Params:  tensor([ 4.0754, -9.9895])\n",
      "    Grad  :  tensor([-0.2199,  1.2448])\n",
      "Epoch 515,Loss 7.614838\n",
      "Epoch 515, Loss 7.614838\n",
      "    Params:  tensor([  4.0776, -10.0019])\n",
      "    Grad  :  tensor([-0.2195,  1.2427])\n",
      "Epoch 516,Loss 7.598927\n",
      "Epoch 516, Loss 7.598927\n",
      "    Params:  tensor([  4.0798, -10.0143])\n",
      "    Grad  :  tensor([-0.2191,  1.2406])\n",
      "Epoch 517,Loss 7.583070\n",
      "Epoch 517, Loss 7.583070\n",
      "    Params:  tensor([  4.0820, -10.0267])\n",
      "    Grad  :  tensor([-0.2188,  1.2385])\n",
      "Epoch 518,Loss 7.567266\n",
      "Epoch 518, Loss 7.567266\n",
      "    Params:  tensor([  4.0842, -10.0391])\n",
      "    Grad  :  tensor([-0.2184,  1.2364])\n",
      "Epoch 519,Loss 7.551517\n",
      "Epoch 519, Loss 7.551517\n",
      "    Params:  tensor([  4.0864, -10.0514])\n",
      "    Grad  :  tensor([-0.2180,  1.2343])\n",
      "Epoch 520,Loss 7.535820\n",
      "Epoch 520, Loss 7.535820\n",
      "    Params:  tensor([  4.0886, -10.0637])\n",
      "    Grad  :  tensor([-0.2177,  1.2322])\n",
      "Epoch 521,Loss 7.520178\n",
      "Epoch 521, Loss 7.520178\n",
      "    Params:  tensor([  4.0907, -10.0760])\n",
      "    Grad  :  tensor([-0.2173,  1.2301])\n",
      "Epoch 522,Loss 7.504589\n",
      "Epoch 522, Loss 7.504589\n",
      "    Params:  tensor([  4.0929, -10.0883])\n",
      "    Grad  :  tensor([-0.2169,  1.2280])\n",
      "Epoch 523,Loss 7.489052\n",
      "Epoch 523, Loss 7.489052\n",
      "    Params:  tensor([  4.0951, -10.1006])\n",
      "    Grad  :  tensor([-0.2166,  1.2259])\n",
      "Epoch 524,Loss 7.473566\n",
      "Epoch 524, Loss 7.473566\n",
      "    Params:  tensor([  4.0972, -10.1128])\n",
      "    Grad  :  tensor([-0.2162,  1.2238])\n",
      "Epoch 525,Loss 7.458134\n",
      "Epoch 525, Loss 7.458134\n",
      "    Params:  tensor([  4.0994, -10.1250])\n",
      "    Grad  :  tensor([-0.2158,  1.2217])\n",
      "Epoch 526,Loss 7.442754\n",
      "Epoch 526, Loss 7.442754\n",
      "    Params:  tensor([  4.1015, -10.1372])\n",
      "    Grad  :  tensor([-0.2154,  1.2197])\n",
      "Epoch 527,Loss 7.427427\n",
      "Epoch 527, Loss 7.427427\n",
      "    Params:  tensor([  4.1037, -10.1494])\n",
      "    Grad  :  tensor([-0.2151,  1.2176])\n",
      "Epoch 528,Loss 7.412154\n",
      "Epoch 528, Loss 7.412154\n",
      "    Params:  tensor([  4.1058, -10.1616])\n",
      "    Grad  :  tensor([-0.2147,  1.2155])\n",
      "Epoch 529,Loss 7.396929\n",
      "Epoch 529, Loss 7.396929\n",
      "    Params:  tensor([  4.1080, -10.1737])\n",
      "    Grad  :  tensor([-0.2144,  1.2135])\n",
      "Epoch 530,Loss 7.381759\n",
      "Epoch 530, Loss 7.381759\n",
      "    Params:  tensor([  4.1101, -10.1858])\n",
      "    Grad  :  tensor([-0.2140,  1.2114])\n",
      "Epoch 531,Loss 7.366637\n",
      "Epoch 531, Loss 7.366637\n",
      "    Params:  tensor([  4.1123, -10.1979])\n",
      "    Grad  :  tensor([-0.2136,  1.2093])\n",
      "Epoch 532,Loss 7.351567\n",
      "Epoch 532, Loss 7.351567\n",
      "    Params:  tensor([  4.1144, -10.2100])\n",
      "    Grad  :  tensor([-0.2133,  1.2073])\n",
      "Epoch 533,Loss 7.336549\n",
      "Epoch 533, Loss 7.336549\n",
      "    Params:  tensor([  4.1165, -10.2220])\n",
      "    Grad  :  tensor([-0.2129,  1.2052])\n",
      "Epoch 534,Loss 7.321584\n",
      "Epoch 534, Loss 7.321584\n",
      "    Params:  tensor([  4.1187, -10.2340])\n",
      "    Grad  :  tensor([-0.2125,  1.2032])\n",
      "Epoch 535,Loss 7.306671\n",
      "Epoch 535, Loss 7.306671\n",
      "    Params:  tensor([  4.1208, -10.2461])\n",
      "    Grad  :  tensor([-0.2122,  1.2012])\n",
      "Epoch 536,Loss 7.291804\n",
      "Epoch 536, Loss 7.291804\n",
      "    Params:  tensor([  4.1229, -10.2581])\n",
      "    Grad  :  tensor([-0.2118,  1.1991])\n",
      "Epoch 537,Loss 7.276989\n",
      "Epoch 537, Loss 7.276989\n",
      "    Params:  tensor([  4.1250, -10.2700])\n",
      "    Grad  :  tensor([-0.2115,  1.1971])\n",
      "Epoch 538,Loss 7.262227\n",
      "Epoch 538, Loss 7.262227\n",
      "    Params:  tensor([  4.1271, -10.2820])\n",
      "    Grad  :  tensor([-0.2111,  1.1950])\n",
      "Epoch 539,Loss 7.247512\n",
      "Epoch 539, Loss 7.247512\n",
      "    Params:  tensor([  4.1292, -10.2939])\n",
      "    Grad  :  tensor([-0.2108,  1.1930])\n",
      "Epoch 540,Loss 7.232845\n",
      "Epoch 540, Loss 7.232845\n",
      "    Params:  tensor([  4.1313, -10.3058])\n",
      "    Grad  :  tensor([-0.2104,  1.1910])\n",
      "Epoch 541,Loss 7.218231\n",
      "Epoch 541, Loss 7.218231\n",
      "    Params:  tensor([  4.1334, -10.3177])\n",
      "    Grad  :  tensor([-0.2100,  1.1890])\n",
      "Epoch 542,Loss 7.203665\n",
      "Epoch 542, Loss 7.203665\n",
      "    Params:  tensor([  4.1355, -10.3296])\n",
      "    Grad  :  tensor([-0.2097,  1.1869])\n",
      "Epoch 543,Loss 7.189151\n",
      "Epoch 543, Loss 7.189151\n",
      "    Params:  tensor([  4.1376, -10.3414])\n",
      "    Grad  :  tensor([-0.2093,  1.1849])\n",
      "Epoch 544,Loss 7.174683\n",
      "Epoch 544, Loss 7.174683\n",
      "    Params:  tensor([  4.1397, -10.3533])\n",
      "    Grad  :  tensor([-0.2090,  1.1829])\n",
      "Epoch 545,Loss 7.160266\n",
      "Epoch 545, Loss 7.160266\n",
      "    Params:  tensor([  4.1418, -10.3651])\n",
      "    Grad  :  tensor([-0.2086,  1.1809])\n",
      "Epoch 546,Loss 7.145897\n",
      "Epoch 546, Loss 7.145897\n",
      "    Params:  tensor([  4.1439, -10.3769])\n",
      "    Grad  :  tensor([-0.2083,  1.1789])\n",
      "Epoch 547,Loss 7.131581\n",
      "Epoch 547, Loss 7.131581\n",
      "    Params:  tensor([  4.1460, -10.3886])\n",
      "    Grad  :  tensor([-0.2079,  1.1769])\n",
      "Epoch 548,Loss 7.117305\n",
      "Epoch 548, Loss 7.117305\n",
      "    Params:  tensor([  4.1480, -10.4004])\n",
      "    Grad  :  tensor([-0.2075,  1.1749])\n",
      "Epoch 549,Loss 7.103083\n",
      "Epoch 549, Loss 7.103083\n",
      "    Params:  tensor([  4.1501, -10.4121])\n",
      "    Grad  :  tensor([-0.2072,  1.1729])\n",
      "Epoch 550,Loss 7.088911\n",
      "Epoch 550, Loss 7.088911\n",
      "    Params:  tensor([  4.1522, -10.4238])\n",
      "    Grad  :  tensor([-0.2068,  1.1709])\n",
      "Epoch 551,Loss 7.074785\n",
      "Epoch 551, Loss 7.074785\n",
      "    Params:  tensor([  4.1542, -10.4355])\n",
      "    Grad  :  tensor([-0.2065,  1.1689])\n",
      "Epoch 552,Loss 7.060707\n",
      "Epoch 552, Loss 7.060707\n",
      "    Params:  tensor([  4.1563, -10.4472])\n",
      "    Grad  :  tensor([-0.2062,  1.1669])\n",
      "Epoch 553,Loss 7.046676\n",
      "Epoch 553, Loss 7.046676\n",
      "    Params:  tensor([  4.1584, -10.4588])\n",
      "    Grad  :  tensor([-0.2058,  1.1649])\n",
      "Epoch 554,Loss 7.032695\n",
      "Epoch 554, Loss 7.032695\n",
      "    Params:  tensor([  4.1604, -10.4704])\n",
      "    Grad  :  tensor([-0.2054,  1.1630])\n",
      "Epoch 555,Loss 7.018755\n",
      "Epoch 555, Loss 7.018755\n",
      "    Params:  tensor([  4.1625, -10.4821])\n",
      "    Grad  :  tensor([-0.2051,  1.1610])\n",
      "Epoch 556,Loss 7.004870\n",
      "Epoch 556, Loss 7.004870\n",
      "    Params:  tensor([  4.1645, -10.4936])\n",
      "    Grad  :  tensor([-0.2047,  1.1590])\n",
      "Epoch 557,Loss 6.991028\n",
      "Epoch 557, Loss 6.991028\n",
      "    Params:  tensor([  4.1666, -10.5052])\n",
      "    Grad  :  tensor([-0.2044,  1.1571])\n",
      "Epoch 558,Loss 6.977232\n",
      "Epoch 558, Loss 6.977232\n",
      "    Params:  tensor([  4.1686, -10.5168])\n",
      "    Grad  :  tensor([-0.2041,  1.1551])\n",
      "Epoch 559,Loss 6.963488\n",
      "Epoch 559, Loss 6.963488\n",
      "    Params:  tensor([  4.1706, -10.5283])\n",
      "    Grad  :  tensor([-0.2037,  1.1531])\n",
      "Epoch 560,Loss 6.949787\n",
      "Epoch 560, Loss 6.949787\n",
      "    Params:  tensor([  4.1727, -10.5398])\n",
      "    Grad  :  tensor([-0.2034,  1.1512])\n",
      "Epoch 561,Loss 6.936135\n",
      "Epoch 561, Loss 6.936135\n",
      "    Params:  tensor([  4.1747, -10.5513])\n",
      "    Grad  :  tensor([-0.2030,  1.1492])\n",
      "Epoch 562,Loss 6.922528\n",
      "Epoch 562, Loss 6.922528\n",
      "    Params:  tensor([  4.1767, -10.5628])\n",
      "    Grad  :  tensor([-0.2027,  1.1473])\n",
      "Epoch 563,Loss 6.908967\n",
      "Epoch 563, Loss 6.908967\n",
      "    Params:  tensor([  4.1787, -10.5742])\n",
      "    Grad  :  tensor([-0.2023,  1.1453])\n",
      "Epoch 564,Loss 6.895452\n",
      "Epoch 564, Loss 6.895452\n",
      "    Params:  tensor([  4.1808, -10.5857])\n",
      "    Grad  :  tensor([-0.2020,  1.1434])\n",
      "Epoch 565,Loss 6.881980\n",
      "Epoch 565, Loss 6.881980\n",
      "    Params:  tensor([  4.1828, -10.5971])\n",
      "    Grad  :  tensor([-0.2016,  1.1414])\n",
      "Epoch 566,Loss 6.868559\n",
      "Epoch 566, Loss 6.868559\n",
      "    Params:  tensor([  4.1848, -10.6085])\n",
      "    Grad  :  tensor([-0.2013,  1.1395])\n",
      "Epoch 567,Loss 6.855180\n",
      "Epoch 567, Loss 6.855180\n",
      "    Params:  tensor([  4.1868, -10.6198])\n",
      "    Grad  :  tensor([-0.2010,  1.1375])\n",
      "Epoch 568,Loss 6.841848\n",
      "Epoch 568, Loss 6.841848\n",
      "    Params:  tensor([  4.1888, -10.6312])\n",
      "    Grad  :  tensor([-0.2006,  1.1356])\n",
      "Epoch 569,Loss 6.828561\n",
      "Epoch 569, Loss 6.828561\n",
      "    Params:  tensor([  4.1908, -10.6425])\n",
      "    Grad  :  tensor([-0.2003,  1.1337])\n",
      "Epoch 570,Loss 6.815319\n",
      "Epoch 570, Loss 6.815319\n",
      "    Params:  tensor([  4.1928, -10.6539])\n",
      "    Grad  :  tensor([-0.1999,  1.1318])\n",
      "Epoch 571,Loss 6.802118\n",
      "Epoch 571, Loss 6.802118\n",
      "    Params:  tensor([  4.1948, -10.6652])\n",
      "    Grad  :  tensor([-0.1996,  1.1298])\n",
      "Epoch 572,Loss 6.788968\n",
      "Epoch 572, Loss 6.788968\n",
      "    Params:  tensor([  4.1968, -10.6764])\n",
      "    Grad  :  tensor([-0.1992,  1.1279])\n",
      "Epoch 573,Loss 6.775864\n",
      "Epoch 573, Loss 6.775864\n",
      "    Params:  tensor([  4.1988, -10.6877])\n",
      "    Grad  :  tensor([-0.1989,  1.1260])\n",
      "Epoch 574,Loss 6.762797\n",
      "Epoch 574, Loss 6.762797\n",
      "    Params:  tensor([  4.2008, -10.6989])\n",
      "    Grad  :  tensor([-0.1986,  1.1241])\n",
      "Epoch 575,Loss 6.749779\n",
      "Epoch 575, Loss 6.749779\n",
      "    Params:  tensor([  4.2028, -10.7102])\n",
      "    Grad  :  tensor([-0.1982,  1.1222])\n",
      "Epoch 576,Loss 6.736804\n",
      "Epoch 576, Loss 6.736804\n",
      "    Params:  tensor([  4.2047, -10.7214])\n",
      "    Grad  :  tensor([-0.1979,  1.1203])\n",
      "Epoch 577,Loss 6.723876\n",
      "Epoch 577, Loss 6.723876\n",
      "    Params:  tensor([  4.2067, -10.7325])\n",
      "    Grad  :  tensor([-0.1976,  1.1184])\n",
      "Epoch 578,Loss 6.710987\n",
      "Epoch 578, Loss 6.710987\n",
      "    Params:  tensor([  4.2087, -10.7437])\n",
      "    Grad  :  tensor([-0.1972,  1.1165])\n",
      "Epoch 579,Loss 6.698142\n",
      "Epoch 579, Loss 6.698142\n",
      "    Params:  tensor([  4.2107, -10.7549])\n",
      "    Grad  :  tensor([-0.1969,  1.1146])\n",
      "Epoch 580,Loss 6.685345\n",
      "Epoch 580, Loss 6.685345\n",
      "    Params:  tensor([  4.2126, -10.7660])\n",
      "    Grad  :  tensor([-0.1966,  1.1127])\n",
      "Epoch 581,Loss 6.672589\n",
      "Epoch 581, Loss 6.672589\n",
      "    Params:  tensor([  4.2146, -10.7771])\n",
      "    Grad  :  tensor([-0.1962,  1.1108])\n",
      "Epoch 582,Loss 6.659873\n",
      "Epoch 582, Loss 6.659873\n",
      "    Params:  tensor([  4.2165, -10.7882])\n",
      "    Grad  :  tensor([-0.1959,  1.1089])\n",
      "Epoch 583,Loss 6.647207\n",
      "Epoch 583, Loss 6.647207\n",
      "    Params:  tensor([  4.2185, -10.7992])\n",
      "    Grad  :  tensor([-0.1956,  1.1070])\n",
      "Epoch 584,Loss 6.634578\n",
      "Epoch 584, Loss 6.634578\n",
      "    Params:  tensor([  4.2204, -10.8103])\n",
      "    Grad  :  tensor([-0.1952,  1.1051])\n",
      "Epoch 585,Loss 6.621994\n",
      "Epoch 585, Loss 6.621994\n",
      "    Params:  tensor([  4.2224, -10.8213])\n",
      "    Grad  :  tensor([-0.1949,  1.1033])\n",
      "Epoch 586,Loss 6.609454\n",
      "Epoch 586, Loss 6.609454\n",
      "    Params:  tensor([  4.2243, -10.8323])\n",
      "    Grad  :  tensor([-0.1946,  1.1014])\n",
      "Epoch 587,Loss 6.596953\n",
      "Epoch 587, Loss 6.596953\n",
      "    Params:  tensor([  4.2263, -10.8433])\n",
      "    Grad  :  tensor([-0.1942,  1.0995])\n",
      "Epoch 588,Loss 6.584499\n",
      "Epoch 588, Loss 6.584499\n",
      "    Params:  tensor([  4.2282, -10.8543])\n",
      "    Grad  :  tensor([-0.1939,  1.0976])\n",
      "Epoch 589,Loss 6.572087\n",
      "Epoch 589, Loss 6.572087\n",
      "    Params:  tensor([  4.2302, -10.8653])\n",
      "    Grad  :  tensor([-0.1936,  1.0958])\n",
      "Epoch 590,Loss 6.559712\n",
      "Epoch 590, Loss 6.559712\n",
      "    Params:  tensor([  4.2321, -10.8762])\n",
      "    Grad  :  tensor([-0.1932,  1.0939])\n",
      "Epoch 591,Loss 6.547384\n",
      "Epoch 591, Loss 6.547384\n",
      "    Params:  tensor([  4.2340, -10.8871])\n",
      "    Grad  :  tensor([-0.1929,  1.0921])\n",
      "Epoch 592,Loss 6.535097\n",
      "Epoch 592, Loss 6.535097\n",
      "    Params:  tensor([  4.2359, -10.8980])\n",
      "    Grad  :  tensor([-0.1926,  1.0902])\n",
      "Epoch 593,Loss 6.522851\n",
      "Epoch 593, Loss 6.522851\n",
      "    Params:  tensor([  4.2379, -10.9089])\n",
      "    Grad  :  tensor([-0.1923,  1.0884])\n",
      "Epoch 594,Loss 6.510646\n",
      "Epoch 594, Loss 6.510646\n",
      "    Params:  tensor([  4.2398, -10.9198])\n",
      "    Grad  :  tensor([-0.1919,  1.0865])\n",
      "Epoch 595,Loss 6.498482\n",
      "Epoch 595, Loss 6.498482\n",
      "    Params:  tensor([  4.2417, -10.9306])\n",
      "    Grad  :  tensor([-0.1916,  1.0847])\n",
      "Epoch 596,Loss 6.486361\n",
      "Epoch 596, Loss 6.486361\n",
      "    Params:  tensor([  4.2436, -10.9415])\n",
      "    Grad  :  tensor([-0.1913,  1.0828])\n",
      "Epoch 597,Loss 6.474282\n",
      "Epoch 597, Loss 6.474282\n",
      "    Params:  tensor([  4.2455, -10.9523])\n",
      "    Grad  :  tensor([-0.1910,  1.0810])\n",
      "Epoch 598,Loss 6.462241\n",
      "Epoch 598, Loss 6.462241\n",
      "    Params:  tensor([  4.2474, -10.9631])\n",
      "    Grad  :  tensor([-0.1906,  1.0791])\n",
      "Epoch 599,Loss 6.450243\n",
      "Epoch 599, Loss 6.450243\n",
      "    Params:  tensor([  4.2493, -10.9738])\n",
      "    Grad  :  tensor([-0.1903,  1.0773])\n",
      "Epoch 600,Loss 6.438284\n",
      "Epoch 600, Loss 6.438284\n",
      "    Params:  tensor([  4.2512, -10.9846])\n",
      "    Grad  :  tensor([-0.1900,  1.0755])\n",
      "Epoch 601,Loss 6.426368\n",
      "Epoch 601, Loss 6.426368\n",
      "    Params:  tensor([  4.2531, -10.9953])\n",
      "    Grad  :  tensor([-0.1897,  1.0737])\n",
      "Epoch 602,Loss 6.414490\n",
      "Epoch 602, Loss 6.414490\n",
      "    Params:  tensor([  4.2550, -11.0060])\n",
      "    Grad  :  tensor([-0.1893,  1.0718])\n",
      "Epoch 603,Loss 6.402653\n",
      "Epoch 603, Loss 6.402653\n",
      "    Params:  tensor([  4.2569, -11.0167])\n",
      "    Grad  :  tensor([-0.1890,  1.0700])\n",
      "Epoch 604,Loss 6.390859\n",
      "Epoch 604, Loss 6.390859\n",
      "    Params:  tensor([  4.2588, -11.0274])\n",
      "    Grad  :  tensor([-0.1887,  1.0682])\n",
      "Epoch 605,Loss 6.379103\n",
      "Epoch 605, Loss 6.379103\n",
      "    Params:  tensor([  4.2607, -11.0381])\n",
      "    Grad  :  tensor([-0.1884,  1.0664])\n",
      "Epoch 606,Loss 6.367385\n",
      "Epoch 606, Loss 6.367385\n",
      "    Params:  tensor([  4.2626, -11.0487])\n",
      "    Grad  :  tensor([-0.1880,  1.0646])\n",
      "Epoch 607,Loss 6.355706\n",
      "Epoch 607, Loss 6.355706\n",
      "    Params:  tensor([  4.2644, -11.0594])\n",
      "    Grad  :  tensor([-0.1877,  1.0628])\n",
      "Epoch 608,Loss 6.344070\n",
      "Epoch 608, Loss 6.344070\n",
      "    Params:  tensor([  4.2663, -11.0700])\n",
      "    Grad  :  tensor([-0.1874,  1.0609])\n",
      "Epoch 609,Loss 6.332472\n",
      "Epoch 609, Loss 6.332472\n",
      "    Params:  tensor([  4.2682, -11.0806])\n",
      "    Grad  :  tensor([-0.1871,  1.0591])\n",
      "Epoch 610,Loss 6.320912\n",
      "Epoch 610, Loss 6.320912\n",
      "    Params:  tensor([  4.2701, -11.0911])\n",
      "    Grad  :  tensor([-0.1868,  1.0573])\n",
      "Epoch 611,Loss 6.309395\n",
      "Epoch 611, Loss 6.309395\n",
      "    Params:  tensor([  4.2719, -11.1017])\n",
      "    Grad  :  tensor([-0.1865,  1.0555])\n",
      "Epoch 612,Loss 6.297915\n",
      "Epoch 612, Loss 6.297915\n",
      "    Params:  tensor([  4.2738, -11.1122])\n",
      "    Grad  :  tensor([-0.1861,  1.0538])\n",
      "Epoch 613,Loss 6.286473\n",
      "Epoch 613, Loss 6.286473\n",
      "    Params:  tensor([  4.2756, -11.1227])\n",
      "    Grad  :  tensor([-0.1858,  1.0520])\n",
      "Epoch 614,Loss 6.275074\n",
      "Epoch 614, Loss 6.275074\n",
      "    Params:  tensor([  4.2775, -11.1333])\n",
      "    Grad  :  tensor([-0.1855,  1.0502])\n",
      "Epoch 615,Loss 6.263708\n",
      "Epoch 615, Loss 6.263708\n",
      "    Params:  tensor([  4.2794, -11.1437])\n",
      "    Grad  :  tensor([-0.1852,  1.0484])\n",
      "Epoch 616,Loss 6.252382\n",
      "Epoch 616, Loss 6.252382\n",
      "    Params:  tensor([  4.2812, -11.1542])\n",
      "    Grad  :  tensor([-0.1849,  1.0466])\n",
      "Epoch 617,Loss 6.241098\n",
      "Epoch 617, Loss 6.241098\n",
      "    Params:  tensor([  4.2830, -11.1646])\n",
      "    Grad  :  tensor([-0.1846,  1.0448])\n",
      "Epoch 618,Loss 6.229849\n",
      "Epoch 618, Loss 6.229849\n",
      "    Params:  tensor([  4.2849, -11.1751])\n",
      "    Grad  :  tensor([-0.1843,  1.0431])\n",
      "Epoch 619,Loss 6.218639\n",
      "Epoch 619, Loss 6.218639\n",
      "    Params:  tensor([  4.2867, -11.1855])\n",
      "    Grad  :  tensor([-0.1840,  1.0413])\n",
      "Epoch 620,Loss 6.207470\n",
      "Epoch 620, Loss 6.207470\n",
      "    Params:  tensor([  4.2886, -11.1959])\n",
      "    Grad  :  tensor([-0.1836,  1.0395])\n",
      "Epoch 621,Loss 6.196334\n",
      "Epoch 621, Loss 6.196334\n",
      "    Params:  tensor([  4.2904, -11.2063])\n",
      "    Grad  :  tensor([-0.1833,  1.0378])\n",
      "Epoch 622,Loss 6.185240\n",
      "Epoch 622, Loss 6.185240\n",
      "    Params:  tensor([  4.2922, -11.2166])\n",
      "    Grad  :  tensor([-0.1830,  1.0360])\n",
      "Epoch 623,Loss 6.174181\n",
      "Epoch 623, Loss 6.174181\n",
      "    Params:  tensor([  4.2941, -11.2270])\n",
      "    Grad  :  tensor([-0.1827,  1.0342])\n",
      "Epoch 624,Loss 6.163159\n",
      "Epoch 624, Loss 6.163159\n",
      "    Params:  tensor([  4.2959, -11.2373])\n",
      "    Grad  :  tensor([-0.1824,  1.0325])\n",
      "Epoch 625,Loss 6.152177\n",
      "Epoch 625, Loss 6.152177\n",
      "    Params:  tensor([  4.2977, -11.2476])\n",
      "    Grad  :  tensor([-0.1821,  1.0307])\n",
      "Epoch 626,Loss 6.141230\n",
      "Epoch 626, Loss 6.141230\n",
      "    Params:  tensor([  4.2995, -11.2579])\n",
      "    Grad  :  tensor([-0.1818,  1.0290])\n",
      "Epoch 627,Loss 6.130322\n",
      "Epoch 627, Loss 6.130322\n",
      "    Params:  tensor([  4.3013, -11.2682])\n",
      "    Grad  :  tensor([-0.1815,  1.0272])\n",
      "Epoch 628,Loss 6.119448\n",
      "Epoch 628, Loss 6.119448\n",
      "    Params:  tensor([  4.3031, -11.2784])\n",
      "    Grad  :  tensor([-0.1811,  1.0255])\n",
      "Epoch 629,Loss 6.108614\n",
      "Epoch 629, Loss 6.108614\n",
      "    Params:  tensor([  4.3050, -11.2887])\n",
      "    Grad  :  tensor([-0.1808,  1.0237])\n",
      "Epoch 630,Loss 6.097815\n",
      "Epoch 630, Loss 6.097815\n",
      "    Params:  tensor([  4.3068, -11.2989])\n",
      "    Grad  :  tensor([-0.1805,  1.0220])\n",
      "Epoch 631,Loss 6.087054\n",
      "Epoch 631, Loss 6.087054\n",
      "    Params:  tensor([  4.3086, -11.3091])\n",
      "    Grad  :  tensor([-0.1802,  1.0203])\n",
      "Epoch 632,Loss 6.076329\n",
      "Epoch 632, Loss 6.076329\n",
      "    Params:  tensor([  4.3104, -11.3193])\n",
      "    Grad  :  tensor([-0.1799,  1.0185])\n",
      "Epoch 633,Loss 6.065644\n",
      "Epoch 633, Loss 6.065644\n",
      "    Params:  tensor([  4.3122, -11.3294])\n",
      "    Grad  :  tensor([-0.1796,  1.0168])\n",
      "Epoch 634,Loss 6.054988\n",
      "Epoch 634, Loss 6.054988\n",
      "    Params:  tensor([  4.3139, -11.3396])\n",
      "    Grad  :  tensor([-0.1793,  1.0151])\n",
      "Epoch 635,Loss 6.044372\n",
      "Epoch 635, Loss 6.044372\n",
      "    Params:  tensor([  4.3157, -11.3497])\n",
      "    Grad  :  tensor([-0.1790,  1.0133])\n",
      "Epoch 636,Loss 6.033794\n",
      "Epoch 636, Loss 6.033794\n",
      "    Params:  tensor([  4.3175, -11.3598])\n",
      "    Grad  :  tensor([-0.1787,  1.0116])\n",
      "Epoch 637,Loss 6.023247\n",
      "Epoch 637, Loss 6.023247\n",
      "    Params:  tensor([  4.3193, -11.3699])\n",
      "    Grad  :  tensor([-0.1784,  1.0099])\n",
      "Epoch 638,Loss 6.012738\n",
      "Epoch 638, Loss 6.012738\n",
      "    Params:  tensor([  4.3211, -11.3800])\n",
      "    Grad  :  tensor([-0.1781,  1.0082])\n",
      "Epoch 639,Loss 6.002264\n",
      "Epoch 639, Loss 6.002264\n",
      "    Params:  tensor([  4.3229, -11.3901])\n",
      "    Grad  :  tensor([-0.1778,  1.0065])\n",
      "Epoch 640,Loss 5.991828\n",
      "Epoch 640, Loss 5.991828\n",
      "    Params:  tensor([  4.3246, -11.4001])\n",
      "    Grad  :  tensor([-0.1775,  1.0048])\n",
      "Epoch 641,Loss 5.981425\n",
      "Epoch 641, Loss 5.981425\n",
      "    Params:  tensor([  4.3264, -11.4102])\n",
      "    Grad  :  tensor([-0.1772,  1.0031])\n",
      "Epoch 642,Loss 5.971058\n",
      "Epoch 642, Loss 5.971058\n",
      "    Params:  tensor([  4.3282, -11.4202])\n",
      "    Grad  :  tensor([-0.1769,  1.0014])\n",
      "Epoch 643,Loss 5.960727\n",
      "Epoch 643, Loss 5.960727\n",
      "    Params:  tensor([  4.3300, -11.4302])\n",
      "    Grad  :  tensor([-0.1766,  0.9997])\n",
      "Epoch 644,Loss 5.950432\n",
      "Epoch 644, Loss 5.950432\n",
      "    Params:  tensor([  4.3317, -11.4401])\n",
      "    Grad  :  tensor([-0.1763,  0.9980])\n",
      "Epoch 645,Loss 5.940171\n",
      "Epoch 645, Loss 5.940171\n",
      "    Params:  tensor([  4.3335, -11.4501])\n",
      "    Grad  :  tensor([-0.1760,  0.9963])\n",
      "Epoch 646,Loss 5.929944\n",
      "Epoch 646, Loss 5.929944\n",
      "    Params:  tensor([  4.3352, -11.4601])\n",
      "    Grad  :  tensor([-0.1757,  0.9946])\n",
      "Epoch 647,Loss 5.919752\n",
      "Epoch 647, Loss 5.919752\n",
      "    Params:  tensor([  4.3370, -11.4700])\n",
      "    Grad  :  tensor([-0.1754,  0.9929])\n",
      "Epoch 648,Loss 5.909596\n",
      "Epoch 648, Loss 5.909596\n",
      "    Params:  tensor([  4.3387, -11.4799])\n",
      "    Grad  :  tensor([-0.1751,  0.9912])\n",
      "Epoch 649,Loss 5.899472\n",
      "Epoch 649, Loss 5.899472\n",
      "    Params:  tensor([  4.3405, -11.4898])\n",
      "    Grad  :  tensor([-0.1748,  0.9895])\n",
      "Epoch 650,Loss 5.889383\n",
      "Epoch 650, Loss 5.889383\n",
      "    Params:  tensor([  4.3422, -11.4997])\n",
      "    Grad  :  tensor([-0.1745,  0.9878])\n",
      "Epoch 651,Loss 5.879326\n",
      "Epoch 651, Loss 5.879326\n",
      "    Params:  tensor([  4.3440, -11.5095])\n",
      "    Grad  :  tensor([-0.1742,  0.9862])\n",
      "Epoch 652,Loss 5.869310\n",
      "Epoch 652, Loss 5.869310\n",
      "    Params:  tensor([  4.3457, -11.5194])\n",
      "    Grad  :  tensor([-0.1739,  0.9845])\n",
      "Epoch 653,Loss 5.859322\n",
      "Epoch 653, Loss 5.859322\n",
      "    Params:  tensor([  4.3474, -11.5292])\n",
      "    Grad  :  tensor([-0.1736,  0.9828])\n",
      "Epoch 654,Loss 5.849374\n",
      "Epoch 654, Loss 5.849374\n",
      "    Params:  tensor([  4.3492, -11.5390])\n",
      "    Grad  :  tensor([-0.1733,  0.9811])\n",
      "Epoch 655,Loss 5.839453\n",
      "Epoch 655, Loss 5.839453\n",
      "    Params:  tensor([  4.3509, -11.5488])\n",
      "    Grad  :  tensor([-0.1730,  0.9795])\n",
      "Epoch 656,Loss 5.829570\n",
      "Epoch 656, Loss 5.829570\n",
      "    Params:  tensor([  4.3526, -11.5586])\n",
      "    Grad  :  tensor([-0.1727,  0.9778])\n",
      "Epoch 657,Loss 5.819718\n",
      "Epoch 657, Loss 5.819718\n",
      "    Params:  tensor([  4.3544, -11.5683])\n",
      "    Grad  :  tensor([-0.1724,  0.9761])\n",
      "Epoch 658,Loss 5.809901\n",
      "Epoch 658, Loss 5.809901\n",
      "    Params:  tensor([  4.3561, -11.5781])\n",
      "    Grad  :  tensor([-0.1722,  0.9745])\n",
      "Epoch 659,Loss 5.800116\n",
      "Epoch 659, Loss 5.800116\n",
      "    Params:  tensor([  4.3578, -11.5878])\n",
      "    Grad  :  tensor([-0.1719,  0.9728])\n",
      "Epoch 660,Loss 5.790367\n",
      "Epoch 660, Loss 5.790367\n",
      "    Params:  tensor([  4.3595, -11.5975])\n",
      "    Grad  :  tensor([-0.1716,  0.9712])\n",
      "Epoch 661,Loss 5.780646\n",
      "Epoch 661, Loss 5.780646\n",
      "    Params:  tensor([  4.3612, -11.6072])\n",
      "    Grad  :  tensor([-0.1713,  0.9695])\n",
      "Epoch 662,Loss 5.770962\n",
      "Epoch 662, Loss 5.770962\n",
      "    Params:  tensor([  4.3629, -11.6169])\n",
      "    Grad  :  tensor([-0.1710,  0.9679])\n",
      "Epoch 663,Loss 5.761312\n",
      "Epoch 663, Loss 5.761312\n",
      "    Params:  tensor([  4.3646, -11.6266])\n",
      "    Grad  :  tensor([-0.1707,  0.9662])\n",
      "Epoch 664,Loss 5.751694\n",
      "Epoch 664, Loss 5.751694\n",
      "    Params:  tensor([  4.3664, -11.6362])\n",
      "    Grad  :  tensor([-0.1704,  0.9646])\n",
      "Epoch 665,Loss 5.742105\n",
      "Epoch 665, Loss 5.742105\n",
      "    Params:  tensor([  4.3681, -11.6458])\n",
      "    Grad  :  tensor([-0.1701,  0.9630])\n",
      "Epoch 666,Loss 5.732550\n",
      "Epoch 666, Loss 5.732550\n",
      "    Params:  tensor([  4.3697, -11.6555])\n",
      "    Grad  :  tensor([-0.1698,  0.9613])\n",
      "Epoch 667,Loss 5.723031\n",
      "Epoch 667, Loss 5.723031\n",
      "    Params:  tensor([  4.3714, -11.6651])\n",
      "    Grad  :  tensor([-0.1695,  0.9597])\n",
      "Epoch 668,Loss 5.713539\n",
      "Epoch 668, Loss 5.713539\n",
      "    Params:  tensor([  4.3731, -11.6746])\n",
      "    Grad  :  tensor([-0.1693,  0.9581])\n",
      "Epoch 669,Loss 5.704083\n",
      "Epoch 669, Loss 5.704083\n",
      "    Params:  tensor([  4.3748, -11.6842])\n",
      "    Grad  :  tensor([-0.1690,  0.9564])\n",
      "Epoch 670,Loss 5.694659\n",
      "Epoch 670, Loss 5.694659\n",
      "    Params:  tensor([  4.3765, -11.6937])\n",
      "    Grad  :  tensor([-0.1687,  0.9548])\n",
      "Epoch 671,Loss 5.685266\n",
      "Epoch 671, Loss 5.685266\n",
      "    Params:  tensor([  4.3782, -11.7033])\n",
      "    Grad  :  tensor([-0.1684,  0.9532])\n",
      "Epoch 672,Loss 5.675904\n",
      "Epoch 672, Loss 5.675904\n",
      "    Params:  tensor([  4.3799, -11.7128])\n",
      "    Grad  :  tensor([-0.1681,  0.9516])\n",
      "Epoch 673,Loss 5.666573\n",
      "Epoch 673, Loss 5.666573\n",
      "    Params:  tensor([  4.3816, -11.7223])\n",
      "    Grad  :  tensor([-0.1678,  0.9499])\n",
      "Epoch 674,Loss 5.657277\n",
      "Epoch 674, Loss 5.657277\n",
      "    Params:  tensor([  4.3832, -11.7318])\n",
      "    Grad  :  tensor([-0.1675,  0.9483])\n",
      "Epoch 675,Loss 5.648010\n",
      "Epoch 675, Loss 5.648010\n",
      "    Params:  tensor([  4.3849, -11.7412])\n",
      "    Grad  :  tensor([-0.1673,  0.9467])\n",
      "Epoch 676,Loss 5.638776\n",
      "Epoch 676, Loss 5.638776\n",
      "    Params:  tensor([  4.3866, -11.7507])\n",
      "    Grad  :  tensor([-0.1670,  0.9451])\n",
      "Epoch 677,Loss 5.629574\n",
      "Epoch 677, Loss 5.629574\n",
      "    Params:  tensor([  4.3882, -11.7601])\n",
      "    Grad  :  tensor([-0.1667,  0.9435])\n",
      "Epoch 678,Loss 5.620402\n",
      "Epoch 678, Loss 5.620402\n",
      "    Params:  tensor([  4.3899, -11.7696])\n",
      "    Grad  :  tensor([-0.1664,  0.9419])\n",
      "Epoch 679,Loss 5.611260\n",
      "Epoch 679, Loss 5.611260\n",
      "    Params:  tensor([  4.3916, -11.7790])\n",
      "    Grad  :  tensor([-0.1661,  0.9403])\n",
      "Epoch 680,Loss 5.602149\n",
      "Epoch 680, Loss 5.602149\n",
      "    Params:  tensor([  4.3932, -11.7883])\n",
      "    Grad  :  tensor([-0.1658,  0.9387])\n",
      "Epoch 681,Loss 5.593071\n",
      "Epoch 681, Loss 5.593071\n",
      "    Params:  tensor([  4.3949, -11.7977])\n",
      "    Grad  :  tensor([-0.1656,  0.9371])\n",
      "Epoch 682,Loss 5.584022\n",
      "Epoch 682, Loss 5.584022\n",
      "    Params:  tensor([  4.3965, -11.8071])\n",
      "    Grad  :  tensor([-0.1653,  0.9355])\n",
      "Epoch 683,Loss 5.575005\n",
      "Epoch 683, Loss 5.575005\n",
      "    Params:  tensor([  4.3982, -11.8164])\n",
      "    Grad  :  tensor([-0.1650,  0.9339])\n",
      "Epoch 684,Loss 5.566019\n",
      "Epoch 684, Loss 5.566019\n",
      "    Params:  tensor([  4.3998, -11.8257])\n",
      "    Grad  :  tensor([-0.1647,  0.9323])\n",
      "Epoch 685,Loss 5.557063\n",
      "Epoch 685, Loss 5.557063\n",
      "    Params:  tensor([  4.4015, -11.8350])\n",
      "    Grad  :  tensor([-0.1644,  0.9308])\n",
      "Epoch 686,Loss 5.548136\n",
      "Epoch 686, Loss 5.548136\n",
      "    Params:  tensor([  4.4031, -11.8443])\n",
      "    Grad  :  tensor([-0.1641,  0.9292])\n",
      "Epoch 687,Loss 5.539241\n",
      "Epoch 687, Loss 5.539241\n",
      "    Params:  tensor([  4.4048, -11.8536])\n",
      "    Grad  :  tensor([-0.1639,  0.9276])\n",
      "Epoch 688,Loss 5.530376\n",
      "Epoch 688, Loss 5.530376\n",
      "    Params:  tensor([  4.4064, -11.8629])\n",
      "    Grad  :  tensor([-0.1636,  0.9260])\n",
      "Epoch 689,Loss 5.521540\n",
      "Epoch 689, Loss 5.521540\n",
      "    Params:  tensor([  4.4080, -11.8721])\n",
      "    Grad  :  tensor([-0.1633,  0.9245])\n",
      "Epoch 690,Loss 5.512734\n",
      "Epoch 690, Loss 5.512734\n",
      "    Params:  tensor([  4.4097, -11.8813])\n",
      "    Grad  :  tensor([-0.1630,  0.9229])\n",
      "Epoch 691,Loss 5.503958\n",
      "Epoch 691, Loss 5.503958\n",
      "    Params:  tensor([  4.4113, -11.8906])\n",
      "    Grad  :  tensor([-0.1628,  0.9213])\n",
      "Epoch 692,Loss 5.495212\n",
      "Epoch 692, Loss 5.495212\n",
      "    Params:  tensor([  4.4129, -11.8998])\n",
      "    Grad  :  tensor([-0.1625,  0.9197])\n",
      "Epoch 693,Loss 5.486496\n",
      "Epoch 693, Loss 5.486496\n",
      "    Params:  tensor([  4.4145, -11.9089])\n",
      "    Grad  :  tensor([-0.1622,  0.9182])\n",
      "Epoch 694,Loss 5.477808\n",
      "Epoch 694, Loss 5.477808\n",
      "    Params:  tensor([  4.4161, -11.9181])\n",
      "    Grad  :  tensor([-0.1619,  0.9166])\n",
      "Epoch 695,Loss 5.469152\n",
      "Epoch 695, Loss 5.469152\n",
      "    Params:  tensor([  4.4178, -11.9272])\n",
      "    Grad  :  tensor([-0.1617,  0.9151])\n",
      "Epoch 696,Loss 5.460525\n",
      "Epoch 696, Loss 5.460525\n",
      "    Params:  tensor([  4.4194, -11.9364])\n",
      "    Grad  :  tensor([-0.1614,  0.9135])\n",
      "Epoch 697,Loss 5.451928\n",
      "Epoch 697, Loss 5.451928\n",
      "    Params:  tensor([  4.4210, -11.9455])\n",
      "    Grad  :  tensor([-0.1611,  0.9120])\n",
      "Epoch 698,Loss 5.443358\n",
      "Epoch 698, Loss 5.443358\n",
      "    Params:  tensor([  4.4226, -11.9546])\n",
      "    Grad  :  tensor([-0.1608,  0.9104])\n",
      "Epoch 699,Loss 5.434819\n",
      "Epoch 699, Loss 5.434819\n",
      "    Params:  tensor([  4.4242, -11.9637])\n",
      "    Grad  :  tensor([-0.1605,  0.9089])\n",
      "Epoch 700,Loss 5.426309\n",
      "Epoch 700, Loss 5.426309\n",
      "    Params:  tensor([  4.4258, -11.9728])\n",
      "    Grad  :  tensor([-0.1603,  0.9073])\n",
      "Epoch 701,Loss 5.417827\n",
      "Epoch 701, Loss 5.417827\n",
      "    Params:  tensor([  4.4274, -11.9818])\n",
      "    Grad  :  tensor([-0.1600,  0.9058])\n",
      "Epoch 702,Loss 5.409372\n",
      "Epoch 702, Loss 5.409372\n",
      "    Params:  tensor([  4.4290, -11.9909])\n",
      "    Grad  :  tensor([-0.1597,  0.9042])\n",
      "Epoch 703,Loss 5.400949\n",
      "Epoch 703, Loss 5.400949\n",
      "    Params:  tensor([  4.4306, -11.9999])\n",
      "    Grad  :  tensor([-0.1595,  0.9027])\n",
      "Epoch 704,Loss 5.392550\n",
      "Epoch 704, Loss 5.392550\n",
      "    Params:  tensor([  4.4322, -12.0089])\n",
      "    Grad  :  tensor([-0.1592,  0.9012])\n",
      "Epoch 705,Loss 5.384184\n",
      "Epoch 705, Loss 5.384184\n",
      "    Params:  tensor([  4.4338, -12.0179])\n",
      "    Grad  :  tensor([-0.1589,  0.8996])\n",
      "Epoch 706,Loss 5.375846\n",
      "Epoch 706, Loss 5.375846\n",
      "    Params:  tensor([  4.4354, -12.0269])\n",
      "    Grad  :  tensor([-0.1586,  0.8981])\n",
      "Epoch 707,Loss 5.367537\n",
      "Epoch 707, Loss 5.367537\n",
      "    Params:  tensor([  4.4369, -12.0359])\n",
      "    Grad  :  tensor([-0.1584,  0.8966])\n",
      "Epoch 708,Loss 5.359253\n",
      "Epoch 708, Loss 5.359253\n",
      "    Params:  tensor([  4.4385, -12.0448])\n",
      "    Grad  :  tensor([-0.1581,  0.8951])\n",
      "Epoch 709,Loss 5.350999\n",
      "Epoch 709, Loss 5.350999\n",
      "    Params:  tensor([  4.4401, -12.0537])\n",
      "    Grad  :  tensor([-0.1578,  0.8935])\n",
      "Epoch 710,Loss 5.342772\n",
      "Epoch 710, Loss 5.342772\n",
      "    Params:  tensor([  4.4417, -12.0627])\n",
      "    Grad  :  tensor([-0.1576,  0.8920])\n",
      "Epoch 711,Loss 5.334575\n",
      "Epoch 711, Loss 5.334575\n",
      "    Params:  tensor([  4.4433, -12.0716])\n",
      "    Grad  :  tensor([-0.1573,  0.8905])\n",
      "Epoch 712,Loss 5.326402\n",
      "Epoch 712, Loss 5.326402\n",
      "    Params:  tensor([  4.4448, -12.0805])\n",
      "    Grad  :  tensor([-0.1570,  0.8890])\n",
      "Epoch 713,Loss 5.318260\n",
      "Epoch 713, Loss 5.318260\n",
      "    Params:  tensor([  4.4464, -12.0893])\n",
      "    Grad  :  tensor([-0.1568,  0.8875])\n",
      "Epoch 714,Loss 5.310144\n",
      "Epoch 714, Loss 5.310144\n",
      "    Params:  tensor([  4.4480, -12.0982])\n",
      "    Grad  :  tensor([-0.1565,  0.8860])\n",
      "Epoch 715,Loss 5.302055\n",
      "Epoch 715, Loss 5.302055\n",
      "    Params:  tensor([  4.4495, -12.1070])\n",
      "    Grad  :  tensor([-0.1562,  0.8845])\n",
      "Epoch 716,Loss 5.293994\n",
      "Epoch 716, Loss 5.293994\n",
      "    Params:  tensor([  4.4511, -12.1159])\n",
      "    Grad  :  tensor([-0.1560,  0.8830])\n",
      "Epoch 717,Loss 5.285964\n",
      "Epoch 717, Loss 5.285964\n",
      "    Params:  tensor([  4.4526, -12.1247])\n",
      "    Grad  :  tensor([-0.1557,  0.8815])\n",
      "Epoch 718,Loss 5.277958\n",
      "Epoch 718, Loss 5.277958\n",
      "    Params:  tensor([  4.4542, -12.1335])\n",
      "    Grad  :  tensor([-0.1555,  0.8800])\n",
      "Epoch 719,Loss 5.269979\n",
      "Epoch 719, Loss 5.269979\n",
      "    Params:  tensor([  4.4557, -12.1423])\n",
      "    Grad  :  tensor([-0.1552,  0.8785])\n",
      "Epoch 720,Loss 5.262027\n",
      "Epoch 720, Loss 5.262027\n",
      "    Params:  tensor([  4.4573, -12.1510])\n",
      "    Grad  :  tensor([-0.1549,  0.8770])\n",
      "Epoch 721,Loss 5.254103\n",
      "Epoch 721, Loss 5.254103\n",
      "    Params:  tensor([  4.4588, -12.1598])\n",
      "    Grad  :  tensor([-0.1547,  0.8755])\n",
      "Epoch 722,Loss 5.246205\n",
      "Epoch 722, Loss 5.246205\n",
      "    Params:  tensor([  4.4604, -12.1685])\n",
      "    Grad  :  tensor([-0.1544,  0.8740])\n",
      "Epoch 723,Loss 5.238335\n",
      "Epoch 723, Loss 5.238335\n",
      "    Params:  tensor([  4.4619, -12.1773])\n",
      "    Grad  :  tensor([-0.1541,  0.8725])\n",
      "Epoch 724,Loss 5.230492\n",
      "Epoch 724, Loss 5.230492\n",
      "    Params:  tensor([  4.4635, -12.1860])\n",
      "    Grad  :  tensor([-0.1539,  0.8710])\n",
      "Epoch 725,Loss 5.222674\n",
      "Epoch 725, Loss 5.222674\n",
      "    Params:  tensor([  4.4650, -12.1947])\n",
      "    Grad  :  tensor([-0.1536,  0.8696])\n",
      "Epoch 726,Loss 5.214881\n",
      "Epoch 726, Loss 5.214881\n",
      "    Params:  tensor([  4.4665, -12.2033])\n",
      "    Grad  :  tensor([-0.1533,  0.8681])\n",
      "Epoch 727,Loss 5.207120\n",
      "Epoch 727, Loss 5.207120\n",
      "    Params:  tensor([  4.4681, -12.2120])\n",
      "    Grad  :  tensor([-0.1531,  0.8666])\n",
      "Epoch 728,Loss 5.199381\n",
      "Epoch 728, Loss 5.199381\n",
      "    Params:  tensor([  4.4696, -12.2207])\n",
      "    Grad  :  tensor([-0.1528,  0.8651])\n",
      "Epoch 729,Loss 5.191670\n",
      "Epoch 729, Loss 5.191670\n",
      "    Params:  tensor([  4.4711, -12.2293])\n",
      "    Grad  :  tensor([-0.1526,  0.8637])\n",
      "Epoch 730,Loss 5.183985\n",
      "Epoch 730, Loss 5.183985\n",
      "    Params:  tensor([  4.4726, -12.2379])\n",
      "    Grad  :  tensor([-0.1523,  0.8622])\n",
      "Epoch 731,Loss 5.176324\n",
      "Epoch 731, Loss 5.176324\n",
      "    Params:  tensor([  4.4742, -12.2465])\n",
      "    Grad  :  tensor([-0.1520,  0.8607])\n",
      "Epoch 732,Loss 5.168688\n",
      "Epoch 732, Loss 5.168688\n",
      "    Params:  tensor([  4.4757, -12.2551])\n",
      "    Grad  :  tensor([-0.1518,  0.8593])\n",
      "Epoch 733,Loss 5.161084\n",
      "Epoch 733, Loss 5.161084\n",
      "    Params:  tensor([  4.4772, -12.2637])\n",
      "    Grad  :  tensor([-0.1515,  0.8578])\n",
      "Epoch 734,Loss 5.153500\n",
      "Epoch 734, Loss 5.153500\n",
      "    Params:  tensor([  4.4787, -12.2723])\n",
      "    Grad  :  tensor([-0.1513,  0.8564])\n",
      "Epoch 735,Loss 5.145944\n",
      "Epoch 735, Loss 5.145944\n",
      "    Params:  tensor([  4.4802, -12.2808])\n",
      "    Grad  :  tensor([-0.1510,  0.8549])\n",
      "Epoch 736,Loss 5.138413\n",
      "Epoch 736, Loss 5.138413\n",
      "    Params:  tensor([  4.4817, -12.2893])\n",
      "    Grad  :  tensor([-0.1508,  0.8535])\n",
      "Epoch 737,Loss 5.130910\n",
      "Epoch 737, Loss 5.130910\n",
      "    Params:  tensor([  4.4832, -12.2979])\n",
      "    Grad  :  tensor([-0.1505,  0.8520])\n",
      "Epoch 738,Loss 5.123428\n",
      "Epoch 738, Loss 5.123428\n",
      "    Params:  tensor([  4.4847, -12.3064])\n",
      "    Grad  :  tensor([-0.1502,  0.8506])\n",
      "Epoch 739,Loss 5.115978\n",
      "Epoch 739, Loss 5.115978\n",
      "    Params:  tensor([  4.4862, -12.3149])\n",
      "    Grad  :  tensor([-0.1500,  0.8491])\n",
      "Epoch 740,Loss 5.108547\n",
      "Epoch 740, Loss 5.108547\n",
      "    Params:  tensor([  4.4877, -12.3233])\n",
      "    Grad  :  tensor([-0.1497,  0.8477])\n",
      "Epoch 741,Loss 5.101143\n",
      "Epoch 741, Loss 5.101143\n",
      "    Params:  tensor([  4.4892, -12.3318])\n",
      "    Grad  :  tensor([-0.1495,  0.8462])\n",
      "Epoch 742,Loss 5.093765\n",
      "Epoch 742, Loss 5.093765\n",
      "    Params:  tensor([  4.4907, -12.3402])\n",
      "    Grad  :  tensor([-0.1492,  0.8448])\n",
      "Epoch 743,Loss 5.086414\n",
      "Epoch 743, Loss 5.086414\n",
      "    Params:  tensor([  4.4922, -12.3487])\n",
      "    Grad  :  tensor([-0.1490,  0.8434])\n",
      "Epoch 744,Loss 5.079086\n",
      "Epoch 744, Loss 5.079086\n",
      "    Params:  tensor([  4.4937, -12.3571])\n",
      "    Grad  :  tensor([-0.1487,  0.8419])\n",
      "Epoch 745,Loss 5.071781\n",
      "Epoch 745, Loss 5.071781\n",
      "    Params:  tensor([  4.4952, -12.3655])\n",
      "    Grad  :  tensor([-0.1485,  0.8405])\n",
      "Epoch 746,Loss 5.064505\n",
      "Epoch 746, Loss 5.064505\n",
      "    Params:  tensor([  4.4967, -12.3739])\n",
      "    Grad  :  tensor([-0.1482,  0.8391])\n",
      "Epoch 747,Loss 5.057247\n",
      "Epoch 747, Loss 5.057247\n",
      "    Params:  tensor([  4.4981, -12.3823])\n",
      "    Grad  :  tensor([-0.1480,  0.8376])\n",
      "Epoch 748,Loss 5.050021\n",
      "Epoch 748, Loss 5.050021\n",
      "    Params:  tensor([  4.4996, -12.3906])\n",
      "    Grad  :  tensor([-0.1477,  0.8362])\n",
      "Epoch 749,Loss 5.042817\n",
      "Epoch 749, Loss 5.042817\n",
      "    Params:  tensor([  4.5011, -12.3990])\n",
      "    Grad  :  tensor([-0.1475,  0.8348])\n",
      "Epoch 750,Loss 5.035636\n",
      "Epoch 750, Loss 5.035636\n",
      "    Params:  tensor([  4.5026, -12.4073])\n",
      "    Grad  :  tensor([-0.1472,  0.8334])\n",
      "Epoch 751,Loss 5.028476\n",
      "Epoch 751, Loss 5.028476\n",
      "    Params:  tensor([  4.5040, -12.4156])\n",
      "    Grad  :  tensor([-0.1470,  0.8320])\n",
      "Epoch 752,Loss 5.021346\n",
      "Epoch 752, Loss 5.021346\n",
      "    Params:  tensor([  4.5055, -12.4239])\n",
      "    Grad  :  tensor([-0.1467,  0.8305])\n",
      "Epoch 753,Loss 5.014240\n",
      "Epoch 753, Loss 5.014240\n",
      "    Params:  tensor([  4.5070, -12.4322])\n",
      "    Grad  :  tensor([-0.1465,  0.8291])\n",
      "Epoch 754,Loss 5.007157\n",
      "Epoch 754, Loss 5.007157\n",
      "    Params:  tensor([  4.5084, -12.4405])\n",
      "    Grad  :  tensor([-0.1462,  0.8277])\n",
      "Epoch 755,Loss 5.000099\n",
      "Epoch 755, Loss 5.000099\n",
      "    Params:  tensor([  4.5099, -12.4488])\n",
      "    Grad  :  tensor([-0.1460,  0.8263])\n",
      "Epoch 756,Loss 4.993064\n",
      "Epoch 756, Loss 4.993064\n",
      "    Params:  tensor([  4.5113, -12.4570])\n",
      "    Grad  :  tensor([-0.1457,  0.8249])\n",
      "Epoch 757,Loss 4.986051\n",
      "Epoch 757, Loss 4.986051\n",
      "    Params:  tensor([  4.5128, -12.4653])\n",
      "    Grad  :  tensor([-0.1455,  0.8235])\n",
      "Epoch 758,Loss 4.979064\n",
      "Epoch 758, Loss 4.979064\n",
      "    Params:  tensor([  4.5143, -12.4735])\n",
      "    Grad  :  tensor([-0.1452,  0.8221])\n",
      "Epoch 759,Loss 4.972100\n",
      "Epoch 759, Loss 4.972100\n",
      "    Params:  tensor([  4.5157, -12.4817])\n",
      "    Grad  :  tensor([-0.1450,  0.8207])\n",
      "Epoch 760,Loss 4.965159\n",
      "Epoch 760, Loss 4.965159\n",
      "    Params:  tensor([  4.5172, -12.4899])\n",
      "    Grad  :  tensor([-0.1447,  0.8193])\n",
      "Epoch 761,Loss 4.958245\n",
      "Epoch 761, Loss 4.958245\n",
      "    Params:  tensor([  4.5186, -12.4981])\n",
      "    Grad  :  tensor([-0.1445,  0.8179])\n",
      "Epoch 762,Loss 4.951351\n",
      "Epoch 762, Loss 4.951351\n",
      "    Params:  tensor([  4.5200, -12.5062])\n",
      "    Grad  :  tensor([-0.1443,  0.8165])\n",
      "Epoch 763,Loss 4.944479\n",
      "Epoch 763, Loss 4.944479\n",
      "    Params:  tensor([  4.5215, -12.5144])\n",
      "    Grad  :  tensor([-0.1440,  0.8152])\n",
      "Epoch 764,Loss 4.937633\n",
      "Epoch 764, Loss 4.937633\n",
      "    Params:  tensor([  4.5229, -12.5225])\n",
      "    Grad  :  tensor([-0.1438,  0.8138])\n",
      "Epoch 765,Loss 4.930812\n",
      "Epoch 765, Loss 4.930812\n",
      "    Params:  tensor([  4.5244, -12.5306])\n",
      "    Grad  :  tensor([-0.1435,  0.8124])\n",
      "Epoch 766,Loss 4.924009\n",
      "Epoch 766, Loss 4.924009\n",
      "    Params:  tensor([  4.5258, -12.5387])\n",
      "    Grad  :  tensor([-0.1433,  0.8110])\n",
      "Epoch 767,Loss 4.917234\n",
      "Epoch 767, Loss 4.917234\n",
      "    Params:  tensor([  4.5272, -12.5468])\n",
      "    Grad  :  tensor([-0.1430,  0.8096])\n",
      "Epoch 768,Loss 4.910480\n",
      "Epoch 768, Loss 4.910480\n",
      "    Params:  tensor([  4.5286, -12.5549])\n",
      "    Grad  :  tensor([-0.1428,  0.8083])\n",
      "Epoch 769,Loss 4.903749\n",
      "Epoch 769, Loss 4.903749\n",
      "    Params:  tensor([  4.5301, -12.5630])\n",
      "    Grad  :  tensor([-0.1426,  0.8069])\n",
      "Epoch 770,Loss 4.897040\n",
      "Epoch 770, Loss 4.897040\n",
      "    Params:  tensor([  4.5315, -12.5711])\n",
      "    Grad  :  tensor([-0.1423,  0.8055])\n",
      "Epoch 771,Loss 4.890356\n",
      "Epoch 771, Loss 4.890356\n",
      "    Params:  tensor([  4.5329, -12.5791])\n",
      "    Grad  :  tensor([-0.1420,  0.8042])\n",
      "Epoch 772,Loss 4.883692\n",
      "Epoch 772, Loss 4.883692\n",
      "    Params:  tensor([  4.5343, -12.5871])\n",
      "    Grad  :  tensor([-0.1418,  0.8028])\n",
      "Epoch 773,Loss 4.877052\n",
      "Epoch 773, Loss 4.877052\n",
      "    Params:  tensor([  4.5357, -12.5951])\n",
      "    Grad  :  tensor([-0.1416,  0.8014])\n",
      "Epoch 774,Loss 4.870436\n",
      "Epoch 774, Loss 4.870436\n",
      "    Params:  tensor([  4.5372, -12.6031])\n",
      "    Grad  :  tensor([-0.1413,  0.8001])\n",
      "Epoch 775,Loss 4.863839\n",
      "Epoch 775, Loss 4.863839\n",
      "    Params:  tensor([  4.5386, -12.6111])\n",
      "    Grad  :  tensor([-0.1411,  0.7987])\n",
      "Epoch 776,Loss 4.857268\n",
      "Epoch 776, Loss 4.857268\n",
      "    Params:  tensor([  4.5400, -12.6191])\n",
      "    Grad  :  tensor([-0.1408,  0.7973])\n",
      "Epoch 777,Loss 4.850718\n",
      "Epoch 777, Loss 4.850718\n",
      "    Params:  tensor([  4.5414, -12.6271])\n",
      "    Grad  :  tensor([-0.1406,  0.7960])\n",
      "Epoch 778,Loss 4.844189\n",
      "Epoch 778, Loss 4.844189\n",
      "    Params:  tensor([  4.5428, -12.6350])\n",
      "    Grad  :  tensor([-0.1404,  0.7946])\n",
      "Epoch 779,Loss 4.837683\n",
      "Epoch 779, Loss 4.837683\n",
      "    Params:  tensor([  4.5442, -12.6429])\n",
      "    Grad  :  tensor([-0.1401,  0.7933])\n",
      "Epoch 780,Loss 4.831196\n",
      "Epoch 780, Loss 4.831196\n",
      "    Params:  tensor([  4.5456, -12.6509])\n",
      "    Grad  :  tensor([-0.1399,  0.7919])\n",
      "Epoch 781,Loss 4.824737\n",
      "Epoch 781, Loss 4.824737\n",
      "    Params:  tensor([  4.5470, -12.6588])\n",
      "    Grad  :  tensor([-0.1397,  0.7906])\n",
      "Epoch 782,Loss 4.818298\n",
      "Epoch 782, Loss 4.818298\n",
      "    Params:  tensor([  4.5484, -12.6667])\n",
      "    Grad  :  tensor([-0.1394,  0.7892])\n",
      "Epoch 783,Loss 4.811879\n",
      "Epoch 783, Loss 4.811879\n",
      "    Params:  tensor([  4.5498, -12.6745])\n",
      "    Grad  :  tensor([-0.1392,  0.7879])\n",
      "Epoch 784,Loss 4.805481\n",
      "Epoch 784, Loss 4.805481\n",
      "    Params:  tensor([  4.5512, -12.6824])\n",
      "    Grad  :  tensor([-0.1389,  0.7866])\n",
      "Epoch 785,Loss 4.799106\n",
      "Epoch 785, Loss 4.799106\n",
      "    Params:  tensor([  4.5525, -12.6902])\n",
      "    Grad  :  tensor([-0.1387,  0.7852])\n",
      "Epoch 786,Loss 4.792755\n",
      "Epoch 786, Loss 4.792755\n",
      "    Params:  tensor([  4.5539, -12.6981])\n",
      "    Grad  :  tensor([-0.1385,  0.7839])\n",
      "Epoch 787,Loss 4.786422\n",
      "Epoch 787, Loss 4.786422\n",
      "    Params:  tensor([  4.5553, -12.7059])\n",
      "    Grad  :  tensor([-0.1382,  0.7826])\n",
      "Epoch 788,Loss 4.780112\n",
      "Epoch 788, Loss 4.780112\n",
      "    Params:  tensor([  4.5567, -12.7137])\n",
      "    Grad  :  tensor([-0.1380,  0.7812])\n",
      "Epoch 789,Loss 4.773824\n",
      "Epoch 789, Loss 4.773824\n",
      "    Params:  tensor([  4.5581, -12.7215])\n",
      "    Grad  :  tensor([-0.1378,  0.7799])\n",
      "Epoch 790,Loss 4.767558\n",
      "Epoch 790, Loss 4.767558\n",
      "    Params:  tensor([  4.5594, -12.7293])\n",
      "    Grad  :  tensor([-0.1375,  0.7786])\n",
      "Epoch 791,Loss 4.761312\n",
      "Epoch 791, Loss 4.761312\n",
      "    Params:  tensor([  4.5608, -12.7371])\n",
      "    Grad  :  tensor([-0.1373,  0.7773])\n",
      "Epoch 792,Loss 4.755087\n",
      "Epoch 792, Loss 4.755087\n",
      "    Params:  tensor([  4.5622, -12.7448])\n",
      "    Grad  :  tensor([-0.1371,  0.7759])\n",
      "Epoch 793,Loss 4.748885\n",
      "Epoch 793, Loss 4.748885\n",
      "    Params:  tensor([  4.5636, -12.7526])\n",
      "    Grad  :  tensor([-0.1368,  0.7746])\n",
      "Epoch 794,Loss 4.742700\n",
      "Epoch 794, Loss 4.742700\n",
      "    Params:  tensor([  4.5649, -12.7603])\n",
      "    Grad  :  tensor([-0.1366,  0.7733])\n",
      "Epoch 795,Loss 4.736537\n",
      "Epoch 795, Loss 4.736537\n",
      "    Params:  tensor([  4.5663, -12.7680])\n",
      "    Grad  :  tensor([-0.1364,  0.7720])\n",
      "Epoch 796,Loss 4.730397\n",
      "Epoch 796, Loss 4.730397\n",
      "    Params:  tensor([  4.5677, -12.7758])\n",
      "    Grad  :  tensor([-0.1361,  0.7707])\n",
      "Epoch 797,Loss 4.724279\n",
      "Epoch 797, Loss 4.724279\n",
      "    Params:  tensor([  4.5690, -12.7834])\n",
      "    Grad  :  tensor([-0.1359,  0.7694])\n",
      "Epoch 798,Loss 4.718181\n",
      "Epoch 798, Loss 4.718181\n",
      "    Params:  tensor([  4.5704, -12.7911])\n",
      "    Grad  :  tensor([-0.1357,  0.7681])\n",
      "Epoch 799,Loss 4.712101\n",
      "Epoch 799, Loss 4.712101\n",
      "    Params:  tensor([  4.5717, -12.7988])\n",
      "    Grad  :  tensor([-0.1354,  0.7668])\n",
      "Epoch 800,Loss 4.706046\n",
      "Epoch 800, Loss 4.706046\n",
      "    Params:  tensor([  4.5731, -12.8064])\n",
      "    Grad  :  tensor([-0.1352,  0.7655])\n",
      "Epoch 801,Loss 4.700009\n",
      "Epoch 801, Loss 4.700009\n",
      "    Params:  tensor([  4.5744, -12.8141])\n",
      "    Grad  :  tensor([-0.1350,  0.7642])\n",
      "Epoch 802,Loss 4.693990\n",
      "Epoch 802, Loss 4.693990\n",
      "    Params:  tensor([  4.5758, -12.8217])\n",
      "    Grad  :  tensor([-0.1347,  0.7629])\n",
      "Epoch 803,Loss 4.687995\n",
      "Epoch 803, Loss 4.687995\n",
      "    Params:  tensor([  4.5771, -12.8293])\n",
      "    Grad  :  tensor([-0.1345,  0.7616])\n",
      "Epoch 804,Loss 4.682020\n",
      "Epoch 804, Loss 4.682020\n",
      "    Params:  tensor([  4.5785, -12.8369])\n",
      "    Grad  :  tensor([-0.1343,  0.7603])\n",
      "Epoch 805,Loss 4.676063\n",
      "Epoch 805, Loss 4.676063\n",
      "    Params:  tensor([  4.5798, -12.8445])\n",
      "    Grad  :  tensor([-0.1341,  0.7590])\n",
      "Epoch 806,Loss 4.670130\n",
      "Epoch 806, Loss 4.670130\n",
      "    Params:  tensor([  4.5811, -12.8521])\n",
      "    Grad  :  tensor([-0.1338,  0.7577])\n",
      "Epoch 807,Loss 4.664214\n",
      "Epoch 807, Loss 4.664214\n",
      "    Params:  tensor([  4.5825, -12.8597])\n",
      "    Grad  :  tensor([-0.1336,  0.7564])\n",
      "Epoch 808,Loss 4.658319\n",
      "Epoch 808, Loss 4.658319\n",
      "    Params:  tensor([  4.5838, -12.8672])\n",
      "    Grad  :  tensor([-0.1334,  0.7551])\n",
      "Epoch 809,Loss 4.652445\n",
      "Epoch 809, Loss 4.652445\n",
      "    Params:  tensor([  4.5851, -12.8748])\n",
      "    Grad  :  tensor([-0.1332,  0.7538])\n",
      "Epoch 810,Loss 4.646592\n",
      "Epoch 810, Loss 4.646592\n",
      "    Params:  tensor([  4.5865, -12.8823])\n",
      "    Grad  :  tensor([-0.1330,  0.7526])\n",
      "Epoch 811,Loss 4.640754\n",
      "Epoch 811, Loss 4.640754\n",
      "    Params:  tensor([  4.5878, -12.8898])\n",
      "    Grad  :  tensor([-0.1327,  0.7513])\n",
      "Epoch 812,Loss 4.634938\n",
      "Epoch 812, Loss 4.634938\n",
      "    Params:  tensor([  4.5891, -12.8973])\n",
      "    Grad  :  tensor([-0.1325,  0.7500])\n",
      "Epoch 813,Loss 4.629142\n",
      "Epoch 813, Loss 4.629142\n",
      "    Params:  tensor([  4.5904, -12.9048])\n",
      "    Grad  :  tensor([-0.1323,  0.7487])\n",
      "Epoch 814,Loss 4.623367\n",
      "Epoch 814, Loss 4.623367\n",
      "    Params:  tensor([  4.5918, -12.9123])\n",
      "    Grad  :  tensor([-0.1320,  0.7475])\n",
      "Epoch 815,Loss 4.617611\n",
      "Epoch 815, Loss 4.617611\n",
      "    Params:  tensor([  4.5931, -12.9197])\n",
      "    Grad  :  tensor([-0.1318,  0.7462])\n",
      "Epoch 816,Loss 4.611872\n",
      "Epoch 816, Loss 4.611872\n",
      "    Params:  tensor([  4.5944, -12.9272])\n",
      "    Grad  :  tensor([-0.1316,  0.7449])\n",
      "Epoch 817,Loss 4.606156\n",
      "Epoch 817, Loss 4.606156\n",
      "    Params:  tensor([  4.5957, -12.9346])\n",
      "    Grad  :  tensor([-0.1314,  0.7437])\n",
      "Epoch 818,Loss 4.600458\n",
      "Epoch 818, Loss 4.600458\n",
      "    Params:  tensor([  4.5970, -12.9420])\n",
      "    Grad  :  tensor([-0.1311,  0.7424])\n",
      "Epoch 819,Loss 4.594780\n",
      "Epoch 819, Loss 4.594780\n",
      "    Params:  tensor([  4.5983, -12.9494])\n",
      "    Grad  :  tensor([-0.1309,  0.7411])\n",
      "Epoch 820,Loss 4.589119\n",
      "Epoch 820, Loss 4.589119\n",
      "    Params:  tensor([  4.5996, -12.9568])\n",
      "    Grad  :  tensor([-0.1307,  0.7399])\n",
      "Epoch 821,Loss 4.583479\n",
      "Epoch 821, Loss 4.583479\n",
      "    Params:  tensor([  4.6009, -12.9642])\n",
      "    Grad  :  tensor([-0.1305,  0.7386])\n",
      "Epoch 822,Loss 4.577857\n",
      "Epoch 822, Loss 4.577857\n",
      "    Params:  tensor([  4.6022, -12.9716])\n",
      "    Grad  :  tensor([-0.1303,  0.7374])\n",
      "Epoch 823,Loss 4.572256\n",
      "Epoch 823, Loss 4.572256\n",
      "    Params:  tensor([  4.6035, -12.9790])\n",
      "    Grad  :  tensor([-0.1300,  0.7361])\n",
      "Epoch 824,Loss 4.566675\n",
      "Epoch 824, Loss 4.566675\n",
      "    Params:  tensor([  4.6048, -12.9863])\n",
      "    Grad  :  tensor([-0.1298,  0.7349])\n",
      "Epoch 825,Loss 4.561108\n",
      "Epoch 825, Loss 4.561108\n",
      "    Params:  tensor([  4.6061, -12.9936])\n",
      "    Grad  :  tensor([-0.1296,  0.7336])\n",
      "Epoch 826,Loss 4.555565\n",
      "Epoch 826, Loss 4.555565\n",
      "    Params:  tensor([  4.6074, -13.0010])\n",
      "    Grad  :  tensor([-0.1294,  0.7324])\n",
      "Epoch 827,Loss 4.550039\n",
      "Epoch 827, Loss 4.550039\n",
      "    Params:  tensor([  4.6087, -13.0083])\n",
      "    Grad  :  tensor([-0.1292,  0.7311])\n",
      "Epoch 828,Loss 4.544534\n",
      "Epoch 828, Loss 4.544534\n",
      "    Params:  tensor([  4.6100, -13.0156])\n",
      "    Grad  :  tensor([-0.1289,  0.7299])\n",
      "Epoch 829,Loss 4.539044\n",
      "Epoch 829, Loss 4.539044\n",
      "    Params:  tensor([  4.6113, -13.0229])\n",
      "    Grad  :  tensor([-0.1287,  0.7286])\n",
      "Epoch 830,Loss 4.533575\n",
      "Epoch 830, Loss 4.533575\n",
      "    Params:  tensor([  4.6126, -13.0301])\n",
      "    Grad  :  tensor([-0.1285,  0.7274])\n",
      "Epoch 831,Loss 4.528122\n",
      "Epoch 831, Loss 4.528122\n",
      "    Params:  tensor([  4.6139, -13.0374])\n",
      "    Grad  :  tensor([-0.1283,  0.7262])\n",
      "Epoch 832,Loss 4.522691\n",
      "Epoch 832, Loss 4.522691\n",
      "    Params:  tensor([  4.6152, -13.0446])\n",
      "    Grad  :  tensor([-0.1280,  0.7249])\n",
      "Epoch 833,Loss 4.517276\n",
      "Epoch 833, Loss 4.517276\n",
      "    Params:  tensor([  4.6164, -13.0519])\n",
      "    Grad  :  tensor([-0.1278,  0.7237])\n",
      "Epoch 834,Loss 4.511879\n",
      "Epoch 834, Loss 4.511879\n",
      "    Params:  tensor([  4.6177, -13.0591])\n",
      "    Grad  :  tensor([-0.1276,  0.7225])\n",
      "Epoch 835,Loss 4.506505\n",
      "Epoch 835, Loss 4.506505\n",
      "    Params:  tensor([  4.6190, -13.0663])\n",
      "    Grad  :  tensor([-0.1274,  0.7212])\n",
      "Epoch 836,Loss 4.501141\n",
      "Epoch 836, Loss 4.501141\n",
      "    Params:  tensor([  4.6203, -13.0735])\n",
      "    Grad  :  tensor([-0.1272,  0.7200])\n",
      "Epoch 837,Loss 4.495801\n",
      "Epoch 837, Loss 4.495801\n",
      "    Params:  tensor([  4.6215, -13.0807])\n",
      "    Grad  :  tensor([-0.1270,  0.7188])\n",
      "Epoch 838,Loss 4.490475\n",
      "Epoch 838, Loss 4.490475\n",
      "    Params:  tensor([  4.6228, -13.0879])\n",
      "    Grad  :  tensor([-0.1268,  0.7176])\n",
      "Epoch 839,Loss 4.485169\n",
      "Epoch 839, Loss 4.485169\n",
      "    Params:  tensor([  4.6241, -13.0950])\n",
      "    Grad  :  tensor([-0.1266,  0.7163])\n",
      "Epoch 840,Loss 4.479884\n",
      "Epoch 840, Loss 4.479884\n",
      "    Params:  tensor([  4.6253, -13.1022])\n",
      "    Grad  :  tensor([-0.1263,  0.7151])\n",
      "Epoch 841,Loss 4.474613\n",
      "Epoch 841, Loss 4.474613\n",
      "    Params:  tensor([  4.6266, -13.1093])\n",
      "    Grad  :  tensor([-0.1261,  0.7139])\n",
      "Epoch 842,Loss 4.469364\n",
      "Epoch 842, Loss 4.469364\n",
      "    Params:  tensor([  4.6278, -13.1165])\n",
      "    Grad  :  tensor([-0.1259,  0.7127])\n",
      "Epoch 843,Loss 4.464130\n",
      "Epoch 843, Loss 4.464130\n",
      "    Params:  tensor([  4.6291, -13.1236])\n",
      "    Grad  :  tensor([-0.1257,  0.7115])\n",
      "Epoch 844,Loss 4.458913\n",
      "Epoch 844, Loss 4.458913\n",
      "    Params:  tensor([  4.6304, -13.1307])\n",
      "    Grad  :  tensor([-0.1255,  0.7103])\n",
      "Epoch 845,Loss 4.453716\n",
      "Epoch 845, Loss 4.453716\n",
      "    Params:  tensor([  4.6316, -13.1378])\n",
      "    Grad  :  tensor([-0.1253,  0.7091])\n",
      "Epoch 846,Loss 4.448535\n",
      "Epoch 846, Loss 4.448535\n",
      "    Params:  tensor([  4.6329, -13.1449])\n",
      "    Grad  :  tensor([-0.1250,  0.7079])\n",
      "Epoch 847,Loss 4.443372\n",
      "Epoch 847, Loss 4.443372\n",
      "    Params:  tensor([  4.6341, -13.1519])\n",
      "    Grad  :  tensor([-0.1249,  0.7067])\n",
      "Epoch 848,Loss 4.438226\n",
      "Epoch 848, Loss 4.438226\n",
      "    Params:  tensor([  4.6353, -13.1590])\n",
      "    Grad  :  tensor([-0.1246,  0.7055])\n",
      "Epoch 849,Loss 4.433099\n",
      "Epoch 849, Loss 4.433099\n",
      "    Params:  tensor([  4.6366, -13.1660])\n",
      "    Grad  :  tensor([-0.1244,  0.7043])\n",
      "Epoch 850,Loss 4.427990\n",
      "Epoch 850, Loss 4.427990\n",
      "    Params:  tensor([  4.6378, -13.1730])\n",
      "    Grad  :  tensor([-0.1242,  0.7031])\n",
      "Epoch 851,Loss 4.422897\n",
      "Epoch 851, Loss 4.422897\n",
      "    Params:  tensor([  4.6391, -13.1801])\n",
      "    Grad  :  tensor([-0.1240,  0.7019])\n",
      "Epoch 852,Loss 4.417819\n",
      "Epoch 852, Loss 4.417819\n",
      "    Params:  tensor([  4.6403, -13.1871])\n",
      "    Grad  :  tensor([-0.1238,  0.7007])\n",
      "Epoch 853,Loss 4.412762\n",
      "Epoch 853, Loss 4.412762\n",
      "    Params:  tensor([  4.6415, -13.1941])\n",
      "    Grad  :  tensor([-0.1236,  0.6995])\n",
      "Epoch 854,Loss 4.407721\n",
      "Epoch 854, Loss 4.407721\n",
      "    Params:  tensor([  4.6428, -13.2010])\n",
      "    Grad  :  tensor([-0.1234,  0.6983])\n",
      "Epoch 855,Loss 4.402698\n",
      "Epoch 855, Loss 4.402698\n",
      "    Params:  tensor([  4.6440, -13.2080])\n",
      "    Grad  :  tensor([-0.1232,  0.6971])\n",
      "Epoch 856,Loss 4.397688\n",
      "Epoch 856, Loss 4.397688\n",
      "    Params:  tensor([  4.6452, -13.2150])\n",
      "    Grad  :  tensor([-0.1229,  0.6959])\n",
      "Epoch 857,Loss 4.392697\n",
      "Epoch 857, Loss 4.392697\n",
      "    Params:  tensor([  4.6465, -13.2219])\n",
      "    Grad  :  tensor([-0.1227,  0.6948])\n",
      "Epoch 858,Loss 4.387725\n",
      "Epoch 858, Loss 4.387725\n",
      "    Params:  tensor([  4.6477, -13.2289])\n",
      "    Grad  :  tensor([-0.1225,  0.6936])\n",
      "Epoch 859,Loss 4.382770\n",
      "Epoch 859, Loss 4.382770\n",
      "    Params:  tensor([  4.6489, -13.2358])\n",
      "    Grad  :  tensor([-0.1223,  0.6924])\n",
      "Epoch 860,Loss 4.377828\n",
      "Epoch 860, Loss 4.377828\n",
      "    Params:  tensor([  4.6501, -13.2427])\n",
      "    Grad  :  tensor([-0.1221,  0.6912])\n",
      "Epoch 861,Loss 4.372905\n",
      "Epoch 861, Loss 4.372905\n",
      "    Params:  tensor([  4.6514, -13.2496])\n",
      "    Grad  :  tensor([-0.1219,  0.6901])\n",
      "Epoch 862,Loss 4.368000\n",
      "Epoch 862, Loss 4.368000\n",
      "    Params:  tensor([  4.6526, -13.2565])\n",
      "    Grad  :  tensor([-0.1217,  0.6889])\n",
      "Epoch 863,Loss 4.363111\n",
      "Epoch 863, Loss 4.363111\n",
      "    Params:  tensor([  4.6538, -13.2634])\n",
      "    Grad  :  tensor([-0.1215,  0.6877])\n",
      "Epoch 864,Loss 4.358238\n",
      "Epoch 864, Loss 4.358238\n",
      "    Params:  tensor([  4.6550, -13.2702])\n",
      "    Grad  :  tensor([-0.1213,  0.6865])\n",
      "Epoch 865,Loss 4.353383\n",
      "Epoch 865, Loss 4.353383\n",
      "    Params:  tensor([  4.6562, -13.2771])\n",
      "    Grad  :  tensor([-0.1211,  0.6854])\n",
      "Epoch 866,Loss 4.348542\n",
      "Epoch 866, Loss 4.348542\n",
      "    Params:  tensor([  4.6574, -13.2839])\n",
      "    Grad  :  tensor([-0.1209,  0.6842])\n",
      "Epoch 867,Loss 4.343716\n",
      "Epoch 867, Loss 4.343716\n",
      "    Params:  tensor([  4.6586, -13.2908])\n",
      "    Grad  :  tensor([-0.1207,  0.6830])\n",
      "Epoch 868,Loss 4.338911\n",
      "Epoch 868, Loss 4.338911\n",
      "    Params:  tensor([  4.6598, -13.2976])\n",
      "    Grad  :  tensor([-0.1205,  0.6819])\n",
      "Epoch 869,Loss 4.334120\n",
      "Epoch 869, Loss 4.334120\n",
      "    Params:  tensor([  4.6610, -13.3044])\n",
      "    Grad  :  tensor([-0.1203,  0.6807])\n",
      "Epoch 870,Loss 4.329345\n",
      "Epoch 870, Loss 4.329345\n",
      "    Params:  tensor([  4.6622, -13.3112])\n",
      "    Grad  :  tensor([-0.1201,  0.6796])\n",
      "Epoch 871,Loss 4.324588\n",
      "Epoch 871, Loss 4.324588\n",
      "    Params:  tensor([  4.6634, -13.3180])\n",
      "    Grad  :  tensor([-0.1198,  0.6784])\n",
      "Epoch 872,Loss 4.319846\n",
      "Epoch 872, Loss 4.319846\n",
      "    Params:  tensor([  4.6646, -13.3247])\n",
      "    Grad  :  tensor([-0.1196,  0.6773])\n",
      "Epoch 873,Loss 4.315117\n",
      "Epoch 873, Loss 4.315117\n",
      "    Params:  tensor([  4.6658, -13.3315])\n",
      "    Grad  :  tensor([-0.1195,  0.6761])\n",
      "Epoch 874,Loss 4.310409\n",
      "Epoch 874, Loss 4.310409\n",
      "    Params:  tensor([  4.6670, -13.3382])\n",
      "    Grad  :  tensor([-0.1192,  0.6750])\n",
      "Epoch 875,Loss 4.305714\n",
      "Epoch 875, Loss 4.305714\n",
      "    Params:  tensor([  4.6682, -13.3450])\n",
      "    Grad  :  tensor([-0.1190,  0.6738])\n",
      "Epoch 876,Loss 4.301036\n",
      "Epoch 876, Loss 4.301036\n",
      "    Params:  tensor([  4.6694, -13.3517])\n",
      "    Grad  :  tensor([-0.1188,  0.6727])\n",
      "Epoch 877,Loss 4.296376\n",
      "Epoch 877, Loss 4.296376\n",
      "    Params:  tensor([  4.6706, -13.3584])\n",
      "    Grad  :  tensor([-0.1186,  0.6715])\n",
      "Epoch 878,Loss 4.291727\n",
      "Epoch 878, Loss 4.291727\n",
      "    Params:  tensor([  4.6718, -13.3651])\n",
      "    Grad  :  tensor([-0.1184,  0.6704])\n",
      "Epoch 879,Loss 4.287098\n",
      "Epoch 879, Loss 4.287098\n",
      "    Params:  tensor([  4.6730, -13.3718])\n",
      "    Grad  :  tensor([-0.1182,  0.6693])\n",
      "Epoch 880,Loss 4.282482\n",
      "Epoch 880, Loss 4.282482\n",
      "    Params:  tensor([  4.6741, -13.3785])\n",
      "    Grad  :  tensor([-0.1180,  0.6681])\n",
      "Epoch 881,Loss 4.277882\n",
      "Epoch 881, Loss 4.277882\n",
      "    Params:  tensor([  4.6753, -13.3852])\n",
      "    Grad  :  tensor([-0.1178,  0.6670])\n",
      "Epoch 882,Loss 4.273299\n",
      "Epoch 882, Loss 4.273299\n",
      "    Params:  tensor([  4.6765, -13.3918])\n",
      "    Grad  :  tensor([-0.1176,  0.6658])\n",
      "Epoch 883,Loss 4.268732\n",
      "Epoch 883, Loss 4.268732\n",
      "    Params:  tensor([  4.6777, -13.3985])\n",
      "    Grad  :  tensor([-0.1174,  0.6647])\n",
      "Epoch 884,Loss 4.264178\n",
      "Epoch 884, Loss 4.264178\n",
      "    Params:  tensor([  4.6788, -13.4051])\n",
      "    Grad  :  tensor([-0.1172,  0.6636])\n",
      "Epoch 885,Loss 4.259643\n",
      "Epoch 885, Loss 4.259643\n",
      "    Params:  tensor([  4.6800, -13.4117])\n",
      "    Grad  :  tensor([-0.1170,  0.6625])\n",
      "Epoch 886,Loss 4.255120\n",
      "Epoch 886, Loss 4.255120\n",
      "    Params:  tensor([  4.6812, -13.4184])\n",
      "    Grad  :  tensor([-0.1168,  0.6613])\n",
      "Epoch 887,Loss 4.250614\n",
      "Epoch 887, Loss 4.250614\n",
      "    Params:  tensor([  4.6823, -13.4250])\n",
      "    Grad  :  tensor([-0.1166,  0.6602])\n",
      "Epoch 888,Loss 4.246124\n",
      "Epoch 888, Loss 4.246124\n",
      "    Params:  tensor([  4.6835, -13.4316])\n",
      "    Grad  :  tensor([-0.1164,  0.6591])\n",
      "Epoch 889,Loss 4.241648\n",
      "Epoch 889, Loss 4.241648\n",
      "    Params:  tensor([  4.6847, -13.4381])\n",
      "    Grad  :  tensor([-0.1162,  0.6580])\n",
      "Epoch 890,Loss 4.237185\n",
      "Epoch 890, Loss 4.237185\n",
      "    Params:  tensor([  4.6858, -13.4447])\n",
      "    Grad  :  tensor([-0.1160,  0.6569])\n",
      "Epoch 891,Loss 4.232740\n",
      "Epoch 891, Loss 4.232740\n",
      "    Params:  tensor([  4.6870, -13.4513])\n",
      "    Grad  :  tensor([-0.1158,  0.6557])\n",
      "Epoch 892,Loss 4.228308\n",
      "Epoch 892, Loss 4.228308\n",
      "    Params:  tensor([  4.6881, -13.4578])\n",
      "    Grad  :  tensor([-0.1157,  0.6546])\n",
      "Epoch 893,Loss 4.223895\n",
      "Epoch 893, Loss 4.223895\n",
      "    Params:  tensor([  4.6893, -13.4643])\n",
      "    Grad  :  tensor([-0.1154,  0.6535])\n",
      "Epoch 894,Loss 4.219494\n",
      "Epoch 894, Loss 4.219494\n",
      "    Params:  tensor([  4.6904, -13.4709])\n",
      "    Grad  :  tensor([-0.1153,  0.6524])\n",
      "Epoch 895,Loss 4.215109\n",
      "Epoch 895, Loss 4.215109\n",
      "    Params:  tensor([  4.6916, -13.4774])\n",
      "    Grad  :  tensor([-0.1151,  0.6513])\n",
      "Epoch 896,Loss 4.210737\n",
      "Epoch 896, Loss 4.210737\n",
      "    Params:  tensor([  4.6927, -13.4839])\n",
      "    Grad  :  tensor([-0.1148,  0.6502])\n",
      "Epoch 897,Loss 4.206383\n",
      "Epoch 897, Loss 4.206383\n",
      "    Params:  tensor([  4.6939, -13.4904])\n",
      "    Grad  :  tensor([-0.1147,  0.6491])\n",
      "Epoch 898,Loss 4.202043\n",
      "Epoch 898, Loss 4.202043\n",
      "    Params:  tensor([  4.6950, -13.4968])\n",
      "    Grad  :  tensor([-0.1145,  0.6480])\n",
      "Epoch 899,Loss 4.197715\n",
      "Epoch 899, Loss 4.197715\n",
      "    Params:  tensor([  4.6962, -13.5033])\n",
      "    Grad  :  tensor([-0.1143,  0.6469])\n",
      "Epoch 900,Loss 4.193405\n",
      "Epoch 900, Loss 4.193405\n",
      "    Params:  tensor([  4.6973, -13.5098])\n",
      "    Grad  :  tensor([-0.1141,  0.6458])\n",
      "Epoch 901,Loss 4.189108\n",
      "Epoch 901, Loss 4.189108\n",
      "    Params:  tensor([  4.6985, -13.5162])\n",
      "    Grad  :  tensor([-0.1139,  0.6447])\n",
      "Epoch 902,Loss 4.184825\n",
      "Epoch 902, Loss 4.184825\n",
      "    Params:  tensor([  4.6996, -13.5227])\n",
      "    Grad  :  tensor([-0.1137,  0.6436])\n",
      "Epoch 903,Loss 4.180559\n",
      "Epoch 903, Loss 4.180559\n",
      "    Params:  tensor([  4.7007, -13.5291])\n",
      "    Grad  :  tensor([-0.1135,  0.6425])\n",
      "Epoch 904,Loss 4.176305\n",
      "Epoch 904, Loss 4.176305\n",
      "    Params:  tensor([  4.7019, -13.5355])\n",
      "    Grad  :  tensor([-0.1133,  0.6414])\n",
      "Epoch 905,Loss 4.172065\n",
      "Epoch 905, Loss 4.172065\n",
      "    Params:  tensor([  4.7030, -13.5419])\n",
      "    Grad  :  tensor([-0.1131,  0.6403])\n",
      "Epoch 906,Loss 4.167842\n",
      "Epoch 906, Loss 4.167842\n",
      "    Params:  tensor([  4.7041, -13.5483])\n",
      "    Grad  :  tensor([-0.1129,  0.6392])\n",
      "Epoch 907,Loss 4.163630\n",
      "Epoch 907, Loss 4.163630\n",
      "    Params:  tensor([  4.7053, -13.5547])\n",
      "    Grad  :  tensor([-0.1127,  0.6381])\n",
      "Epoch 908,Loss 4.159436\n",
      "Epoch 908, Loss 4.159436\n",
      "    Params:  tensor([  4.7064, -13.5610])\n",
      "    Grad  :  tensor([-0.1125,  0.6371])\n",
      "Epoch 909,Loss 4.155253\n",
      "Epoch 909, Loss 4.155253\n",
      "    Params:  tensor([  4.7075, -13.5674])\n",
      "    Grad  :  tensor([-0.1124,  0.6360])\n",
      "Epoch 910,Loss 4.151086\n",
      "Epoch 910, Loss 4.151086\n",
      "    Params:  tensor([  4.7086, -13.5738])\n",
      "    Grad  :  tensor([-0.1122,  0.6349])\n",
      "Epoch 911,Loss 4.146934\n",
      "Epoch 911, Loss 4.146934\n",
      "    Params:  tensor([  4.7097, -13.5801])\n",
      "    Grad  :  tensor([-0.1120,  0.6338])\n",
      "Epoch 912,Loss 4.142794\n",
      "Epoch 912, Loss 4.142794\n",
      "    Params:  tensor([  4.7109, -13.5864])\n",
      "    Grad  :  tensor([-0.1118,  0.6327])\n",
      "Epoch 913,Loss 4.138669\n",
      "Epoch 913, Loss 4.138669\n",
      "    Params:  tensor([  4.7120, -13.5927])\n",
      "    Grad  :  tensor([-0.1116,  0.6317])\n",
      "Epoch 914,Loss 4.134559\n",
      "Epoch 914, Loss 4.134559\n",
      "    Params:  tensor([  4.7131, -13.5990])\n",
      "    Grad  :  tensor([-0.1114,  0.6306])\n",
      "Epoch 915,Loss 4.130465\n",
      "Epoch 915, Loss 4.130465\n",
      "    Params:  tensor([  4.7142, -13.6053])\n",
      "    Grad  :  tensor([-0.1112,  0.6295])\n",
      "Epoch 916,Loss 4.126378\n",
      "Epoch 916, Loss 4.126378\n",
      "    Params:  tensor([  4.7153, -13.6116])\n",
      "    Grad  :  tensor([-0.1110,  0.6284])\n",
      "Epoch 917,Loss 4.122310\n",
      "Epoch 917, Loss 4.122310\n",
      "    Params:  tensor([  4.7164, -13.6179])\n",
      "    Grad  :  tensor([-0.1108,  0.6274])\n",
      "Epoch 918,Loss 4.118253\n",
      "Epoch 918, Loss 4.118253\n",
      "    Params:  tensor([  4.7175, -13.6242])\n",
      "    Grad  :  tensor([-0.1107,  0.6263])\n",
      "Epoch 919,Loss 4.114213\n",
      "Epoch 919, Loss 4.114213\n",
      "    Params:  tensor([  4.7186, -13.6304])\n",
      "    Grad  :  tensor([-0.1104,  0.6253])\n",
      "Epoch 920,Loss 4.110184\n",
      "Epoch 920, Loss 4.110184\n",
      "    Params:  tensor([  4.7197, -13.6367])\n",
      "    Grad  :  tensor([-0.1103,  0.6242])\n",
      "Epoch 921,Loss 4.106170\n",
      "Epoch 921, Loss 4.106170\n",
      "    Params:  tensor([  4.7208, -13.6429])\n",
      "    Grad  :  tensor([-0.1101,  0.6231])\n",
      "Epoch 922,Loss 4.102171\n",
      "Epoch 922, Loss 4.102171\n",
      "    Params:  tensor([  4.7219, -13.6491])\n",
      "    Grad  :  tensor([-0.1099,  0.6221])\n",
      "Epoch 923,Loss 4.098181\n",
      "Epoch 923, Loss 4.098181\n",
      "    Params:  tensor([  4.7230, -13.6553])\n",
      "    Grad  :  tensor([-0.1097,  0.6210])\n",
      "Epoch 924,Loss 4.094209\n",
      "Epoch 924, Loss 4.094209\n",
      "    Params:  tensor([  4.7241, -13.6615])\n",
      "    Grad  :  tensor([-0.1095,  0.6200])\n",
      "Epoch 925,Loss 4.090250\n",
      "Epoch 925, Loss 4.090250\n",
      "    Params:  tensor([  4.7252, -13.6677])\n",
      "    Grad  :  tensor([-0.1093,  0.6189])\n",
      "Epoch 926,Loss 4.086300\n",
      "Epoch 926, Loss 4.086300\n",
      "    Params:  tensor([  4.7263, -13.6739])\n",
      "    Grad  :  tensor([-0.1091,  0.6179])\n",
      "Epoch 927,Loss 4.082366\n",
      "Epoch 927, Loss 4.082366\n",
      "    Params:  tensor([  4.7274, -13.6800])\n",
      "    Grad  :  tensor([-0.1090,  0.6168])\n",
      "Epoch 928,Loss 4.078448\n",
      "Epoch 928, Loss 4.078448\n",
      "    Params:  tensor([  4.7285, -13.6862])\n",
      "    Grad  :  tensor([-0.1088,  0.6158])\n",
      "Epoch 929,Loss 4.074540\n",
      "Epoch 929, Loss 4.074540\n",
      "    Params:  tensor([  4.7296, -13.6924])\n",
      "    Grad  :  tensor([-0.1086,  0.6147])\n",
      "Epoch 930,Loss 4.070650\n",
      "Epoch 930, Loss 4.070650\n",
      "    Params:  tensor([  4.7307, -13.6985])\n",
      "    Grad  :  tensor([-0.1084,  0.6137])\n",
      "Epoch 931,Loss 4.066769\n",
      "Epoch 931, Loss 4.066769\n",
      "    Params:  tensor([  4.7317, -13.7046])\n",
      "    Grad  :  tensor([-0.1082,  0.6126])\n",
      "Epoch 932,Loss 4.062900\n",
      "Epoch 932, Loss 4.062900\n",
      "    Params:  tensor([  4.7328, -13.7107])\n",
      "    Grad  :  tensor([-0.1080,  0.6116])\n",
      "Epoch 933,Loss 4.059047\n",
      "Epoch 933, Loss 4.059047\n",
      "    Params:  tensor([  4.7339, -13.7168])\n",
      "    Grad  :  tensor([-0.1079,  0.6105])\n",
      "Epoch 934,Loss 4.055204\n",
      "Epoch 934, Loss 4.055204\n",
      "    Params:  tensor([  4.7350, -13.7229])\n",
      "    Grad  :  tensor([-0.1077,  0.6095])\n",
      "Epoch 935,Loss 4.051378\n",
      "Epoch 935, Loss 4.051378\n",
      "    Params:  tensor([  4.7360, -13.7290])\n",
      "    Grad  :  tensor([-0.1075,  0.6085])\n",
      "Epoch 936,Loss 4.047564\n",
      "Epoch 936, Loss 4.047564\n",
      "    Params:  tensor([  4.7371, -13.7351])\n",
      "    Grad  :  tensor([-0.1073,  0.6074])\n",
      "Epoch 937,Loss 4.043762\n",
      "Epoch 937, Loss 4.043762\n",
      "    Params:  tensor([  4.7382, -13.7412])\n",
      "    Grad  :  tensor([-0.1071,  0.6064])\n",
      "Epoch 938,Loss 4.039972\n",
      "Epoch 938, Loss 4.039972\n",
      "    Params:  tensor([  4.7393, -13.7472])\n",
      "    Grad  :  tensor([-0.1069,  0.6054])\n",
      "Epoch 939,Loss 4.036197\n",
      "Epoch 939, Loss 4.036197\n",
      "    Params:  tensor([  4.7403, -13.7533])\n",
      "    Grad  :  tensor([-0.1068,  0.6043])\n",
      "Epoch 940,Loss 4.032433\n",
      "Epoch 940, Loss 4.032433\n",
      "    Params:  tensor([  4.7414, -13.7593])\n",
      "    Grad  :  tensor([-0.1066,  0.6033])\n",
      "Epoch 941,Loss 4.028685\n",
      "Epoch 941, Loss 4.028685\n",
      "    Params:  tensor([  4.7425, -13.7653])\n",
      "    Grad  :  tensor([-0.1064,  0.6023])\n",
      "Epoch 942,Loss 4.024947\n",
      "Epoch 942, Loss 4.024947\n",
      "    Params:  tensor([  4.7435, -13.7713])\n",
      "    Grad  :  tensor([-0.1062,  0.6013])\n",
      "Epoch 943,Loss 4.021224\n",
      "Epoch 943, Loss 4.021224\n",
      "    Params:  tensor([  4.7446, -13.7773])\n",
      "    Grad  :  tensor([-0.1060,  0.6002])\n",
      "Epoch 944,Loss 4.017508\n",
      "Epoch 944, Loss 4.017508\n",
      "    Params:  tensor([  4.7456, -13.7833])\n",
      "    Grad  :  tensor([-0.1058,  0.5992])\n",
      "Epoch 945,Loss 4.013810\n",
      "Epoch 945, Loss 4.013810\n",
      "    Params:  tensor([  4.7467, -13.7893])\n",
      "    Grad  :  tensor([-0.1057,  0.5982])\n",
      "Epoch 946,Loss 4.010122\n",
      "Epoch 946, Loss 4.010122\n",
      "    Params:  tensor([  4.7478, -13.7953])\n",
      "    Grad  :  tensor([-0.1055,  0.5972])\n",
      "Epoch 947,Loss 4.006450\n",
      "Epoch 947, Loss 4.006450\n",
      "    Params:  tensor([  4.7488, -13.8012])\n",
      "    Grad  :  tensor([-0.1053,  0.5962])\n",
      "Epoch 948,Loss 4.002786\n",
      "Epoch 948, Loss 4.002786\n",
      "    Params:  tensor([  4.7499, -13.8072])\n",
      "    Grad  :  tensor([-0.1051,  0.5952])\n",
      "Epoch 949,Loss 3.999137\n",
      "Epoch 949, Loss 3.999137\n",
      "    Params:  tensor([  4.7509, -13.8131])\n",
      "    Grad  :  tensor([-0.1050,  0.5942])\n",
      "Epoch 950,Loss 3.995498\n",
      "Epoch 950, Loss 3.995498\n",
      "    Params:  tensor([  4.7520, -13.8191])\n",
      "    Grad  :  tensor([-0.1048,  0.5932])\n",
      "Epoch 951,Loss 3.991874\n",
      "Epoch 951, Loss 3.991874\n",
      "    Params:  tensor([  4.7530, -13.8250])\n",
      "    Grad  :  tensor([-0.1046,  0.5921])\n",
      "Epoch 952,Loss 3.988262\n",
      "Epoch 952, Loss 3.988262\n",
      "    Params:  tensor([  4.7540, -13.8309])\n",
      "    Grad  :  tensor([-0.1044,  0.5911])\n",
      "Epoch 953,Loss 3.984660\n",
      "Epoch 953, Loss 3.984660\n",
      "    Params:  tensor([  4.7551, -13.8368])\n",
      "    Grad  :  tensor([-0.1042,  0.5901])\n",
      "Epoch 954,Loss 3.981072\n",
      "Epoch 954, Loss 3.981072\n",
      "    Params:  tensor([  4.7561, -13.8427])\n",
      "    Grad  :  tensor([-0.1041,  0.5891])\n",
      "Epoch 955,Loss 3.977496\n",
      "Epoch 955, Loss 3.977496\n",
      "    Params:  tensor([  4.7572, -13.8486])\n",
      "    Grad  :  tensor([-0.1039,  0.5881])\n",
      "Epoch 956,Loss 3.973933\n",
      "Epoch 956, Loss 3.973933\n",
      "    Params:  tensor([  4.7582, -13.8544])\n",
      "    Grad  :  tensor([-0.1037,  0.5871])\n",
      "Epoch 957,Loss 3.970381\n",
      "Epoch 957, Loss 3.970381\n",
      "    Params:  tensor([  4.7592, -13.8603])\n",
      "    Grad  :  tensor([-0.1035,  0.5861])\n",
      "Epoch 958,Loss 3.966843\n",
      "Epoch 958, Loss 3.966843\n",
      "    Params:  tensor([  4.7603, -13.8661])\n",
      "    Grad  :  tensor([-0.1034,  0.5851])\n",
      "Epoch 959,Loss 3.963314\n",
      "Epoch 959, Loss 3.963314\n",
      "    Params:  tensor([  4.7613, -13.8720])\n",
      "    Grad  :  tensor([-0.1032,  0.5841])\n",
      "Epoch 960,Loss 3.959798\n",
      "Epoch 960, Loss 3.959798\n",
      "    Params:  tensor([  4.7623, -13.8778])\n",
      "    Grad  :  tensor([-0.1030,  0.5832])\n",
      "Epoch 961,Loss 3.956294\n",
      "Epoch 961, Loss 3.956294\n",
      "    Params:  tensor([  4.7634, -13.8836])\n",
      "    Grad  :  tensor([-0.1029,  0.5822])\n",
      "Epoch 962,Loss 3.952803\n",
      "Epoch 962, Loss 3.952803\n",
      "    Params:  tensor([  4.7644, -13.8895])\n",
      "    Grad  :  tensor([-0.1027,  0.5812])\n",
      "Epoch 963,Loss 3.949322\n",
      "Epoch 963, Loss 3.949322\n",
      "    Params:  tensor([  4.7654, -13.8953])\n",
      "    Grad  :  tensor([-0.1025,  0.5802])\n",
      "Epoch 964,Loss 3.945855\n",
      "Epoch 964, Loss 3.945855\n",
      "    Params:  tensor([  4.7664, -13.9010])\n",
      "    Grad  :  tensor([-0.1023,  0.5792])\n",
      "Epoch 965,Loss 3.942399\n",
      "Epoch 965, Loss 3.942399\n",
      "    Params:  tensor([  4.7675, -13.9068])\n",
      "    Grad  :  tensor([-0.1022,  0.5782])\n",
      "Epoch 966,Loss 3.938953\n",
      "Epoch 966, Loss 3.938953\n",
      "    Params:  tensor([  4.7685, -13.9126])\n",
      "    Grad  :  tensor([-0.1020,  0.5772])\n",
      "Epoch 967,Loss 3.935520\n",
      "Epoch 967, Loss 3.935520\n",
      "    Params:  tensor([  4.7695, -13.9184])\n",
      "    Grad  :  tensor([-0.1018,  0.5763])\n",
      "Epoch 968,Loss 3.932098\n",
      "Epoch 968, Loss 3.932098\n",
      "    Params:  tensor([  4.7705, -13.9241])\n",
      "    Grad  :  tensor([-0.1016,  0.5753])\n",
      "Epoch 969,Loss 3.928689\n",
      "Epoch 969, Loss 3.928689\n",
      "    Params:  tensor([  4.7715, -13.9299])\n",
      "    Grad  :  tensor([-0.1014,  0.5743])\n",
      "Epoch 970,Loss 3.925291\n",
      "Epoch 970, Loss 3.925291\n",
      "    Params:  tensor([  4.7725, -13.9356])\n",
      "    Grad  :  tensor([-0.1013,  0.5733])\n",
      "Epoch 971,Loss 3.921905\n",
      "Epoch 971, Loss 3.921905\n",
      "    Params:  tensor([  4.7736, -13.9413])\n",
      "    Grad  :  tensor([-0.1011,  0.5723])\n",
      "Epoch 972,Loss 3.918529\n",
      "Epoch 972, Loss 3.918529\n",
      "    Params:  tensor([  4.7746, -13.9470])\n",
      "    Grad  :  tensor([-0.1009,  0.5714])\n",
      "Epoch 973,Loss 3.915166\n",
      "Epoch 973, Loss 3.915166\n",
      "    Params:  tensor([  4.7756, -13.9527])\n",
      "    Grad  :  tensor([-0.1007,  0.5704])\n",
      "Epoch 974,Loss 3.911816\n",
      "Epoch 974, Loss 3.911816\n",
      "    Params:  tensor([  4.7766, -13.9584])\n",
      "    Grad  :  tensor([-0.1006,  0.5694])\n",
      "Epoch 975,Loss 3.908474\n",
      "Epoch 975, Loss 3.908474\n",
      "    Params:  tensor([  4.7776, -13.9641])\n",
      "    Grad  :  tensor([-0.1004,  0.5685])\n",
      "Epoch 976,Loss 3.905146\n",
      "Epoch 976, Loss 3.905146\n",
      "    Params:  tensor([  4.7786, -13.9698])\n",
      "    Grad  :  tensor([-0.1003,  0.5675])\n",
      "Epoch 977,Loss 3.901826\n",
      "Epoch 977, Loss 3.901826\n",
      "    Params:  tensor([  4.7796, -13.9755])\n",
      "    Grad  :  tensor([-0.1001,  0.5665])\n",
      "Epoch 978,Loss 3.898518\n",
      "Epoch 978, Loss 3.898518\n",
      "    Params:  tensor([  4.7806, -13.9811])\n",
      "    Grad  :  tensor([-0.0999,  0.5656])\n",
      "Epoch 979,Loss 3.895221\n",
      "Epoch 979, Loss 3.895221\n",
      "    Params:  tensor([  4.7816, -13.9868])\n",
      "    Grad  :  tensor([-0.0997,  0.5646])\n",
      "Epoch 980,Loss 3.891936\n",
      "Epoch 980, Loss 3.891936\n",
      "    Params:  tensor([  4.7826, -13.9924])\n",
      "    Grad  :  tensor([-0.0996,  0.5637])\n",
      "Epoch 981,Loss 3.888664\n",
      "Epoch 981, Loss 3.888664\n",
      "    Params:  tensor([  4.7836, -13.9980])\n",
      "    Grad  :  tensor([-0.0994,  0.5627])\n",
      "Epoch 982,Loss 3.885402\n",
      "Epoch 982, Loss 3.885402\n",
      "    Params:  tensor([  4.7846, -14.0036])\n",
      "    Grad  :  tensor([-0.0992,  0.5617])\n",
      "Epoch 983,Loss 3.882150\n",
      "Epoch 983, Loss 3.882150\n",
      "    Params:  tensor([  4.7856, -14.0092])\n",
      "    Grad  :  tensor([-0.0991,  0.5608])\n",
      "Epoch 984,Loss 3.878911\n",
      "Epoch 984, Loss 3.878911\n",
      "    Params:  tensor([  4.7865, -14.0148])\n",
      "    Grad  :  tensor([-0.0989,  0.5598])\n",
      "Epoch 985,Loss 3.875682\n",
      "Epoch 985, Loss 3.875682\n",
      "    Params:  tensor([  4.7875, -14.0204])\n",
      "    Grad  :  tensor([-0.0987,  0.5589])\n",
      "Epoch 986,Loss 3.872464\n",
      "Epoch 986, Loss 3.872464\n",
      "    Params:  tensor([  4.7885, -14.0260])\n",
      "    Grad  :  tensor([-0.0985,  0.5579])\n",
      "Epoch 987,Loss 3.869255\n",
      "Epoch 987, Loss 3.869255\n",
      "    Params:  tensor([  4.7895, -14.0316])\n",
      "    Grad  :  tensor([-0.0984,  0.5570])\n",
      "Epoch 988,Loss 3.866060\n",
      "Epoch 988, Loss 3.866060\n",
      "    Params:  tensor([  4.7905, -14.0371])\n",
      "    Grad  :  tensor([-0.0982,  0.5560])\n",
      "Epoch 989,Loss 3.862875\n",
      "Epoch 989, Loss 3.862875\n",
      "    Params:  tensor([  4.7915, -14.0427])\n",
      "    Grad  :  tensor([-0.0981,  0.5551])\n",
      "Epoch 990,Loss 3.859699\n",
      "Epoch 990, Loss 3.859699\n",
      "    Params:  tensor([  4.7924, -14.0482])\n",
      "    Grad  :  tensor([-0.0979,  0.5542])\n",
      "Epoch 991,Loss 3.856536\n",
      "Epoch 991, Loss 3.856536\n",
      "    Params:  tensor([  4.7934, -14.0538])\n",
      "    Grad  :  tensor([-0.0977,  0.5532])\n",
      "Epoch 992,Loss 3.853381\n",
      "Epoch 992, Loss 3.853381\n",
      "    Params:  tensor([  4.7944, -14.0593])\n",
      "    Grad  :  tensor([-0.0976,  0.5523])\n",
      "Epoch 993,Loss 3.850239\n",
      "Epoch 993, Loss 3.850239\n",
      "    Params:  tensor([  4.7954, -14.0648])\n",
      "    Grad  :  tensor([-0.0974,  0.5513])\n",
      "Epoch 994,Loss 3.847108\n",
      "Epoch 994, Loss 3.847108\n",
      "    Params:  tensor([  4.7963, -14.0703])\n",
      "    Grad  :  tensor([-0.0972,  0.5504])\n",
      "Epoch 995,Loss 3.843986\n",
      "Epoch 995, Loss 3.843986\n",
      "    Params:  tensor([  4.7973, -14.0758])\n",
      "    Grad  :  tensor([-0.0971,  0.5495])\n",
      "Epoch 996,Loss 3.840876\n",
      "Epoch 996, Loss 3.840876\n",
      "    Params:  tensor([  4.7983, -14.0813])\n",
      "    Grad  :  tensor([-0.0969,  0.5485])\n",
      "Epoch 997,Loss 3.837775\n",
      "Epoch 997, Loss 3.837775\n",
      "    Params:  tensor([  4.7992, -14.0868])\n",
      "    Grad  :  tensor([-0.0967,  0.5476])\n",
      "Epoch 998,Loss 3.834686\n",
      "Epoch 998, Loss 3.834686\n",
      "    Params:  tensor([  4.8002, -14.0922])\n",
      "    Grad  :  tensor([-0.0966,  0.5467])\n",
      "Epoch 999,Loss 3.831606\n",
      "Epoch 999, Loss 3.831606\n",
      "    Params:  tensor([  4.8012, -14.0977])\n",
      "    Grad  :  tensor([-0.0964,  0.5457])\n",
      "Epoch 1000,Loss 3.828538\n",
      "Epoch 1000, Loss 3.828538\n",
      "    Params:  tensor([  4.8021, -14.1031])\n",
      "    Grad  :  tensor([-0.0962,  0.5448])\n",
      "Epoch 1001,Loss 3.825483\n",
      "Epoch 1001, Loss 3.825483\n",
      "    Params:  tensor([  4.8031, -14.1086])\n",
      "    Grad  :  tensor([-0.0961,  0.5439])\n",
      "Epoch 1002,Loss 3.822433\n",
      "Epoch 1002, Loss 3.822433\n",
      "    Params:  tensor([  4.8041, -14.1140])\n",
      "    Grad  :  tensor([-0.0959,  0.5430])\n",
      "Epoch 1003,Loss 3.819398\n",
      "Epoch 1003, Loss 3.819398\n",
      "    Params:  tensor([  4.8050, -14.1194])\n",
      "    Grad  :  tensor([-0.0957,  0.5420])\n",
      "Epoch 1004,Loss 3.816369\n",
      "Epoch 1004, Loss 3.816369\n",
      "    Params:  tensor([  4.8060, -14.1248])\n",
      "    Grad  :  tensor([-0.0956,  0.5411])\n",
      "Epoch 1005,Loss 3.813350\n",
      "Epoch 1005, Loss 3.813350\n",
      "    Params:  tensor([  4.8069, -14.1302])\n",
      "    Grad  :  tensor([-0.0954,  0.5402])\n",
      "Epoch 1006,Loss 3.810344\n",
      "Epoch 1006, Loss 3.810344\n",
      "    Params:  tensor([  4.8079, -14.1356])\n",
      "    Grad  :  tensor([-0.0953,  0.5393])\n",
      "Epoch 1007,Loss 3.807348\n",
      "Epoch 1007, Loss 3.807348\n",
      "    Params:  tensor([  4.8088, -14.1410])\n",
      "    Grad  :  tensor([-0.0951,  0.5384])\n",
      "Epoch 1008,Loss 3.804360\n",
      "Epoch 1008, Loss 3.804360\n",
      "    Params:  tensor([  4.8098, -14.1464])\n",
      "    Grad  :  tensor([-0.0949,  0.5375])\n",
      "Epoch 1009,Loss 3.801384\n",
      "Epoch 1009, Loss 3.801384\n",
      "    Params:  tensor([  4.8107, -14.1518])\n",
      "    Grad  :  tensor([-0.0948,  0.5365])\n",
      "Epoch 1010,Loss 3.798421\n",
      "Epoch 1010, Loss 3.798421\n",
      "    Params:  tensor([  4.8117, -14.1571])\n",
      "    Grad  :  tensor([-0.0946,  0.5356])\n",
      "Epoch 1011,Loss 3.795465\n",
      "Epoch 1011, Loss 3.795465\n",
      "    Params:  tensor([  4.8126, -14.1625])\n",
      "    Grad  :  tensor([-0.0945,  0.5347])\n",
      "Epoch 1012,Loss 3.792518\n",
      "Epoch 1012, Loss 3.792518\n",
      "    Params:  tensor([  4.8136, -14.1678])\n",
      "    Grad  :  tensor([-0.0943,  0.5338])\n",
      "Epoch 1013,Loss 3.789584\n",
      "Epoch 1013, Loss 3.789584\n",
      "    Params:  tensor([  4.8145, -14.1731])\n",
      "    Grad  :  tensor([-0.0942,  0.5329])\n",
      "Epoch 1014,Loss 3.786658\n",
      "Epoch 1014, Loss 3.786658\n",
      "    Params:  tensor([  4.8154, -14.1784])\n",
      "    Grad  :  tensor([-0.0940,  0.5320])\n",
      "Epoch 1015,Loss 3.783740\n",
      "Epoch 1015, Loss 3.783740\n",
      "    Params:  tensor([  4.8164, -14.1838])\n",
      "    Grad  :  tensor([-0.0938,  0.5311])\n",
      "Epoch 1016,Loss 3.780832\n",
      "Epoch 1016, Loss 3.780832\n",
      "    Params:  tensor([  4.8173, -14.1891])\n",
      "    Grad  :  tensor([-0.0937,  0.5302])\n",
      "Epoch 1017,Loss 3.777939\n",
      "Epoch 1017, Loss 3.777939\n",
      "    Params:  tensor([  4.8183, -14.1943])\n",
      "    Grad  :  tensor([-0.0935,  0.5293])\n",
      "Epoch 1018,Loss 3.775053\n",
      "Epoch 1018, Loss 3.775053\n",
      "    Params:  tensor([  4.8192, -14.1996])\n",
      "    Grad  :  tensor([-0.0933,  0.5284])\n",
      "Epoch 1019,Loss 3.772173\n",
      "Epoch 1019, Loss 3.772173\n",
      "    Params:  tensor([  4.8201, -14.2049])\n",
      "    Grad  :  tensor([-0.0932,  0.5275])\n",
      "Epoch 1020,Loss 3.769311\n",
      "Epoch 1020, Loss 3.769311\n",
      "    Params:  tensor([  4.8210, -14.2102])\n",
      "    Grad  :  tensor([-0.0930,  0.5266])\n",
      "Epoch 1021,Loss 3.766450\n",
      "Epoch 1021, Loss 3.766450\n",
      "    Params:  tensor([  4.8220, -14.2154])\n",
      "    Grad  :  tensor([-0.0929,  0.5257])\n",
      "Epoch 1022,Loss 3.763602\n",
      "Epoch 1022, Loss 3.763602\n",
      "    Params:  tensor([  4.8229, -14.2207])\n",
      "    Grad  :  tensor([-0.0927,  0.5248])\n",
      "Epoch 1023,Loss 3.760766\n",
      "Epoch 1023, Loss 3.760766\n",
      "    Params:  tensor([  4.8238, -14.2259])\n",
      "    Grad  :  tensor([-0.0926,  0.5239])\n",
      "Epoch 1024,Loss 3.757936\n",
      "Epoch 1024, Loss 3.757936\n",
      "    Params:  tensor([  4.8248, -14.2311])\n",
      "    Grad  :  tensor([-0.0924,  0.5230])\n",
      "Epoch 1025,Loss 3.755118\n",
      "Epoch 1025, Loss 3.755118\n",
      "    Params:  tensor([  4.8257, -14.2364])\n",
      "    Grad  :  tensor([-0.0922,  0.5221])\n",
      "Epoch 1026,Loss 3.752309\n",
      "Epoch 1026, Loss 3.752309\n",
      "    Params:  tensor([  4.8266, -14.2416])\n",
      "    Grad  :  tensor([-0.0921,  0.5213])\n",
      "Epoch 1027,Loss 3.749511\n",
      "Epoch 1027, Loss 3.749511\n",
      "    Params:  tensor([  4.8275, -14.2468])\n",
      "    Grad  :  tensor([-0.0919,  0.5204])\n",
      "Epoch 1028,Loss 3.746722\n",
      "Epoch 1028, Loss 3.746722\n",
      "    Params:  tensor([  4.8284, -14.2520])\n",
      "    Grad  :  tensor([-0.0918,  0.5195])\n",
      "Epoch 1029,Loss 3.743940\n",
      "Epoch 1029, Loss 3.743940\n",
      "    Params:  tensor([  4.8293, -14.2572])\n",
      "    Grad  :  tensor([-0.0916,  0.5186])\n",
      "Epoch 1030,Loss 3.741169\n",
      "Epoch 1030, Loss 3.741169\n",
      "    Params:  tensor([  4.8303, -14.2623])\n",
      "    Grad  :  tensor([-0.0915,  0.5177])\n",
      "Epoch 1031,Loss 3.738407\n",
      "Epoch 1031, Loss 3.738407\n",
      "    Params:  tensor([  4.8312, -14.2675])\n",
      "    Grad  :  tensor([-0.0913,  0.5168])\n",
      "Epoch 1032,Loss 3.735656\n",
      "Epoch 1032, Loss 3.735656\n",
      "    Params:  tensor([  4.8321, -14.2727])\n",
      "    Grad  :  tensor([-0.0912,  0.5160])\n",
      "Epoch 1033,Loss 3.732914\n",
      "Epoch 1033, Loss 3.732914\n",
      "    Params:  tensor([  4.8330, -14.2778])\n",
      "    Grad  :  tensor([-0.0910,  0.5151])\n",
      "Epoch 1034,Loss 3.730181\n",
      "Epoch 1034, Loss 3.730181\n",
      "    Params:  tensor([  4.8339, -14.2830])\n",
      "    Grad  :  tensor([-0.0908,  0.5142])\n",
      "Epoch 1035,Loss 3.727456\n",
      "Epoch 1035, Loss 3.727456\n",
      "    Params:  tensor([  4.8348, -14.2881])\n",
      "    Grad  :  tensor([-0.0907,  0.5133])\n",
      "Epoch 1036,Loss 3.724740\n",
      "Epoch 1036, Loss 3.724740\n",
      "    Params:  tensor([  4.8357, -14.2932])\n",
      "    Grad  :  tensor([-0.0905,  0.5125])\n",
      "Epoch 1037,Loss 3.722034\n",
      "Epoch 1037, Loss 3.722034\n",
      "    Params:  tensor([  4.8366, -14.2983])\n",
      "    Grad  :  tensor([-0.0904,  0.5116])\n",
      "Epoch 1038,Loss 3.719337\n",
      "Epoch 1038, Loss 3.719337\n",
      "    Params:  tensor([  4.8375, -14.3034])\n",
      "    Grad  :  tensor([-0.0902,  0.5107])\n",
      "Epoch 1039,Loss 3.716651\n",
      "Epoch 1039, Loss 3.716651\n",
      "    Params:  tensor([  4.8384, -14.3085])\n",
      "    Grad  :  tensor([-0.0901,  0.5099])\n",
      "Epoch 1040,Loss 3.713972\n",
      "Epoch 1040, Loss 3.713972\n",
      "    Params:  tensor([  4.8393, -14.3136])\n",
      "    Grad  :  tensor([-0.0899,  0.5090])\n",
      "Epoch 1041,Loss 3.711302\n",
      "Epoch 1041, Loss 3.711302\n",
      "    Params:  tensor([  4.8402, -14.3187])\n",
      "    Grad  :  tensor([-0.0898,  0.5081])\n",
      "Epoch 1042,Loss 3.708644\n",
      "Epoch 1042, Loss 3.708644\n",
      "    Params:  tensor([  4.8411, -14.3238])\n",
      "    Grad  :  tensor([-0.0896,  0.5073])\n",
      "Epoch 1043,Loss 3.705991\n",
      "Epoch 1043, Loss 3.705991\n",
      "    Params:  tensor([  4.8420, -14.3288])\n",
      "    Grad  :  tensor([-0.0895,  0.5064])\n",
      "Epoch 1044,Loss 3.703351\n",
      "Epoch 1044, Loss 3.703351\n",
      "    Params:  tensor([  4.8429, -14.3339])\n",
      "    Grad  :  tensor([-0.0893,  0.5055])\n",
      "Epoch 1045,Loss 3.700716\n",
      "Epoch 1045, Loss 3.700716\n",
      "    Params:  tensor([  4.8438, -14.3390])\n",
      "    Grad  :  tensor([-0.0892,  0.5047])\n",
      "Epoch 1046,Loss 3.698091\n",
      "Epoch 1046, Loss 3.698091\n",
      "    Params:  tensor([  4.8447, -14.3440])\n",
      "    Grad  :  tensor([-0.0890,  0.5038])\n",
      "Epoch 1047,Loss 3.695476\n",
      "Epoch 1047, Loss 3.695476\n",
      "    Params:  tensor([  4.8456, -14.3490])\n",
      "    Grad  :  tensor([-0.0888,  0.5030])\n",
      "Epoch 1048,Loss 3.692869\n",
      "Epoch 1048, Loss 3.692869\n",
      "    Params:  tensor([  4.8465, -14.3540])\n",
      "    Grad  :  tensor([-0.0887,  0.5021])\n",
      "Epoch 1049,Loss 3.690273\n",
      "Epoch 1049, Loss 3.690273\n",
      "    Params:  tensor([  4.8473, -14.3591])\n",
      "    Grad  :  tensor([-0.0886,  0.5013])\n",
      "Epoch 1050,Loss 3.687683\n",
      "Epoch 1050, Loss 3.687683\n",
      "    Params:  tensor([  4.8482, -14.3641])\n",
      "    Grad  :  tensor([-0.0884,  0.5004])\n",
      "Epoch 1051,Loss 3.685104\n",
      "Epoch 1051, Loss 3.685104\n",
      "    Params:  tensor([  4.8491, -14.3691])\n",
      "    Grad  :  tensor([-0.0882,  0.4996])\n",
      "Epoch 1052,Loss 3.682532\n",
      "Epoch 1052, Loss 3.682532\n",
      "    Params:  tensor([  4.8500, -14.3740])\n",
      "    Grad  :  tensor([-0.0881,  0.4987])\n",
      "Epoch 1053,Loss 3.679969\n",
      "Epoch 1053, Loss 3.679969\n",
      "    Params:  tensor([  4.8509, -14.3790])\n",
      "    Grad  :  tensor([-0.0879,  0.4979])\n",
      "Epoch 1054,Loss 3.677417\n",
      "Epoch 1054, Loss 3.677417\n",
      "    Params:  tensor([  4.8518, -14.3840])\n",
      "    Grad  :  tensor([-0.0878,  0.4970])\n",
      "Epoch 1055,Loss 3.674871\n",
      "Epoch 1055, Loss 3.674871\n",
      "    Params:  tensor([  4.8526, -14.3889])\n",
      "    Grad  :  tensor([-0.0877,  0.4962])\n",
      "Epoch 1056,Loss 3.672335\n",
      "Epoch 1056, Loss 3.672335\n",
      "    Params:  tensor([  4.8535, -14.3939])\n",
      "    Grad  :  tensor([-0.0875,  0.4953])\n",
      "Epoch 1057,Loss 3.669804\n",
      "Epoch 1057, Loss 3.669804\n",
      "    Params:  tensor([  4.8544, -14.3988])\n",
      "    Grad  :  tensor([-0.0873,  0.4945])\n",
      "Epoch 1058,Loss 3.667287\n",
      "Epoch 1058, Loss 3.667287\n",
      "    Params:  tensor([  4.8552, -14.4038])\n",
      "    Grad  :  tensor([-0.0872,  0.4936])\n",
      "Epoch 1059,Loss 3.664775\n",
      "Epoch 1059, Loss 3.664775\n",
      "    Params:  tensor([  4.8561, -14.4087])\n",
      "    Grad  :  tensor([-0.0870,  0.4928])\n",
      "Epoch 1060,Loss 3.662273\n",
      "Epoch 1060, Loss 3.662273\n",
      "    Params:  tensor([  4.8570, -14.4136])\n",
      "    Grad  :  tensor([-0.0869,  0.4920])\n",
      "Epoch 1061,Loss 3.659778\n",
      "Epoch 1061, Loss 3.659778\n",
      "    Params:  tensor([  4.8579, -14.4185])\n",
      "    Grad  :  tensor([-0.0868,  0.4911])\n",
      "Epoch 1062,Loss 3.657295\n",
      "Epoch 1062, Loss 3.657295\n",
      "    Params:  tensor([  4.8587, -14.4234])\n",
      "    Grad  :  tensor([-0.0866,  0.4903])\n",
      "Epoch 1063,Loss 3.654816\n",
      "Epoch 1063, Loss 3.654816\n",
      "    Params:  tensor([  4.8596, -14.4283])\n",
      "    Grad  :  tensor([-0.0865,  0.4895])\n",
      "Epoch 1064,Loss 3.652349\n",
      "Epoch 1064, Loss 3.652349\n",
      "    Params:  tensor([  4.8604, -14.4332])\n",
      "    Grad  :  tensor([-0.0863,  0.4886])\n",
      "Epoch 1065,Loss 3.649889\n",
      "Epoch 1065, Loss 3.649889\n",
      "    Params:  tensor([  4.8613, -14.4381])\n",
      "    Grad  :  tensor([-0.0862,  0.4878])\n",
      "Epoch 1066,Loss 3.647437\n",
      "Epoch 1066, Loss 3.647437\n",
      "    Params:  tensor([  4.8622, -14.4430])\n",
      "    Grad  :  tensor([-0.0860,  0.4870])\n",
      "Epoch 1067,Loss 3.644991\n",
      "Epoch 1067, Loss 3.644991\n",
      "    Params:  tensor([  4.8630, -14.4478])\n",
      "    Grad  :  tensor([-0.0859,  0.4862])\n",
      "Epoch 1068,Loss 3.642559\n",
      "Epoch 1068, Loss 3.642559\n",
      "    Params:  tensor([  4.8639, -14.4527])\n",
      "    Grad  :  tensor([-0.0857,  0.4853])\n",
      "Epoch 1069,Loss 3.640132\n",
      "Epoch 1069, Loss 3.640132\n",
      "    Params:  tensor([  4.8647, -14.4575])\n",
      "    Grad  :  tensor([-0.0856,  0.4845])\n",
      "Epoch 1070,Loss 3.637711\n",
      "Epoch 1070, Loss 3.637711\n",
      "    Params:  tensor([  4.8656, -14.4624])\n",
      "    Grad  :  tensor([-0.0854,  0.4837])\n",
      "Epoch 1071,Loss 3.635302\n",
      "Epoch 1071, Loss 3.635302\n",
      "    Params:  tensor([  4.8665, -14.4672])\n",
      "    Grad  :  tensor([-0.0853,  0.4829])\n",
      "Epoch 1072,Loss 3.632902\n",
      "Epoch 1072, Loss 3.632902\n",
      "    Params:  tensor([  4.8673, -14.4720])\n",
      "    Grad  :  tensor([-0.0851,  0.4820])\n",
      "Epoch 1073,Loss 3.630508\n",
      "Epoch 1073, Loss 3.630508\n",
      "    Params:  tensor([  4.8682, -14.4768])\n",
      "    Grad  :  tensor([-0.0850,  0.4812])\n",
      "Epoch 1074,Loss 3.628119\n",
      "Epoch 1074, Loss 3.628119\n",
      "    Params:  tensor([  4.8690, -14.4816])\n",
      "    Grad  :  tensor([-0.0849,  0.4804])\n",
      "Epoch 1075,Loss 3.625741\n",
      "Epoch 1075, Loss 3.625741\n",
      "    Params:  tensor([  4.8698, -14.4864])\n",
      "    Grad  :  tensor([-0.0847,  0.4796])\n",
      "Epoch 1076,Loss 3.623374\n",
      "Epoch 1076, Loss 3.623374\n",
      "    Params:  tensor([  4.8707, -14.4912])\n",
      "    Grad  :  tensor([-0.0846,  0.4788])\n",
      "Epoch 1077,Loss 3.621010\n",
      "Epoch 1077, Loss 3.621010\n",
      "    Params:  tensor([  4.8715, -14.4960])\n",
      "    Grad  :  tensor([-0.0844,  0.4780])\n",
      "Epoch 1078,Loss 3.618659\n",
      "Epoch 1078, Loss 3.618659\n",
      "    Params:  tensor([  4.8724, -14.5008])\n",
      "    Grad  :  tensor([-0.0843,  0.4771])\n",
      "Epoch 1079,Loss 3.616311\n",
      "Epoch 1079, Loss 3.616311\n",
      "    Params:  tensor([  4.8732, -14.5055])\n",
      "    Grad  :  tensor([-0.0841,  0.4763])\n",
      "Epoch 1080,Loss 3.613973\n",
      "Epoch 1080, Loss 3.613973\n",
      "    Params:  tensor([  4.8741, -14.5103])\n",
      "    Grad  :  tensor([-0.0840,  0.4755])\n",
      "Epoch 1081,Loss 3.611643\n",
      "Epoch 1081, Loss 3.611643\n",
      "    Params:  tensor([  4.8749, -14.5150])\n",
      "    Grad  :  tensor([-0.0839,  0.4747])\n",
      "Epoch 1082,Loss 3.609321\n",
      "Epoch 1082, Loss 3.609321\n",
      "    Params:  tensor([  4.8757, -14.5198])\n",
      "    Grad  :  tensor([-0.0837,  0.4739])\n",
      "Epoch 1083,Loss 3.607008\n",
      "Epoch 1083, Loss 3.607008\n",
      "    Params:  tensor([  4.8766, -14.5245])\n",
      "    Grad  :  tensor([-0.0836,  0.4731])\n",
      "Epoch 1084,Loss 3.604701\n",
      "Epoch 1084, Loss 3.604701\n",
      "    Params:  tensor([  4.8774, -14.5292])\n",
      "    Grad  :  tensor([-0.0834,  0.4723])\n",
      "Epoch 1085,Loss 3.602403\n",
      "Epoch 1085, Loss 3.602403\n",
      "    Params:  tensor([  4.8782, -14.5339])\n",
      "    Grad  :  tensor([-0.0833,  0.4715])\n",
      "Epoch 1086,Loss 3.600114\n",
      "Epoch 1086, Loss 3.600114\n",
      "    Params:  tensor([  4.8791, -14.5387])\n",
      "    Grad  :  tensor([-0.0832,  0.4707])\n",
      "Epoch 1087,Loss 3.597831\n",
      "Epoch 1087, Loss 3.597831\n",
      "    Params:  tensor([  4.8799, -14.5434])\n",
      "    Grad  :  tensor([-0.0830,  0.4699])\n",
      "Epoch 1088,Loss 3.595553\n",
      "Epoch 1088, Loss 3.595553\n",
      "    Params:  tensor([  4.8807, -14.5480])\n",
      "    Grad  :  tensor([-0.0829,  0.4691])\n",
      "Epoch 1089,Loss 3.593287\n",
      "Epoch 1089, Loss 3.593287\n",
      "    Params:  tensor([  4.8816, -14.5527])\n",
      "    Grad  :  tensor([-0.0827,  0.4683])\n",
      "Epoch 1090,Loss 3.591030\n",
      "Epoch 1090, Loss 3.591030\n",
      "    Params:  tensor([  4.8824, -14.5574])\n",
      "    Grad  :  tensor([-0.0826,  0.4675])\n",
      "Epoch 1091,Loss 3.588776\n",
      "Epoch 1091, Loss 3.588776\n",
      "    Params:  tensor([  4.8832, -14.5621])\n",
      "    Grad  :  tensor([-0.0824,  0.4667])\n",
      "Epoch 1092,Loss 3.586534\n",
      "Epoch 1092, Loss 3.586534\n",
      "    Params:  tensor([  4.8840, -14.5667])\n",
      "    Grad  :  tensor([-0.0823,  0.4659])\n",
      "Epoch 1093,Loss 3.584294\n",
      "Epoch 1093, Loss 3.584294\n",
      "    Params:  tensor([  4.8849, -14.5714])\n",
      "    Grad  :  tensor([-0.0822,  0.4651])\n",
      "Epoch 1094,Loss 3.582067\n",
      "Epoch 1094, Loss 3.582067\n",
      "    Params:  tensor([  4.8857, -14.5760])\n",
      "    Grad  :  tensor([-0.0820,  0.4643])\n",
      "Epoch 1095,Loss 3.579845\n",
      "Epoch 1095, Loss 3.579845\n",
      "    Params:  tensor([  4.8865, -14.5807])\n",
      "    Grad  :  tensor([-0.0819,  0.4636])\n",
      "Epoch 1096,Loss 3.577631\n",
      "Epoch 1096, Loss 3.577631\n",
      "    Params:  tensor([  4.8873, -14.5853])\n",
      "    Grad  :  tensor([-0.0818,  0.4628])\n",
      "Epoch 1097,Loss 3.575424\n",
      "Epoch 1097, Loss 3.575424\n",
      "    Params:  tensor([  4.8881, -14.5899])\n",
      "    Grad  :  tensor([-0.0816,  0.4620])\n",
      "Epoch 1098,Loss 3.573225\n",
      "Epoch 1098, Loss 3.573225\n",
      "    Params:  tensor([  4.8889, -14.5945])\n",
      "    Grad  :  tensor([-0.0815,  0.4612])\n",
      "Epoch 1099,Loss 3.571035\n",
      "Epoch 1099, Loss 3.571035\n",
      "    Params:  tensor([  4.8898, -14.5991])\n",
      "    Grad  :  tensor([-0.0813,  0.4604])\n",
      "Epoch 1100,Loss 3.568848\n",
      "Epoch 1100, Loss 3.568848\n",
      "    Params:  tensor([  4.8906, -14.6037])\n",
      "    Grad  :  tensor([-0.0812,  0.4596])\n",
      "Epoch 1101,Loss 3.566673\n",
      "Epoch 1101, Loss 3.566673\n",
      "    Params:  tensor([  4.8914, -14.6083])\n",
      "    Grad  :  tensor([-0.0810,  0.4588])\n",
      "Epoch 1102,Loss 3.564506\n",
      "Epoch 1102, Loss 3.564506\n",
      "    Params:  tensor([  4.8922, -14.6129])\n",
      "    Grad  :  tensor([-0.0809,  0.4581])\n",
      "Epoch 1103,Loss 3.562341\n",
      "Epoch 1103, Loss 3.562341\n",
      "    Params:  tensor([  4.8930, -14.6175])\n",
      "    Grad  :  tensor([-0.0808,  0.4573])\n",
      "Epoch 1104,Loss 3.560185\n",
      "Epoch 1104, Loss 3.560185\n",
      "    Params:  tensor([  4.8938, -14.6220])\n",
      "    Grad  :  tensor([-0.0806,  0.4565])\n",
      "Epoch 1105,Loss 3.558040\n",
      "Epoch 1105, Loss 3.558040\n",
      "    Params:  tensor([  4.8946, -14.6266])\n",
      "    Grad  :  tensor([-0.0805,  0.4557])\n",
      "Epoch 1106,Loss 3.555901\n",
      "Epoch 1106, Loss 3.555901\n",
      "    Params:  tensor([  4.8954, -14.6311])\n",
      "    Grad  :  tensor([-0.0804,  0.4550])\n",
      "Epoch 1107,Loss 3.553767\n",
      "Epoch 1107, Loss 3.553767\n",
      "    Params:  tensor([  4.8962, -14.6357])\n",
      "    Grad  :  tensor([-0.0802,  0.4542])\n",
      "Epoch 1108,Loss 3.551641\n",
      "Epoch 1108, Loss 3.551641\n",
      "    Params:  tensor([  4.8970, -14.6402])\n",
      "    Grad  :  tensor([-0.0801,  0.4534])\n",
      "Epoch 1109,Loss 3.549524\n",
      "Epoch 1109, Loss 3.549524\n",
      "    Params:  tensor([  4.8978, -14.6447])\n",
      "    Grad  :  tensor([-0.0799,  0.4527])\n",
      "Epoch 1110,Loss 3.547411\n",
      "Epoch 1110, Loss 3.547411\n",
      "    Params:  tensor([  4.8986, -14.6493])\n",
      "    Grad  :  tensor([-0.0798,  0.4519])\n",
      "Epoch 1111,Loss 3.545309\n",
      "Epoch 1111, Loss 3.545309\n",
      "    Params:  tensor([  4.8994, -14.6538])\n",
      "    Grad  :  tensor([-0.0797,  0.4511])\n",
      "Epoch 1112,Loss 3.543211\n",
      "Epoch 1112, Loss 3.543211\n",
      "    Params:  tensor([  4.9002, -14.6583])\n",
      "    Grad  :  tensor([-0.0796,  0.4503])\n",
      "Epoch 1113,Loss 3.541124\n",
      "Epoch 1113, Loss 3.541124\n",
      "    Params:  tensor([  4.9010, -14.6628])\n",
      "    Grad  :  tensor([-0.0794,  0.4496])\n",
      "Epoch 1114,Loss 3.539041\n",
      "Epoch 1114, Loss 3.539041\n",
      "    Params:  tensor([  4.9018, -14.6673])\n",
      "    Grad  :  tensor([-0.0793,  0.4488])\n",
      "Epoch 1115,Loss 3.536967\n",
      "Epoch 1115, Loss 3.536967\n",
      "    Params:  tensor([  4.9026, -14.6717])\n",
      "    Grad  :  tensor([-0.0791,  0.4481])\n",
      "Epoch 1116,Loss 3.534896\n",
      "Epoch 1116, Loss 3.534896\n",
      "    Params:  tensor([  4.9034, -14.6762])\n",
      "    Grad  :  tensor([-0.0790,  0.4473])\n",
      "Epoch 1117,Loss 3.532835\n",
      "Epoch 1117, Loss 3.532835\n",
      "    Params:  tensor([  4.9042, -14.6807])\n",
      "    Grad  :  tensor([-0.0789,  0.4465])\n",
      "Epoch 1118,Loss 3.530781\n",
      "Epoch 1118, Loss 3.530781\n",
      "    Params:  tensor([  4.9049, -14.6851])\n",
      "    Grad  :  tensor([-0.0787,  0.4458])\n",
      "Epoch 1119,Loss 3.528734\n",
      "Epoch 1119, Loss 3.528734\n",
      "    Params:  tensor([  4.9057, -14.6896])\n",
      "    Grad  :  tensor([-0.0786,  0.4450])\n",
      "Epoch 1120,Loss 3.526694\n",
      "Epoch 1120, Loss 3.526694\n",
      "    Params:  tensor([  4.9065, -14.6940])\n",
      "    Grad  :  tensor([-0.0785,  0.4443])\n",
      "Epoch 1121,Loss 3.524662\n",
      "Epoch 1121, Loss 3.524662\n",
      "    Params:  tensor([  4.9073, -14.6985])\n",
      "    Grad  :  tensor([-0.0784,  0.4435])\n",
      "Epoch 1122,Loss 3.522633\n",
      "Epoch 1122, Loss 3.522633\n",
      "    Params:  tensor([  4.9081, -14.7029])\n",
      "    Grad  :  tensor([-0.0782,  0.4428])\n",
      "Epoch 1123,Loss 3.520614\n",
      "Epoch 1123, Loss 3.520614\n",
      "    Params:  tensor([  4.9089, -14.7073])\n",
      "    Grad  :  tensor([-0.0781,  0.4420])\n",
      "Epoch 1124,Loss 3.518601\n",
      "Epoch 1124, Loss 3.518601\n",
      "    Params:  tensor([  4.9096, -14.7117])\n",
      "    Grad  :  tensor([-0.0779,  0.4413])\n",
      "Epoch 1125,Loss 3.516594\n",
      "Epoch 1125, Loss 3.516594\n",
      "    Params:  tensor([  4.9104, -14.7161])\n",
      "    Grad  :  tensor([-0.0778,  0.4405])\n",
      "Epoch 1126,Loss 3.514594\n",
      "Epoch 1126, Loss 3.514594\n",
      "    Params:  tensor([  4.9112, -14.7205])\n",
      "    Grad  :  tensor([-0.0777,  0.4398])\n",
      "Epoch 1127,Loss 3.512602\n",
      "Epoch 1127, Loss 3.512602\n",
      "    Params:  tensor([  4.9120, -14.7249])\n",
      "    Grad  :  tensor([-0.0775,  0.4390])\n",
      "Epoch 1128,Loss 3.510619\n",
      "Epoch 1128, Loss 3.510619\n",
      "    Params:  tensor([  4.9128, -14.7293])\n",
      "    Grad  :  tensor([-0.0774,  0.4383])\n",
      "Epoch 1129,Loss 3.508637\n",
      "Epoch 1129, Loss 3.508637\n",
      "    Params:  tensor([  4.9135, -14.7337])\n",
      "    Grad  :  tensor([-0.0773,  0.4375])\n",
      "Epoch 1130,Loss 3.506665\n",
      "Epoch 1130, Loss 3.506665\n",
      "    Params:  tensor([  4.9143, -14.7380])\n",
      "    Grad  :  tensor([-0.0772,  0.4368])\n",
      "Epoch 1131,Loss 3.504699\n",
      "Epoch 1131, Loss 3.504699\n",
      "    Params:  tensor([  4.9151, -14.7424])\n",
      "    Grad  :  tensor([-0.0770,  0.4360])\n",
      "Epoch 1132,Loss 3.502741\n",
      "Epoch 1132, Loss 3.502741\n",
      "    Params:  tensor([  4.9158, -14.7467])\n",
      "    Grad  :  tensor([-0.0769,  0.4353])\n",
      "Epoch 1133,Loss 3.500789\n",
      "Epoch 1133, Loss 3.500789\n",
      "    Params:  tensor([  4.9166, -14.7511])\n",
      "    Grad  :  tensor([-0.0767,  0.4346])\n",
      "Epoch 1134,Loss 3.498843\n",
      "Epoch 1134, Loss 3.498843\n",
      "    Params:  tensor([  4.9174, -14.7554])\n",
      "    Grad  :  tensor([-0.0766,  0.4338])\n",
      "Epoch 1135,Loss 3.496905\n",
      "Epoch 1135, Loss 3.496905\n",
      "    Params:  tensor([  4.9181, -14.7598])\n",
      "    Grad  :  tensor([-0.0765,  0.4331])\n",
      "Epoch 1136,Loss 3.494972\n",
      "Epoch 1136, Loss 3.494972\n",
      "    Params:  tensor([  4.9189, -14.7641])\n",
      "    Grad  :  tensor([-0.0764,  0.4323])\n",
      "Epoch 1137,Loss 3.493046\n",
      "Epoch 1137, Loss 3.493046\n",
      "    Params:  tensor([  4.9197, -14.7684])\n",
      "    Grad  :  tensor([-0.0763,  0.4316])\n",
      "Epoch 1138,Loss 3.491127\n",
      "Epoch 1138, Loss 3.491127\n",
      "    Params:  tensor([  4.9204, -14.7727])\n",
      "    Grad  :  tensor([-0.0761,  0.4309])\n",
      "Epoch 1139,Loss 3.489214\n",
      "Epoch 1139, Loss 3.489214\n",
      "    Params:  tensor([  4.9212, -14.7770])\n",
      "    Grad  :  tensor([-0.0760,  0.4301])\n",
      "Epoch 1140,Loss 3.487308\n",
      "Epoch 1140, Loss 3.487308\n",
      "    Params:  tensor([  4.9219, -14.7813])\n",
      "    Grad  :  tensor([-0.0759,  0.4294])\n",
      "Epoch 1141,Loss 3.485410\n",
      "Epoch 1141, Loss 3.485410\n",
      "    Params:  tensor([  4.9227, -14.7856])\n",
      "    Grad  :  tensor([-0.0757,  0.4287])\n",
      "Epoch 1142,Loss 3.483515\n",
      "Epoch 1142, Loss 3.483515\n",
      "    Params:  tensor([  4.9235, -14.7899])\n",
      "    Grad  :  tensor([-0.0756,  0.4280])\n",
      "Epoch 1143,Loss 3.481627\n",
      "Epoch 1143, Loss 3.481627\n",
      "    Params:  tensor([  4.9242, -14.7941])\n",
      "    Grad  :  tensor([-0.0755,  0.4272])\n",
      "Epoch 1144,Loss 3.479746\n",
      "Epoch 1144, Loss 3.479746\n",
      "    Params:  tensor([  4.9250, -14.7984])\n",
      "    Grad  :  tensor([-0.0753,  0.4265])\n",
      "Epoch 1145,Loss 3.477872\n",
      "Epoch 1145, Loss 3.477872\n",
      "    Params:  tensor([  4.9257, -14.8027])\n",
      "    Grad  :  tensor([-0.0752,  0.4258])\n",
      "Epoch 1146,Loss 3.476005\n",
      "Epoch 1146, Loss 3.476005\n",
      "    Params:  tensor([  4.9265, -14.8069])\n",
      "    Grad  :  tensor([-0.0751,  0.4250])\n",
      "Epoch 1147,Loss 3.474143\n",
      "Epoch 1147, Loss 3.474143\n",
      "    Params:  tensor([  4.9272, -14.8112])\n",
      "    Grad  :  tensor([-0.0750,  0.4243])\n",
      "Epoch 1148,Loss 3.472288\n",
      "Epoch 1148, Loss 3.472288\n",
      "    Params:  tensor([  4.9280, -14.8154])\n",
      "    Grad  :  tensor([-0.0748,  0.4236])\n",
      "Epoch 1149,Loss 3.470441\n",
      "Epoch 1149, Loss 3.470441\n",
      "    Params:  tensor([  4.9287, -14.8196])\n",
      "    Grad  :  tensor([-0.0747,  0.4229])\n",
      "Epoch 1150,Loss 3.468597\n",
      "Epoch 1150, Loss 3.468597\n",
      "    Params:  tensor([  4.9295, -14.8238])\n",
      "    Grad  :  tensor([-0.0746,  0.4222])\n",
      "Epoch 1151,Loss 3.466762\n",
      "Epoch 1151, Loss 3.466762\n",
      "    Params:  tensor([  4.9302, -14.8281])\n",
      "    Grad  :  tensor([-0.0745,  0.4215])\n",
      "Epoch 1152,Loss 3.464930\n",
      "Epoch 1152, Loss 3.464930\n",
      "    Params:  tensor([  4.9309, -14.8323])\n",
      "    Grad  :  tensor([-0.0743,  0.4207])\n",
      "Epoch 1153,Loss 3.463105\n",
      "Epoch 1153, Loss 3.463105\n",
      "    Params:  tensor([  4.9317, -14.8365])\n",
      "    Grad  :  tensor([-0.0742,  0.4200])\n",
      "Epoch 1154,Loss 3.461290\n",
      "Epoch 1154, Loss 3.461290\n",
      "    Params:  tensor([  4.9324, -14.8407])\n",
      "    Grad  :  tensor([-0.0741,  0.4193])\n",
      "Epoch 1155,Loss 3.459477\n",
      "Epoch 1155, Loss 3.459477\n",
      "    Params:  tensor([  4.9332, -14.8448])\n",
      "    Grad  :  tensor([-0.0739,  0.4186])\n",
      "Epoch 1156,Loss 3.457671\n",
      "Epoch 1156, Loss 3.457671\n",
      "    Params:  tensor([  4.9339, -14.8490])\n",
      "    Grad  :  tensor([-0.0738,  0.4179])\n",
      "Epoch 1157,Loss 3.455873\n",
      "Epoch 1157, Loss 3.455873\n",
      "    Params:  tensor([  4.9346, -14.8532])\n",
      "    Grad  :  tensor([-0.0737,  0.4172])\n",
      "Epoch 1158,Loss 3.454080\n",
      "Epoch 1158, Loss 3.454080\n",
      "    Params:  tensor([  4.9354, -14.8574])\n",
      "    Grad  :  tensor([-0.0736,  0.4165])\n",
      "Epoch 1159,Loss 3.452293\n",
      "Epoch 1159, Loss 3.452293\n",
      "    Params:  tensor([  4.9361, -14.8615])\n",
      "    Grad  :  tensor([-0.0734,  0.4158])\n",
      "Epoch 1160,Loss 3.450513\n",
      "Epoch 1160, Loss 3.450513\n",
      "    Params:  tensor([  4.9368, -14.8657])\n",
      "    Grad  :  tensor([-0.0733,  0.4151])\n",
      "Epoch 1161,Loss 3.448736\n",
      "Epoch 1161, Loss 3.448736\n",
      "    Params:  tensor([  4.9376, -14.8698])\n",
      "    Grad  :  tensor([-0.0732,  0.4143])\n",
      "Epoch 1162,Loss 3.446968\n",
      "Epoch 1162, Loss 3.446968\n",
      "    Params:  tensor([  4.9383, -14.8739])\n",
      "    Grad  :  tensor([-0.0731,  0.4136])\n",
      "Epoch 1163,Loss 3.445203\n",
      "Epoch 1163, Loss 3.445203\n",
      "    Params:  tensor([  4.9390, -14.8781])\n",
      "    Grad  :  tensor([-0.0730,  0.4129])\n",
      "Epoch 1164,Loss 3.443449\n",
      "Epoch 1164, Loss 3.443449\n",
      "    Params:  tensor([  4.9398, -14.8822])\n",
      "    Grad  :  tensor([-0.0728,  0.4122])\n",
      "Epoch 1165,Loss 3.441697\n",
      "Epoch 1165, Loss 3.441697\n",
      "    Params:  tensor([  4.9405, -14.8863])\n",
      "    Grad  :  tensor([-0.0727,  0.4115])\n",
      "Epoch 1166,Loss 3.439952\n",
      "Epoch 1166, Loss 3.439952\n",
      "    Params:  tensor([  4.9412, -14.8904])\n",
      "    Grad  :  tensor([-0.0726,  0.4108])\n",
      "Epoch 1167,Loss 3.438210\n",
      "Epoch 1167, Loss 3.438210\n",
      "    Params:  tensor([  4.9419, -14.8945])\n",
      "    Grad  :  tensor([-0.0725,  0.4101])\n",
      "Epoch 1168,Loss 3.436479\n",
      "Epoch 1168, Loss 3.436479\n",
      "    Params:  tensor([  4.9427, -14.8986])\n",
      "    Grad  :  tensor([-0.0723,  0.4094])\n",
      "Epoch 1169,Loss 3.434753\n",
      "Epoch 1169, Loss 3.434753\n",
      "    Params:  tensor([  4.9434, -14.9027])\n",
      "    Grad  :  tensor([-0.0722,  0.4087])\n",
      "Epoch 1170,Loss 3.433030\n",
      "Epoch 1170, Loss 3.433030\n",
      "    Params:  tensor([  4.9441, -14.9068])\n",
      "    Grad  :  tensor([-0.0721,  0.4081])\n",
      "Epoch 1171,Loss 3.431314\n",
      "Epoch 1171, Loss 3.431314\n",
      "    Params:  tensor([  4.9448, -14.9109])\n",
      "    Grad  :  tensor([-0.0720,  0.4074])\n",
      "Epoch 1172,Loss 3.429607\n",
      "Epoch 1172, Loss 3.429607\n",
      "    Params:  tensor([  4.9455, -14.9149])\n",
      "    Grad  :  tensor([-0.0719,  0.4067])\n",
      "Epoch 1173,Loss 3.427903\n",
      "Epoch 1173, Loss 3.427903\n",
      "    Params:  tensor([  4.9463, -14.9190])\n",
      "    Grad  :  tensor([-0.0717,  0.4060])\n",
      "Epoch 1174,Loss 3.426204\n",
      "Epoch 1174, Loss 3.426204\n",
      "    Params:  tensor([  4.9470, -14.9230])\n",
      "    Grad  :  tensor([-0.0716,  0.4053])\n",
      "Epoch 1175,Loss 3.424510\n",
      "Epoch 1175, Loss 3.424510\n",
      "    Params:  tensor([  4.9477, -14.9271])\n",
      "    Grad  :  tensor([-0.0715,  0.4046])\n",
      "Epoch 1176,Loss 3.422823\n",
      "Epoch 1176, Loss 3.422823\n",
      "    Params:  tensor([  4.9484, -14.9311])\n",
      "    Grad  :  tensor([-0.0714,  0.4039])\n",
      "Epoch 1177,Loss 3.421144\n",
      "Epoch 1177, Loss 3.421144\n",
      "    Params:  tensor([  4.9491, -14.9352])\n",
      "    Grad  :  tensor([-0.0712,  0.4032])\n",
      "Epoch 1178,Loss 3.419468\n",
      "Epoch 1178, Loss 3.419468\n",
      "    Params:  tensor([  4.9498, -14.9392])\n",
      "    Grad  :  tensor([-0.0711,  0.4025])\n",
      "Epoch 1179,Loss 3.417798\n",
      "Epoch 1179, Loss 3.417798\n",
      "    Params:  tensor([  4.9505, -14.9432])\n",
      "    Grad  :  tensor([-0.0710,  0.4019])\n",
      "Epoch 1180,Loss 3.416134\n",
      "Epoch 1180, Loss 3.416134\n",
      "    Params:  tensor([  4.9512, -14.9472])\n",
      "    Grad  :  tensor([-0.0709,  0.4012])\n",
      "Epoch 1181,Loss 3.414476\n",
      "Epoch 1181, Loss 3.414476\n",
      "    Params:  tensor([  4.9520, -14.9512])\n",
      "    Grad  :  tensor([-0.0708,  0.4005])\n",
      "Epoch 1182,Loss 3.412824\n",
      "Epoch 1182, Loss 3.412824\n",
      "    Params:  tensor([  4.9527, -14.9552])\n",
      "    Grad  :  tensor([-0.0706,  0.3998])\n",
      "Epoch 1183,Loss 3.411176\n",
      "Epoch 1183, Loss 3.411176\n",
      "    Params:  tensor([  4.9534, -14.9592])\n",
      "    Grad  :  tensor([-0.0705,  0.3991])\n",
      "Epoch 1184,Loss 3.409534\n",
      "Epoch 1184, Loss 3.409534\n",
      "    Params:  tensor([  4.9541, -14.9632])\n",
      "    Grad  :  tensor([-0.0704,  0.3985])\n",
      "Epoch 1185,Loss 3.407900\n",
      "Epoch 1185, Loss 3.407900\n",
      "    Params:  tensor([  4.9548, -14.9672])\n",
      "    Grad  :  tensor([-0.0703,  0.3978])\n",
      "Epoch 1186,Loss 3.406271\n",
      "Epoch 1186, Loss 3.406271\n",
      "    Params:  tensor([  4.9555, -14.9711])\n",
      "    Grad  :  tensor([-0.0701,  0.3971])\n",
      "Epoch 1187,Loss 3.404645\n",
      "Epoch 1187, Loss 3.404645\n",
      "    Params:  tensor([  4.9562, -14.9751])\n",
      "    Grad  :  tensor([-0.0700,  0.3964])\n",
      "Epoch 1188,Loss 3.403024\n",
      "Epoch 1188, Loss 3.403024\n",
      "    Params:  tensor([  4.9569, -14.9791])\n",
      "    Grad  :  tensor([-0.0699,  0.3958])\n",
      "Epoch 1189,Loss 3.401413\n",
      "Epoch 1189, Loss 3.401413\n",
      "    Params:  tensor([  4.9576, -14.9830])\n",
      "    Grad  :  tensor([-0.0698,  0.3951])\n",
      "Epoch 1190,Loss 3.399802\n",
      "Epoch 1190, Loss 3.399802\n",
      "    Params:  tensor([  4.9583, -14.9870])\n",
      "    Grad  :  tensor([-0.0697,  0.3944])\n",
      "Epoch 1191,Loss 3.398200\n",
      "Epoch 1191, Loss 3.398200\n",
      "    Params:  tensor([  4.9590, -14.9909])\n",
      "    Grad  :  tensor([-0.0696,  0.3937])\n",
      "Epoch 1192,Loss 3.396602\n",
      "Epoch 1192, Loss 3.396602\n",
      "    Params:  tensor([  4.9597, -14.9948])\n",
      "    Grad  :  tensor([-0.0694,  0.3931])\n",
      "Epoch 1193,Loss 3.395011\n",
      "Epoch 1193, Loss 3.395011\n",
      "    Params:  tensor([  4.9604, -14.9988])\n",
      "    Grad  :  tensor([-0.0693,  0.3924])\n",
      "Epoch 1194,Loss 3.393425\n",
      "Epoch 1194, Loss 3.393425\n",
      "    Params:  tensor([  4.9610, -15.0027])\n",
      "    Grad  :  tensor([-0.0692,  0.3917])\n",
      "Epoch 1195,Loss 3.391844\n",
      "Epoch 1195, Loss 3.391844\n",
      "    Params:  tensor([  4.9617, -15.0066])\n",
      "    Grad  :  tensor([-0.0691,  0.3911])\n",
      "Epoch 1196,Loss 3.390266\n",
      "Epoch 1196, Loss 3.390266\n",
      "    Params:  tensor([  4.9624, -15.0105])\n",
      "    Grad  :  tensor([-0.0690,  0.3904])\n",
      "Epoch 1197,Loss 3.388697\n",
      "Epoch 1197, Loss 3.388697\n",
      "    Params:  tensor([  4.9631, -15.0144])\n",
      "    Grad  :  tensor([-0.0689,  0.3897])\n",
      "Epoch 1198,Loss 3.387131\n",
      "Epoch 1198, Loss 3.387131\n",
      "    Params:  tensor([  4.9638, -15.0183])\n",
      "    Grad  :  tensor([-0.0688,  0.3891])\n",
      "Epoch 1199,Loss 3.385571\n",
      "Epoch 1199, Loss 3.385571\n",
      "    Params:  tensor([  4.9645, -15.0222])\n",
      "    Grad  :  tensor([-0.0686,  0.3884])\n",
      "Epoch 1200,Loss 3.384018\n",
      "Epoch 1200, Loss 3.384018\n",
      "    Params:  tensor([  4.9652, -15.0260])\n",
      "    Grad  :  tensor([-0.0685,  0.3878])\n",
      "Epoch 1201,Loss 3.382467\n",
      "Epoch 1201, Loss 3.382467\n",
      "    Params:  tensor([  4.9659, -15.0299])\n",
      "    Grad  :  tensor([-0.0684,  0.3871])\n",
      "Epoch 1202,Loss 3.380925\n",
      "Epoch 1202, Loss 3.380925\n",
      "    Params:  tensor([  4.9665, -15.0338])\n",
      "    Grad  :  tensor([-0.0683,  0.3864])\n",
      "Epoch 1203,Loss 3.379385\n",
      "Epoch 1203, Loss 3.379385\n",
      "    Params:  tensor([  4.9672, -15.0376])\n",
      "    Grad  :  tensor([-0.0681,  0.3858])\n",
      "Epoch 1204,Loss 3.377851\n",
      "Epoch 1204, Loss 3.377851\n",
      "    Params:  tensor([  4.9679, -15.0415])\n",
      "    Grad  :  tensor([-0.0680,  0.3851])\n",
      "Epoch 1205,Loss 3.376323\n",
      "Epoch 1205, Loss 3.376323\n",
      "    Params:  tensor([  4.9686, -15.0453])\n",
      "    Grad  :  tensor([-0.0679,  0.3845])\n",
      "Epoch 1206,Loss 3.374800\n",
      "Epoch 1206, Loss 3.374800\n",
      "    Params:  tensor([  4.9693, -15.0492])\n",
      "    Grad  :  tensor([-0.0678,  0.3838])\n",
      "Epoch 1207,Loss 3.373284\n",
      "Epoch 1207, Loss 3.373284\n",
      "    Params:  tensor([  4.9699, -15.0530])\n",
      "    Grad  :  tensor([-0.0677,  0.3832])\n",
      "Epoch 1208,Loss 3.371769\n",
      "Epoch 1208, Loss 3.371769\n",
      "    Params:  tensor([  4.9706, -15.0568])\n",
      "    Grad  :  tensor([-0.0676,  0.3825])\n",
      "Epoch 1209,Loss 3.370261\n",
      "Epoch 1209, Loss 3.370261\n",
      "    Params:  tensor([  4.9713, -15.0606])\n",
      "    Grad  :  tensor([-0.0675,  0.3819])\n",
      "Epoch 1210,Loss 3.368760\n",
      "Epoch 1210, Loss 3.368760\n",
      "    Params:  tensor([  4.9720, -15.0645])\n",
      "    Grad  :  tensor([-0.0673,  0.3812])\n",
      "Epoch 1211,Loss 3.367262\n",
      "Epoch 1211, Loss 3.367262\n",
      "    Params:  tensor([  4.9726, -15.0683])\n",
      "    Grad  :  tensor([-0.0672,  0.3806])\n",
      "Epoch 1212,Loss 3.365771\n",
      "Epoch 1212, Loss 3.365771\n",
      "    Params:  tensor([  4.9733, -15.0721])\n",
      "    Grad  :  tensor([-0.0671,  0.3799])\n",
      "Epoch 1213,Loss 3.364282\n",
      "Epoch 1213, Loss 3.364282\n",
      "    Params:  tensor([  4.9740, -15.0758])\n",
      "    Grad  :  tensor([-0.0670,  0.3793])\n",
      "Epoch 1214,Loss 3.362800\n",
      "Epoch 1214, Loss 3.362800\n",
      "    Params:  tensor([  4.9746, -15.0796])\n",
      "    Grad  :  tensor([-0.0669,  0.3786])\n",
      "Epoch 1215,Loss 3.361324\n",
      "Epoch 1215, Loss 3.361324\n",
      "    Params:  tensor([  4.9753, -15.0834])\n",
      "    Grad  :  tensor([-0.0668,  0.3780])\n",
      "Epoch 1216,Loss 3.359850\n",
      "Epoch 1216, Loss 3.359850\n",
      "    Params:  tensor([  4.9760, -15.0872])\n",
      "    Grad  :  tensor([-0.0667,  0.3774])\n",
      "Epoch 1217,Loss 3.358384\n",
      "Epoch 1217, Loss 3.358384\n",
      "    Params:  tensor([  4.9766, -15.0910])\n",
      "    Grad  :  tensor([-0.0665,  0.3767])\n",
      "Epoch 1218,Loss 3.356921\n",
      "Epoch 1218, Loss 3.356921\n",
      "    Params:  tensor([  4.9773, -15.0947])\n",
      "    Grad  :  tensor([-0.0664,  0.3761])\n",
      "Epoch 1219,Loss 3.355464\n",
      "Epoch 1219, Loss 3.355464\n",
      "    Params:  tensor([  4.9780, -15.0985])\n",
      "    Grad  :  tensor([-0.0663,  0.3754])\n",
      "Epoch 1220,Loss 3.354012\n",
      "Epoch 1220, Loss 3.354012\n",
      "    Params:  tensor([  4.9786, -15.1022])\n",
      "    Grad  :  tensor([-0.0662,  0.3748])\n",
      "Epoch 1221,Loss 3.352564\n",
      "Epoch 1221, Loss 3.352564\n",
      "    Params:  tensor([  4.9793, -15.1060])\n",
      "    Grad  :  tensor([-0.0661,  0.3742])\n",
      "Epoch 1222,Loss 3.351122\n",
      "Epoch 1222, Loss 3.351122\n",
      "    Params:  tensor([  4.9799, -15.1097])\n",
      "    Grad  :  tensor([-0.0660,  0.3735])\n",
      "Epoch 1223,Loss 3.349685\n",
      "Epoch 1223, Loss 3.349685\n",
      "    Params:  tensor([  4.9806, -15.1134])\n",
      "    Grad  :  tensor([-0.0659,  0.3729])\n",
      "Epoch 1224,Loss 3.348251\n",
      "Epoch 1224, Loss 3.348251\n",
      "    Params:  tensor([  4.9813, -15.1171])\n",
      "    Grad  :  tensor([-0.0657,  0.3723])\n",
      "Epoch 1225,Loss 3.346824\n",
      "Epoch 1225, Loss 3.346824\n",
      "    Params:  tensor([  4.9819, -15.1209])\n",
      "    Grad  :  tensor([-0.0656,  0.3716])\n",
      "Epoch 1226,Loss 3.345403\n",
      "Epoch 1226, Loss 3.345403\n",
      "    Params:  tensor([  4.9826, -15.1246])\n",
      "    Grad  :  tensor([-0.0655,  0.3710])\n",
      "Epoch 1227,Loss 3.343982\n",
      "Epoch 1227, Loss 3.343982\n",
      "    Params:  tensor([  4.9832, -15.1283])\n",
      "    Grad  :  tensor([-0.0654,  0.3704])\n",
      "Epoch 1228,Loss 3.342571\n",
      "Epoch 1228, Loss 3.342571\n",
      "    Params:  tensor([  4.9839, -15.1320])\n",
      "    Grad  :  tensor([-0.0653,  0.3697])\n",
      "Epoch 1229,Loss 3.341160\n",
      "Epoch 1229, Loss 3.341160\n",
      "    Params:  tensor([  4.9845, -15.1357])\n",
      "    Grad  :  tensor([-0.0652,  0.3691])\n",
      "Epoch 1230,Loss 3.339758\n",
      "Epoch 1230, Loss 3.339758\n",
      "    Params:  tensor([  4.9852, -15.1393])\n",
      "    Grad  :  tensor([-0.0651,  0.3685])\n",
      "Epoch 1231,Loss 3.338359\n",
      "Epoch 1231, Loss 3.338359\n",
      "    Params:  tensor([  4.9858, -15.1430])\n",
      "    Grad  :  tensor([-0.0650,  0.3679])\n",
      "Epoch 1232,Loss 3.336965\n",
      "Epoch 1232, Loss 3.336965\n",
      "    Params:  tensor([  4.9865, -15.1467])\n",
      "    Grad  :  tensor([-0.0649,  0.3672])\n",
      "Epoch 1233,Loss 3.335577\n",
      "Epoch 1233, Loss 3.335577\n",
      "    Params:  tensor([  4.9871, -15.1504])\n",
      "    Grad  :  tensor([-0.0648,  0.3666])\n",
      "Epoch 1234,Loss 3.334192\n",
      "Epoch 1234, Loss 3.334192\n",
      "    Params:  tensor([  4.9878, -15.1540])\n",
      "    Grad  :  tensor([-0.0646,  0.3660])\n",
      "Epoch 1235,Loss 3.332811\n",
      "Epoch 1235, Loss 3.332811\n",
      "    Params:  tensor([  4.9884, -15.1577])\n",
      "    Grad  :  tensor([-0.0645,  0.3654])\n",
      "Epoch 1236,Loss 3.331436\n",
      "Epoch 1236, Loss 3.331436\n",
      "    Params:  tensor([  4.9891, -15.1613])\n",
      "    Grad  :  tensor([-0.0644,  0.3647])\n",
      "Epoch 1237,Loss 3.330065\n",
      "Epoch 1237, Loss 3.330065\n",
      "    Params:  tensor([  4.9897, -15.1650])\n",
      "    Grad  :  tensor([-0.0643,  0.3641])\n",
      "Epoch 1238,Loss 3.328699\n",
      "Epoch 1238, Loss 3.328699\n",
      "    Params:  tensor([  4.9904, -15.1686])\n",
      "    Grad  :  tensor([-0.0642,  0.3635])\n",
      "Epoch 1239,Loss 3.327339\n",
      "Epoch 1239, Loss 3.327339\n",
      "    Params:  tensor([  4.9910, -15.1722])\n",
      "    Grad  :  tensor([-0.0641,  0.3629])\n",
      "Epoch 1240,Loss 3.325980\n",
      "Epoch 1240, Loss 3.325980\n",
      "    Params:  tensor([  4.9916, -15.1759])\n",
      "    Grad  :  tensor([-0.0640,  0.3623])\n",
      "Epoch 1241,Loss 3.324628\n",
      "Epoch 1241, Loss 3.324628\n",
      "    Params:  tensor([  4.9923, -15.1795])\n",
      "    Grad  :  tensor([-0.0639,  0.3617])\n",
      "Epoch 1242,Loss 3.323279\n",
      "Epoch 1242, Loss 3.323279\n",
      "    Params:  tensor([  4.9929, -15.1831])\n",
      "    Grad  :  tensor([-0.0638,  0.3610])\n",
      "Epoch 1243,Loss 3.321935\n",
      "Epoch 1243, Loss 3.321935\n",
      "    Params:  tensor([  4.9936, -15.1867])\n",
      "    Grad  :  tensor([-0.0637,  0.3604])\n",
      "Epoch 1244,Loss 3.320600\n",
      "Epoch 1244, Loss 3.320600\n",
      "    Params:  tensor([  4.9942, -15.1903])\n",
      "    Grad  :  tensor([-0.0636,  0.3598])\n",
      "Epoch 1245,Loss 3.319264\n",
      "Epoch 1245, Loss 3.319264\n",
      "    Params:  tensor([  4.9948, -15.1939])\n",
      "    Grad  :  tensor([-0.0635,  0.3592])\n",
      "Epoch 1246,Loss 3.317935\n",
      "Epoch 1246, Loss 3.317935\n",
      "    Params:  tensor([  4.9955, -15.1975])\n",
      "    Grad  :  tensor([-0.0633,  0.3586])\n",
      "Epoch 1247,Loss 3.316611\n",
      "Epoch 1247, Loss 3.316611\n",
      "    Params:  tensor([  4.9961, -15.2010])\n",
      "    Grad  :  tensor([-0.0633,  0.3580])\n",
      "Epoch 1248,Loss 3.315289\n",
      "Epoch 1248, Loss 3.315289\n",
      "    Params:  tensor([  4.9967, -15.2046])\n",
      "    Grad  :  tensor([-0.0631,  0.3574])\n",
      "Epoch 1249,Loss 3.313973\n",
      "Epoch 1249, Loss 3.313973\n",
      "    Params:  tensor([  4.9973, -15.2082])\n",
      "    Grad  :  tensor([-0.0630,  0.3568])\n",
      "Epoch 1250,Loss 3.312663\n",
      "Epoch 1250, Loss 3.312663\n",
      "    Params:  tensor([  4.9980, -15.2117])\n",
      "    Grad  :  tensor([-0.0629,  0.3562])\n",
      "Epoch 1251,Loss 3.311353\n",
      "Epoch 1251, Loss 3.311353\n",
      "    Params:  tensor([  4.9986, -15.2153])\n",
      "    Grad  :  tensor([-0.0628,  0.3556])\n",
      "Epoch 1252,Loss 3.310053\n",
      "Epoch 1252, Loss 3.310053\n",
      "    Params:  tensor([  4.9992, -15.2189])\n",
      "    Grad  :  tensor([-0.0627,  0.3550])\n",
      "Epoch 1253,Loss 3.308756\n",
      "Epoch 1253, Loss 3.308756\n",
      "    Params:  tensor([  4.9999, -15.2224])\n",
      "    Grad  :  tensor([-0.0626,  0.3543])\n",
      "Epoch 1254,Loss 3.307463\n",
      "Epoch 1254, Loss 3.307463\n",
      "    Params:  tensor([  5.0005, -15.2259])\n",
      "    Grad  :  tensor([-0.0625,  0.3537])\n",
      "Epoch 1255,Loss 3.306170\n",
      "Epoch 1255, Loss 3.306170\n",
      "    Params:  tensor([  5.0011, -15.2295])\n",
      "    Grad  :  tensor([-0.0624,  0.3531])\n",
      "Epoch 1256,Loss 3.304887\n",
      "Epoch 1256, Loss 3.304887\n",
      "    Params:  tensor([  5.0017, -15.2330])\n",
      "    Grad  :  tensor([-0.0623,  0.3525])\n",
      "Epoch 1257,Loss 3.303605\n",
      "Epoch 1257, Loss 3.303605\n",
      "    Params:  tensor([  5.0024, -15.2365])\n",
      "    Grad  :  tensor([-0.0622,  0.3519])\n",
      "Epoch 1258,Loss 3.302329\n",
      "Epoch 1258, Loss 3.302329\n",
      "    Params:  tensor([  5.0030, -15.2400])\n",
      "    Grad  :  tensor([-0.0621,  0.3514])\n",
      "Epoch 1259,Loss 3.301057\n",
      "Epoch 1259, Loss 3.301057\n",
      "    Params:  tensor([  5.0036, -15.2435])\n",
      "    Grad  :  tensor([-0.0620,  0.3508])\n",
      "Epoch 1260,Loss 3.299791\n",
      "Epoch 1260, Loss 3.299791\n",
      "    Params:  tensor([  5.0042, -15.2470])\n",
      "    Grad  :  tensor([-0.0619,  0.3502])\n",
      "Epoch 1261,Loss 3.298528\n",
      "Epoch 1261, Loss 3.298528\n",
      "    Params:  tensor([  5.0048, -15.2505])\n",
      "    Grad  :  tensor([-0.0618,  0.3496])\n",
      "Epoch 1262,Loss 3.297267\n",
      "Epoch 1262, Loss 3.297267\n",
      "    Params:  tensor([  5.0054, -15.2540])\n",
      "    Grad  :  tensor([-0.0616,  0.3490])\n",
      "Epoch 1263,Loss 3.296014\n",
      "Epoch 1263, Loss 3.296014\n",
      "    Params:  tensor([  5.0061, -15.2575])\n",
      "    Grad  :  tensor([-0.0615,  0.3484])\n",
      "Epoch 1264,Loss 3.294762\n",
      "Epoch 1264, Loss 3.294762\n",
      "    Params:  tensor([  5.0067, -15.2610])\n",
      "    Grad  :  tensor([-0.0614,  0.3478])\n",
      "Epoch 1265,Loss 3.293517\n",
      "Epoch 1265, Loss 3.293517\n",
      "    Params:  tensor([  5.0073, -15.2645])\n",
      "    Grad  :  tensor([-0.0613,  0.3472])\n",
      "Epoch 1266,Loss 3.292276\n",
      "Epoch 1266, Loss 3.292276\n",
      "    Params:  tensor([  5.0079, -15.2679])\n",
      "    Grad  :  tensor([-0.0612,  0.3466])\n",
      "Epoch 1267,Loss 3.291036\n",
      "Epoch 1267, Loss 3.291036\n",
      "    Params:  tensor([  5.0085, -15.2714])\n",
      "    Grad  :  tensor([-0.0611,  0.3460])\n",
      "Epoch 1268,Loss 3.289804\n",
      "Epoch 1268, Loss 3.289804\n",
      "    Params:  tensor([  5.0091, -15.2748])\n",
      "    Grad  :  tensor([-0.0610,  0.3454])\n",
      "Epoch 1269,Loss 3.288573\n",
      "Epoch 1269, Loss 3.288573\n",
      "    Params:  tensor([  5.0097, -15.2783])\n",
      "    Grad  :  tensor([-0.0609,  0.3448])\n",
      "Epoch 1270,Loss 3.287347\n",
      "Epoch 1270, Loss 3.287347\n",
      "    Params:  tensor([  5.0103, -15.2817])\n",
      "    Grad  :  tensor([-0.0608,  0.3443])\n",
      "Epoch 1271,Loss 3.286129\n",
      "Epoch 1271, Loss 3.286129\n",
      "    Params:  tensor([  5.0109, -15.2852])\n",
      "    Grad  :  tensor([-0.0607,  0.3437])\n",
      "Epoch 1272,Loss 3.284911\n",
      "Epoch 1272, Loss 3.284911\n",
      "    Params:  tensor([  5.0116, -15.2886])\n",
      "    Grad  :  tensor([-0.0606,  0.3431])\n",
      "Epoch 1273,Loss 3.283698\n",
      "Epoch 1273, Loss 3.283698\n",
      "    Params:  tensor([  5.0122, -15.2920])\n",
      "    Grad  :  tensor([-0.0605,  0.3425])\n",
      "Epoch 1274,Loss 3.282488\n",
      "Epoch 1274, Loss 3.282488\n",
      "    Params:  tensor([  5.0128, -15.2954])\n",
      "    Grad  :  tensor([-0.0604,  0.3419])\n",
      "Epoch 1275,Loss 3.281284\n",
      "Epoch 1275, Loss 3.281284\n",
      "    Params:  tensor([  5.0134, -15.2988])\n",
      "    Grad  :  tensor([-0.0603,  0.3413])\n",
      "Epoch 1276,Loss 3.280085\n",
      "Epoch 1276, Loss 3.280085\n",
      "    Params:  tensor([  5.0140, -15.3023])\n",
      "    Grad  :  tensor([-0.0602,  0.3408])\n",
      "Epoch 1277,Loss 3.278888\n",
      "Epoch 1277, Loss 3.278888\n",
      "    Params:  tensor([  5.0146, -15.3057])\n",
      "    Grad  :  tensor([-0.0601,  0.3402])\n",
      "Epoch 1278,Loss 3.277696\n",
      "Epoch 1278, Loss 3.277696\n",
      "    Params:  tensor([  5.0152, -15.3091])\n",
      "    Grad  :  tensor([-0.0600,  0.3396])\n",
      "Epoch 1279,Loss 3.276506\n",
      "Epoch 1279, Loss 3.276506\n",
      "    Params:  tensor([  5.0158, -15.3124])\n",
      "    Grad  :  tensor([-0.0599,  0.3390])\n",
      "Epoch 1280,Loss 3.275322\n",
      "Epoch 1280, Loss 3.275322\n",
      "    Params:  tensor([  5.0164, -15.3158])\n",
      "    Grad  :  tensor([-0.0598,  0.3384])\n",
      "Epoch 1281,Loss 3.274142\n",
      "Epoch 1281, Loss 3.274142\n",
      "    Params:  tensor([  5.0170, -15.3192])\n",
      "    Grad  :  tensor([-0.0597,  0.3379])\n",
      "Epoch 1282,Loss 3.272968\n",
      "Epoch 1282, Loss 3.272968\n",
      "    Params:  tensor([  5.0176, -15.3226])\n",
      "    Grad  :  tensor([-0.0596,  0.3373])\n",
      "Epoch 1283,Loss 3.271793\n",
      "Epoch 1283, Loss 3.271793\n",
      "    Params:  tensor([  5.0182, -15.3259])\n",
      "    Grad  :  tensor([-0.0595,  0.3367])\n",
      "Epoch 1284,Loss 3.270625\n",
      "Epoch 1284, Loss 3.270625\n",
      "    Params:  tensor([  5.0187, -15.3293])\n",
      "    Grad  :  tensor([-0.0594,  0.3362])\n",
      "Epoch 1285,Loss 3.269460\n",
      "Epoch 1285, Loss 3.269460\n",
      "    Params:  tensor([  5.0193, -15.3327])\n",
      "    Grad  :  tensor([-0.0593,  0.3356])\n",
      "Epoch 1286,Loss 3.268301\n",
      "Epoch 1286, Loss 3.268301\n",
      "    Params:  tensor([  5.0199, -15.3360])\n",
      "    Grad  :  tensor([-0.0592,  0.3350])\n",
      "Epoch 1287,Loss 3.267143\n",
      "Epoch 1287, Loss 3.267143\n",
      "    Params:  tensor([  5.0205, -15.3394])\n",
      "    Grad  :  tensor([-0.0591,  0.3344])\n",
      "Epoch 1288,Loss 3.265991\n",
      "Epoch 1288, Loss 3.265991\n",
      "    Params:  tensor([  5.0211, -15.3427])\n",
      "    Grad  :  tensor([-0.0590,  0.3339])\n",
      "Epoch 1289,Loss 3.264842\n",
      "Epoch 1289, Loss 3.264842\n",
      "    Params:  tensor([  5.0217, -15.3460])\n",
      "    Grad  :  tensor([-0.0589,  0.3333])\n",
      "Epoch 1290,Loss 3.263700\n",
      "Epoch 1290, Loss 3.263700\n",
      "    Params:  tensor([  5.0223, -15.3494])\n",
      "    Grad  :  tensor([-0.0588,  0.3327])\n",
      "Epoch 1291,Loss 3.262556\n",
      "Epoch 1291, Loss 3.262556\n",
      "    Params:  tensor([  5.0229, -15.3527])\n",
      "    Grad  :  tensor([-0.0587,  0.3322])\n",
      "Epoch 1292,Loss 3.261421\n",
      "Epoch 1292, Loss 3.261421\n",
      "    Params:  tensor([  5.0235, -15.3560])\n",
      "    Grad  :  tensor([-0.0586,  0.3316])\n",
      "Epoch 1293,Loss 3.260287\n",
      "Epoch 1293, Loss 3.260287\n",
      "    Params:  tensor([  5.0240, -15.3593])\n",
      "    Grad  :  tensor([-0.0585,  0.3311])\n",
      "Epoch 1294,Loss 3.259160\n",
      "Epoch 1294, Loss 3.259160\n",
      "    Params:  tensor([  5.0246, -15.3626])\n",
      "    Grad  :  tensor([-0.0584,  0.3305])\n",
      "Epoch 1295,Loss 3.258033\n",
      "Epoch 1295, Loss 3.258033\n",
      "    Params:  tensor([  5.0252, -15.3659])\n",
      "    Grad  :  tensor([-0.0583,  0.3299])\n",
      "Epoch 1296,Loss 3.256912\n",
      "Epoch 1296, Loss 3.256912\n",
      "    Params:  tensor([  5.0258, -15.3692])\n",
      "    Grad  :  tensor([-0.0582,  0.3294])\n",
      "Epoch 1297,Loss 3.255794\n",
      "Epoch 1297, Loss 3.255794\n",
      "    Params:  tensor([  5.0264, -15.3725])\n",
      "    Grad  :  tensor([-0.0581,  0.3288])\n",
      "Epoch 1298,Loss 3.254681\n",
      "Epoch 1298, Loss 3.254681\n",
      "    Params:  tensor([  5.0270, -15.3758])\n",
      "    Grad  :  tensor([-0.0580,  0.3282])\n",
      "Epoch 1299,Loss 3.253569\n",
      "Epoch 1299, Loss 3.253569\n",
      "    Params:  tensor([  5.0275, -15.3791])\n",
      "    Grad  :  tensor([-0.0579,  0.3277])\n",
      "Epoch 1300,Loss 3.252462\n",
      "Epoch 1300, Loss 3.252462\n",
      "    Params:  tensor([  5.0281, -15.3823])\n",
      "    Grad  :  tensor([-0.0578,  0.3271])\n",
      "Epoch 1301,Loss 3.251362\n",
      "Epoch 1301, Loss 3.251362\n",
      "    Params:  tensor([  5.0287, -15.3856])\n",
      "    Grad  :  tensor([-0.0577,  0.3266])\n",
      "Epoch 1302,Loss 3.250263\n",
      "Epoch 1302, Loss 3.250263\n",
      "    Params:  tensor([  5.0293, -15.3888])\n",
      "    Grad  :  tensor([-0.0576,  0.3260])\n",
      "Epoch 1303,Loss 3.249168\n",
      "Epoch 1303, Loss 3.249168\n",
      "    Params:  tensor([  5.0298, -15.3921])\n",
      "    Grad  :  tensor([-0.0575,  0.3255])\n",
      "Epoch 1304,Loss 3.248077\n",
      "Epoch 1304, Loss 3.248077\n",
      "    Params:  tensor([  5.0304, -15.3954])\n",
      "    Grad  :  tensor([-0.0574,  0.3249])\n",
      "Epoch 1305,Loss 3.246988\n",
      "Epoch 1305, Loss 3.246988\n",
      "    Params:  tensor([  5.0310, -15.3986])\n",
      "    Grad  :  tensor([-0.0573,  0.3244])\n",
      "Epoch 1306,Loss 3.245904\n",
      "Epoch 1306, Loss 3.245904\n",
      "    Params:  tensor([  5.0316, -15.4018])\n",
      "    Grad  :  tensor([-0.0572,  0.3238])\n",
      "Epoch 1307,Loss 3.244824\n",
      "Epoch 1307, Loss 3.244824\n",
      "    Params:  tensor([  5.0321, -15.4051])\n",
      "    Grad  :  tensor([-0.0571,  0.3233])\n",
      "Epoch 1308,Loss 3.243747\n",
      "Epoch 1308, Loss 3.243747\n",
      "    Params:  tensor([  5.0327, -15.4083])\n",
      "    Grad  :  tensor([-0.0570,  0.3227])\n",
      "Epoch 1309,Loss 3.242674\n",
      "Epoch 1309, Loss 3.242674\n",
      "    Params:  tensor([  5.0333, -15.4115])\n",
      "    Grad  :  tensor([-0.0569,  0.3222])\n",
      "Epoch 1310,Loss 3.241606\n",
      "Epoch 1310, Loss 3.241606\n",
      "    Params:  tensor([  5.0338, -15.4147])\n",
      "    Grad  :  tensor([-0.0568,  0.3216])\n",
      "Epoch 1311,Loss 3.240538\n",
      "Epoch 1311, Loss 3.240538\n",
      "    Params:  tensor([  5.0344, -15.4179])\n",
      "    Grad  :  tensor([-0.0567,  0.3211])\n",
      "Epoch 1312,Loss 3.239475\n",
      "Epoch 1312, Loss 3.239475\n",
      "    Params:  tensor([  5.0350, -15.4211])\n",
      "    Grad  :  tensor([-0.0566,  0.3205])\n",
      "Epoch 1313,Loss 3.238419\n",
      "Epoch 1313, Loss 3.238419\n",
      "    Params:  tensor([  5.0355, -15.4243])\n",
      "    Grad  :  tensor([-0.0565,  0.3200])\n",
      "Epoch 1314,Loss 3.237363\n",
      "Epoch 1314, Loss 3.237363\n",
      "    Params:  tensor([  5.0361, -15.4275])\n",
      "    Grad  :  tensor([-0.0564,  0.3194])\n",
      "Epoch 1315,Loss 3.236314\n",
      "Epoch 1315, Loss 3.236314\n",
      "    Params:  tensor([  5.0367, -15.4307])\n",
      "    Grad  :  tensor([-0.0563,  0.3189])\n",
      "Epoch 1316,Loss 3.235265\n",
      "Epoch 1316, Loss 3.235265\n",
      "    Params:  tensor([  5.0372, -15.4339])\n",
      "    Grad  :  tensor([-0.0562,  0.3184])\n",
      "Epoch 1317,Loss 3.234218\n",
      "Epoch 1317, Loss 3.234218\n",
      "    Params:  tensor([  5.0378, -15.4371])\n",
      "    Grad  :  tensor([-0.0561,  0.3178])\n",
      "Epoch 1318,Loss 3.233179\n",
      "Epoch 1318, Loss 3.233179\n",
      "    Params:  tensor([  5.0383, -15.4403])\n",
      "    Grad  :  tensor([-0.0561,  0.3173])\n",
      "Epoch 1319,Loss 3.232143\n",
      "Epoch 1319, Loss 3.232143\n",
      "    Params:  tensor([  5.0389, -15.4434])\n",
      "    Grad  :  tensor([-0.0560,  0.3167])\n",
      "Epoch 1320,Loss 3.231109\n",
      "Epoch 1320, Loss 3.231109\n",
      "    Params:  tensor([  5.0395, -15.4466])\n",
      "    Grad  :  tensor([-0.0558,  0.3162])\n",
      "Epoch 1321,Loss 3.230078\n",
      "Epoch 1321, Loss 3.230078\n",
      "    Params:  tensor([  5.0400, -15.4498])\n",
      "    Grad  :  tensor([-0.0558,  0.3157])\n",
      "Epoch 1322,Loss 3.229051\n",
      "Epoch 1322, Loss 3.229051\n",
      "    Params:  tensor([  5.0406, -15.4529])\n",
      "    Grad  :  tensor([-0.0557,  0.3151])\n",
      "Epoch 1323,Loss 3.228027\n",
      "Epoch 1323, Loss 3.228027\n",
      "    Params:  tensor([  5.0411, -15.4560])\n",
      "    Grad  :  tensor([-0.0556,  0.3146])\n",
      "Epoch 1324,Loss 3.227010\n",
      "Epoch 1324, Loss 3.227010\n",
      "    Params:  tensor([  5.0417, -15.4592])\n",
      "    Grad  :  tensor([-0.0555,  0.3141])\n",
      "Epoch 1325,Loss 3.225992\n",
      "Epoch 1325, Loss 3.225992\n",
      "    Params:  tensor([  5.0422, -15.4623])\n",
      "    Grad  :  tensor([-0.0554,  0.3135])\n",
      "Epoch 1326,Loss 3.224979\n",
      "Epoch 1326, Loss 3.224979\n",
      "    Params:  tensor([  5.0428, -15.4655])\n",
      "    Grad  :  tensor([-0.0553,  0.3130])\n",
      "Epoch 1327,Loss 3.223971\n",
      "Epoch 1327, Loss 3.223971\n",
      "    Params:  tensor([  5.0433, -15.4686])\n",
      "    Grad  :  tensor([-0.0552,  0.3125])\n",
      "Epoch 1328,Loss 3.222965\n",
      "Epoch 1328, Loss 3.222965\n",
      "    Params:  tensor([  5.0439, -15.4717])\n",
      "    Grad  :  tensor([-0.0551,  0.3119])\n",
      "Epoch 1329,Loss 3.221960\n",
      "Epoch 1329, Loss 3.221960\n",
      "    Params:  tensor([  5.0444, -15.4748])\n",
      "    Grad  :  tensor([-0.0550,  0.3114])\n",
      "Epoch 1330,Loss 3.220962\n",
      "Epoch 1330, Loss 3.220962\n",
      "    Params:  tensor([  5.0450, -15.4779])\n",
      "    Grad  :  tensor([-0.0549,  0.3109])\n",
      "Epoch 1331,Loss 3.219967\n",
      "Epoch 1331, Loss 3.219967\n",
      "    Params:  tensor([  5.0455, -15.4810])\n",
      "    Grad  :  tensor([-0.0548,  0.3103])\n",
      "Epoch 1332,Loss 3.218975\n",
      "Epoch 1332, Loss 3.218975\n",
      "    Params:  tensor([  5.0461, -15.4841])\n",
      "    Grad  :  tensor([-0.0547,  0.3098])\n",
      "Epoch 1333,Loss 3.217986\n",
      "Epoch 1333, Loss 3.217986\n",
      "    Params:  tensor([  5.0466, -15.4872])\n",
      "    Grad  :  tensor([-0.0546,  0.3093])\n",
      "Epoch 1334,Loss 3.217000\n",
      "Epoch 1334, Loss 3.217000\n",
      "    Params:  tensor([  5.0472, -15.4903])\n",
      "    Grad  :  tensor([-0.0545,  0.3088])\n",
      "Epoch 1335,Loss 3.216017\n",
      "Epoch 1335, Loss 3.216017\n",
      "    Params:  tensor([  5.0477, -15.4934])\n",
      "    Grad  :  tensor([-0.0544,  0.3082])\n",
      "Epoch 1336,Loss 3.215038\n",
      "Epoch 1336, Loss 3.215038\n",
      "    Params:  tensor([  5.0483, -15.4965])\n",
      "    Grad  :  tensor([-0.0543,  0.3077])\n",
      "Epoch 1337,Loss 3.214062\n",
      "Epoch 1337, Loss 3.214062\n",
      "    Params:  tensor([  5.0488, -15.4995])\n",
      "    Grad  :  tensor([-0.0543,  0.3072])\n",
      "Epoch 1338,Loss 3.213092\n",
      "Epoch 1338, Loss 3.213092\n",
      "    Params:  tensor([  5.0494, -15.5026])\n",
      "    Grad  :  tensor([-0.0542,  0.3067])\n",
      "Epoch 1339,Loss 3.212122\n",
      "Epoch 1339, Loss 3.212122\n",
      "    Params:  tensor([  5.0499, -15.5057])\n",
      "    Grad  :  tensor([-0.0541,  0.3061])\n",
      "Epoch 1340,Loss 3.211157\n",
      "Epoch 1340, Loss 3.211157\n",
      "    Params:  tensor([  5.0504, -15.5087])\n",
      "    Grad  :  tensor([-0.0540,  0.3056])\n",
      "Epoch 1341,Loss 3.210192\n",
      "Epoch 1341, Loss 3.210192\n",
      "    Params:  tensor([  5.0510, -15.5118])\n",
      "    Grad  :  tensor([-0.0539,  0.3051])\n",
      "Epoch 1342,Loss 3.209235\n",
      "Epoch 1342, Loss 3.209235\n",
      "    Params:  tensor([  5.0515, -15.5148])\n",
      "    Grad  :  tensor([-0.0538,  0.3046])\n",
      "Epoch 1343,Loss 3.208279\n",
      "Epoch 1343, Loss 3.208279\n",
      "    Params:  tensor([  5.0521, -15.5179])\n",
      "    Grad  :  tensor([-0.0537,  0.3041])\n",
      "Epoch 1344,Loss 3.207326\n",
      "Epoch 1344, Loss 3.207326\n",
      "    Params:  tensor([  5.0526, -15.5209])\n",
      "    Grad  :  tensor([-0.0536,  0.3036])\n",
      "Epoch 1345,Loss 3.206376\n",
      "Epoch 1345, Loss 3.206376\n",
      "    Params:  tensor([  5.0531, -15.5239])\n",
      "    Grad  :  tensor([-0.0535,  0.3030])\n",
      "Epoch 1346,Loss 3.205430\n",
      "Epoch 1346, Loss 3.205430\n",
      "    Params:  tensor([  5.0537, -15.5269])\n",
      "    Grad  :  tensor([-0.0534,  0.3025])\n",
      "Epoch 1347,Loss 3.204488\n",
      "Epoch 1347, Loss 3.204488\n",
      "    Params:  tensor([  5.0542, -15.5300])\n",
      "    Grad  :  tensor([-0.0533,  0.3020])\n",
      "Epoch 1348,Loss 3.203547\n",
      "Epoch 1348, Loss 3.203547\n",
      "    Params:  tensor([  5.0547, -15.5330])\n",
      "    Grad  :  tensor([-0.0532,  0.3015])\n",
      "Epoch 1349,Loss 3.202610\n",
      "Epoch 1349, Loss 3.202610\n",
      "    Params:  tensor([  5.0553, -15.5360])\n",
      "    Grad  :  tensor([-0.0532,  0.3010])\n",
      "Epoch 1350,Loss 3.201678\n",
      "Epoch 1350, Loss 3.201678\n",
      "    Params:  tensor([  5.0558, -15.5390])\n",
      "    Grad  :  tensor([-0.0531,  0.3005])\n",
      "Epoch 1351,Loss 3.200747\n",
      "Epoch 1351, Loss 3.200747\n",
      "    Params:  tensor([  5.0563, -15.5420])\n",
      "    Grad  :  tensor([-0.0530,  0.3000])\n",
      "Epoch 1352,Loss 3.199820\n",
      "Epoch 1352, Loss 3.199820\n",
      "    Params:  tensor([  5.0568, -15.5450])\n",
      "    Grad  :  tensor([-0.0529,  0.2995])\n",
      "Epoch 1353,Loss 3.198897\n",
      "Epoch 1353, Loss 3.198897\n",
      "    Params:  tensor([  5.0574, -15.5480])\n",
      "    Grad  :  tensor([-0.0528,  0.2989])\n",
      "Epoch 1354,Loss 3.197976\n",
      "Epoch 1354, Loss 3.197976\n",
      "    Params:  tensor([  5.0579, -15.5510])\n",
      "    Grad  :  tensor([-0.0527,  0.2984])\n",
      "Epoch 1355,Loss 3.197060\n",
      "Epoch 1355, Loss 3.197060\n",
      "    Params:  tensor([  5.0584, -15.5539])\n",
      "    Grad  :  tensor([-0.0526,  0.2979])\n",
      "Epoch 1356,Loss 3.196143\n",
      "Epoch 1356, Loss 3.196143\n",
      "    Params:  tensor([  5.0590, -15.5569])\n",
      "    Grad  :  tensor([-0.0525,  0.2974])\n",
      "Epoch 1357,Loss 3.195231\n",
      "Epoch 1357, Loss 3.195231\n",
      "    Params:  tensor([  5.0595, -15.5599])\n",
      "    Grad  :  tensor([-0.0524,  0.2969])\n",
      "Epoch 1358,Loss 3.194324\n",
      "Epoch 1358, Loss 3.194324\n",
      "    Params:  tensor([  5.0600, -15.5629])\n",
      "    Grad  :  tensor([-0.0524,  0.2964])\n",
      "Epoch 1359,Loss 3.193420\n",
      "Epoch 1359, Loss 3.193420\n",
      "    Params:  tensor([  5.0605, -15.5658])\n",
      "    Grad  :  tensor([-0.0523,  0.2959])\n",
      "Epoch 1360,Loss 3.192517\n",
      "Epoch 1360, Loss 3.192517\n",
      "    Params:  tensor([  5.0610, -15.5688])\n",
      "    Grad  :  tensor([-0.0522,  0.2954])\n",
      "Epoch 1361,Loss 3.191616\n",
      "Epoch 1361, Loss 3.191616\n",
      "    Params:  tensor([  5.0616, -15.5717])\n",
      "    Grad  :  tensor([-0.0521,  0.2949])\n",
      "Epoch 1362,Loss 3.190720\n",
      "Epoch 1362, Loss 3.190720\n",
      "    Params:  tensor([  5.0621, -15.5747])\n",
      "    Grad  :  tensor([-0.0520,  0.2944])\n",
      "Epoch 1363,Loss 3.189829\n",
      "Epoch 1363, Loss 3.189829\n",
      "    Params:  tensor([  5.0626, -15.5776])\n",
      "    Grad  :  tensor([-0.0519,  0.2939])\n",
      "Epoch 1364,Loss 3.188938\n",
      "Epoch 1364, Loss 3.188938\n",
      "    Params:  tensor([  5.0631, -15.5805])\n",
      "    Grad  :  tensor([-0.0518,  0.2934])\n",
      "Epoch 1365,Loss 3.188051\n",
      "Epoch 1365, Loss 3.188051\n",
      "    Params:  tensor([  5.0636, -15.5835])\n",
      "    Grad  :  tensor([-0.0517,  0.2929])\n",
      "Epoch 1366,Loss 3.187166\n",
      "Epoch 1366, Loss 3.187166\n",
      "    Params:  tensor([  5.0642, -15.5864])\n",
      "    Grad  :  tensor([-0.0516,  0.2924])\n",
      "Epoch 1367,Loss 3.186287\n",
      "Epoch 1367, Loss 3.186287\n",
      "    Params:  tensor([  5.0647, -15.5893])\n",
      "    Grad  :  tensor([-0.0516,  0.2919])\n",
      "Epoch 1368,Loss 3.185409\n",
      "Epoch 1368, Loss 3.185409\n",
      "    Params:  tensor([  5.0652, -15.5922])\n",
      "    Grad  :  tensor([-0.0515,  0.2914])\n",
      "Epoch 1369,Loss 3.184534\n",
      "Epoch 1369, Loss 3.184534\n",
      "    Params:  tensor([  5.0657, -15.5951])\n",
      "    Grad  :  tensor([-0.0514,  0.2909])\n",
      "Epoch 1370,Loss 3.183662\n",
      "Epoch 1370, Loss 3.183662\n",
      "    Params:  tensor([  5.0662, -15.5980])\n",
      "    Grad  :  tensor([-0.0513,  0.2904])\n",
      "Epoch 1371,Loss 3.182792\n",
      "Epoch 1371, Loss 3.182792\n",
      "    Params:  tensor([  5.0667, -15.6009])\n",
      "    Grad  :  tensor([-0.0512,  0.2899])\n",
      "Epoch 1372,Loss 3.181925\n",
      "Epoch 1372, Loss 3.181925\n",
      "    Params:  tensor([  5.0672, -15.6038])\n",
      "    Grad  :  tensor([-0.0511,  0.2894])\n",
      "Epoch 1373,Loss 3.181063\n",
      "Epoch 1373, Loss 3.181063\n",
      "    Params:  tensor([  5.0678, -15.6067])\n",
      "    Grad  :  tensor([-0.0510,  0.2890])\n",
      "Epoch 1374,Loss 3.180201\n",
      "Epoch 1374, Loss 3.180201\n",
      "    Params:  tensor([  5.0683, -15.6096])\n",
      "    Grad  :  tensor([-0.0509,  0.2885])\n",
      "Epoch 1375,Loss 3.179347\n",
      "Epoch 1375, Loss 3.179347\n",
      "    Params:  tensor([  5.0688, -15.6125])\n",
      "    Grad  :  tensor([-0.0509,  0.2880])\n",
      "Epoch 1376,Loss 3.178490\n",
      "Epoch 1376, Loss 3.178490\n",
      "    Params:  tensor([  5.0693, -15.6154])\n",
      "    Grad  :  tensor([-0.0508,  0.2875])\n",
      "Epoch 1377,Loss 3.177638\n",
      "Epoch 1377, Loss 3.177638\n",
      "    Params:  tensor([  5.0698, -15.6182])\n",
      "    Grad  :  tensor([-0.0507,  0.2870])\n",
      "Epoch 1378,Loss 3.176789\n",
      "Epoch 1378, Loss 3.176789\n",
      "    Params:  tensor([  5.0703, -15.6211])\n",
      "    Grad  :  tensor([-0.0506,  0.2865])\n",
      "Epoch 1379,Loss 3.175945\n",
      "Epoch 1379, Loss 3.175945\n",
      "    Params:  tensor([  5.0708, -15.6240])\n",
      "    Grad  :  tensor([-0.0505,  0.2860])\n",
      "Epoch 1380,Loss 3.175101\n",
      "Epoch 1380, Loss 3.175101\n",
      "    Params:  tensor([  5.0713, -15.6268])\n",
      "    Grad  :  tensor([-0.0504,  0.2855])\n",
      "Epoch 1381,Loss 3.174262\n",
      "Epoch 1381, Loss 3.174262\n",
      "    Params:  tensor([  5.0718, -15.6297])\n",
      "    Grad  :  tensor([-0.0504,  0.2850])\n",
      "Epoch 1382,Loss 3.173425\n",
      "Epoch 1382, Loss 3.173425\n",
      "    Params:  tensor([  5.0723, -15.6325])\n",
      "    Grad  :  tensor([-0.0503,  0.2846])\n",
      "Epoch 1383,Loss 3.172590\n",
      "Epoch 1383, Loss 3.172590\n",
      "    Params:  tensor([  5.0728, -15.6353])\n",
      "    Grad  :  tensor([-0.0502,  0.2841])\n",
      "Epoch 1384,Loss 3.171759\n",
      "Epoch 1384, Loss 3.171759\n",
      "    Params:  tensor([  5.0733, -15.6382])\n",
      "    Grad  :  tensor([-0.0501,  0.2836])\n",
      "Epoch 1385,Loss 3.170929\n",
      "Epoch 1385, Loss 3.170929\n",
      "    Params:  tensor([  5.0738, -15.6410])\n",
      "    Grad  :  tensor([-0.0500,  0.2831])\n",
      "Epoch 1386,Loss 3.170103\n",
      "Epoch 1386, Loss 3.170103\n",
      "    Params:  tensor([  5.0743, -15.6438])\n",
      "    Grad  :  tensor([-0.0499,  0.2826])\n",
      "Epoch 1387,Loss 3.169280\n",
      "Epoch 1387, Loss 3.169280\n",
      "    Params:  tensor([  5.0748, -15.6467])\n",
      "    Grad  :  tensor([-0.0498,  0.2822])\n",
      "Epoch 1388,Loss 3.168462\n",
      "Epoch 1388, Loss 3.168462\n",
      "    Params:  tensor([  5.0753, -15.6495])\n",
      "    Grad  :  tensor([-0.0498,  0.2817])\n",
      "Epoch 1389,Loss 3.167644\n",
      "Epoch 1389, Loss 3.167644\n",
      "    Params:  tensor([  5.0758, -15.6523])\n",
      "    Grad  :  tensor([-0.0497,  0.2812])\n",
      "Epoch 1390,Loss 3.166827\n",
      "Epoch 1390, Loss 3.166827\n",
      "    Params:  tensor([  5.0763, -15.6551])\n",
      "    Grad  :  tensor([-0.0496,  0.2807])\n",
      "Epoch 1391,Loss 3.166017\n",
      "Epoch 1391, Loss 3.166017\n",
      "    Params:  tensor([  5.0768, -15.6579])\n",
      "    Grad  :  tensor([-0.0495,  0.2802])\n",
      "Epoch 1392,Loss 3.165207\n",
      "Epoch 1392, Loss 3.165207\n",
      "    Params:  tensor([  5.0773, -15.6607])\n",
      "    Grad  :  tensor([-0.0494,  0.2798])\n",
      "Epoch 1393,Loss 3.164401\n",
      "Epoch 1393, Loss 3.164401\n",
      "    Params:  tensor([  5.0778, -15.6635])\n",
      "    Grad  :  tensor([-0.0493,  0.2793])\n",
      "Epoch 1394,Loss 3.163594\n",
      "Epoch 1394, Loss 3.163594\n",
      "    Params:  tensor([  5.0783, -15.6663])\n",
      "    Grad  :  tensor([-0.0492,  0.2788])\n",
      "Epoch 1395,Loss 3.162795\n",
      "Epoch 1395, Loss 3.162795\n",
      "    Params:  tensor([  5.0788, -15.6691])\n",
      "    Grad  :  tensor([-0.0492,  0.2783])\n",
      "Epoch 1396,Loss 3.161996\n",
      "Epoch 1396, Loss 3.161996\n",
      "    Params:  tensor([  5.0793, -15.6718])\n",
      "    Grad  :  tensor([-0.0491,  0.2779])\n",
      "Epoch 1397,Loss 3.161201\n",
      "Epoch 1397, Loss 3.161201\n",
      "    Params:  tensor([  5.0797, -15.6746])\n",
      "    Grad  :  tensor([-0.0490,  0.2774])\n",
      "Epoch 1398,Loss 3.160410\n",
      "Epoch 1398, Loss 3.160410\n",
      "    Params:  tensor([  5.0802, -15.6774])\n",
      "    Grad  :  tensor([-0.0489,  0.2769])\n",
      "Epoch 1399,Loss 3.159618\n",
      "Epoch 1399, Loss 3.159618\n",
      "    Params:  tensor([  5.0807, -15.6802])\n",
      "    Grad  :  tensor([-0.0488,  0.2765])\n",
      "Epoch 1400,Loss 3.158830\n",
      "Epoch 1400, Loss 3.158830\n",
      "    Params:  tensor([  5.0812, -15.6829])\n",
      "    Grad  :  tensor([-0.0488,  0.2760])\n",
      "Epoch 1401,Loss 3.158046\n",
      "Epoch 1401, Loss 3.158046\n",
      "    Params:  tensor([  5.0817, -15.6857])\n",
      "    Grad  :  tensor([-0.0487,  0.2755])\n",
      "Epoch 1402,Loss 3.157263\n",
      "Epoch 1402, Loss 3.157263\n",
      "    Params:  tensor([  5.0822, -15.6884])\n",
      "    Grad  :  tensor([-0.0486,  0.2751])\n",
      "Epoch 1403,Loss 3.156484\n",
      "Epoch 1403, Loss 3.156484\n",
      "    Params:  tensor([  5.0827, -15.6912])\n",
      "    Grad  :  tensor([-0.0485,  0.2746])\n",
      "Epoch 1404,Loss 3.155708\n",
      "Epoch 1404, Loss 3.155708\n",
      "    Params:  tensor([  5.0832, -15.6939])\n",
      "    Grad  :  tensor([-0.0484,  0.2741])\n",
      "Epoch 1405,Loss 3.154933\n",
      "Epoch 1405, Loss 3.154933\n",
      "    Params:  tensor([  5.0836, -15.6966])\n",
      "    Grad  :  tensor([-0.0483,  0.2736])\n",
      "Epoch 1406,Loss 3.154162\n",
      "Epoch 1406, Loss 3.154162\n",
      "    Params:  tensor([  5.0841, -15.6994])\n",
      "    Grad  :  tensor([-0.0483,  0.2732])\n",
      "Epoch 1407,Loss 3.153393\n",
      "Epoch 1407, Loss 3.153393\n",
      "    Params:  tensor([  5.0846, -15.7021])\n",
      "    Grad  :  tensor([-0.0482,  0.2727])\n",
      "Epoch 1408,Loss 3.152628\n",
      "Epoch 1408, Loss 3.152628\n",
      "    Params:  tensor([  5.0851, -15.7048])\n",
      "    Grad  :  tensor([-0.0481,  0.2723])\n",
      "Epoch 1409,Loss 3.151865\n",
      "Epoch 1409, Loss 3.151865\n",
      "    Params:  tensor([  5.0856, -15.7075])\n",
      "    Grad  :  tensor([-0.0480,  0.2718])\n",
      "Epoch 1410,Loss 3.151101\n",
      "Epoch 1410, Loss 3.151101\n",
      "    Params:  tensor([  5.0860, -15.7103])\n",
      "    Grad  :  tensor([-0.0479,  0.2713])\n",
      "Epoch 1411,Loss 3.150343\n",
      "Epoch 1411, Loss 3.150343\n",
      "    Params:  tensor([  5.0865, -15.7130])\n",
      "    Grad  :  tensor([-0.0479,  0.2709])\n",
      "Epoch 1412,Loss 3.149587\n",
      "Epoch 1412, Loss 3.149587\n",
      "    Params:  tensor([  5.0870, -15.7157])\n",
      "    Grad  :  tensor([-0.0478,  0.2704])\n",
      "Epoch 1413,Loss 3.148833\n",
      "Epoch 1413, Loss 3.148833\n",
      "    Params:  tensor([  5.0875, -15.7184])\n",
      "    Grad  :  tensor([-0.0477,  0.2700])\n",
      "Epoch 1414,Loss 3.148083\n",
      "Epoch 1414, Loss 3.148083\n",
      "    Params:  tensor([  5.0879, -15.7211])\n",
      "    Grad  :  tensor([-0.0476,  0.2695])\n",
      "Epoch 1415,Loss 3.147335\n",
      "Epoch 1415, Loss 3.147335\n",
      "    Params:  tensor([  5.0884, -15.7238])\n",
      "    Grad  :  tensor([-0.0475,  0.2690])\n",
      "Epoch 1416,Loss 3.146588\n",
      "Epoch 1416, Loss 3.146588\n",
      "    Params:  tensor([  5.0889, -15.7264])\n",
      "    Grad  :  tensor([-0.0475,  0.2686])\n",
      "Epoch 1417,Loss 3.145845\n",
      "Epoch 1417, Loss 3.145845\n",
      "    Params:  tensor([  5.0894, -15.7291])\n",
      "    Grad  :  tensor([-0.0474,  0.2681])\n",
      "Epoch 1418,Loss 3.145105\n",
      "Epoch 1418, Loss 3.145105\n",
      "    Params:  tensor([  5.0898, -15.7318])\n",
      "    Grad  :  tensor([-0.0473,  0.2677])\n",
      "Epoch 1419,Loss 3.144367\n",
      "Epoch 1419, Loss 3.144367\n",
      "    Params:  tensor([  5.0903, -15.7345])\n",
      "    Grad  :  tensor([-0.0472,  0.2672])\n",
      "Epoch 1420,Loss 3.143630\n",
      "Epoch 1420, Loss 3.143630\n",
      "    Params:  tensor([  5.0908, -15.7371])\n",
      "    Grad  :  tensor([-0.0471,  0.2668])\n",
      "Epoch 1421,Loss 3.142899\n",
      "Epoch 1421, Loss 3.142899\n",
      "    Params:  tensor([  5.0913, -15.7398])\n",
      "    Grad  :  tensor([-0.0470,  0.2663])\n",
      "Epoch 1422,Loss 3.142166\n",
      "Epoch 1422, Loss 3.142166\n",
      "    Params:  tensor([  5.0917, -15.7425])\n",
      "    Grad  :  tensor([-0.0469,  0.2659])\n",
      "Epoch 1423,Loss 3.141439\n",
      "Epoch 1423, Loss 3.141439\n",
      "    Params:  tensor([  5.0922, -15.7451])\n",
      "    Grad  :  tensor([-0.0469,  0.2654])\n",
      "Epoch 1424,Loss 3.140712\n",
      "Epoch 1424, Loss 3.140712\n",
      "    Params:  tensor([  5.0927, -15.7478])\n",
      "    Grad  :  tensor([-0.0468,  0.2649])\n",
      "Epoch 1425,Loss 3.139989\n",
      "Epoch 1425, Loss 3.139989\n",
      "    Params:  tensor([  5.0931, -15.7504])\n",
      "    Grad  :  tensor([-0.0467,  0.2645])\n",
      "Epoch 1426,Loss 3.139271\n",
      "Epoch 1426, Loss 3.139271\n",
      "    Params:  tensor([  5.0936, -15.7530])\n",
      "    Grad  :  tensor([-0.0466,  0.2641])\n",
      "Epoch 1427,Loss 3.138551\n",
      "Epoch 1427, Loss 3.138551\n",
      "    Params:  tensor([  5.0941, -15.7557])\n",
      "    Grad  :  tensor([-0.0466,  0.2636])\n",
      "Epoch 1428,Loss 3.137835\n",
      "Epoch 1428, Loss 3.137835\n",
      "    Params:  tensor([  5.0945, -15.7583])\n",
      "    Grad  :  tensor([-0.0465,  0.2632])\n",
      "Epoch 1429,Loss 3.137121\n",
      "Epoch 1429, Loss 3.137121\n",
      "    Params:  tensor([  5.0950, -15.7609])\n",
      "    Grad  :  tensor([-0.0464,  0.2627])\n",
      "Epoch 1430,Loss 3.136409\n",
      "Epoch 1430, Loss 3.136409\n",
      "    Params:  tensor([  5.0955, -15.7636])\n",
      "    Grad  :  tensor([-0.0463,  0.2623])\n",
      "Epoch 1431,Loss 3.135702\n",
      "Epoch 1431, Loss 3.135702\n",
      "    Params:  tensor([  5.0959, -15.7662])\n",
      "    Grad  :  tensor([-0.0462,  0.2618])\n",
      "Epoch 1432,Loss 3.134994\n",
      "Epoch 1432, Loss 3.134994\n",
      "    Params:  tensor([  5.0964, -15.7688])\n",
      "    Grad  :  tensor([-0.0461,  0.2614])\n",
      "Epoch 1433,Loss 3.134292\n",
      "Epoch 1433, Loss 3.134292\n",
      "    Params:  tensor([  5.0968, -15.7714])\n",
      "    Grad  :  tensor([-0.0461,  0.2609])\n",
      "Epoch 1434,Loss 3.133590\n",
      "Epoch 1434, Loss 3.133590\n",
      "    Params:  tensor([  5.0973, -15.7740])\n",
      "    Grad  :  tensor([-0.0460,  0.2605])\n",
      "Epoch 1435,Loss 3.132889\n",
      "Epoch 1435, Loss 3.132889\n",
      "    Params:  tensor([  5.0978, -15.7766])\n",
      "    Grad  :  tensor([-0.0459,  0.2600])\n",
      "Epoch 1436,Loss 3.132194\n",
      "Epoch 1436, Loss 3.132194\n",
      "    Params:  tensor([  5.0982, -15.7792])\n",
      "    Grad  :  tensor([-0.0459,  0.2596])\n",
      "Epoch 1437,Loss 3.131500\n",
      "Epoch 1437, Loss 3.131500\n",
      "    Params:  tensor([  5.0987, -15.7818])\n",
      "    Grad  :  tensor([-0.0458,  0.2592])\n",
      "Epoch 1438,Loss 3.130810\n",
      "Epoch 1438, Loss 3.130810\n",
      "    Params:  tensor([  5.0991, -15.7844])\n",
      "    Grad  :  tensor([-0.0457,  0.2587])\n",
      "Epoch 1439,Loss 3.130119\n",
      "Epoch 1439, Loss 3.130119\n",
      "    Params:  tensor([  5.0996, -15.7870])\n",
      "    Grad  :  tensor([-0.0456,  0.2583])\n",
      "Epoch 1440,Loss 3.129432\n",
      "Epoch 1440, Loss 3.129432\n",
      "    Params:  tensor([  5.1000, -15.7895])\n",
      "    Grad  :  tensor([-0.0455,  0.2578])\n",
      "Epoch 1441,Loss 3.128746\n",
      "Epoch 1441, Loss 3.128746\n",
      "    Params:  tensor([  5.1005, -15.7921])\n",
      "    Grad  :  tensor([-0.0455,  0.2574])\n",
      "Epoch 1442,Loss 3.128064\n",
      "Epoch 1442, Loss 3.128064\n",
      "    Params:  tensor([  5.1010, -15.7947])\n",
      "    Grad  :  tensor([-0.0454,  0.2570])\n",
      "Epoch 1443,Loss 3.127382\n",
      "Epoch 1443, Loss 3.127382\n",
      "    Params:  tensor([  5.1014, -15.7973])\n",
      "    Grad  :  tensor([-0.0453,  0.2565])\n",
      "Epoch 1444,Loss 3.126705\n",
      "Epoch 1444, Loss 3.126705\n",
      "    Params:  tensor([  5.1019, -15.7998])\n",
      "    Grad  :  tensor([-0.0453,  0.2561])\n",
      "Epoch 1445,Loss 3.126030\n",
      "Epoch 1445, Loss 3.126030\n",
      "    Params:  tensor([  5.1023, -15.8024])\n",
      "    Grad  :  tensor([-0.0452,  0.2557])\n",
      "Epoch 1446,Loss 3.125356\n",
      "Epoch 1446, Loss 3.125356\n",
      "    Params:  tensor([  5.1028, -15.8049])\n",
      "    Grad  :  tensor([-0.0451,  0.2552])\n",
      "Epoch 1447,Loss 3.124683\n",
      "Epoch 1447, Loss 3.124683\n",
      "    Params:  tensor([  5.1032, -15.8075])\n",
      "    Grad  :  tensor([-0.0450,  0.2548])\n",
      "Epoch 1448,Loss 3.124016\n",
      "Epoch 1448, Loss 3.124016\n",
      "    Params:  tensor([  5.1037, -15.8100])\n",
      "    Grad  :  tensor([-0.0449,  0.2544])\n",
      "Epoch 1449,Loss 3.123349\n",
      "Epoch 1449, Loss 3.123349\n",
      "    Params:  tensor([  5.1041, -15.8126])\n",
      "    Grad  :  tensor([-0.0449,  0.2539])\n",
      "Epoch 1450,Loss 3.122686\n",
      "Epoch 1450, Loss 3.122686\n",
      "    Params:  tensor([  5.1046, -15.8151])\n",
      "    Grad  :  tensor([-0.0448,  0.2535])\n",
      "Epoch 1451,Loss 3.122022\n",
      "Epoch 1451, Loss 3.122022\n",
      "    Params:  tensor([  5.1050, -15.8176])\n",
      "    Grad  :  tensor([-0.0447,  0.2531])\n",
      "Epoch 1452,Loss 3.121362\n",
      "Epoch 1452, Loss 3.121362\n",
      "    Params:  tensor([  5.1055, -15.8201])\n",
      "    Grad  :  tensor([-0.0446,  0.2526])\n",
      "Epoch 1453,Loss 3.120707\n",
      "Epoch 1453, Loss 3.120707\n",
      "    Params:  tensor([  5.1059, -15.8227])\n",
      "    Grad  :  tensor([-0.0445,  0.2522])\n",
      "Epoch 1454,Loss 3.120049\n",
      "Epoch 1454, Loss 3.120049\n",
      "    Params:  tensor([  5.1063, -15.8252])\n",
      "    Grad  :  tensor([-0.0445,  0.2518])\n",
      "Epoch 1455,Loss 3.119397\n",
      "Epoch 1455, Loss 3.119397\n",
      "    Params:  tensor([  5.1068, -15.8277])\n",
      "    Grad  :  tensor([-0.0444,  0.2513])\n",
      "Epoch 1456,Loss 3.118746\n",
      "Epoch 1456, Loss 3.118746\n",
      "    Params:  tensor([  5.1072, -15.8302])\n",
      "    Grad  :  tensor([-0.0443,  0.2509])\n",
      "Epoch 1457,Loss 3.118098\n",
      "Epoch 1457, Loss 3.118098\n",
      "    Params:  tensor([  5.1077, -15.8327])\n",
      "    Grad  :  tensor([-0.0442,  0.2505])\n",
      "Epoch 1458,Loss 3.117451\n",
      "Epoch 1458, Loss 3.117451\n",
      "    Params:  tensor([  5.1081, -15.8352])\n",
      "    Grad  :  tensor([-0.0442,  0.2501])\n",
      "Epoch 1459,Loss 3.116805\n",
      "Epoch 1459, Loss 3.116805\n",
      "    Params:  tensor([  5.1086, -15.8377])\n",
      "    Grad  :  tensor([-0.0441,  0.2496])\n",
      "Epoch 1460,Loss 3.116164\n",
      "Epoch 1460, Loss 3.116164\n",
      "    Params:  tensor([  5.1090, -15.8402])\n",
      "    Grad  :  tensor([-0.0440,  0.2492])\n",
      "Epoch 1461,Loss 3.115525\n",
      "Epoch 1461, Loss 3.115525\n",
      "    Params:  tensor([  5.1094, -15.8427])\n",
      "    Grad  :  tensor([-0.0439,  0.2488])\n",
      "Epoch 1462,Loss 3.114886\n",
      "Epoch 1462, Loss 3.114886\n",
      "    Params:  tensor([  5.1099, -15.8452])\n",
      "    Grad  :  tensor([-0.0439,  0.2484])\n",
      "Epoch 1463,Loss 3.114251\n",
      "Epoch 1463, Loss 3.114251\n",
      "    Params:  tensor([  5.1103, -15.8477])\n",
      "    Grad  :  tensor([-0.0438,  0.2480])\n",
      "Epoch 1464,Loss 3.113617\n",
      "Epoch 1464, Loss 3.113617\n",
      "    Params:  tensor([  5.1107, -15.8501])\n",
      "    Grad  :  tensor([-0.0437,  0.2475])\n",
      "Epoch 1465,Loss 3.112985\n",
      "Epoch 1465, Loss 3.112985\n",
      "    Params:  tensor([  5.1112, -15.8526])\n",
      "    Grad  :  tensor([-0.0437,  0.2471])\n",
      "Epoch 1466,Loss 3.112358\n",
      "Epoch 1466, Loss 3.112358\n",
      "    Params:  tensor([  5.1116, -15.8551])\n",
      "    Grad  :  tensor([-0.0436,  0.2467])\n",
      "Epoch 1467,Loss 3.111731\n",
      "Epoch 1467, Loss 3.111731\n",
      "    Params:  tensor([  5.1121, -15.8575])\n",
      "    Grad  :  tensor([-0.0435,  0.2463])\n",
      "Epoch 1468,Loss 3.111103\n",
      "Epoch 1468, Loss 3.111103\n",
      "    Params:  tensor([  5.1125, -15.8600])\n",
      "    Grad  :  tensor([-0.0434,  0.2459])\n",
      "Epoch 1469,Loss 3.110484\n",
      "Epoch 1469, Loss 3.110484\n",
      "    Params:  tensor([  5.1129, -15.8624])\n",
      "    Grad  :  tensor([-0.0433,  0.2454])\n",
      "Epoch 1470,Loss 3.109859\n",
      "Epoch 1470, Loss 3.109859\n",
      "    Params:  tensor([  5.1134, -15.8649])\n",
      "    Grad  :  tensor([-0.0433,  0.2450])\n",
      "Epoch 1471,Loss 3.109243\n",
      "Epoch 1471, Loss 3.109243\n",
      "    Params:  tensor([  5.1138, -15.8673])\n",
      "    Grad  :  tensor([-0.0432,  0.2446])\n",
      "Epoch 1472,Loss 3.108627\n",
      "Epoch 1472, Loss 3.108627\n",
      "    Params:  tensor([  5.1142, -15.8698])\n",
      "    Grad  :  tensor([-0.0431,  0.2442])\n",
      "Epoch 1473,Loss 3.108011\n",
      "Epoch 1473, Loss 3.108011\n",
      "    Params:  tensor([  5.1147, -15.8722])\n",
      "    Grad  :  tensor([-0.0430,  0.2438])\n",
      "Epoch 1474,Loss 3.107401\n",
      "Epoch 1474, Loss 3.107401\n",
      "    Params:  tensor([  5.1151, -15.8747])\n",
      "    Grad  :  tensor([-0.0430,  0.2434])\n",
      "Epoch 1475,Loss 3.106791\n",
      "Epoch 1475, Loss 3.106791\n",
      "    Params:  tensor([  5.1155, -15.8771])\n",
      "    Grad  :  tensor([-0.0429,  0.2429])\n",
      "Epoch 1476,Loss 3.106180\n",
      "Epoch 1476, Loss 3.106180\n",
      "    Params:  tensor([  5.1159, -15.8795])\n",
      "    Grad  :  tensor([-0.0428,  0.2425])\n",
      "Epoch 1477,Loss 3.105575\n",
      "Epoch 1477, Loss 3.105575\n",
      "    Params:  tensor([  5.1164, -15.8819])\n",
      "    Grad  :  tensor([-0.0428,  0.2421])\n",
      "Epoch 1478,Loss 3.104972\n",
      "Epoch 1478, Loss 3.104972\n",
      "    Params:  tensor([  5.1168, -15.8843])\n",
      "    Grad  :  tensor([-0.0427,  0.2417])\n",
      "Epoch 1479,Loss 3.104370\n",
      "Epoch 1479, Loss 3.104370\n",
      "    Params:  tensor([  5.1172, -15.8868])\n",
      "    Grad  :  tensor([-0.0426,  0.2413])\n",
      "Epoch 1480,Loss 3.103770\n",
      "Epoch 1480, Loss 3.103770\n",
      "    Params:  tensor([  5.1176, -15.8892])\n",
      "    Grad  :  tensor([-0.0425,  0.2409])\n",
      "Epoch 1481,Loss 3.103172\n",
      "Epoch 1481, Loss 3.103172\n",
      "    Params:  tensor([  5.1181, -15.8916])\n",
      "    Grad  :  tensor([-0.0425,  0.2405])\n",
      "Epoch 1482,Loss 3.102576\n",
      "Epoch 1482, Loss 3.102576\n",
      "    Params:  tensor([  5.1185, -15.8940])\n",
      "    Grad  :  tensor([-0.0424,  0.2401])\n",
      "Epoch 1483,Loss 3.101982\n",
      "Epoch 1483, Loss 3.101982\n",
      "    Params:  tensor([  5.1189, -15.8964])\n",
      "    Grad  :  tensor([-0.0423,  0.2397])\n",
      "Epoch 1484,Loss 3.101390\n",
      "Epoch 1484, Loss 3.101390\n",
      "    Params:  tensor([  5.1193, -15.8988])\n",
      "    Grad  :  tensor([-0.0423,  0.2393])\n",
      "Epoch 1485,Loss 3.100802\n",
      "Epoch 1485, Loss 3.100802\n",
      "    Params:  tensor([  5.1198, -15.9011])\n",
      "    Grad  :  tensor([-0.0422,  0.2388])\n",
      "Epoch 1486,Loss 3.100213\n",
      "Epoch 1486, Loss 3.100213\n",
      "    Params:  tensor([  5.1202, -15.9035])\n",
      "    Grad  :  tensor([-0.0421,  0.2384])\n",
      "Epoch 1487,Loss 3.099627\n",
      "Epoch 1487, Loss 3.099627\n",
      "    Params:  tensor([  5.1206, -15.9059])\n",
      "    Grad  :  tensor([-0.0421,  0.2380])\n",
      "Epoch 1488,Loss 3.099044\n",
      "Epoch 1488, Loss 3.099044\n",
      "    Params:  tensor([  5.1210, -15.9083])\n",
      "    Grad  :  tensor([-0.0420,  0.2376])\n",
      "Epoch 1489,Loss 3.098463\n",
      "Epoch 1489, Loss 3.098463\n",
      "    Params:  tensor([  5.1214, -15.9107])\n",
      "    Grad  :  tensor([-0.0419,  0.2372])\n",
      "Epoch 1490,Loss 3.097883\n",
      "Epoch 1490, Loss 3.097883\n",
      "    Params:  tensor([  5.1219, -15.9130])\n",
      "    Grad  :  tensor([-0.0418,  0.2368])\n",
      "Epoch 1491,Loss 3.097302\n",
      "Epoch 1491, Loss 3.097302\n",
      "    Params:  tensor([  5.1223, -15.9154])\n",
      "    Grad  :  tensor([-0.0418,  0.2364])\n",
      "Epoch 1492,Loss 3.096727\n",
      "Epoch 1492, Loss 3.096727\n",
      "    Params:  tensor([  5.1227, -15.9178])\n",
      "    Grad  :  tensor([-0.0417,  0.2360])\n",
      "Epoch 1493,Loss 3.096153\n",
      "Epoch 1493, Loss 3.096153\n",
      "    Params:  tensor([  5.1231, -15.9201])\n",
      "    Grad  :  tensor([-0.0416,  0.2356])\n",
      "Epoch 1494,Loss 3.095583\n",
      "Epoch 1494, Loss 3.095583\n",
      "    Params:  tensor([  5.1235, -15.9225])\n",
      "    Grad  :  tensor([-0.0416,  0.2352])\n",
      "Epoch 1495,Loss 3.095011\n",
      "Epoch 1495, Loss 3.095011\n",
      "    Params:  tensor([  5.1239, -15.9248])\n",
      "    Grad  :  tensor([-0.0415,  0.2348])\n",
      "Epoch 1496,Loss 3.094444\n",
      "Epoch 1496, Loss 3.094444\n",
      "    Params:  tensor([  5.1244, -15.9272])\n",
      "    Grad  :  tensor([-0.0414,  0.2344])\n",
      "Epoch 1497,Loss 3.093877\n",
      "Epoch 1497, Loss 3.093877\n",
      "    Params:  tensor([  5.1248, -15.9295])\n",
      "    Grad  :  tensor([-0.0413,  0.2340])\n",
      "Epoch 1498,Loss 3.093314\n",
      "Epoch 1498, Loss 3.093314\n",
      "    Params:  tensor([  5.1252, -15.9318])\n",
      "    Grad  :  tensor([-0.0413,  0.2336])\n",
      "Epoch 1499,Loss 3.092751\n",
      "Epoch 1499, Loss 3.092751\n",
      "    Params:  tensor([  5.1256, -15.9342])\n",
      "    Grad  :  tensor([-0.0412,  0.2332])\n",
      "Epoch 1500,Loss 3.092191\n",
      "Epoch 1500, Loss 3.092191\n",
      "    Params:  tensor([  5.1260, -15.9365])\n",
      "    Grad  :  tensor([-0.0411,  0.2328])\n",
      "Epoch 1501,Loss 3.091630\n",
      "Epoch 1501, Loss 3.091630\n",
      "    Params:  tensor([  5.1264, -15.9388])\n",
      "    Grad  :  tensor([-0.0411,  0.2324])\n",
      "Epoch 1502,Loss 3.091074\n",
      "Epoch 1502, Loss 3.091074\n",
      "    Params:  tensor([  5.1268, -15.9411])\n",
      "    Grad  :  tensor([-0.0410,  0.2320])\n",
      "Epoch 1503,Loss 3.090520\n",
      "Epoch 1503, Loss 3.090520\n",
      "    Params:  tensor([  5.1272, -15.9435])\n",
      "    Grad  :  tensor([-0.0409,  0.2317])\n",
      "Epoch 1504,Loss 3.089969\n",
      "Epoch 1504, Loss 3.089969\n",
      "    Params:  tensor([  5.1276, -15.9458])\n",
      "    Grad  :  tensor([-0.0408,  0.2313])\n",
      "Epoch 1505,Loss 3.089417\n",
      "Epoch 1505, Loss 3.089417\n",
      "    Params:  tensor([  5.1281, -15.9481])\n",
      "    Grad  :  tensor([-0.0408,  0.2309])\n",
      "Epoch 1506,Loss 3.088867\n",
      "Epoch 1506, Loss 3.088867\n",
      "    Params:  tensor([  5.1285, -15.9504])\n",
      "    Grad  :  tensor([-0.0407,  0.2305])\n",
      "Epoch 1507,Loss 3.088320\n",
      "Epoch 1507, Loss 3.088320\n",
      "    Params:  tensor([  5.1289, -15.9527])\n",
      "    Grad  :  tensor([-0.0406,  0.2301])\n",
      "Epoch 1508,Loss 3.087775\n",
      "Epoch 1508, Loss 3.087775\n",
      "    Params:  tensor([  5.1293, -15.9550])\n",
      "    Grad  :  tensor([-0.0406,  0.2297])\n",
      "Epoch 1509,Loss 3.087232\n",
      "Epoch 1509, Loss 3.087232\n",
      "    Params:  tensor([  5.1297, -15.9573])\n",
      "    Grad  :  tensor([-0.0405,  0.2293])\n",
      "Epoch 1510,Loss 3.086690\n",
      "Epoch 1510, Loss 3.086690\n",
      "    Params:  tensor([  5.1301, -15.9596])\n",
      "    Grad  :  tensor([-0.0404,  0.2289])\n",
      "Epoch 1511,Loss 3.086150\n",
      "Epoch 1511, Loss 3.086150\n",
      "    Params:  tensor([  5.1305, -15.9618])\n",
      "    Grad  :  tensor([-0.0404,  0.2285])\n",
      "Epoch 1512,Loss 3.085612\n",
      "Epoch 1512, Loss 3.085612\n",
      "    Params:  tensor([  5.1309, -15.9641])\n",
      "    Grad  :  tensor([-0.0403,  0.2281])\n",
      "Epoch 1513,Loss 3.085075\n",
      "Epoch 1513, Loss 3.085075\n",
      "    Params:  tensor([  5.1313, -15.9664])\n",
      "    Grad  :  tensor([-0.0402,  0.2277])\n",
      "Epoch 1514,Loss 3.084542\n",
      "Epoch 1514, Loss 3.084542\n",
      "    Params:  tensor([  5.1317, -15.9687])\n",
      "    Grad  :  tensor([-0.0402,  0.2274])\n",
      "Epoch 1515,Loss 3.084009\n",
      "Epoch 1515, Loss 3.084009\n",
      "    Params:  tensor([  5.1321, -15.9709])\n",
      "    Grad  :  tensor([-0.0401,  0.2270])\n",
      "Epoch 1516,Loss 3.083478\n",
      "Epoch 1516, Loss 3.083478\n",
      "    Params:  tensor([  5.1325, -15.9732])\n",
      "    Grad  :  tensor([-0.0400,  0.2266])\n",
      "Epoch 1517,Loss 3.082948\n",
      "Epoch 1517, Loss 3.082948\n",
      "    Params:  tensor([  5.1329, -15.9755])\n",
      "    Grad  :  tensor([-0.0400,  0.2262])\n",
      "Epoch 1518,Loss 3.082422\n",
      "Epoch 1518, Loss 3.082422\n",
      "    Params:  tensor([  5.1333, -15.9777])\n",
      "    Grad  :  tensor([-0.0399,  0.2258])\n",
      "Epoch 1519,Loss 3.081897\n",
      "Epoch 1519, Loss 3.081897\n",
      "    Params:  tensor([  5.1337, -15.9800])\n",
      "    Grad  :  tensor([-0.0398,  0.2254])\n",
      "Epoch 1520,Loss 3.081373\n",
      "Epoch 1520, Loss 3.081373\n",
      "    Params:  tensor([  5.1341, -15.9822])\n",
      "    Grad  :  tensor([-0.0398,  0.2250])\n",
      "Epoch 1521,Loss 3.080850\n",
      "Epoch 1521, Loss 3.080850\n",
      "    Params:  tensor([  5.1345, -15.9845])\n",
      "    Grad  :  tensor([-0.0397,  0.2247])\n",
      "Epoch 1522,Loss 3.080331\n",
      "Epoch 1522, Loss 3.080331\n",
      "    Params:  tensor([  5.1349, -15.9867])\n",
      "    Grad  :  tensor([-0.0396,  0.2243])\n",
      "Epoch 1523,Loss 3.079811\n",
      "Epoch 1523, Loss 3.079811\n",
      "    Params:  tensor([  5.1353, -15.9890])\n",
      "    Grad  :  tensor([-0.0396,  0.2239])\n",
      "Epoch 1524,Loss 3.079296\n",
      "Epoch 1524, Loss 3.079296\n",
      "    Params:  tensor([  5.1357, -15.9912])\n",
      "    Grad  :  tensor([-0.0395,  0.2235])\n",
      "Epoch 1525,Loss 3.078781\n",
      "Epoch 1525, Loss 3.078781\n",
      "    Params:  tensor([  5.1361, -15.9934])\n",
      "    Grad  :  tensor([-0.0394,  0.2231])\n",
      "Epoch 1526,Loss 3.078268\n",
      "Epoch 1526, Loss 3.078268\n",
      "    Params:  tensor([  5.1365, -15.9957])\n",
      "    Grad  :  tensor([-0.0394,  0.2228])\n",
      "Epoch 1527,Loss 3.077758\n",
      "Epoch 1527, Loss 3.077758\n",
      "    Params:  tensor([  5.1369, -15.9979])\n",
      "    Grad  :  tensor([-0.0393,  0.2224])\n",
      "Epoch 1528,Loss 3.077248\n",
      "Epoch 1528, Loss 3.077248\n",
      "    Params:  tensor([  5.1372, -16.0001])\n",
      "    Grad  :  tensor([-0.0392,  0.2220])\n",
      "Epoch 1529,Loss 3.076739\n",
      "Epoch 1529, Loss 3.076739\n",
      "    Params:  tensor([  5.1376, -16.0023])\n",
      "    Grad  :  tensor([-0.0391,  0.2216])\n",
      "Epoch 1530,Loss 3.076232\n",
      "Epoch 1530, Loss 3.076232\n",
      "    Params:  tensor([  5.1380, -16.0045])\n",
      "    Grad  :  tensor([-0.0391,  0.2213])\n",
      "Epoch 1531,Loss 3.075729\n",
      "Epoch 1531, Loss 3.075729\n",
      "    Params:  tensor([  5.1384, -16.0067])\n",
      "    Grad  :  tensor([-0.0390,  0.2209])\n",
      "Epoch 1532,Loss 3.075225\n",
      "Epoch 1532, Loss 3.075225\n",
      "    Params:  tensor([  5.1388, -16.0089])\n",
      "    Grad  :  tensor([-0.0390,  0.2205])\n",
      "Epoch 1533,Loss 3.074724\n",
      "Epoch 1533, Loss 3.074724\n",
      "    Params:  tensor([  5.1392, -16.0111])\n",
      "    Grad  :  tensor([-0.0389,  0.2201])\n",
      "Epoch 1534,Loss 3.074227\n",
      "Epoch 1534, Loss 3.074227\n",
      "    Params:  tensor([  5.1396, -16.0133])\n",
      "    Grad  :  tensor([-0.0388,  0.2198])\n",
      "Epoch 1535,Loss 3.073726\n",
      "Epoch 1535, Loss 3.073726\n",
      "    Params:  tensor([  5.1400, -16.0155])\n",
      "    Grad  :  tensor([-0.0387,  0.2194])\n",
      "Epoch 1536,Loss 3.073232\n",
      "Epoch 1536, Loss 3.073232\n",
      "    Params:  tensor([  5.1404, -16.0177])\n",
      "    Grad  :  tensor([-0.0387,  0.2190])\n",
      "Epoch 1537,Loss 3.072739\n",
      "Epoch 1537, Loss 3.072739\n",
      "    Params:  tensor([  5.1407, -16.0199])\n",
      "    Grad  :  tensor([-0.0386,  0.2186])\n",
      "Epoch 1538,Loss 3.072245\n",
      "Epoch 1538, Loss 3.072245\n",
      "    Params:  tensor([  5.1411, -16.0221])\n",
      "    Grad  :  tensor([-0.0385,  0.2183])\n",
      "Epoch 1539,Loss 3.071753\n",
      "Epoch 1539, Loss 3.071753\n",
      "    Params:  tensor([  5.1415, -16.0243])\n",
      "    Grad  :  tensor([-0.0385,  0.2179])\n",
      "Epoch 1540,Loss 3.071265\n",
      "Epoch 1540, Loss 3.071265\n",
      "    Params:  tensor([  5.1419, -16.0264])\n",
      "    Grad  :  tensor([-0.0384,  0.2175])\n",
      "Epoch 1541,Loss 3.070778\n",
      "Epoch 1541, Loss 3.070778\n",
      "    Params:  tensor([  5.1423, -16.0286])\n",
      "    Grad  :  tensor([-0.0383,  0.2172])\n",
      "Epoch 1542,Loss 3.070293\n",
      "Epoch 1542, Loss 3.070293\n",
      "    Params:  tensor([  5.1427, -16.0308])\n",
      "    Grad  :  tensor([-0.0383,  0.2168])\n",
      "Epoch 1543,Loss 3.069808\n",
      "Epoch 1543, Loss 3.069808\n",
      "    Params:  tensor([  5.1430, -16.0330])\n",
      "    Grad  :  tensor([-0.0382,  0.2164])\n",
      "Epoch 1544,Loss 3.069326\n",
      "Epoch 1544, Loss 3.069326\n",
      "    Params:  tensor([  5.1434, -16.0351])\n",
      "    Grad  :  tensor([-0.0382,  0.2161])\n",
      "Epoch 1545,Loss 3.068845\n",
      "Epoch 1545, Loss 3.068845\n",
      "    Params:  tensor([  5.1438, -16.0373])\n",
      "    Grad  :  tensor([-0.0381,  0.2157])\n",
      "Epoch 1546,Loss 3.068366\n",
      "Epoch 1546, Loss 3.068366\n",
      "    Params:  tensor([  5.1442, -16.0394])\n",
      "    Grad  :  tensor([-0.0380,  0.2153])\n",
      "Epoch 1547,Loss 3.067887\n",
      "Epoch 1547, Loss 3.067887\n",
      "    Params:  tensor([  5.1446, -16.0416])\n",
      "    Grad  :  tensor([-0.0380,  0.2150])\n",
      "Epoch 1548,Loss 3.067412\n",
      "Epoch 1548, Loss 3.067412\n",
      "    Params:  tensor([  5.1449, -16.0437])\n",
      "    Grad  :  tensor([-0.0379,  0.2146])\n",
      "Epoch 1549,Loss 3.066937\n",
      "Epoch 1549, Loss 3.066937\n",
      "    Params:  tensor([  5.1453, -16.0459])\n",
      "    Grad  :  tensor([-0.0378,  0.2142])\n",
      "Epoch 1550,Loss 3.066463\n",
      "Epoch 1550, Loss 3.066463\n",
      "    Params:  tensor([  5.1457, -16.0480])\n",
      "    Grad  :  tensor([-0.0378,  0.2139])\n",
      "Epoch 1551,Loss 3.065993\n",
      "Epoch 1551, Loss 3.065993\n",
      "    Params:  tensor([  5.1461, -16.0501])\n",
      "    Grad  :  tensor([-0.0377,  0.2135])\n",
      "Epoch 1552,Loss 3.065524\n",
      "Epoch 1552, Loss 3.065524\n",
      "    Params:  tensor([  5.1465, -16.0523])\n",
      "    Grad  :  tensor([-0.0376,  0.2131])\n",
      "Epoch 1553,Loss 3.065055\n",
      "Epoch 1553, Loss 3.065055\n",
      "    Params:  tensor([  5.1468, -16.0544])\n",
      "    Grad  :  tensor([-0.0376,  0.2128])\n",
      "Epoch 1554,Loss 3.064588\n",
      "Epoch 1554, Loss 3.064588\n",
      "    Params:  tensor([  5.1472, -16.0565])\n",
      "    Grad  :  tensor([-0.0375,  0.2124])\n",
      "Epoch 1555,Loss 3.064123\n",
      "Epoch 1555, Loss 3.064123\n",
      "    Params:  tensor([  5.1476, -16.0586])\n",
      "    Grad  :  tensor([-0.0375,  0.2120])\n",
      "Epoch 1556,Loss 3.063660\n",
      "Epoch 1556, Loss 3.063660\n",
      "    Params:  tensor([  5.1480, -16.0608])\n",
      "    Grad  :  tensor([-0.0374,  0.2117])\n",
      "Epoch 1557,Loss 3.063199\n",
      "Epoch 1557, Loss 3.063199\n",
      "    Params:  tensor([  5.1483, -16.0629])\n",
      "    Grad  :  tensor([-0.0373,  0.2113])\n",
      "Epoch 1558,Loss 3.062738\n",
      "Epoch 1558, Loss 3.062738\n",
      "    Params:  tensor([  5.1487, -16.0650])\n",
      "    Grad  :  tensor([-0.0373,  0.2110])\n",
      "Epoch 1559,Loss 3.062280\n",
      "Epoch 1559, Loss 3.062280\n",
      "    Params:  tensor([  5.1491, -16.0671])\n",
      "    Grad  :  tensor([-0.0372,  0.2106])\n",
      "Epoch 1560,Loss 3.061822\n",
      "Epoch 1560, Loss 3.061822\n",
      "    Params:  tensor([  5.1494, -16.0692])\n",
      "    Grad  :  tensor([-0.0371,  0.2103])\n",
      "Epoch 1561,Loss 3.061367\n",
      "Epoch 1561, Loss 3.061367\n",
      "    Params:  tensor([  5.1498, -16.0713])\n",
      "    Grad  :  tensor([-0.0371,  0.2099])\n",
      "Epoch 1562,Loss 3.060913\n",
      "Epoch 1562, Loss 3.060913\n",
      "    Params:  tensor([  5.1502, -16.0734])\n",
      "    Grad  :  tensor([-0.0370,  0.2095])\n",
      "Epoch 1563,Loss 3.060462\n",
      "Epoch 1563, Loss 3.060462\n",
      "    Params:  tensor([  5.1506, -16.0755])\n",
      "    Grad  :  tensor([-0.0370,  0.2092])\n",
      "Epoch 1564,Loss 3.060011\n",
      "Epoch 1564, Loss 3.060011\n",
      "    Params:  tensor([  5.1509, -16.0776])\n",
      "    Grad  :  tensor([-0.0369,  0.2088])\n",
      "Epoch 1565,Loss 3.059561\n",
      "Epoch 1565, Loss 3.059561\n",
      "    Params:  tensor([  5.1513, -16.0796])\n",
      "    Grad  :  tensor([-0.0368,  0.2085])\n",
      "Epoch 1566,Loss 3.059114\n",
      "Epoch 1566, Loss 3.059114\n",
      "    Params:  tensor([  5.1517, -16.0817])\n",
      "    Grad  :  tensor([-0.0368,  0.2081])\n",
      "Epoch 1567,Loss 3.058668\n",
      "Epoch 1567, Loss 3.058668\n",
      "    Params:  tensor([  5.1520, -16.0838])\n",
      "    Grad  :  tensor([-0.0367,  0.2078])\n",
      "Epoch 1568,Loss 3.058221\n",
      "Epoch 1568, Loss 3.058221\n",
      "    Params:  tensor([  5.1524, -16.0859])\n",
      "    Grad  :  tensor([-0.0366,  0.2074])\n",
      "Epoch 1569,Loss 3.057781\n",
      "Epoch 1569, Loss 3.057781\n",
      "    Params:  tensor([  5.1528, -16.0880])\n",
      "    Grad  :  tensor([-0.0366,  0.2071])\n",
      "Epoch 1570,Loss 3.057338\n",
      "Epoch 1570, Loss 3.057338\n",
      "    Params:  tensor([  5.1531, -16.0900])\n",
      "    Grad  :  tensor([-0.0365,  0.2067])\n",
      "Epoch 1571,Loss 3.056898\n",
      "Epoch 1571, Loss 3.056898\n",
      "    Params:  tensor([  5.1535, -16.0921])\n",
      "    Grad  :  tensor([-0.0364,  0.2064])\n",
      "Epoch 1572,Loss 3.056458\n",
      "Epoch 1572, Loss 3.056458\n",
      "    Params:  tensor([  5.1539, -16.0941])\n",
      "    Grad  :  tensor([-0.0364,  0.2060])\n",
      "Epoch 1573,Loss 3.056019\n",
      "Epoch 1573, Loss 3.056019\n",
      "    Params:  tensor([  5.1542, -16.0962])\n",
      "    Grad  :  tensor([-0.0363,  0.2057])\n",
      "Epoch 1574,Loss 3.055585\n",
      "Epoch 1574, Loss 3.055585\n",
      "    Params:  tensor([  5.1546, -16.0983])\n",
      "    Grad  :  tensor([-0.0363,  0.2053])\n",
      "Epoch 1575,Loss 3.055151\n",
      "Epoch 1575, Loss 3.055151\n",
      "    Params:  tensor([  5.1549, -16.1003])\n",
      "    Grad  :  tensor([-0.0362,  0.2050])\n",
      "Epoch 1576,Loss 3.054717\n",
      "Epoch 1576, Loss 3.054717\n",
      "    Params:  tensor([  5.1553, -16.1023])\n",
      "    Grad  :  tensor([-0.0361,  0.2046])\n",
      "Epoch 1577,Loss 3.054286\n",
      "Epoch 1577, Loss 3.054286\n",
      "    Params:  tensor([  5.1557, -16.1044])\n",
      "    Grad  :  tensor([-0.0361,  0.2043])\n",
      "Epoch 1578,Loss 3.053857\n",
      "Epoch 1578, Loss 3.053857\n",
      "    Params:  tensor([  5.1560, -16.1064])\n",
      "    Grad  :  tensor([-0.0360,  0.2039])\n",
      "Epoch 1579,Loss 3.053427\n",
      "Epoch 1579, Loss 3.053427\n",
      "    Params:  tensor([  5.1564, -16.1085])\n",
      "    Grad  :  tensor([-0.0360,  0.2036])\n",
      "Epoch 1580,Loss 3.053000\n",
      "Epoch 1580, Loss 3.053000\n",
      "    Params:  tensor([  5.1567, -16.1105])\n",
      "    Grad  :  tensor([-0.0359,  0.2032])\n",
      "Epoch 1581,Loss 3.052576\n",
      "Epoch 1581, Loss 3.052576\n",
      "    Params:  tensor([  5.1571, -16.1125])\n",
      "    Grad  :  tensor([-0.0358,  0.2029])\n",
      "Epoch 1582,Loss 3.052152\n",
      "Epoch 1582, Loss 3.052152\n",
      "    Params:  tensor([  5.1575, -16.1146])\n",
      "    Grad  :  tensor([-0.0358,  0.2025])\n",
      "Epoch 1583,Loss 3.051730\n",
      "Epoch 1583, Loss 3.051730\n",
      "    Params:  tensor([  5.1578, -16.1166])\n",
      "    Grad  :  tensor([-0.0357,  0.2022])\n",
      "Epoch 1584,Loss 3.051306\n",
      "Epoch 1584, Loss 3.051306\n",
      "    Params:  tensor([  5.1582, -16.1186])\n",
      "    Grad  :  tensor([-0.0357,  0.2018])\n",
      "Epoch 1585,Loss 3.050888\n",
      "Epoch 1585, Loss 3.050888\n",
      "    Params:  tensor([  5.1585, -16.1206])\n",
      "    Grad  :  tensor([-0.0356,  0.2015])\n",
      "Epoch 1586,Loss 3.050471\n",
      "Epoch 1586, Loss 3.050471\n",
      "    Params:  tensor([  5.1589, -16.1226])\n",
      "    Grad  :  tensor([-0.0355,  0.2012])\n",
      "Epoch 1587,Loss 3.050052\n",
      "Epoch 1587, Loss 3.050052\n",
      "    Params:  tensor([  5.1592, -16.1246])\n",
      "    Grad  :  tensor([-0.0355,  0.2008])\n",
      "Epoch 1588,Loss 3.049639\n",
      "Epoch 1588, Loss 3.049639\n",
      "    Params:  tensor([  5.1596, -16.1266])\n",
      "    Grad  :  tensor([-0.0354,  0.2005])\n",
      "Epoch 1589,Loss 3.049223\n",
      "Epoch 1589, Loss 3.049223\n",
      "    Params:  tensor([  5.1599, -16.1286])\n",
      "    Grad  :  tensor([-0.0354,  0.2001])\n",
      "Epoch 1590,Loss 3.048811\n",
      "Epoch 1590, Loss 3.048811\n",
      "    Params:  tensor([  5.1603, -16.1306])\n",
      "    Grad  :  tensor([-0.0353,  0.1998])\n",
      "Epoch 1591,Loss 3.048398\n",
      "Epoch 1591, Loss 3.048398\n",
      "    Params:  tensor([  5.1607, -16.1326])\n",
      "    Grad  :  tensor([-0.0353,  0.1995])\n",
      "Epoch 1592,Loss 3.047991\n",
      "Epoch 1592, Loss 3.047991\n",
      "    Params:  tensor([  5.1610, -16.1346])\n",
      "    Grad  :  tensor([-0.0352,  0.1991])\n",
      "Epoch 1593,Loss 3.047581\n",
      "Epoch 1593, Loss 3.047581\n",
      "    Params:  tensor([  5.1614, -16.1366])\n",
      "    Grad  :  tensor([-0.0351,  0.1988])\n",
      "Epoch 1594,Loss 3.047173\n",
      "Epoch 1594, Loss 3.047173\n",
      "    Params:  tensor([  5.1617, -16.1386])\n",
      "    Grad  :  tensor([-0.0351,  0.1984])\n",
      "Epoch 1595,Loss 3.046768\n",
      "Epoch 1595, Loss 3.046768\n",
      "    Params:  tensor([  5.1621, -16.1406])\n",
      "    Grad  :  tensor([-0.0350,  0.1981])\n",
      "Epoch 1596,Loss 3.046362\n",
      "Epoch 1596, Loss 3.046362\n",
      "    Params:  tensor([  5.1624, -16.1425])\n",
      "    Grad  :  tensor([-0.0349,  0.1978])\n",
      "Epoch 1597,Loss 3.045960\n",
      "Epoch 1597, Loss 3.045960\n",
      "    Params:  tensor([  5.1628, -16.1445])\n",
      "    Grad  :  tensor([-0.0349,  0.1974])\n",
      "Epoch 1598,Loss 3.045559\n",
      "Epoch 1598, Loss 3.045559\n",
      "    Params:  tensor([  5.1631, -16.1465])\n",
      "    Grad  :  tensor([-0.0348,  0.1971])\n",
      "Epoch 1599,Loss 3.045160\n",
      "Epoch 1599, Loss 3.045160\n",
      "    Params:  tensor([  5.1635, -16.1485])\n",
      "    Grad  :  tensor([-0.0348,  0.1968])\n",
      "Epoch 1600,Loss 3.044759\n",
      "Epoch 1600, Loss 3.044759\n",
      "    Params:  tensor([  5.1638, -16.1504])\n",
      "    Grad  :  tensor([-0.0347,  0.1964])\n",
      "Epoch 1601,Loss 3.044361\n",
      "Epoch 1601, Loss 3.044361\n",
      "    Params:  tensor([  5.1641, -16.1524])\n",
      "    Grad  :  tensor([-0.0346,  0.1961])\n",
      "Epoch 1602,Loss 3.043966\n",
      "Epoch 1602, Loss 3.043966\n",
      "    Params:  tensor([  5.1645, -16.1543])\n",
      "    Grad  :  tensor([-0.0346,  0.1958])\n",
      "Epoch 1603,Loss 3.043571\n",
      "Epoch 1603, Loss 3.043571\n",
      "    Params:  tensor([  5.1648, -16.1563])\n",
      "    Grad  :  tensor([-0.0345,  0.1954])\n",
      "Epoch 1604,Loss 3.043176\n",
      "Epoch 1604, Loss 3.043176\n",
      "    Params:  tensor([  5.1652, -16.1582])\n",
      "    Grad  :  tensor([-0.0345,  0.1951])\n",
      "Epoch 1605,Loss 3.042785\n",
      "Epoch 1605, Loss 3.042785\n",
      "    Params:  tensor([  5.1655, -16.1602])\n",
      "    Grad  :  tensor([-0.0344,  0.1948])\n",
      "Epoch 1606,Loss 3.042395\n",
      "Epoch 1606, Loss 3.042395\n",
      "    Params:  tensor([  5.1659, -16.1621])\n",
      "    Grad  :  tensor([-0.0343,  0.1944])\n",
      "Epoch 1607,Loss 3.042005\n",
      "Epoch 1607, Loss 3.042005\n",
      "    Params:  tensor([  5.1662, -16.1641])\n",
      "    Grad  :  tensor([-0.0343,  0.1941])\n",
      "Epoch 1608,Loss 3.041615\n",
      "Epoch 1608, Loss 3.041615\n",
      "    Params:  tensor([  5.1666, -16.1660])\n",
      "    Grad  :  tensor([-0.0342,  0.1938])\n",
      "Epoch 1609,Loss 3.041230\n",
      "Epoch 1609, Loss 3.041230\n",
      "    Params:  tensor([  5.1669, -16.1680])\n",
      "    Grad  :  tensor([-0.0342,  0.1934])\n",
      "Epoch 1610,Loss 3.040844\n",
      "Epoch 1610, Loss 3.040844\n",
      "    Params:  tensor([  5.1672, -16.1699])\n",
      "    Grad  :  tensor([-0.0341,  0.1931])\n",
      "Epoch 1611,Loss 3.040461\n",
      "Epoch 1611, Loss 3.040461\n",
      "    Params:  tensor([  5.1676, -16.1718])\n",
      "    Grad  :  tensor([-0.0341,  0.1928])\n",
      "Epoch 1612,Loss 3.040077\n",
      "Epoch 1612, Loss 3.040077\n",
      "    Params:  tensor([  5.1679, -16.1737])\n",
      "    Grad  :  tensor([-0.0340,  0.1925])\n",
      "Epoch 1613,Loss 3.039695\n",
      "Epoch 1613, Loss 3.039695\n",
      "    Params:  tensor([  5.1683, -16.1757])\n",
      "    Grad  :  tensor([-0.0339,  0.1921])\n",
      "Epoch 1614,Loss 3.039314\n",
      "Epoch 1614, Loss 3.039314\n",
      "    Params:  tensor([  5.1686, -16.1776])\n",
      "    Grad  :  tensor([-0.0339,  0.1918])\n",
      "Epoch 1615,Loss 3.038934\n",
      "Epoch 1615, Loss 3.038934\n",
      "    Params:  tensor([  5.1689, -16.1795])\n",
      "    Grad  :  tensor([-0.0338,  0.1915])\n",
      "Epoch 1616,Loss 3.038557\n",
      "Epoch 1616, Loss 3.038557\n",
      "    Params:  tensor([  5.1693, -16.1814])\n",
      "    Grad  :  tensor([-0.0338,  0.1912])\n",
      "Epoch 1617,Loss 3.038181\n",
      "Epoch 1617, Loss 3.038181\n",
      "    Params:  tensor([  5.1696, -16.1833])\n",
      "    Grad  :  tensor([-0.0337,  0.1908])\n",
      "Epoch 1618,Loss 3.037805\n",
      "Epoch 1618, Loss 3.037805\n",
      "    Params:  tensor([  5.1699, -16.1852])\n",
      "    Grad  :  tensor([-0.0337,  0.1905])\n",
      "Epoch 1619,Loss 3.037432\n",
      "Epoch 1619, Loss 3.037432\n",
      "    Params:  tensor([  5.1703, -16.1871])\n",
      "    Grad  :  tensor([-0.0336,  0.1902])\n",
      "Epoch 1620,Loss 3.037059\n",
      "Epoch 1620, Loss 3.037059\n",
      "    Params:  tensor([  5.1706, -16.1890])\n",
      "    Grad  :  tensor([-0.0335,  0.1899])\n",
      "Epoch 1621,Loss 3.036689\n",
      "Epoch 1621, Loss 3.036689\n",
      "    Params:  tensor([  5.1710, -16.1909])\n",
      "    Grad  :  tensor([-0.0335,  0.1895])\n",
      "Epoch 1622,Loss 3.036319\n",
      "Epoch 1622, Loss 3.036319\n",
      "    Params:  tensor([  5.1713, -16.1928])\n",
      "    Grad  :  tensor([-0.0334,  0.1892])\n",
      "Epoch 1623,Loss 3.035949\n",
      "Epoch 1623, Loss 3.035949\n",
      "    Params:  tensor([  5.1716, -16.1947])\n",
      "    Grad  :  tensor([-0.0334,  0.1889])\n",
      "Epoch 1624,Loss 3.035583\n",
      "Epoch 1624, Loss 3.035583\n",
      "    Params:  tensor([  5.1720, -16.1966])\n",
      "    Grad  :  tensor([-0.0333,  0.1886])\n",
      "Epoch 1625,Loss 3.035216\n",
      "Epoch 1625, Loss 3.035216\n",
      "    Params:  tensor([  5.1723, -16.1985])\n",
      "    Grad  :  tensor([-0.0333,  0.1883])\n",
      "Epoch 1626,Loss 3.034849\n",
      "Epoch 1626, Loss 3.034849\n",
      "    Params:  tensor([  5.1726, -16.2003])\n",
      "    Grad  :  tensor([-0.0332,  0.1879])\n",
      "Epoch 1627,Loss 3.034485\n",
      "Epoch 1627, Loss 3.034485\n",
      "    Params:  tensor([  5.1729, -16.2022])\n",
      "    Grad  :  tensor([-0.0331,  0.1876])\n",
      "Epoch 1628,Loss 3.034123\n",
      "Epoch 1628, Loss 3.034123\n",
      "    Params:  tensor([  5.1733, -16.2041])\n",
      "    Grad  :  tensor([-0.0331,  0.1873])\n",
      "Epoch 1629,Loss 3.033762\n",
      "Epoch 1629, Loss 3.033762\n",
      "    Params:  tensor([  5.1736, -16.2060])\n",
      "    Grad  :  tensor([-0.0330,  0.1870])\n",
      "Epoch 1630,Loss 3.033402\n",
      "Epoch 1630, Loss 3.033402\n",
      "    Params:  tensor([  5.1739, -16.2078])\n",
      "    Grad  :  tensor([-0.0330,  0.1867])\n",
      "Epoch 1631,Loss 3.033041\n",
      "Epoch 1631, Loss 3.033041\n",
      "    Params:  tensor([  5.1743, -16.2097])\n",
      "    Grad  :  tensor([-0.0329,  0.1863])\n",
      "Epoch 1632,Loss 3.032685\n",
      "Epoch 1632, Loss 3.032685\n",
      "    Params:  tensor([  5.1746, -16.2116])\n",
      "    Grad  :  tensor([-0.0329,  0.1860])\n",
      "Epoch 1633,Loss 3.032329\n",
      "Epoch 1633, Loss 3.032329\n",
      "    Params:  tensor([  5.1749, -16.2134])\n",
      "    Grad  :  tensor([-0.0328,  0.1857])\n",
      "Epoch 1634,Loss 3.031973\n",
      "Epoch 1634, Loss 3.031973\n",
      "    Params:  tensor([  5.1753, -16.2153])\n",
      "    Grad  :  tensor([-0.0327,  0.1854])\n",
      "Epoch 1635,Loss 3.031619\n",
      "Epoch 1635, Loss 3.031619\n",
      "    Params:  tensor([  5.1756, -16.2171])\n",
      "    Grad  :  tensor([-0.0327,  0.1851])\n",
      "Epoch 1636,Loss 3.031265\n",
      "Epoch 1636, Loss 3.031265\n",
      "    Params:  tensor([  5.1759, -16.2190])\n",
      "    Grad  :  tensor([-0.0326,  0.1848])\n",
      "Epoch 1637,Loss 3.030913\n",
      "Epoch 1637, Loss 3.030913\n",
      "    Params:  tensor([  5.1762, -16.2208])\n",
      "    Grad  :  tensor([-0.0326,  0.1845])\n",
      "Epoch 1638,Loss 3.030564\n",
      "Epoch 1638, Loss 3.030564\n",
      "    Params:  tensor([  5.1766, -16.2226])\n",
      "    Grad  :  tensor([-0.0325,  0.1841])\n",
      "Epoch 1639,Loss 3.030215\n",
      "Epoch 1639, Loss 3.030215\n",
      "    Params:  tensor([  5.1769, -16.2245])\n",
      "    Grad  :  tensor([-0.0325,  0.1838])\n",
      "Epoch 1640,Loss 3.029867\n",
      "Epoch 1640, Loss 3.029867\n",
      "    Params:  tensor([  5.1772, -16.2263])\n",
      "    Grad  :  tensor([-0.0324,  0.1835])\n",
      "Epoch 1641,Loss 3.029518\n",
      "Epoch 1641, Loss 3.029518\n",
      "    Params:  tensor([  5.1775, -16.2282])\n",
      "    Grad  :  tensor([-0.0324,  0.1832])\n",
      "Epoch 1642,Loss 3.029173\n",
      "Epoch 1642, Loss 3.029173\n",
      "    Params:  tensor([  5.1779, -16.2300])\n",
      "    Grad  :  tensor([-0.0323,  0.1829])\n",
      "Epoch 1643,Loss 3.028828\n",
      "Epoch 1643, Loss 3.028828\n",
      "    Params:  tensor([  5.1782, -16.2318])\n",
      "    Grad  :  tensor([-0.0323,  0.1826])\n",
      "Epoch 1644,Loss 3.028486\n",
      "Epoch 1644, Loss 3.028486\n",
      "    Params:  tensor([  5.1785, -16.2336])\n",
      "    Grad  :  tensor([-0.0322,  0.1823])\n",
      "Epoch 1645,Loss 3.028142\n",
      "Epoch 1645, Loss 3.028142\n",
      "    Params:  tensor([  5.1788, -16.2355])\n",
      "    Grad  :  tensor([-0.0321,  0.1820])\n",
      "Epoch 1646,Loss 3.027802\n",
      "Epoch 1646, Loss 3.027802\n",
      "    Params:  tensor([  5.1791, -16.2373])\n",
      "    Grad  :  tensor([-0.0321,  0.1817])\n",
      "Epoch 1647,Loss 3.027463\n",
      "Epoch 1647, Loss 3.027463\n",
      "    Params:  tensor([  5.1795, -16.2391])\n",
      "    Grad  :  tensor([-0.0320,  0.1813])\n",
      "Epoch 1648,Loss 3.027122\n",
      "Epoch 1648, Loss 3.027122\n",
      "    Params:  tensor([  5.1798, -16.2409])\n",
      "    Grad  :  tensor([-0.0320,  0.1810])\n",
      "Epoch 1649,Loss 3.026784\n",
      "Epoch 1649, Loss 3.026784\n",
      "    Params:  tensor([  5.1801, -16.2427])\n",
      "    Grad  :  tensor([-0.0319,  0.1807])\n",
      "Epoch 1650,Loss 3.026447\n",
      "Epoch 1650, Loss 3.026447\n",
      "    Params:  tensor([  5.1804, -16.2445])\n",
      "    Grad  :  tensor([-0.0319,  0.1804])\n",
      "Epoch 1651,Loss 3.026111\n",
      "Epoch 1651, Loss 3.026111\n",
      "    Params:  tensor([  5.1807, -16.2463])\n",
      "    Grad  :  tensor([-0.0318,  0.1801])\n",
      "Epoch 1652,Loss 3.025780\n",
      "Epoch 1652, Loss 3.025780\n",
      "    Params:  tensor([  5.1811, -16.2481])\n",
      "    Grad  :  tensor([-0.0318,  0.1798])\n",
      "Epoch 1653,Loss 3.025447\n",
      "Epoch 1653, Loss 3.025447\n",
      "    Params:  tensor([  5.1814, -16.2499])\n",
      "    Grad  :  tensor([-0.0317,  0.1795])\n",
      "Epoch 1654,Loss 3.025114\n",
      "Epoch 1654, Loss 3.025114\n",
      "    Params:  tensor([  5.1817, -16.2517])\n",
      "    Grad  :  tensor([-0.0317,  0.1792])\n",
      "Epoch 1655,Loss 3.024782\n",
      "Epoch 1655, Loss 3.024782\n",
      "    Params:  tensor([  5.1820, -16.2535])\n",
      "    Grad  :  tensor([-0.0316,  0.1789])\n",
      "Epoch 1656,Loss 3.024452\n",
      "Epoch 1656, Loss 3.024452\n",
      "    Params:  tensor([  5.1823, -16.2553])\n",
      "    Grad  :  tensor([-0.0316,  0.1786])\n",
      "Epoch 1657,Loss 3.024125\n",
      "Epoch 1657, Loss 3.024125\n",
      "    Params:  tensor([  5.1826, -16.2570])\n",
      "    Grad  :  tensor([-0.0315,  0.1783])\n",
      "Epoch 1658,Loss 3.023796\n",
      "Epoch 1658, Loss 3.023796\n",
      "    Params:  tensor([  5.1829, -16.2588])\n",
      "    Grad  :  tensor([-0.0315,  0.1780])\n",
      "Epoch 1659,Loss 3.023471\n",
      "Epoch 1659, Loss 3.023471\n",
      "    Params:  tensor([  5.1833, -16.2606])\n",
      "    Grad  :  tensor([-0.0314,  0.1777])\n",
      "Epoch 1660,Loss 3.023145\n",
      "Epoch 1660, Loss 3.023145\n",
      "    Params:  tensor([  5.1836, -16.2624])\n",
      "    Grad  :  tensor([-0.0313,  0.1774])\n",
      "Epoch 1661,Loss 3.022820\n",
      "Epoch 1661, Loss 3.022820\n",
      "    Params:  tensor([  5.1839, -16.2641])\n",
      "    Grad  :  tensor([-0.0313,  0.1771])\n",
      "Epoch 1662,Loss 3.022498\n",
      "Epoch 1662, Loss 3.022498\n",
      "    Params:  tensor([  5.1842, -16.2659])\n",
      "    Grad  :  tensor([-0.0312,  0.1768])\n",
      "Epoch 1663,Loss 3.022177\n",
      "Epoch 1663, Loss 3.022177\n",
      "    Params:  tensor([  5.1845, -16.2677])\n",
      "    Grad  :  tensor([-0.0312,  0.1765])\n",
      "Epoch 1664,Loss 3.021855\n",
      "Epoch 1664, Loss 3.021855\n",
      "    Params:  tensor([  5.1848, -16.2694])\n",
      "    Grad  :  tensor([-0.0311,  0.1762])\n",
      "Epoch 1665,Loss 3.021534\n",
      "Epoch 1665, Loss 3.021534\n",
      "    Params:  tensor([  5.1851, -16.2712])\n",
      "    Grad  :  tensor([-0.0311,  0.1759])\n",
      "Epoch 1666,Loss 3.021217\n",
      "Epoch 1666, Loss 3.021217\n",
      "    Params:  tensor([  5.1854, -16.2730])\n",
      "    Grad  :  tensor([-0.0310,  0.1756])\n",
      "Epoch 1667,Loss 3.020898\n",
      "Epoch 1667, Loss 3.020898\n",
      "    Params:  tensor([  5.1858, -16.2747])\n",
      "    Grad  :  tensor([-0.0310,  0.1753])\n",
      "Epoch 1668,Loss 3.020582\n",
      "Epoch 1668, Loss 3.020582\n",
      "    Params:  tensor([  5.1861, -16.2765])\n",
      "    Grad  :  tensor([-0.0309,  0.1750])\n",
      "Epoch 1669,Loss 3.020265\n",
      "Epoch 1669, Loss 3.020265\n",
      "    Params:  tensor([  5.1864, -16.2782])\n",
      "    Grad  :  tensor([-0.0309,  0.1747])\n",
      "Epoch 1670,Loss 3.019952\n",
      "Epoch 1670, Loss 3.019952\n",
      "    Params:  tensor([  5.1867, -16.2800])\n",
      "    Grad  :  tensor([-0.0308,  0.1744])\n",
      "Epoch 1671,Loss 3.019639\n",
      "Epoch 1671, Loss 3.019639\n",
      "    Params:  tensor([  5.1870, -16.2817])\n",
      "    Grad  :  tensor([-0.0308,  0.1741])\n",
      "Epoch 1672,Loss 3.019325\n",
      "Epoch 1672, Loss 3.019325\n",
      "    Params:  tensor([  5.1873, -16.2834])\n",
      "    Grad  :  tensor([-0.0307,  0.1738])\n",
      "Epoch 1673,Loss 3.019016\n",
      "Epoch 1673, Loss 3.019016\n",
      "    Params:  tensor([  5.1876, -16.2852])\n",
      "    Grad  :  tensor([-0.0307,  0.1735])\n",
      "Epoch 1674,Loss 3.018706\n",
      "Epoch 1674, Loss 3.018706\n",
      "    Params:  tensor([  5.1879, -16.2869])\n",
      "    Grad  :  tensor([-0.0306,  0.1732])\n",
      "Epoch 1675,Loss 3.018395\n",
      "Epoch 1675, Loss 3.018395\n",
      "    Params:  tensor([  5.1882, -16.2886])\n",
      "    Grad  :  tensor([-0.0305,  0.1729])\n",
      "Epoch 1676,Loss 3.018089\n",
      "Epoch 1676, Loss 3.018089\n",
      "    Params:  tensor([  5.1885, -16.2904])\n",
      "    Grad  :  tensor([-0.0305,  0.1726])\n",
      "Epoch 1677,Loss 3.017780\n",
      "Epoch 1677, Loss 3.017780\n",
      "    Params:  tensor([  5.1888, -16.2921])\n",
      "    Grad  :  tensor([-0.0304,  0.1723])\n",
      "Epoch 1678,Loss 3.017475\n",
      "Epoch 1678, Loss 3.017475\n",
      "    Params:  tensor([  5.1891, -16.2938])\n",
      "    Grad  :  tensor([-0.0304,  0.1720])\n",
      "Epoch 1679,Loss 3.017170\n",
      "Epoch 1679, Loss 3.017170\n",
      "    Params:  tensor([  5.1894, -16.2955])\n",
      "    Grad  :  tensor([-0.0303,  0.1717])\n",
      "Epoch 1680,Loss 3.016867\n",
      "Epoch 1680, Loss 3.016867\n",
      "    Params:  tensor([  5.1897, -16.2972])\n",
      "    Grad  :  tensor([-0.0303,  0.1715])\n",
      "Epoch 1681,Loss 3.016564\n",
      "Epoch 1681, Loss 3.016564\n",
      "    Params:  tensor([  5.1900, -16.2989])\n",
      "    Grad  :  tensor([-0.0302,  0.1712])\n",
      "Epoch 1682,Loss 3.016262\n",
      "Epoch 1682, Loss 3.016262\n",
      "    Params:  tensor([  5.1903, -16.3006])\n",
      "    Grad  :  tensor([-0.0302,  0.1709])\n",
      "Epoch 1683,Loss 3.015959\n",
      "Epoch 1683, Loss 3.015959\n",
      "    Params:  tensor([  5.1906, -16.3024])\n",
      "    Grad  :  tensor([-0.0301,  0.1706])\n",
      "Epoch 1684,Loss 3.015662\n",
      "Epoch 1684, Loss 3.015662\n",
      "    Params:  tensor([  5.1909, -16.3041])\n",
      "    Grad  :  tensor([-0.0301,  0.1703])\n",
      "Epoch 1685,Loss 3.015361\n",
      "Epoch 1685, Loss 3.015361\n",
      "    Params:  tensor([  5.1912, -16.3058])\n",
      "    Grad  :  tensor([-0.0300,  0.1700])\n",
      "Epoch 1686,Loss 3.015064\n",
      "Epoch 1686, Loss 3.015064\n",
      "    Params:  tensor([  5.1915, -16.3075])\n",
      "    Grad  :  tensor([-0.0300,  0.1697])\n",
      "Epoch 1687,Loss 3.014768\n",
      "Epoch 1687, Loss 3.014768\n",
      "    Params:  tensor([  5.1918, -16.3091])\n",
      "    Grad  :  tensor([-0.0299,  0.1694])\n",
      "Epoch 1688,Loss 3.014472\n",
      "Epoch 1688, Loss 3.014472\n",
      "    Params:  tensor([  5.1921, -16.3108])\n",
      "    Grad  :  tensor([-0.0299,  0.1691])\n",
      "Epoch 1689,Loss 3.014179\n",
      "Epoch 1689, Loss 3.014179\n",
      "    Params:  tensor([  5.1924, -16.3125])\n",
      "    Grad  :  tensor([-0.0298,  0.1688])\n",
      "Epoch 1690,Loss 3.013884\n",
      "Epoch 1690, Loss 3.013884\n",
      "    Params:  tensor([  5.1927, -16.3142])\n",
      "    Grad  :  tensor([-0.0298,  0.1686])\n",
      "Epoch 1691,Loss 3.013591\n",
      "Epoch 1691, Loss 3.013591\n",
      "    Params:  tensor([  5.1930, -16.3159])\n",
      "    Grad  :  tensor([-0.0297,  0.1683])\n",
      "Epoch 1692,Loss 3.013299\n",
      "Epoch 1692, Loss 3.013299\n",
      "    Params:  tensor([  5.1933, -16.3176])\n",
      "    Grad  :  tensor([-0.0297,  0.1680])\n",
      "Epoch 1693,Loss 3.013008\n",
      "Epoch 1693, Loss 3.013008\n",
      "    Params:  tensor([  5.1936, -16.3193])\n",
      "    Grad  :  tensor([-0.0296,  0.1677])\n",
      "Epoch 1694,Loss 3.012719\n",
      "Epoch 1694, Loss 3.012719\n",
      "    Params:  tensor([  5.1939, -16.3209])\n",
      "    Grad  :  tensor([-0.0296,  0.1674])\n",
      "Epoch 1695,Loss 3.012431\n",
      "Epoch 1695, Loss 3.012431\n",
      "    Params:  tensor([  5.1942, -16.3226])\n",
      "    Grad  :  tensor([-0.0295,  0.1671])\n",
      "Epoch 1696,Loss 3.012141\n",
      "Epoch 1696, Loss 3.012141\n",
      "    Params:  tensor([  5.1945, -16.3243])\n",
      "    Grad  :  tensor([-0.0295,  0.1668])\n",
      "Epoch 1697,Loss 3.011855\n",
      "Epoch 1697, Loss 3.011855\n",
      "    Params:  tensor([  5.1948, -16.3259])\n",
      "    Grad  :  tensor([-0.0294,  0.1666])\n",
      "Epoch 1698,Loss 3.011570\n",
      "Epoch 1698, Loss 3.011570\n",
      "    Params:  tensor([  5.1951, -16.3276])\n",
      "    Grad  :  tensor([-0.0294,  0.1663])\n",
      "Epoch 1699,Loss 3.011284\n",
      "Epoch 1699, Loss 3.011284\n",
      "    Params:  tensor([  5.1954, -16.3293])\n",
      "    Grad  :  tensor([-0.0293,  0.1660])\n",
      "Epoch 1700,Loss 3.011001\n",
      "Epoch 1700, Loss 3.011001\n",
      "    Params:  tensor([  5.1957, -16.3309])\n",
      "    Grad  :  tensor([-0.0293,  0.1657])\n",
      "Epoch 1701,Loss 3.010718\n",
      "Epoch 1701, Loss 3.010718\n",
      "    Params:  tensor([  5.1960, -16.3326])\n",
      "    Grad  :  tensor([-0.0292,  0.1654])\n",
      "Epoch 1702,Loss 3.010436\n",
      "Epoch 1702, Loss 3.010436\n",
      "    Params:  tensor([  5.1963, -16.3342])\n",
      "    Grad  :  tensor([-0.0292,  0.1652])\n",
      "Epoch 1703,Loss 3.010156\n",
      "Epoch 1703, Loss 3.010156\n",
      "    Params:  tensor([  5.1966, -16.3359])\n",
      "    Grad  :  tensor([-0.0291,  0.1649])\n",
      "Epoch 1704,Loss 3.009876\n",
      "Epoch 1704, Loss 3.009876\n",
      "    Params:  tensor([  5.1968, -16.3375])\n",
      "    Grad  :  tensor([-0.0291,  0.1646])\n",
      "Epoch 1705,Loss 3.009595\n",
      "Epoch 1705, Loss 3.009595\n",
      "    Params:  tensor([  5.1971, -16.3392])\n",
      "    Grad  :  tensor([-0.0290,  0.1643])\n",
      "Epoch 1706,Loss 3.009319\n",
      "Epoch 1706, Loss 3.009319\n",
      "    Params:  tensor([  5.1974, -16.3408])\n",
      "    Grad  :  tensor([-0.0290,  0.1640])\n",
      "Epoch 1707,Loss 3.009040\n",
      "Epoch 1707, Loss 3.009040\n",
      "    Params:  tensor([  5.1977, -16.3424])\n",
      "    Grad  :  tensor([-0.0289,  0.1638])\n",
      "Epoch 1708,Loss 3.008763\n",
      "Epoch 1708, Loss 3.008763\n",
      "    Params:  tensor([  5.1980, -16.3441])\n",
      "    Grad  :  tensor([-0.0289,  0.1635])\n",
      "Epoch 1709,Loss 3.008487\n",
      "Epoch 1709, Loss 3.008487\n",
      "    Params:  tensor([  5.1983, -16.3457])\n",
      "    Grad  :  tensor([-0.0288,  0.1632])\n",
      "Epoch 1710,Loss 3.008215\n",
      "Epoch 1710, Loss 3.008215\n",
      "    Params:  tensor([  5.1986, -16.3473])\n",
      "    Grad  :  tensor([-0.0288,  0.1629])\n",
      "Epoch 1711,Loss 3.007941\n",
      "Epoch 1711, Loss 3.007941\n",
      "    Params:  tensor([  5.1989, -16.3490])\n",
      "    Grad  :  tensor([-0.0287,  0.1626])\n",
      "Epoch 1712,Loss 3.007668\n",
      "Epoch 1712, Loss 3.007668\n",
      "    Params:  tensor([  5.1992, -16.3506])\n",
      "    Grad  :  tensor([-0.0287,  0.1624])\n",
      "Epoch 1713,Loss 3.007397\n",
      "Epoch 1713, Loss 3.007397\n",
      "    Params:  tensor([  5.1994, -16.3522])\n",
      "    Grad  :  tensor([-0.0286,  0.1621])\n",
      "Epoch 1714,Loss 3.007126\n",
      "Epoch 1714, Loss 3.007126\n",
      "    Params:  tensor([  5.1997, -16.3538])\n",
      "    Grad  :  tensor([-0.0286,  0.1618])\n",
      "Epoch 1715,Loss 3.006857\n",
      "Epoch 1715, Loss 3.006857\n",
      "    Params:  tensor([  5.2000, -16.3554])\n",
      "    Grad  :  tensor([-0.0285,  0.1615])\n",
      "Epoch 1716,Loss 3.006586\n",
      "Epoch 1716, Loss 3.006586\n",
      "    Params:  tensor([  5.2003, -16.3570])\n",
      "    Grad  :  tensor([-0.0285,  0.1613])\n",
      "Epoch 1717,Loss 3.006318\n",
      "Epoch 1717, Loss 3.006318\n",
      "    Params:  tensor([  5.2006, -16.3587])\n",
      "    Grad  :  tensor([-0.0284,  0.1610])\n",
      "Epoch 1718,Loss 3.006052\n",
      "Epoch 1718, Loss 3.006052\n",
      "    Params:  tensor([  5.2009, -16.3603])\n",
      "    Grad  :  tensor([-0.0284,  0.1607])\n",
      "Epoch 1719,Loss 3.005785\n",
      "Epoch 1719, Loss 3.005785\n",
      "    Params:  tensor([  5.2012, -16.3619])\n",
      "    Grad  :  tensor([-0.0284,  0.1604])\n",
      "Epoch 1720,Loss 3.005521\n",
      "Epoch 1720, Loss 3.005521\n",
      "    Params:  tensor([  5.2014, -16.3635])\n",
      "    Grad  :  tensor([-0.0283,  0.1602])\n",
      "Epoch 1721,Loss 3.005256\n",
      "Epoch 1721, Loss 3.005256\n",
      "    Params:  tensor([  5.2017, -16.3651])\n",
      "    Grad  :  tensor([-0.0283,  0.1599])\n",
      "Epoch 1722,Loss 3.004993\n",
      "Epoch 1722, Loss 3.004993\n",
      "    Params:  tensor([  5.2020, -16.3667])\n",
      "    Grad  :  tensor([-0.0282,  0.1596])\n",
      "Epoch 1723,Loss 3.004729\n",
      "Epoch 1723, Loss 3.004729\n",
      "    Params:  tensor([  5.2023, -16.3683])\n",
      "    Grad  :  tensor([-0.0281,  0.1594])\n",
      "Epoch 1724,Loss 3.004467\n",
      "Epoch 1724, Loss 3.004467\n",
      "    Params:  tensor([  5.2026, -16.3699])\n",
      "    Grad  :  tensor([-0.0281,  0.1591])\n",
      "Epoch 1725,Loss 3.004207\n",
      "Epoch 1725, Loss 3.004207\n",
      "    Params:  tensor([  5.2028, -16.3714])\n",
      "    Grad  :  tensor([-0.0280,  0.1588])\n",
      "Epoch 1726,Loss 3.003947\n",
      "Epoch 1726, Loss 3.003947\n",
      "    Params:  tensor([  5.2031, -16.3730])\n",
      "    Grad  :  tensor([-0.0280,  0.1586])\n",
      "Epoch 1727,Loss 3.003690\n",
      "Epoch 1727, Loss 3.003690\n",
      "    Params:  tensor([  5.2034, -16.3746])\n",
      "    Grad  :  tensor([-0.0280,  0.1583])\n",
      "Epoch 1728,Loss 3.003431\n",
      "Epoch 1728, Loss 3.003431\n",
      "    Params:  tensor([  5.2037, -16.3762])\n",
      "    Grad  :  tensor([-0.0279,  0.1580])\n",
      "Epoch 1729,Loss 3.003174\n",
      "Epoch 1729, Loss 3.003174\n",
      "    Params:  tensor([  5.2040, -16.3778])\n",
      "    Grad  :  tensor([-0.0279,  0.1577])\n",
      "Epoch 1730,Loss 3.002918\n",
      "Epoch 1730, Loss 3.002918\n",
      "    Params:  tensor([  5.2042, -16.3793])\n",
      "    Grad  :  tensor([-0.0278,  0.1575])\n",
      "Epoch 1731,Loss 3.002661\n",
      "Epoch 1731, Loss 3.002661\n",
      "    Params:  tensor([  5.2045, -16.3809])\n",
      "    Grad  :  tensor([-0.0278,  0.1572])\n",
      "Epoch 1732,Loss 3.002406\n",
      "Epoch 1732, Loss 3.002406\n",
      "    Params:  tensor([  5.2048, -16.3825])\n",
      "    Grad  :  tensor([-0.0277,  0.1569])\n",
      "Epoch 1733,Loss 3.002152\n",
      "Epoch 1733, Loss 3.002152\n",
      "    Params:  tensor([  5.2051, -16.3840])\n",
      "    Grad  :  tensor([-0.0277,  0.1567])\n",
      "Epoch 1734,Loss 3.001901\n",
      "Epoch 1734, Loss 3.001901\n",
      "    Params:  tensor([  5.2053, -16.3856])\n",
      "    Grad  :  tensor([-0.0276,  0.1564])\n",
      "Epoch 1735,Loss 3.001649\n",
      "Epoch 1735, Loss 3.001649\n",
      "    Params:  tensor([  5.2056, -16.3872])\n",
      "    Grad  :  tensor([-0.0276,  0.1561])\n",
      "Epoch 1736,Loss 3.001395\n",
      "Epoch 1736, Loss 3.001395\n",
      "    Params:  tensor([  5.2059, -16.3887])\n",
      "    Grad  :  tensor([-0.0275,  0.1559])\n",
      "Epoch 1737,Loss 3.001145\n",
      "Epoch 1737, Loss 3.001145\n",
      "    Params:  tensor([  5.2062, -16.3903])\n",
      "    Grad  :  tensor([-0.0275,  0.1556])\n",
      "Epoch 1738,Loss 3.000898\n",
      "Epoch 1738, Loss 3.000898\n",
      "    Params:  tensor([  5.2064, -16.3918])\n",
      "    Grad  :  tensor([-0.0275,  0.1553])\n",
      "Epoch 1739,Loss 3.000648\n",
      "Epoch 1739, Loss 3.000648\n",
      "    Params:  tensor([  5.2067, -16.3934])\n",
      "    Grad  :  tensor([-0.0274,  0.1551])\n",
      "Epoch 1740,Loss 3.000400\n",
      "Epoch 1740, Loss 3.000400\n",
      "    Params:  tensor([  5.2070, -16.3949])\n",
      "    Grad  :  tensor([-0.0273,  0.1548])\n",
      "Epoch 1741,Loss 3.000154\n",
      "Epoch 1741, Loss 3.000154\n",
      "    Params:  tensor([  5.2073, -16.3965])\n",
      "    Grad  :  tensor([-0.0273,  0.1546])\n",
      "Epoch 1742,Loss 2.999907\n",
      "Epoch 1742, Loss 2.999907\n",
      "    Params:  tensor([  5.2075, -16.3980])\n",
      "    Grad  :  tensor([-0.0273,  0.1543])\n",
      "Epoch 1743,Loss 2.999662\n",
      "Epoch 1743, Loss 2.999662\n",
      "    Params:  tensor([  5.2078, -16.3996])\n",
      "    Grad  :  tensor([-0.0272,  0.1540])\n",
      "Epoch 1744,Loss 2.999417\n",
      "Epoch 1744, Loss 2.999417\n",
      "    Params:  tensor([  5.2081, -16.4011])\n",
      "    Grad  :  tensor([-0.0272,  0.1538])\n",
      "Epoch 1745,Loss 2.999174\n",
      "Epoch 1745, Loss 2.999174\n",
      "    Params:  tensor([  5.2084, -16.4026])\n",
      "    Grad  :  tensor([-0.0271,  0.1535])\n",
      "Epoch 1746,Loss 2.998930\n",
      "Epoch 1746, Loss 2.998930\n",
      "    Params:  tensor([  5.2086, -16.4042])\n",
      "    Grad  :  tensor([-0.0271,  0.1533])\n",
      "Epoch 1747,Loss 2.998688\n",
      "Epoch 1747, Loss 2.998688\n",
      "    Params:  tensor([  5.2089, -16.4057])\n",
      "    Grad  :  tensor([-0.0270,  0.1530])\n",
      "Epoch 1748,Loss 2.998448\n",
      "Epoch 1748, Loss 2.998448\n",
      "    Params:  tensor([  5.2092, -16.4072])\n",
      "    Grad  :  tensor([-0.0270,  0.1527])\n",
      "Epoch 1749,Loss 2.998208\n",
      "Epoch 1749, Loss 2.998208\n",
      "    Params:  tensor([  5.2094, -16.4088])\n",
      "    Grad  :  tensor([-0.0269,  0.1525])\n",
      "Epoch 1750,Loss 2.997968\n",
      "Epoch 1750, Loss 2.997968\n",
      "    Params:  tensor([  5.2097, -16.4103])\n",
      "    Grad  :  tensor([-0.0269,  0.1522])\n",
      "Epoch 1751,Loss 2.997730\n",
      "Epoch 1751, Loss 2.997730\n",
      "    Params:  tensor([  5.2100, -16.4118])\n",
      "    Grad  :  tensor([-0.0268,  0.1520])\n",
      "Epoch 1752,Loss 2.997490\n",
      "Epoch 1752, Loss 2.997490\n",
      "    Params:  tensor([  5.2102, -16.4133])\n",
      "    Grad  :  tensor([-0.0268,  0.1517])\n",
      "Epoch 1753,Loss 2.997254\n",
      "Epoch 1753, Loss 2.997254\n",
      "    Params:  tensor([  5.2105, -16.4148])\n",
      "    Grad  :  tensor([-0.0267,  0.1514])\n",
      "Epoch 1754,Loss 2.997018\n",
      "Epoch 1754, Loss 2.997018\n",
      "    Params:  tensor([  5.2108, -16.4163])\n",
      "    Grad  :  tensor([-0.0267,  0.1512])\n",
      "Epoch 1755,Loss 2.996782\n",
      "Epoch 1755, Loss 2.996782\n",
      "    Params:  tensor([  5.2110, -16.4179])\n",
      "    Grad  :  tensor([-0.0266,  0.1509])\n",
      "Epoch 1756,Loss 2.996548\n",
      "Epoch 1756, Loss 2.996548\n",
      "    Params:  tensor([  5.2113, -16.4194])\n",
      "    Grad  :  tensor([-0.0266,  0.1507])\n",
      "Epoch 1757,Loss 2.996313\n",
      "Epoch 1757, Loss 2.996313\n",
      "    Params:  tensor([  5.2116, -16.4209])\n",
      "    Grad  :  tensor([-0.0266,  0.1504])\n",
      "Epoch 1758,Loss 2.996081\n",
      "Epoch 1758, Loss 2.996081\n",
      "    Params:  tensor([  5.2118, -16.4224])\n",
      "    Grad  :  tensor([-0.0265,  0.1502])\n",
      "Epoch 1759,Loss 2.995847\n",
      "Epoch 1759, Loss 2.995847\n",
      "    Params:  tensor([  5.2121, -16.4239])\n",
      "    Grad  :  tensor([-0.0265,  0.1499])\n",
      "Epoch 1760,Loss 2.995615\n",
      "Epoch 1760, Loss 2.995615\n",
      "    Params:  tensor([  5.2124, -16.4254])\n",
      "    Grad  :  tensor([-0.0264,  0.1496])\n",
      "Epoch 1761,Loss 2.995387\n",
      "Epoch 1761, Loss 2.995387\n",
      "    Params:  tensor([  5.2126, -16.4269])\n",
      "    Grad  :  tensor([-0.0264,  0.1494])\n",
      "Epoch 1762,Loss 2.995156\n",
      "Epoch 1762, Loss 2.995156\n",
      "    Params:  tensor([  5.2129, -16.4283])\n",
      "    Grad  :  tensor([-0.0263,  0.1491])\n",
      "Epoch 1763,Loss 2.994928\n",
      "Epoch 1763, Loss 2.994928\n",
      "    Params:  tensor([  5.2132, -16.4298])\n",
      "    Grad  :  tensor([-0.0263,  0.1489])\n",
      "Epoch 1764,Loss 2.994699\n",
      "Epoch 1764, Loss 2.994699\n",
      "    Params:  tensor([  5.2134, -16.4313])\n",
      "    Grad  :  tensor([-0.0263,  0.1486])\n",
      "Epoch 1765,Loss 2.994471\n",
      "Epoch 1765, Loss 2.994471\n",
      "    Params:  tensor([  5.2137, -16.4328])\n",
      "    Grad  :  tensor([-0.0262,  0.1484])\n",
      "Epoch 1766,Loss 2.994245\n",
      "Epoch 1766, Loss 2.994245\n",
      "    Params:  tensor([  5.2139, -16.4343])\n",
      "    Grad  :  tensor([-0.0262,  0.1481])\n",
      "Epoch 1767,Loss 2.994019\n",
      "Epoch 1767, Loss 2.994019\n",
      "    Params:  tensor([  5.2142, -16.4358])\n",
      "    Grad  :  tensor([-0.0261,  0.1479])\n",
      "Epoch 1768,Loss 2.993794\n",
      "Epoch 1768, Loss 2.993794\n",
      "    Params:  tensor([  5.2145, -16.4372])\n",
      "    Grad  :  tensor([-0.0261,  0.1476])\n",
      "Epoch 1769,Loss 2.993569\n",
      "Epoch 1769, Loss 2.993569\n",
      "    Params:  tensor([  5.2147, -16.4387])\n",
      "    Grad  :  tensor([-0.0260,  0.1474])\n",
      "Epoch 1770,Loss 2.993344\n",
      "Epoch 1770, Loss 2.993344\n",
      "    Params:  tensor([  5.2150, -16.4402])\n",
      "    Grad  :  tensor([-0.0260,  0.1471])\n",
      "Epoch 1771,Loss 2.993121\n",
      "Epoch 1771, Loss 2.993121\n",
      "    Params:  tensor([  5.2152, -16.4417])\n",
      "    Grad  :  tensor([-0.0260,  0.1469])\n",
      "Epoch 1772,Loss 2.992900\n",
      "Epoch 1772, Loss 2.992900\n",
      "    Params:  tensor([  5.2155, -16.4431])\n",
      "    Grad  :  tensor([-0.0259,  0.1466])\n",
      "Epoch 1773,Loss 2.992678\n",
      "Epoch 1773, Loss 2.992678\n",
      "    Params:  tensor([  5.2158, -16.4446])\n",
      "    Grad  :  tensor([-0.0259,  0.1464])\n",
      "Epoch 1774,Loss 2.992457\n",
      "Epoch 1774, Loss 2.992457\n",
      "    Params:  tensor([  5.2160, -16.4460])\n",
      "    Grad  :  tensor([-0.0258,  0.1461])\n",
      "Epoch 1775,Loss 2.992237\n",
      "Epoch 1775, Loss 2.992237\n",
      "    Params:  tensor([  5.2163, -16.4475])\n",
      "    Grad  :  tensor([-0.0258,  0.1459])\n",
      "Epoch 1776,Loss 2.992017\n",
      "Epoch 1776, Loss 2.992017\n",
      "    Params:  tensor([  5.2165, -16.4490])\n",
      "    Grad  :  tensor([-0.0257,  0.1456])\n",
      "Epoch 1777,Loss 2.991798\n",
      "Epoch 1777, Loss 2.991798\n",
      "    Params:  tensor([  5.2168, -16.4504])\n",
      "    Grad  :  tensor([-0.0257,  0.1454])\n",
      "Epoch 1778,Loss 2.991582\n",
      "Epoch 1778, Loss 2.991582\n",
      "    Params:  tensor([  5.2170, -16.4519])\n",
      "    Grad  :  tensor([-0.0256,  0.1451])\n",
      "Epoch 1779,Loss 2.991366\n",
      "Epoch 1779, Loss 2.991366\n",
      "    Params:  tensor([  5.2173, -16.4533])\n",
      "    Grad  :  tensor([-0.0256,  0.1449])\n",
      "Epoch 1780,Loss 2.991146\n",
      "Epoch 1780, Loss 2.991146\n",
      "    Params:  tensor([  5.2176, -16.4548])\n",
      "    Grad  :  tensor([-0.0256,  0.1446])\n",
      "Epoch 1781,Loss 2.990932\n",
      "Epoch 1781, Loss 2.990932\n",
      "    Params:  tensor([  5.2178, -16.4562])\n",
      "    Grad  :  tensor([-0.0255,  0.1444])\n",
      "Epoch 1782,Loss 2.990719\n",
      "Epoch 1782, Loss 2.990719\n",
      "    Params:  tensor([  5.2181, -16.4576])\n",
      "    Grad  :  tensor([-0.0255,  0.1442])\n",
      "Epoch 1783,Loss 2.990503\n",
      "Epoch 1783, Loss 2.990503\n",
      "    Params:  tensor([  5.2183, -16.4591])\n",
      "    Grad  :  tensor([-0.0254,  0.1439])\n",
      "Epoch 1784,Loss 2.990288\n",
      "Epoch 1784, Loss 2.990288\n",
      "    Params:  tensor([  5.2186, -16.4605])\n",
      "    Grad  :  tensor([-0.0254,  0.1437])\n",
      "Epoch 1785,Loss 2.990078\n",
      "Epoch 1785, Loss 2.990078\n",
      "    Params:  tensor([  5.2188, -16.4620])\n",
      "    Grad  :  tensor([-0.0253,  0.1434])\n",
      "Epoch 1786,Loss 2.989866\n",
      "Epoch 1786, Loss 2.989866\n",
      "    Params:  tensor([  5.2191, -16.4634])\n",
      "    Grad  :  tensor([-0.0253,  0.1432])\n",
      "Epoch 1787,Loss 2.989655\n",
      "Epoch 1787, Loss 2.989655\n",
      "    Params:  tensor([  5.2193, -16.4648])\n",
      "    Grad  :  tensor([-0.0252,  0.1429])\n",
      "Epoch 1788,Loss 2.989443\n",
      "Epoch 1788, Loss 2.989443\n",
      "    Params:  tensor([  5.2196, -16.4662])\n",
      "    Grad  :  tensor([-0.0252,  0.1427])\n",
      "Epoch 1789,Loss 2.989233\n",
      "Epoch 1789, Loss 2.989233\n",
      "    Params:  tensor([  5.2198, -16.4677])\n",
      "    Grad  :  tensor([-0.0252,  0.1424])\n",
      "Epoch 1790,Loss 2.989025\n",
      "Epoch 1790, Loss 2.989025\n",
      "    Params:  tensor([  5.2201, -16.4691])\n",
      "    Grad  :  tensor([-0.0251,  0.1422])\n",
      "Epoch 1791,Loss 2.988817\n",
      "Epoch 1791, Loss 2.988817\n",
      "    Params:  tensor([  5.2203, -16.4705])\n",
      "    Grad  :  tensor([-0.0251,  0.1420])\n",
      "Epoch 1792,Loss 2.988609\n",
      "Epoch 1792, Loss 2.988609\n",
      "    Params:  tensor([  5.2206, -16.4719])\n",
      "    Grad  :  tensor([-0.0250,  0.1417])\n",
      "Epoch 1793,Loss 2.988401\n",
      "Epoch 1793, Loss 2.988401\n",
      "    Params:  tensor([  5.2208, -16.4733])\n",
      "    Grad  :  tensor([-0.0250,  0.1415])\n",
      "Epoch 1794,Loss 2.988195\n",
      "Epoch 1794, Loss 2.988195\n",
      "    Params:  tensor([  5.2211, -16.4748])\n",
      "    Grad  :  tensor([-0.0249,  0.1412])\n",
      "Epoch 1795,Loss 2.987989\n",
      "Epoch 1795, Loss 2.987989\n",
      "    Params:  tensor([  5.2213, -16.4762])\n",
      "    Grad  :  tensor([-0.0249,  0.1410])\n",
      "Epoch 1796,Loss 2.987785\n",
      "Epoch 1796, Loss 2.987785\n",
      "    Params:  tensor([  5.2216, -16.4776])\n",
      "    Grad  :  tensor([-0.0249,  0.1408])\n",
      "Epoch 1797,Loss 2.987582\n",
      "Epoch 1797, Loss 2.987582\n",
      "    Params:  tensor([  5.2218, -16.4790])\n",
      "    Grad  :  tensor([-0.0248,  0.1405])\n",
      "Epoch 1798,Loss 2.987377\n",
      "Epoch 1798, Loss 2.987377\n",
      "    Params:  tensor([  5.2221, -16.4804])\n",
      "    Grad  :  tensor([-0.0248,  0.1403])\n",
      "Epoch 1799,Loss 2.987174\n",
      "Epoch 1799, Loss 2.987174\n",
      "    Params:  tensor([  5.2223, -16.4818])\n",
      "    Grad  :  tensor([-0.0247,  0.1400])\n",
      "Epoch 1800,Loss 2.986974\n",
      "Epoch 1800, Loss 2.986974\n",
      "    Params:  tensor([  5.2226, -16.4832])\n",
      "    Grad  :  tensor([-0.0247,  0.1398])\n",
      "Epoch 1801,Loss 2.986771\n",
      "Epoch 1801, Loss 2.986771\n",
      "    Params:  tensor([  5.2228, -16.4846])\n",
      "    Grad  :  tensor([-0.0246,  0.1396])\n",
      "Epoch 1802,Loss 2.986570\n",
      "Epoch 1802, Loss 2.986570\n",
      "    Params:  tensor([  5.2231, -16.4860])\n",
      "    Grad  :  tensor([-0.0246,  0.1393])\n",
      "Epoch 1803,Loss 2.986371\n",
      "Epoch 1803, Loss 2.986371\n",
      "    Params:  tensor([  5.2233, -16.4874])\n",
      "    Grad  :  tensor([-0.0246,  0.1391])\n",
      "Epoch 1804,Loss 2.986171\n",
      "Epoch 1804, Loss 2.986171\n",
      "    Params:  tensor([  5.2236, -16.4888])\n",
      "    Grad  :  tensor([-0.0245,  0.1389])\n",
      "Epoch 1805,Loss 2.985972\n",
      "Epoch 1805, Loss 2.985972\n",
      "    Params:  tensor([  5.2238, -16.4901])\n",
      "    Grad  :  tensor([-0.0245,  0.1386])\n",
      "Epoch 1806,Loss 2.985774\n",
      "Epoch 1806, Loss 2.985774\n",
      "    Params:  tensor([  5.2241, -16.4915])\n",
      "    Grad  :  tensor([-0.0245,  0.1384])\n",
      "Epoch 1807,Loss 2.985578\n",
      "Epoch 1807, Loss 2.985578\n",
      "    Params:  tensor([  5.2243, -16.4929])\n",
      "    Grad  :  tensor([-0.0244,  0.1382])\n",
      "Epoch 1808,Loss 2.985381\n",
      "Epoch 1808, Loss 2.985381\n",
      "    Params:  tensor([  5.2245, -16.4943])\n",
      "    Grad  :  tensor([-0.0244,  0.1379])\n",
      "Epoch 1809,Loss 2.985184\n",
      "Epoch 1809, Loss 2.985184\n",
      "    Params:  tensor([  5.2248, -16.4957])\n",
      "    Grad  :  tensor([-0.0243,  0.1377])\n",
      "Epoch 1810,Loss 2.984989\n",
      "Epoch 1810, Loss 2.984989\n",
      "    Params:  tensor([  5.2250, -16.4970])\n",
      "    Grad  :  tensor([-0.0243,  0.1374])\n",
      "Epoch 1811,Loss 2.984793\n",
      "Epoch 1811, Loss 2.984793\n",
      "    Params:  tensor([  5.2253, -16.4984])\n",
      "    Grad  :  tensor([-0.0243,  0.1372])\n",
      "Epoch 1812,Loss 2.984601\n",
      "Epoch 1812, Loss 2.984601\n",
      "    Params:  tensor([  5.2255, -16.4998])\n",
      "    Grad  :  tensor([-0.0242,  0.1370])\n",
      "Epoch 1813,Loss 2.984407\n",
      "Epoch 1813, Loss 2.984407\n",
      "    Params:  tensor([  5.2258, -16.5011])\n",
      "    Grad  :  tensor([-0.0242,  0.1368])\n",
      "Epoch 1814,Loss 2.984215\n",
      "Epoch 1814, Loss 2.984215\n",
      "    Params:  tensor([  5.2260, -16.5025])\n",
      "    Grad  :  tensor([-0.0241,  0.1365])\n",
      "Epoch 1815,Loss 2.984022\n",
      "Epoch 1815, Loss 2.984022\n",
      "    Params:  tensor([  5.2262, -16.5039])\n",
      "    Grad  :  tensor([-0.0241,  0.1363])\n",
      "Epoch 1816,Loss 2.983831\n",
      "Epoch 1816, Loss 2.983831\n",
      "    Params:  tensor([  5.2265, -16.5052])\n",
      "    Grad  :  tensor([-0.0240,  0.1361])\n",
      "Epoch 1817,Loss 2.983639\n",
      "Epoch 1817, Loss 2.983639\n",
      "    Params:  tensor([  5.2267, -16.5066])\n",
      "    Grad  :  tensor([-0.0240,  0.1358])\n",
      "Epoch 1818,Loss 2.983449\n",
      "Epoch 1818, Loss 2.983449\n",
      "    Params:  tensor([  5.2270, -16.5079])\n",
      "    Grad  :  tensor([-0.0239,  0.1356])\n",
      "Epoch 1819,Loss 2.983259\n",
      "Epoch 1819, Loss 2.983259\n",
      "    Params:  tensor([  5.2272, -16.5093])\n",
      "    Grad  :  tensor([-0.0239,  0.1354])\n",
      "Epoch 1820,Loss 2.983073\n",
      "Epoch 1820, Loss 2.983073\n",
      "    Params:  tensor([  5.2274, -16.5107])\n",
      "    Grad  :  tensor([-0.0239,  0.1351])\n",
      "Epoch 1821,Loss 2.982884\n",
      "Epoch 1821, Loss 2.982884\n",
      "    Params:  tensor([  5.2277, -16.5120])\n",
      "    Grad  :  tensor([-0.0238,  0.1349])\n",
      "Epoch 1822,Loss 2.982697\n",
      "Epoch 1822, Loss 2.982697\n",
      "    Params:  tensor([  5.2279, -16.5133])\n",
      "    Grad  :  tensor([-0.0238,  0.1347])\n",
      "Epoch 1823,Loss 2.982510\n",
      "Epoch 1823, Loss 2.982510\n",
      "    Params:  tensor([  5.2281, -16.5147])\n",
      "    Grad  :  tensor([-0.0237,  0.1344])\n",
      "Epoch 1824,Loss 2.982322\n",
      "Epoch 1824, Loss 2.982322\n",
      "    Params:  tensor([  5.2284, -16.5160])\n",
      "    Grad  :  tensor([-0.0237,  0.1342])\n",
      "Epoch 1825,Loss 2.982137\n",
      "Epoch 1825, Loss 2.982137\n",
      "    Params:  tensor([  5.2286, -16.5174])\n",
      "    Grad  :  tensor([-0.0237,  0.1340])\n",
      "Epoch 1826,Loss 2.981953\n",
      "Epoch 1826, Loss 2.981953\n",
      "    Params:  tensor([  5.2289, -16.5187])\n",
      "    Grad  :  tensor([-0.0236,  0.1338])\n",
      "Epoch 1827,Loss 2.981769\n",
      "Epoch 1827, Loss 2.981769\n",
      "    Params:  tensor([  5.2291, -16.5200])\n",
      "    Grad  :  tensor([-0.0236,  0.1335])\n",
      "Epoch 1828,Loss 2.981586\n",
      "Epoch 1828, Loss 2.981586\n",
      "    Params:  tensor([  5.2293, -16.5214])\n",
      "    Grad  :  tensor([-0.0236,  0.1333])\n",
      "Epoch 1829,Loss 2.981402\n",
      "Epoch 1829, Loss 2.981402\n",
      "    Params:  tensor([  5.2296, -16.5227])\n",
      "    Grad  :  tensor([-0.0235,  0.1331])\n",
      "Epoch 1830,Loss 2.981219\n",
      "Epoch 1830, Loss 2.981219\n",
      "    Params:  tensor([  5.2298, -16.5240])\n",
      "    Grad  :  tensor([-0.0235,  0.1329])\n",
      "Epoch 1831,Loss 2.981037\n",
      "Epoch 1831, Loss 2.981037\n",
      "    Params:  tensor([  5.2300, -16.5254])\n",
      "    Grad  :  tensor([-0.0235,  0.1326])\n",
      "Epoch 1832,Loss 2.980856\n",
      "Epoch 1832, Loss 2.980856\n",
      "    Params:  tensor([  5.2303, -16.5267])\n",
      "    Grad  :  tensor([-0.0234,  0.1324])\n",
      "Epoch 1833,Loss 2.980675\n",
      "Epoch 1833, Loss 2.980675\n",
      "    Params:  tensor([  5.2305, -16.5280])\n",
      "    Grad  :  tensor([-0.0234,  0.1322])\n",
      "Epoch 1834,Loss 2.980495\n",
      "Epoch 1834, Loss 2.980495\n",
      "    Params:  tensor([  5.2307, -16.5293])\n",
      "    Grad  :  tensor([-0.0233,  0.1320])\n",
      "Epoch 1835,Loss 2.980315\n",
      "Epoch 1835, Loss 2.980315\n",
      "    Params:  tensor([  5.2310, -16.5306])\n",
      "    Grad  :  tensor([-0.0233,  0.1317])\n",
      "Epoch 1836,Loss 2.980137\n",
      "Epoch 1836, Loss 2.980137\n",
      "    Params:  tensor([  5.2312, -16.5320])\n",
      "    Grad  :  tensor([-0.0232,  0.1315])\n",
      "Epoch 1837,Loss 2.979958\n",
      "Epoch 1837, Loss 2.979958\n",
      "    Params:  tensor([  5.2314, -16.5333])\n",
      "    Grad  :  tensor([-0.0232,  0.1313])\n",
      "Epoch 1838,Loss 2.979782\n",
      "Epoch 1838, Loss 2.979782\n",
      "    Params:  tensor([  5.2317, -16.5346])\n",
      "    Grad  :  tensor([-0.0232,  0.1311])\n",
      "Epoch 1839,Loss 2.979604\n",
      "Epoch 1839, Loss 2.979604\n",
      "    Params:  tensor([  5.2319, -16.5359])\n",
      "    Grad  :  tensor([-0.0231,  0.1308])\n",
      "Epoch 1840,Loss 2.979428\n",
      "Epoch 1840, Loss 2.979428\n",
      "    Params:  tensor([  5.2321, -16.5372])\n",
      "    Grad  :  tensor([-0.0231,  0.1306])\n",
      "Epoch 1841,Loss 2.979253\n",
      "Epoch 1841, Loss 2.979253\n",
      "    Params:  tensor([  5.2324, -16.5385])\n",
      "    Grad  :  tensor([-0.0230,  0.1304])\n",
      "Epoch 1842,Loss 2.979078\n",
      "Epoch 1842, Loss 2.979078\n",
      "    Params:  tensor([  5.2326, -16.5398])\n",
      "    Grad  :  tensor([-0.0230,  0.1302])\n",
      "Epoch 1843,Loss 2.978902\n",
      "Epoch 1843, Loss 2.978902\n",
      "    Params:  tensor([  5.2328, -16.5411])\n",
      "    Grad  :  tensor([-0.0229,  0.1300])\n",
      "Epoch 1844,Loss 2.978729\n",
      "Epoch 1844, Loss 2.978729\n",
      "    Params:  tensor([  5.2330, -16.5424])\n",
      "    Grad  :  tensor([-0.0229,  0.1297])\n",
      "Epoch 1845,Loss 2.978556\n",
      "Epoch 1845, Loss 2.978556\n",
      "    Params:  tensor([  5.2333, -16.5437])\n",
      "    Grad  :  tensor([-0.0229,  0.1295])\n",
      "Epoch 1846,Loss 2.978382\n",
      "Epoch 1846, Loss 2.978382\n",
      "    Params:  tensor([  5.2335, -16.5450])\n",
      "    Grad  :  tensor([-0.0228,  0.1293])\n",
      "Epoch 1847,Loss 2.978211\n",
      "Epoch 1847, Loss 2.978211\n",
      "    Params:  tensor([  5.2337, -16.5463])\n",
      "    Grad  :  tensor([-0.0228,  0.1291])\n",
      "Epoch 1848,Loss 2.978039\n",
      "Epoch 1848, Loss 2.978039\n",
      "    Params:  tensor([  5.2340, -16.5476])\n",
      "    Grad  :  tensor([-0.0228,  0.1288])\n",
      "Epoch 1849,Loss 2.977867\n",
      "Epoch 1849, Loss 2.977867\n",
      "    Params:  tensor([  5.2342, -16.5489])\n",
      "    Grad  :  tensor([-0.0227,  0.1286])\n",
      "Epoch 1850,Loss 2.977696\n",
      "Epoch 1850, Loss 2.977696\n",
      "    Params:  tensor([  5.2344, -16.5501])\n",
      "    Grad  :  tensor([-0.0227,  0.1284])\n",
      "Epoch 1851,Loss 2.977527\n",
      "Epoch 1851, Loss 2.977527\n",
      "    Params:  tensor([  5.2346, -16.5514])\n",
      "    Grad  :  tensor([-0.0227,  0.1282])\n",
      "Epoch 1852,Loss 2.977357\n",
      "Epoch 1852, Loss 2.977357\n",
      "    Params:  tensor([  5.2349, -16.5527])\n",
      "    Grad  :  tensor([-0.0226,  0.1280])\n",
      "Epoch 1853,Loss 2.977188\n",
      "Epoch 1853, Loss 2.977188\n",
      "    Params:  tensor([  5.2351, -16.5540])\n",
      "    Grad  :  tensor([-0.0226,  0.1278])\n",
      "Epoch 1854,Loss 2.977021\n",
      "Epoch 1854, Loss 2.977021\n",
      "    Params:  tensor([  5.2353, -16.5553])\n",
      "    Grad  :  tensor([-0.0225,  0.1275])\n",
      "Epoch 1855,Loss 2.976853\n",
      "Epoch 1855, Loss 2.976853\n",
      "    Params:  tensor([  5.2355, -16.5565])\n",
      "    Grad  :  tensor([-0.0225,  0.1273])\n",
      "Epoch 1856,Loss 2.976687\n",
      "Epoch 1856, Loss 2.976687\n",
      "    Params:  tensor([  5.2358, -16.5578])\n",
      "    Grad  :  tensor([-0.0225,  0.1271])\n",
      "Epoch 1857,Loss 2.976520\n",
      "Epoch 1857, Loss 2.976520\n",
      "    Params:  tensor([  5.2360, -16.5591])\n",
      "    Grad  :  tensor([-0.0224,  0.1269])\n",
      "Epoch 1858,Loss 2.976354\n",
      "Epoch 1858, Loss 2.976354\n",
      "    Params:  tensor([  5.2362, -16.5603])\n",
      "    Grad  :  tensor([-0.0224,  0.1267])\n",
      "Epoch 1859,Loss 2.976189\n",
      "Epoch 1859, Loss 2.976189\n",
      "    Params:  tensor([  5.2364, -16.5616])\n",
      "    Grad  :  tensor([-0.0223,  0.1265])\n",
      "Epoch 1860,Loss 2.976023\n",
      "Epoch 1860, Loss 2.976023\n",
      "    Params:  tensor([  5.2367, -16.5629])\n",
      "    Grad  :  tensor([-0.0223,  0.1263])\n",
      "Epoch 1861,Loss 2.975860\n",
      "Epoch 1861, Loss 2.975860\n",
      "    Params:  tensor([  5.2369, -16.5641])\n",
      "    Grad  :  tensor([-0.0223,  0.1260])\n",
      "Epoch 1862,Loss 2.975697\n",
      "Epoch 1862, Loss 2.975697\n",
      "    Params:  tensor([  5.2371, -16.5654])\n",
      "    Grad  :  tensor([-0.0222,  0.1258])\n",
      "Epoch 1863,Loss 2.975533\n",
      "Epoch 1863, Loss 2.975533\n",
      "    Params:  tensor([  5.2373, -16.5666])\n",
      "    Grad  :  tensor([-0.0222,  0.1256])\n",
      "Epoch 1864,Loss 2.975369\n",
      "Epoch 1864, Loss 2.975369\n",
      "    Params:  tensor([  5.2375, -16.5679])\n",
      "    Grad  :  tensor([-0.0222,  0.1254])\n",
      "Epoch 1865,Loss 2.975208\n",
      "Epoch 1865, Loss 2.975208\n",
      "    Params:  tensor([  5.2378, -16.5691])\n",
      "    Grad  :  tensor([-0.0221,  0.1252])\n",
      "Epoch 1866,Loss 2.975046\n",
      "Epoch 1866, Loss 2.975046\n",
      "    Params:  tensor([  5.2380, -16.5704])\n",
      "    Grad  :  tensor([-0.0221,  0.1250])\n",
      "Epoch 1867,Loss 2.974886\n",
      "Epoch 1867, Loss 2.974886\n",
      "    Params:  tensor([  5.2382, -16.5716])\n",
      "    Grad  :  tensor([-0.0220,  0.1248])\n",
      "Epoch 1868,Loss 2.974725\n",
      "Epoch 1868, Loss 2.974725\n",
      "    Params:  tensor([  5.2384, -16.5729])\n",
      "    Grad  :  tensor([-0.0220,  0.1245])\n",
      "Epoch 1869,Loss 2.974565\n",
      "Epoch 1869, Loss 2.974565\n",
      "    Params:  tensor([  5.2386, -16.5741])\n",
      "    Grad  :  tensor([-0.0220,  0.1243])\n",
      "Epoch 1870,Loss 2.974406\n",
      "Epoch 1870, Loss 2.974406\n",
      "    Params:  tensor([  5.2389, -16.5754])\n",
      "    Grad  :  tensor([-0.0219,  0.1241])\n",
      "Epoch 1871,Loss 2.974248\n",
      "Epoch 1871, Loss 2.974248\n",
      "    Params:  tensor([  5.2391, -16.5766])\n",
      "    Grad  :  tensor([-0.0219,  0.1239])\n",
      "Epoch 1872,Loss 2.974088\n",
      "Epoch 1872, Loss 2.974088\n",
      "    Params:  tensor([  5.2393, -16.5778])\n",
      "    Grad  :  tensor([-0.0219,  0.1237])\n",
      "Epoch 1873,Loss 2.973930\n",
      "Epoch 1873, Loss 2.973930\n",
      "    Params:  tensor([  5.2395, -16.5791])\n",
      "    Grad  :  tensor([-0.0218,  0.1235])\n",
      "Epoch 1874,Loss 2.973776\n",
      "Epoch 1874, Loss 2.973776\n",
      "    Params:  tensor([  5.2397, -16.5803])\n",
      "    Grad  :  tensor([-0.0218,  0.1233])\n",
      "Epoch 1875,Loss 2.973618\n",
      "Epoch 1875, Loss 2.973618\n",
      "    Params:  tensor([  5.2400, -16.5815])\n",
      "    Grad  :  tensor([-0.0217,  0.1231])\n",
      "Epoch 1876,Loss 2.973463\n",
      "Epoch 1876, Loss 2.973463\n",
      "    Params:  tensor([  5.2402, -16.5828])\n",
      "    Grad  :  tensor([-0.0217,  0.1229])\n",
      "Epoch 1877,Loss 2.973307\n",
      "Epoch 1877, Loss 2.973307\n",
      "    Params:  tensor([  5.2404, -16.5840])\n",
      "    Grad  :  tensor([-0.0217,  0.1227])\n",
      "Epoch 1878,Loss 2.973151\n",
      "Epoch 1878, Loss 2.973151\n",
      "    Params:  tensor([  5.2406, -16.5852])\n",
      "    Grad  :  tensor([-0.0216,  0.1224])\n",
      "Epoch 1879,Loss 2.972996\n",
      "Epoch 1879, Loss 2.972996\n",
      "    Params:  tensor([  5.2408, -16.5864])\n",
      "    Grad  :  tensor([-0.0216,  0.1222])\n",
      "Epoch 1880,Loss 2.972843\n",
      "Epoch 1880, Loss 2.972843\n",
      "    Params:  tensor([  5.2410, -16.5877])\n",
      "    Grad  :  tensor([-0.0215,  0.1220])\n",
      "Epoch 1881,Loss 2.972690\n",
      "Epoch 1881, Loss 2.972690\n",
      "    Params:  tensor([  5.2413, -16.5889])\n",
      "    Grad  :  tensor([-0.0215,  0.1218])\n",
      "Epoch 1882,Loss 2.972536\n",
      "Epoch 1882, Loss 2.972536\n",
      "    Params:  tensor([  5.2415, -16.5901])\n",
      "    Grad  :  tensor([-0.0215,  0.1216])\n",
      "Epoch 1883,Loss 2.972383\n",
      "Epoch 1883, Loss 2.972383\n",
      "    Params:  tensor([  5.2417, -16.5913])\n",
      "    Grad  :  tensor([-0.0214,  0.1214])\n",
      "Epoch 1884,Loss 2.972232\n",
      "Epoch 1884, Loss 2.972232\n",
      "    Params:  tensor([  5.2419, -16.5925])\n",
      "    Grad  :  tensor([-0.0214,  0.1212])\n",
      "Epoch 1885,Loss 2.972081\n",
      "Epoch 1885, Loss 2.972081\n",
      "    Params:  tensor([  5.2421, -16.5937])\n",
      "    Grad  :  tensor([-0.0214,  0.1210])\n",
      "Epoch 1886,Loss 2.971931\n",
      "Epoch 1886, Loss 2.971931\n",
      "    Params:  tensor([  5.2423, -16.5949])\n",
      "    Grad  :  tensor([-0.0213,  0.1208])\n",
      "Epoch 1887,Loss 2.971780\n",
      "Epoch 1887, Loss 2.971780\n",
      "    Params:  tensor([  5.2425, -16.5961])\n",
      "    Grad  :  tensor([-0.0213,  0.1206])\n",
      "Epoch 1888,Loss 2.971630\n",
      "Epoch 1888, Loss 2.971630\n",
      "    Params:  tensor([  5.2427, -16.5974])\n",
      "    Grad  :  tensor([-0.0213,  0.1204])\n",
      "Epoch 1889,Loss 2.971481\n",
      "Epoch 1889, Loss 2.971481\n",
      "    Params:  tensor([  5.2430, -16.5986])\n",
      "    Grad  :  tensor([-0.0212,  0.1202])\n",
      "Epoch 1890,Loss 2.971332\n",
      "Epoch 1890, Loss 2.971332\n",
      "    Params:  tensor([  5.2432, -16.5998])\n",
      "    Grad  :  tensor([-0.0212,  0.1200])\n",
      "Epoch 1891,Loss 2.971184\n",
      "Epoch 1891, Loss 2.971184\n",
      "    Params:  tensor([  5.2434, -16.6010])\n",
      "    Grad  :  tensor([-0.0212,  0.1198])\n",
      "Epoch 1892,Loss 2.971035\n",
      "Epoch 1892, Loss 2.971035\n",
      "    Params:  tensor([  5.2436, -16.6021])\n",
      "    Grad  :  tensor([-0.0211,  0.1196])\n",
      "Epoch 1893,Loss 2.970888\n",
      "Epoch 1893, Loss 2.970888\n",
      "    Params:  tensor([  5.2438, -16.6033])\n",
      "    Grad  :  tensor([-0.0211,  0.1194])\n",
      "Epoch 1894,Loss 2.970741\n",
      "Epoch 1894, Loss 2.970741\n",
      "    Params:  tensor([  5.2440, -16.6045])\n",
      "    Grad  :  tensor([-0.0211,  0.1192])\n",
      "Epoch 1895,Loss 2.970596\n",
      "Epoch 1895, Loss 2.970596\n",
      "    Params:  tensor([  5.2442, -16.6057])\n",
      "    Grad  :  tensor([-0.0210,  0.1190])\n",
      "Epoch 1896,Loss 2.970449\n",
      "Epoch 1896, Loss 2.970449\n",
      "    Params:  tensor([  5.2444, -16.6069])\n",
      "    Grad  :  tensor([-0.0210,  0.1188])\n",
      "Epoch 1897,Loss 2.970304\n",
      "Epoch 1897, Loss 2.970304\n",
      "    Params:  tensor([  5.2446, -16.6081])\n",
      "    Grad  :  tensor([-0.0209,  0.1186])\n",
      "Epoch 1898,Loss 2.970159\n",
      "Epoch 1898, Loss 2.970159\n",
      "    Params:  tensor([  5.2449, -16.6093])\n",
      "    Grad  :  tensor([-0.0209,  0.1183])\n",
      "Epoch 1899,Loss 2.970016\n",
      "Epoch 1899, Loss 2.970016\n",
      "    Params:  tensor([  5.2451, -16.6105])\n",
      "    Grad  :  tensor([-0.0209,  0.1182])\n",
      "Epoch 1900,Loss 2.969871\n",
      "Epoch 1900, Loss 2.969871\n",
      "    Params:  tensor([  5.2453, -16.6116])\n",
      "    Grad  :  tensor([-0.0208,  0.1180])\n",
      "Epoch 1901,Loss 2.969727\n",
      "Epoch 1901, Loss 2.969727\n",
      "    Params:  tensor([  5.2455, -16.6128])\n",
      "    Grad  :  tensor([-0.0208,  0.1178])\n",
      "Epoch 1902,Loss 2.969586\n",
      "Epoch 1902, Loss 2.969586\n",
      "    Params:  tensor([  5.2457, -16.6140])\n",
      "    Grad  :  tensor([-0.0208,  0.1175])\n",
      "Epoch 1903,Loss 2.969443\n",
      "Epoch 1903, Loss 2.969443\n",
      "    Params:  tensor([  5.2459, -16.6152])\n",
      "    Grad  :  tensor([-0.0207,  0.1173])\n",
      "Epoch 1904,Loss 2.969302\n",
      "Epoch 1904, Loss 2.969302\n",
      "    Params:  tensor([  5.2461, -16.6163])\n",
      "    Grad  :  tensor([-0.0207,  0.1172])\n",
      "Epoch 1905,Loss 2.969160\n",
      "Epoch 1905, Loss 2.969160\n",
      "    Params:  tensor([  5.2463, -16.6175])\n",
      "    Grad  :  tensor([-0.0206,  0.1170])\n",
      "Epoch 1906,Loss 2.969017\n",
      "Epoch 1906, Loss 2.969017\n",
      "    Params:  tensor([  5.2465, -16.6187])\n",
      "    Grad  :  tensor([-0.0206,  0.1168])\n",
      "Epoch 1907,Loss 2.968879\n",
      "Epoch 1907, Loss 2.968879\n",
      "    Params:  tensor([  5.2467, -16.6198])\n",
      "    Grad  :  tensor([-0.0206,  0.1166])\n",
      "Epoch 1908,Loss 2.968739\n",
      "Epoch 1908, Loss 2.968739\n",
      "    Params:  tensor([  5.2469, -16.6210])\n",
      "    Grad  :  tensor([-0.0205,  0.1164])\n",
      "Epoch 1909,Loss 2.968599\n",
      "Epoch 1909, Loss 2.968599\n",
      "    Params:  tensor([  5.2471, -16.6222])\n",
      "    Grad  :  tensor([-0.0205,  0.1162])\n",
      "Epoch 1910,Loss 2.968460\n",
      "Epoch 1910, Loss 2.968460\n",
      "    Params:  tensor([  5.2473, -16.6233])\n",
      "    Grad  :  tensor([-0.0205,  0.1160])\n",
      "Epoch 1911,Loss 2.968321\n",
      "Epoch 1911, Loss 2.968321\n",
      "    Params:  tensor([  5.2475, -16.6245])\n",
      "    Grad  :  tensor([-0.0204,  0.1158])\n",
      "Epoch 1912,Loss 2.968183\n",
      "Epoch 1912, Loss 2.968183\n",
      "    Params:  tensor([  5.2477, -16.6256])\n",
      "    Grad  :  tensor([-0.0204,  0.1156])\n",
      "Epoch 1913,Loss 2.968046\n",
      "Epoch 1913, Loss 2.968046\n",
      "    Params:  tensor([  5.2479, -16.6268])\n",
      "    Grad  :  tensor([-0.0204,  0.1154])\n",
      "Epoch 1914,Loss 2.967908\n",
      "Epoch 1914, Loss 2.967908\n",
      "    Params:  tensor([  5.2482, -16.6279])\n",
      "    Grad  :  tensor([-0.0204,  0.1152])\n",
      "Epoch 1915,Loss 2.967772\n",
      "Epoch 1915, Loss 2.967772\n",
      "    Params:  tensor([  5.2484, -16.6291])\n",
      "    Grad  :  tensor([-0.0203,  0.1150])\n",
      "Epoch 1916,Loss 2.967636\n",
      "Epoch 1916, Loss 2.967636\n",
      "    Params:  tensor([  5.2486, -16.6302])\n",
      "    Grad  :  tensor([-0.0203,  0.1148])\n",
      "Epoch 1917,Loss 2.967499\n",
      "Epoch 1917, Loss 2.967499\n",
      "    Params:  tensor([  5.2488, -16.6314])\n",
      "    Grad  :  tensor([-0.0202,  0.1146])\n",
      "Epoch 1918,Loss 2.967365\n",
      "Epoch 1918, Loss 2.967365\n",
      "    Params:  tensor([  5.2490, -16.6325])\n",
      "    Grad  :  tensor([-0.0202,  0.1144])\n",
      "Epoch 1919,Loss 2.967230\n",
      "Epoch 1919, Loss 2.967230\n",
      "    Params:  tensor([  5.2492, -16.6337])\n",
      "    Grad  :  tensor([-0.0202,  0.1142])\n",
      "Epoch 1920,Loss 2.967095\n",
      "Epoch 1920, Loss 2.967095\n",
      "    Params:  tensor([  5.2494, -16.6348])\n",
      "    Grad  :  tensor([-0.0202,  0.1140])\n",
      "Epoch 1921,Loss 2.966961\n",
      "Epoch 1921, Loss 2.966961\n",
      "    Params:  tensor([  5.2496, -16.6360])\n",
      "    Grad  :  tensor([-0.0201,  0.1138])\n",
      "Epoch 1922,Loss 2.966828\n",
      "Epoch 1922, Loss 2.966828\n",
      "    Params:  tensor([  5.2498, -16.6371])\n",
      "    Grad  :  tensor([-0.0201,  0.1136])\n",
      "Epoch 1923,Loss 2.966693\n",
      "Epoch 1923, Loss 2.966693\n",
      "    Params:  tensor([  5.2500, -16.6382])\n",
      "    Grad  :  tensor([-0.0200,  0.1134])\n",
      "Epoch 1924,Loss 2.966561\n",
      "Epoch 1924, Loss 2.966561\n",
      "    Params:  tensor([  5.2502, -16.6394])\n",
      "    Grad  :  tensor([-0.0200,  0.1132])\n",
      "Epoch 1925,Loss 2.966429\n",
      "Epoch 1925, Loss 2.966429\n",
      "    Params:  tensor([  5.2504, -16.6405])\n",
      "    Grad  :  tensor([-0.0200,  0.1130])\n",
      "Epoch 1926,Loss 2.966297\n",
      "Epoch 1926, Loss 2.966297\n",
      "    Params:  tensor([  5.2506, -16.6416])\n",
      "    Grad  :  tensor([-0.0199,  0.1128])\n",
      "Epoch 1927,Loss 2.966168\n",
      "Epoch 1927, Loss 2.966168\n",
      "    Params:  tensor([  5.2508, -16.6427])\n",
      "    Grad  :  tensor([-0.0199,  0.1127])\n",
      "Epoch 1928,Loss 2.966036\n",
      "Epoch 1928, Loss 2.966036\n",
      "    Params:  tensor([  5.2510, -16.6439])\n",
      "    Grad  :  tensor([-0.0199,  0.1125])\n",
      "Epoch 1929,Loss 2.965904\n",
      "Epoch 1929, Loss 2.965904\n",
      "    Params:  tensor([  5.2512, -16.6450])\n",
      "    Grad  :  tensor([-0.0198,  0.1123])\n",
      "Epoch 1930,Loss 2.965777\n",
      "Epoch 1930, Loss 2.965777\n",
      "    Params:  tensor([  5.2514, -16.6461])\n",
      "    Grad  :  tensor([-0.0198,  0.1121])\n",
      "Epoch 1931,Loss 2.965647\n",
      "Epoch 1931, Loss 2.965647\n",
      "    Params:  tensor([  5.2516, -16.6472])\n",
      "    Grad  :  tensor([-0.0198,  0.1119])\n",
      "Epoch 1932,Loss 2.965516\n",
      "Epoch 1932, Loss 2.965516\n",
      "    Params:  tensor([  5.2518, -16.6484])\n",
      "    Grad  :  tensor([-0.0197,  0.1117])\n",
      "Epoch 1933,Loss 2.965388\n",
      "Epoch 1933, Loss 2.965388\n",
      "    Params:  tensor([  5.2520, -16.6495])\n",
      "    Grad  :  tensor([-0.0197,  0.1115])\n",
      "Epoch 1934,Loss 2.965261\n",
      "Epoch 1934, Loss 2.965261\n",
      "    Params:  tensor([  5.2522, -16.6506])\n",
      "    Grad  :  tensor([-0.0197,  0.1113])\n",
      "Epoch 1935,Loss 2.965131\n",
      "Epoch 1935, Loss 2.965131\n",
      "    Params:  tensor([  5.2523, -16.6517])\n",
      "    Grad  :  tensor([-0.0196,  0.1111])\n",
      "Epoch 1936,Loss 2.965006\n",
      "Epoch 1936, Loss 2.965006\n",
      "    Params:  tensor([  5.2525, -16.6528])\n",
      "    Grad  :  tensor([-0.0196,  0.1109])\n",
      "Epoch 1937,Loss 2.964877\n",
      "Epoch 1937, Loss 2.964877\n",
      "    Params:  tensor([  5.2527, -16.6539])\n",
      "    Grad  :  tensor([-0.0196,  0.1108])\n",
      "Epoch 1938,Loss 2.964751\n",
      "Epoch 1938, Loss 2.964751\n",
      "    Params:  tensor([  5.2529, -16.6550])\n",
      "    Grad  :  tensor([-0.0195,  0.1106])\n",
      "Epoch 1939,Loss 2.964625\n",
      "Epoch 1939, Loss 2.964625\n",
      "    Params:  tensor([  5.2531, -16.6561])\n",
      "    Grad  :  tensor([-0.0195,  0.1104])\n",
      "Epoch 1940,Loss 2.964500\n",
      "Epoch 1940, Loss 2.964500\n",
      "    Params:  tensor([  5.2533, -16.6572])\n",
      "    Grad  :  tensor([-0.0195,  0.1102])\n",
      "Epoch 1941,Loss 2.964375\n",
      "Epoch 1941, Loss 2.964375\n",
      "    Params:  tensor([  5.2535, -16.6583])\n",
      "    Grad  :  tensor([-0.0195,  0.1100])\n",
      "Epoch 1942,Loss 2.964250\n",
      "Epoch 1942, Loss 2.964250\n",
      "    Params:  tensor([  5.2537, -16.6594])\n",
      "    Grad  :  tensor([-0.0194,  0.1098])\n",
      "Epoch 1943,Loss 2.964126\n",
      "Epoch 1943, Loss 2.964126\n",
      "    Params:  tensor([  5.2539, -16.6605])\n",
      "    Grad  :  tensor([-0.0194,  0.1096])\n",
      "Epoch 1944,Loss 2.964001\n",
      "Epoch 1944, Loss 2.964001\n",
      "    Params:  tensor([  5.2541, -16.6616])\n",
      "    Grad  :  tensor([-0.0194,  0.1094])\n",
      "Epoch 1945,Loss 2.963879\n",
      "Epoch 1945, Loss 2.963879\n",
      "    Params:  tensor([  5.2543, -16.6627])\n",
      "    Grad  :  tensor([-0.0193,  0.1093])\n",
      "Epoch 1946,Loss 2.963756\n",
      "Epoch 1946, Loss 2.963756\n",
      "    Params:  tensor([  5.2545, -16.6638])\n",
      "    Grad  :  tensor([-0.0193,  0.1091])\n",
      "Epoch 1947,Loss 2.963632\n",
      "Epoch 1947, Loss 2.963632\n",
      "    Params:  tensor([  5.2547, -16.6649])\n",
      "    Grad  :  tensor([-0.0192,  0.1089])\n",
      "Epoch 1948,Loss 2.963511\n",
      "Epoch 1948, Loss 2.963511\n",
      "    Params:  tensor([  5.2549, -16.6660])\n",
      "    Grad  :  tensor([-0.0192,  0.1087])\n",
      "Epoch 1949,Loss 2.963388\n",
      "Epoch 1949, Loss 2.963388\n",
      "    Params:  tensor([  5.2551, -16.6671])\n",
      "    Grad  :  tensor([-0.0192,  0.1085])\n",
      "Epoch 1950,Loss 2.963266\n",
      "Epoch 1950, Loss 2.963266\n",
      "    Params:  tensor([  5.2553, -16.6681])\n",
      "    Grad  :  tensor([-0.0191,  0.1083])\n",
      "Epoch 1951,Loss 2.963149\n",
      "Epoch 1951, Loss 2.963149\n",
      "    Params:  tensor([  5.2554, -16.6692])\n",
      "    Grad  :  tensor([-0.0191,  0.1081])\n",
      "Epoch 1952,Loss 2.963026\n",
      "Epoch 1952, Loss 2.963026\n",
      "    Params:  tensor([  5.2556, -16.6703])\n",
      "    Grad  :  tensor([-0.0191,  0.1080])\n",
      "Epoch 1953,Loss 2.962907\n",
      "Epoch 1953, Loss 2.962907\n",
      "    Params:  tensor([  5.2558, -16.6714])\n",
      "    Grad  :  tensor([-0.0190,  0.1078])\n",
      "Epoch 1954,Loss 2.962788\n",
      "Epoch 1954, Loss 2.962788\n",
      "    Params:  tensor([  5.2560, -16.6725])\n",
      "    Grad  :  tensor([-0.0190,  0.1076])\n",
      "Epoch 1955,Loss 2.962667\n",
      "Epoch 1955, Loss 2.962667\n",
      "    Params:  tensor([  5.2562, -16.6735])\n",
      "    Grad  :  tensor([-0.0190,  0.1074])\n",
      "Epoch 1956,Loss 2.962547\n",
      "Epoch 1956, Loss 2.962547\n",
      "    Params:  tensor([  5.2564, -16.6746])\n",
      "    Grad  :  tensor([-0.0189,  0.1072])\n",
      "Epoch 1957,Loss 2.962429\n",
      "Epoch 1957, Loss 2.962429\n",
      "    Params:  tensor([  5.2566, -16.6757])\n",
      "    Grad  :  tensor([-0.0189,  0.1071])\n",
      "Epoch 1958,Loss 2.962312\n",
      "Epoch 1958, Loss 2.962312\n",
      "    Params:  tensor([  5.2568, -16.6767])\n",
      "    Grad  :  tensor([-0.0189,  0.1069])\n",
      "Epoch 1959,Loss 2.962195\n",
      "Epoch 1959, Loss 2.962195\n",
      "    Params:  tensor([  5.2570, -16.6778])\n",
      "    Grad  :  tensor([-0.0188,  0.1067])\n",
      "Epoch 1960,Loss 2.962078\n",
      "Epoch 1960, Loss 2.962078\n",
      "    Params:  tensor([  5.2572, -16.6789])\n",
      "    Grad  :  tensor([-0.0188,  0.1065])\n",
      "Epoch 1961,Loss 2.961959\n",
      "Epoch 1961, Loss 2.961959\n",
      "    Params:  tensor([  5.2573, -16.6799])\n",
      "    Grad  :  tensor([-0.0188,  0.1063])\n",
      "Epoch 1962,Loss 2.961843\n",
      "Epoch 1962, Loss 2.961843\n",
      "    Params:  tensor([  5.2575, -16.6810])\n",
      "    Grad  :  tensor([-0.0187,  0.1062])\n",
      "Epoch 1963,Loss 2.961728\n",
      "Epoch 1963, Loss 2.961728\n",
      "    Params:  tensor([  5.2577, -16.6821])\n",
      "    Grad  :  tensor([-0.0187,  0.1060])\n",
      "Epoch 1964,Loss 2.961611\n",
      "Epoch 1964, Loss 2.961611\n",
      "    Params:  tensor([  5.2579, -16.6831])\n",
      "    Grad  :  tensor([-0.0187,  0.1058])\n",
      "Epoch 1965,Loss 2.961496\n",
      "Epoch 1965, Loss 2.961496\n",
      "    Params:  tensor([  5.2581, -16.6842])\n",
      "    Grad  :  tensor([-0.0187,  0.1056])\n",
      "Epoch 1966,Loss 2.961382\n",
      "Epoch 1966, Loss 2.961382\n",
      "    Params:  tensor([  5.2583, -16.6852])\n",
      "    Grad  :  tensor([-0.0186,  0.1054])\n",
      "Epoch 1967,Loss 2.961267\n",
      "Epoch 1967, Loss 2.961267\n",
      "    Params:  tensor([  5.2585, -16.6863])\n",
      "    Grad  :  tensor([-0.0186,  0.1052])\n",
      "Epoch 1968,Loss 2.961153\n",
      "Epoch 1968, Loss 2.961153\n",
      "    Params:  tensor([  5.2586, -16.6873])\n",
      "    Grad  :  tensor([-0.0186,  0.1051])\n",
      "Epoch 1969,Loss 2.961038\n",
      "Epoch 1969, Loss 2.961038\n",
      "    Params:  tensor([  5.2588, -16.6884])\n",
      "    Grad  :  tensor([-0.0185,  0.1049])\n",
      "Epoch 1970,Loss 2.960926\n",
      "Epoch 1970, Loss 2.960926\n",
      "    Params:  tensor([  5.2590, -16.6894])\n",
      "    Grad  :  tensor([-0.0185,  0.1047])\n",
      "Epoch 1971,Loss 2.960813\n",
      "Epoch 1971, Loss 2.960813\n",
      "    Params:  tensor([  5.2592, -16.6905])\n",
      "    Grad  :  tensor([-0.0185,  0.1045])\n",
      "Epoch 1972,Loss 2.960700\n",
      "Epoch 1972, Loss 2.960700\n",
      "    Params:  tensor([  5.2594, -16.6915])\n",
      "    Grad  :  tensor([-0.0184,  0.1044])\n",
      "Epoch 1973,Loss 2.960587\n",
      "Epoch 1973, Loss 2.960587\n",
      "    Params:  tensor([  5.2596, -16.6926])\n",
      "    Grad  :  tensor([-0.0184,  0.1042])\n",
      "Epoch 1974,Loss 2.960475\n",
      "Epoch 1974, Loss 2.960475\n",
      "    Params:  tensor([  5.2598, -16.6936])\n",
      "    Grad  :  tensor([-0.0184,  0.1040])\n",
      "Epoch 1975,Loss 2.960365\n",
      "Epoch 1975, Loss 2.960365\n",
      "    Params:  tensor([  5.2599, -16.6946])\n",
      "    Grad  :  tensor([-0.0183,  0.1038])\n",
      "Epoch 1976,Loss 2.960255\n",
      "Epoch 1976, Loss 2.960255\n",
      "    Params:  tensor([  5.2601, -16.6957])\n",
      "    Grad  :  tensor([-0.0183,  0.1037])\n",
      "Epoch 1977,Loss 2.960143\n",
      "Epoch 1977, Loss 2.960143\n",
      "    Params:  tensor([  5.2603, -16.6967])\n",
      "    Grad  :  tensor([-0.0183,  0.1035])\n",
      "Epoch 1978,Loss 2.960033\n",
      "Epoch 1978, Loss 2.960033\n",
      "    Params:  tensor([  5.2605, -16.6977])\n",
      "    Grad  :  tensor([-0.0182,  0.1033])\n",
      "Epoch 1979,Loss 2.959923\n",
      "Epoch 1979, Loss 2.959923\n",
      "    Params:  tensor([  5.2607, -16.6988])\n",
      "    Grad  :  tensor([-0.0182,  0.1031])\n",
      "Epoch 1980,Loss 2.959813\n",
      "Epoch 1980, Loss 2.959813\n",
      "    Params:  tensor([  5.2608, -16.6998])\n",
      "    Grad  :  tensor([-0.0182,  0.1029])\n",
      "Epoch 1981,Loss 2.959703\n",
      "Epoch 1981, Loss 2.959703\n",
      "    Params:  tensor([  5.2610, -16.7008])\n",
      "    Grad  :  tensor([-0.0182,  0.1028])\n",
      "Epoch 1982,Loss 2.959594\n",
      "Epoch 1982, Loss 2.959594\n",
      "    Params:  tensor([  5.2612, -16.7019])\n",
      "    Grad  :  tensor([-0.0181,  0.1026])\n",
      "Epoch 1983,Loss 2.959486\n",
      "Epoch 1983, Loss 2.959486\n",
      "    Params:  tensor([  5.2614, -16.7029])\n",
      "    Grad  :  tensor([-0.0181,  0.1024])\n",
      "Epoch 1984,Loss 2.959378\n",
      "Epoch 1984, Loss 2.959378\n",
      "    Params:  tensor([  5.2616, -16.7039])\n",
      "    Grad  :  tensor([-0.0181,  0.1022])\n",
      "Epoch 1985,Loss 2.959271\n",
      "Epoch 1985, Loss 2.959271\n",
      "    Params:  tensor([  5.2618, -16.7049])\n",
      "    Grad  :  tensor([-0.0180,  0.1021])\n",
      "Epoch 1986,Loss 2.959162\n",
      "Epoch 1986, Loss 2.959162\n",
      "    Params:  tensor([  5.2619, -16.7059])\n",
      "    Grad  :  tensor([-0.0180,  0.1019])\n",
      "Epoch 1987,Loss 2.959055\n",
      "Epoch 1987, Loss 2.959055\n",
      "    Params:  tensor([  5.2621, -16.7070])\n",
      "    Grad  :  tensor([-0.0180,  0.1017])\n",
      "Epoch 1988,Loss 2.958950\n",
      "Epoch 1988, Loss 2.958950\n",
      "    Params:  tensor([  5.2623, -16.7080])\n",
      "    Grad  :  tensor([-0.0179,  0.1016])\n",
      "Epoch 1989,Loss 2.958842\n",
      "Epoch 1989, Loss 2.958842\n",
      "    Params:  tensor([  5.2625, -16.7090])\n",
      "    Grad  :  tensor([-0.0179,  0.1014])\n",
      "Epoch 1990,Loss 2.958738\n",
      "Epoch 1990, Loss 2.958738\n",
      "    Params:  tensor([  5.2626, -16.7100])\n",
      "    Grad  :  tensor([-0.0179,  0.1012])\n",
      "Epoch 1991,Loss 2.958632\n",
      "Epoch 1991, Loss 2.958632\n",
      "    Params:  tensor([  5.2628, -16.7110])\n",
      "    Grad  :  tensor([-0.0179,  0.1010])\n",
      "Epoch 1992,Loss 2.958526\n",
      "Epoch 1992, Loss 2.958526\n",
      "    Params:  tensor([  5.2630, -16.7120])\n",
      "    Grad  :  tensor([-0.0178,  0.1009])\n",
      "Epoch 1993,Loss 2.958422\n",
      "Epoch 1993, Loss 2.958422\n",
      "    Params:  tensor([  5.2632, -16.7130])\n",
      "    Grad  :  tensor([-0.0178,  0.1007])\n",
      "Epoch 1994,Loss 2.958317\n",
      "Epoch 1994, Loss 2.958317\n",
      "    Params:  tensor([  5.2634, -16.7140])\n",
      "    Grad  :  tensor([-0.0178,  0.1005])\n",
      "Epoch 1995,Loss 2.958212\n",
      "Epoch 1995, Loss 2.958212\n",
      "    Params:  tensor([  5.2635, -16.7150])\n",
      "    Grad  :  tensor([-0.0177,  0.1004])\n",
      "Epoch 1996,Loss 2.958109\n",
      "Epoch 1996, Loss 2.958109\n",
      "    Params:  tensor([  5.2637, -16.7160])\n",
      "    Grad  :  tensor([-0.0177,  0.1002])\n",
      "Epoch 1997,Loss 2.958006\n",
      "Epoch 1997, Loss 2.958006\n",
      "    Params:  tensor([  5.2639, -16.7170])\n",
      "    Grad  :  tensor([-0.0176,  0.1000])\n",
      "Epoch 1998,Loss 2.957904\n",
      "Epoch 1998, Loss 2.957904\n",
      "    Params:  tensor([  5.2641, -16.7180])\n",
      "    Grad  :  tensor([-0.0176,  0.0998])\n",
      "Epoch 1999,Loss 2.957801\n",
      "Epoch 1999, Loss 2.957801\n",
      "    Params:  tensor([  5.2642, -16.7190])\n",
      "    Grad  :  tensor([-0.0176,  0.0997])\n",
      "Epoch 2000,Loss 2.957698\n",
      "Epoch 2000, Loss 2.957698\n",
      "    Params:  tensor([  5.2644, -16.7200])\n",
      "    Grad  :  tensor([-0.0176,  0.0995])\n",
      "Epoch 2001,Loss 2.957596\n",
      "Epoch 2001, Loss 2.957596\n",
      "    Params:  tensor([  5.2646, -16.7210])\n",
      "    Grad  :  tensor([-0.0176,  0.0993])\n",
      "Epoch 2002,Loss 2.957494\n",
      "Epoch 2002, Loss 2.957494\n",
      "    Params:  tensor([  5.2648, -16.7220])\n",
      "    Grad  :  tensor([-0.0175,  0.0992])\n",
      "Epoch 2003,Loss 2.957393\n",
      "Epoch 2003, Loss 2.957393\n",
      "    Params:  tensor([  5.2649, -16.7230])\n",
      "    Grad  :  tensor([-0.0175,  0.0990])\n",
      "Epoch 2004,Loss 2.957292\n",
      "Epoch 2004, Loss 2.957292\n",
      "    Params:  tensor([  5.2651, -16.7240])\n",
      "    Grad  :  tensor([-0.0174,  0.0988])\n",
      "Epoch 2005,Loss 2.957193\n",
      "Epoch 2005, Loss 2.957193\n",
      "    Params:  tensor([  5.2653, -16.7250])\n",
      "    Grad  :  tensor([-0.0174,  0.0987])\n",
      "Epoch 2006,Loss 2.957091\n",
      "Epoch 2006, Loss 2.957091\n",
      "    Params:  tensor([  5.2655, -16.7260])\n",
      "    Grad  :  tensor([-0.0174,  0.0985])\n",
      "Epoch 2007,Loss 2.956992\n",
      "Epoch 2007, Loss 2.956992\n",
      "    Params:  tensor([  5.2656, -16.7269])\n",
      "    Grad  :  tensor([-0.0174,  0.0983])\n",
      "Epoch 2008,Loss 2.956892\n",
      "Epoch 2008, Loss 2.956892\n",
      "    Params:  tensor([  5.2658, -16.7279])\n",
      "    Grad  :  tensor([-0.0173,  0.0982])\n",
      "Epoch 2009,Loss 2.956792\n",
      "Epoch 2009, Loss 2.956792\n",
      "    Params:  tensor([  5.2660, -16.7289])\n",
      "    Grad  :  tensor([-0.0173,  0.0980])\n",
      "Epoch 2010,Loss 2.956694\n",
      "Epoch 2010, Loss 2.956694\n",
      "    Params:  tensor([  5.2662, -16.7299])\n",
      "    Grad  :  tensor([-0.0173,  0.0978])\n",
      "Epoch 2011,Loss 2.956595\n",
      "Epoch 2011, Loss 2.956595\n",
      "    Params:  tensor([  5.2663, -16.7309])\n",
      "    Grad  :  tensor([-0.0172,  0.0977])\n",
      "Epoch 2012,Loss 2.956496\n",
      "Epoch 2012, Loss 2.956496\n",
      "    Params:  tensor([  5.2665, -16.7318])\n",
      "    Grad  :  tensor([-0.0172,  0.0975])\n",
      "Epoch 2013,Loss 2.956397\n",
      "Epoch 2013, Loss 2.956397\n",
      "    Params:  tensor([  5.2667, -16.7328])\n",
      "    Grad  :  tensor([-0.0172,  0.0973])\n",
      "Epoch 2014,Loss 2.956300\n",
      "Epoch 2014, Loss 2.956300\n",
      "    Params:  tensor([  5.2668, -16.7338])\n",
      "    Grad  :  tensor([-0.0172,  0.0972])\n",
      "Epoch 2015,Loss 2.956204\n",
      "Epoch 2015, Loss 2.956204\n",
      "    Params:  tensor([  5.2670, -16.7348])\n",
      "    Grad  :  tensor([-0.0171,  0.0970])\n",
      "Epoch 2016,Loss 2.956108\n",
      "Epoch 2016, Loss 2.956108\n",
      "    Params:  tensor([  5.2672, -16.7357])\n",
      "    Grad  :  tensor([-0.0171,  0.0968])\n",
      "Epoch 2017,Loss 2.956010\n",
      "Epoch 2017, Loss 2.956010\n",
      "    Params:  tensor([  5.2674, -16.7367])\n",
      "    Grad  :  tensor([-0.0171,  0.0967])\n",
      "Epoch 2018,Loss 2.955914\n",
      "Epoch 2018, Loss 2.955914\n",
      "    Params:  tensor([  5.2675, -16.7377])\n",
      "    Grad  :  tensor([-0.0171,  0.0965])\n",
      "Epoch 2019,Loss 2.955817\n",
      "Epoch 2019, Loss 2.955817\n",
      "    Params:  tensor([  5.2677, -16.7386])\n",
      "    Grad  :  tensor([-0.0170,  0.0963])\n",
      "Epoch 2020,Loss 2.955722\n",
      "Epoch 2020, Loss 2.955722\n",
      "    Params:  tensor([  5.2679, -16.7396])\n",
      "    Grad  :  tensor([-0.0170,  0.0962])\n",
      "Epoch 2021,Loss 2.955627\n",
      "Epoch 2021, Loss 2.955627\n",
      "    Params:  tensor([  5.2680, -16.7405])\n",
      "    Grad  :  tensor([-0.0170,  0.0960])\n",
      "Epoch 2022,Loss 2.955533\n",
      "Epoch 2022, Loss 2.955533\n",
      "    Params:  tensor([  5.2682, -16.7415])\n",
      "    Grad  :  tensor([-0.0169,  0.0959])\n",
      "Epoch 2023,Loss 2.955436\n",
      "Epoch 2023, Loss 2.955436\n",
      "    Params:  tensor([  5.2684, -16.7425])\n",
      "    Grad  :  tensor([-0.0169,  0.0957])\n",
      "Epoch 2024,Loss 2.955343\n",
      "Epoch 2024, Loss 2.955343\n",
      "    Params:  tensor([  5.2686, -16.7434])\n",
      "    Grad  :  tensor([-0.0169,  0.0955])\n",
      "Epoch 2025,Loss 2.955250\n",
      "Epoch 2025, Loss 2.955250\n",
      "    Params:  tensor([  5.2687, -16.7444])\n",
      "    Grad  :  tensor([-0.0169,  0.0954])\n",
      "Epoch 2026,Loss 2.955154\n",
      "Epoch 2026, Loss 2.955154\n",
      "    Params:  tensor([  5.2689, -16.7453])\n",
      "    Grad  :  tensor([-0.0168,  0.0952])\n",
      "Epoch 2027,Loss 2.955062\n",
      "Epoch 2027, Loss 2.955062\n",
      "    Params:  tensor([  5.2691, -16.7463])\n",
      "    Grad  :  tensor([-0.0168,  0.0950])\n",
      "Epoch 2028,Loss 2.954969\n",
      "Epoch 2028, Loss 2.954969\n",
      "    Params:  tensor([  5.2692, -16.7472])\n",
      "    Grad  :  tensor([-0.0168,  0.0949])\n",
      "Epoch 2029,Loss 2.954875\n",
      "Epoch 2029, Loss 2.954875\n",
      "    Params:  tensor([  5.2694, -16.7482])\n",
      "    Grad  :  tensor([-0.0167,  0.0947])\n",
      "Epoch 2030,Loss 2.954783\n",
      "Epoch 2030, Loss 2.954783\n",
      "    Params:  tensor([  5.2696, -16.7491])\n",
      "    Grad  :  tensor([-0.0167,  0.0946])\n",
      "Epoch 2031,Loss 2.954691\n",
      "Epoch 2031, Loss 2.954691\n",
      "    Params:  tensor([  5.2697, -16.7501])\n",
      "    Grad  :  tensor([-0.0167,  0.0944])\n",
      "Epoch 2032,Loss 2.954600\n",
      "Epoch 2032, Loss 2.954600\n",
      "    Params:  tensor([  5.2699, -16.7510])\n",
      "    Grad  :  tensor([-0.0167,  0.0942])\n",
      "Epoch 2033,Loss 2.954507\n",
      "Epoch 2033, Loss 2.954507\n",
      "    Params:  tensor([  5.2701, -16.7519])\n",
      "    Grad  :  tensor([-0.0166,  0.0941])\n",
      "Epoch 2034,Loss 2.954417\n",
      "Epoch 2034, Loss 2.954417\n",
      "    Params:  tensor([  5.2702, -16.7529])\n",
      "    Grad  :  tensor([-0.0166,  0.0939])\n",
      "Epoch 2035,Loss 2.954326\n",
      "Epoch 2035, Loss 2.954326\n",
      "    Params:  tensor([  5.2704, -16.7538])\n",
      "    Grad  :  tensor([-0.0165,  0.0938])\n",
      "Epoch 2036,Loss 2.954235\n",
      "Epoch 2036, Loss 2.954235\n",
      "    Params:  tensor([  5.2706, -16.7547])\n",
      "    Grad  :  tensor([-0.0165,  0.0936])\n",
      "Epoch 2037,Loss 2.954145\n",
      "Epoch 2037, Loss 2.954145\n",
      "    Params:  tensor([  5.2707, -16.7557])\n",
      "    Grad  :  tensor([-0.0165,  0.0934])\n",
      "Epoch 2038,Loss 2.954055\n",
      "Epoch 2038, Loss 2.954055\n",
      "    Params:  tensor([  5.2709, -16.7566])\n",
      "    Grad  :  tensor([-0.0165,  0.0933])\n",
      "Epoch 2039,Loss 2.953966\n",
      "Epoch 2039, Loss 2.953966\n",
      "    Params:  tensor([  5.2710, -16.7575])\n",
      "    Grad  :  tensor([-0.0164,  0.0931])\n",
      "Epoch 2040,Loss 2.953876\n",
      "Epoch 2040, Loss 2.953876\n",
      "    Params:  tensor([  5.2712, -16.7585])\n",
      "    Grad  :  tensor([-0.0164,  0.0930])\n",
      "Epoch 2041,Loss 2.953787\n",
      "Epoch 2041, Loss 2.953787\n",
      "    Params:  tensor([  5.2714, -16.7594])\n",
      "    Grad  :  tensor([-0.0164,  0.0928])\n",
      "Epoch 2042,Loss 2.953698\n",
      "Epoch 2042, Loss 2.953698\n",
      "    Params:  tensor([  5.2715, -16.7603])\n",
      "    Grad  :  tensor([-0.0164,  0.0926])\n",
      "Epoch 2043,Loss 2.953610\n",
      "Epoch 2043, Loss 2.953610\n",
      "    Params:  tensor([  5.2717, -16.7613])\n",
      "    Grad  :  tensor([-0.0163,  0.0925])\n",
      "Epoch 2044,Loss 2.953521\n",
      "Epoch 2044, Loss 2.953521\n",
      "    Params:  tensor([  5.2719, -16.7622])\n",
      "    Grad  :  tensor([-0.0163,  0.0923])\n",
      "Epoch 2045,Loss 2.953434\n",
      "Epoch 2045, Loss 2.953434\n",
      "    Params:  tensor([  5.2720, -16.7631])\n",
      "    Grad  :  tensor([-0.0163,  0.0922])\n",
      "Epoch 2046,Loss 2.953346\n",
      "Epoch 2046, Loss 2.953346\n",
      "    Params:  tensor([  5.2722, -16.7640])\n",
      "    Grad  :  tensor([-0.0163,  0.0920])\n",
      "Epoch 2047,Loss 2.953259\n",
      "Epoch 2047, Loss 2.953259\n",
      "    Params:  tensor([  5.2724, -16.7649])\n",
      "    Grad  :  tensor([-0.0162,  0.0919])\n",
      "Epoch 2048,Loss 2.953171\n",
      "Epoch 2048, Loss 2.953171\n",
      "    Params:  tensor([  5.2725, -16.7659])\n",
      "    Grad  :  tensor([-0.0162,  0.0917])\n",
      "Epoch 2049,Loss 2.953085\n",
      "Epoch 2049, Loss 2.953085\n",
      "    Params:  tensor([  5.2727, -16.7668])\n",
      "    Grad  :  tensor([-0.0162,  0.0915])\n",
      "Epoch 2050,Loss 2.953000\n",
      "Epoch 2050, Loss 2.953000\n",
      "    Params:  tensor([  5.2728, -16.7677])\n",
      "    Grad  :  tensor([-0.0162,  0.0914])\n",
      "Epoch 2051,Loss 2.952913\n",
      "Epoch 2051, Loss 2.952913\n",
      "    Params:  tensor([  5.2730, -16.7686])\n",
      "    Grad  :  tensor([-0.0161,  0.0912])\n",
      "Epoch 2052,Loss 2.952828\n",
      "Epoch 2052, Loss 2.952828\n",
      "    Params:  tensor([  5.2732, -16.7695])\n",
      "    Grad  :  tensor([-0.0161,  0.0911])\n",
      "Epoch 2053,Loss 2.952742\n",
      "Epoch 2053, Loss 2.952742\n",
      "    Params:  tensor([  5.2733, -16.7704])\n",
      "    Grad  :  tensor([-0.0161,  0.0909])\n",
      "Epoch 2054,Loss 2.952657\n",
      "Epoch 2054, Loss 2.952657\n",
      "    Params:  tensor([  5.2735, -16.7713])\n",
      "    Grad  :  tensor([-0.0160,  0.0908])\n",
      "Epoch 2055,Loss 2.952571\n",
      "Epoch 2055, Loss 2.952571\n",
      "    Params:  tensor([  5.2736, -16.7722])\n",
      "    Grad  :  tensor([-0.0160,  0.0906])\n",
      "Epoch 2056,Loss 2.952487\n",
      "Epoch 2056, Loss 2.952487\n",
      "    Params:  tensor([  5.2738, -16.7731])\n",
      "    Grad  :  tensor([-0.0160,  0.0905])\n",
      "Epoch 2057,Loss 2.952403\n",
      "Epoch 2057, Loss 2.952403\n",
      "    Params:  tensor([  5.2740, -16.7740])\n",
      "    Grad  :  tensor([-0.0160,  0.0903])\n",
      "Epoch 2058,Loss 2.952318\n",
      "Epoch 2058, Loss 2.952318\n",
      "    Params:  tensor([  5.2741, -16.7749])\n",
      "    Grad  :  tensor([-0.0159,  0.0902])\n",
      "Epoch 2059,Loss 2.952235\n",
      "Epoch 2059, Loss 2.952235\n",
      "    Params:  tensor([  5.2743, -16.7758])\n",
      "    Grad  :  tensor([-0.0159,  0.0900])\n",
      "Epoch 2060,Loss 2.952152\n",
      "Epoch 2060, Loss 2.952152\n",
      "    Params:  tensor([  5.2744, -16.7767])\n",
      "    Grad  :  tensor([-0.0159,  0.0899])\n",
      "Epoch 2061,Loss 2.952068\n",
      "Epoch 2061, Loss 2.952068\n",
      "    Params:  tensor([  5.2746, -16.7776])\n",
      "    Grad  :  tensor([-0.0158,  0.0897])\n",
      "Epoch 2062,Loss 2.951985\n",
      "Epoch 2062, Loss 2.951985\n",
      "    Params:  tensor([  5.2748, -16.7785])\n",
      "    Grad  :  tensor([-0.0158,  0.0895])\n",
      "Epoch 2063,Loss 2.951902\n",
      "Epoch 2063, Loss 2.951902\n",
      "    Params:  tensor([  5.2749, -16.7794])\n",
      "    Grad  :  tensor([-0.0158,  0.0894])\n",
      "Epoch 2064,Loss 2.951820\n",
      "Epoch 2064, Loss 2.951820\n",
      "    Params:  tensor([  5.2751, -16.7803])\n",
      "    Grad  :  tensor([-0.0158,  0.0892])\n",
      "Epoch 2065,Loss 2.951738\n",
      "Epoch 2065, Loss 2.951738\n",
      "    Params:  tensor([  5.2752, -16.7812])\n",
      "    Grad  :  tensor([-0.0157,  0.0891])\n",
      "Epoch 2066,Loss 2.951656\n",
      "Epoch 2066, Loss 2.951656\n",
      "    Params:  tensor([  5.2754, -16.7821])\n",
      "    Grad  :  tensor([-0.0157,  0.0889])\n",
      "Epoch 2067,Loss 2.951576\n",
      "Epoch 2067, Loss 2.951576\n",
      "    Params:  tensor([  5.2755, -16.7830])\n",
      "    Grad  :  tensor([-0.0157,  0.0888])\n",
      "Epoch 2068,Loss 2.951494\n",
      "Epoch 2068, Loss 2.951494\n",
      "    Params:  tensor([  5.2757, -16.7839])\n",
      "    Grad  :  tensor([-0.0157,  0.0886])\n",
      "Epoch 2069,Loss 2.951413\n",
      "Epoch 2069, Loss 2.951413\n",
      "    Params:  tensor([  5.2759, -16.7848])\n",
      "    Grad  :  tensor([-0.0157,  0.0885])\n",
      "Epoch 2070,Loss 2.951333\n",
      "Epoch 2070, Loss 2.951333\n",
      "    Params:  tensor([  5.2760, -16.7856])\n",
      "    Grad  :  tensor([-0.0156,  0.0883])\n",
      "Epoch 2071,Loss 2.951252\n",
      "Epoch 2071, Loss 2.951252\n",
      "    Params:  tensor([  5.2762, -16.7865])\n",
      "    Grad  :  tensor([-0.0156,  0.0882])\n",
      "Epoch 2072,Loss 2.951171\n",
      "Epoch 2072, Loss 2.951171\n",
      "    Params:  tensor([  5.2763, -16.7874])\n",
      "    Grad  :  tensor([-0.0155,  0.0880])\n",
      "Epoch 2073,Loss 2.951093\n",
      "Epoch 2073, Loss 2.951093\n",
      "    Params:  tensor([  5.2765, -16.7883])\n",
      "    Grad  :  tensor([-0.0155,  0.0879])\n",
      "Epoch 2074,Loss 2.951012\n",
      "Epoch 2074, Loss 2.951012\n",
      "    Params:  tensor([  5.2766, -16.7892])\n",
      "    Grad  :  tensor([-0.0155,  0.0877])\n",
      "Epoch 2075,Loss 2.950932\n",
      "Epoch 2075, Loss 2.950932\n",
      "    Params:  tensor([  5.2768, -16.7900])\n",
      "    Grad  :  tensor([-0.0155,  0.0876])\n",
      "Epoch 2076,Loss 2.950853\n",
      "Epoch 2076, Loss 2.950853\n",
      "    Params:  tensor([  5.2769, -16.7909])\n",
      "    Grad  :  tensor([-0.0154,  0.0874])\n",
      "Epoch 2077,Loss 2.950774\n",
      "Epoch 2077, Loss 2.950774\n",
      "    Params:  tensor([  5.2771, -16.7918])\n",
      "    Grad  :  tensor([-0.0154,  0.0873])\n",
      "Epoch 2078,Loss 2.950697\n",
      "Epoch 2078, Loss 2.950697\n",
      "    Params:  tensor([  5.2772, -16.7927])\n",
      "    Grad  :  tensor([-0.0154,  0.0871])\n",
      "Epoch 2079,Loss 2.950618\n",
      "Epoch 2079, Loss 2.950618\n",
      "    Params:  tensor([  5.2774, -16.7935])\n",
      "    Grad  :  tensor([-0.0154,  0.0870])\n",
      "Epoch 2080,Loss 2.950540\n",
      "Epoch 2080, Loss 2.950540\n",
      "    Params:  tensor([  5.2776, -16.7944])\n",
      "    Grad  :  tensor([-0.0154,  0.0868])\n",
      "Epoch 2081,Loss 2.950463\n",
      "Epoch 2081, Loss 2.950463\n",
      "    Params:  tensor([  5.2777, -16.7953])\n",
      "    Grad  :  tensor([-0.0153,  0.0867])\n",
      "Epoch 2082,Loss 2.950385\n",
      "Epoch 2082, Loss 2.950385\n",
      "    Params:  tensor([  5.2779, -16.7961])\n",
      "    Grad  :  tensor([-0.0153,  0.0866])\n",
      "Epoch 2083,Loss 2.950308\n",
      "Epoch 2083, Loss 2.950308\n",
      "    Params:  tensor([  5.2780, -16.7970])\n",
      "    Grad  :  tensor([-0.0153,  0.0864])\n",
      "Epoch 2084,Loss 2.950231\n",
      "Epoch 2084, Loss 2.950231\n",
      "    Params:  tensor([  5.2782, -16.7979])\n",
      "    Grad  :  tensor([-0.0152,  0.0863])\n",
      "Epoch 2085,Loss 2.950154\n",
      "Epoch 2085, Loss 2.950154\n",
      "    Params:  tensor([  5.2783, -16.7987])\n",
      "    Grad  :  tensor([-0.0152,  0.0861])\n",
      "Epoch 2086,Loss 2.950078\n",
      "Epoch 2086, Loss 2.950078\n",
      "    Params:  tensor([  5.2785, -16.7996])\n",
      "    Grad  :  tensor([-0.0152,  0.0860])\n",
      "Epoch 2087,Loss 2.950003\n",
      "Epoch 2087, Loss 2.950003\n",
      "    Params:  tensor([  5.2786, -16.8004])\n",
      "    Grad  :  tensor([-0.0152,  0.0858])\n",
      "Epoch 2088,Loss 2.949925\n",
      "Epoch 2088, Loss 2.949925\n",
      "    Params:  tensor([  5.2788, -16.8013])\n",
      "    Grad  :  tensor([-0.0152,  0.0857])\n",
      "Epoch 2089,Loss 2.949850\n",
      "Epoch 2089, Loss 2.949850\n",
      "    Params:  tensor([  5.2789, -16.8021])\n",
      "    Grad  :  tensor([-0.0151,  0.0855])\n",
      "Epoch 2090,Loss 2.949776\n",
      "Epoch 2090, Loss 2.949776\n",
      "    Params:  tensor([  5.2791, -16.8030])\n",
      "    Grad  :  tensor([-0.0151,  0.0854])\n",
      "Epoch 2091,Loss 2.949699\n",
      "Epoch 2091, Loss 2.949699\n",
      "    Params:  tensor([  5.2792, -16.8039])\n",
      "    Grad  :  tensor([-0.0151,  0.0852])\n",
      "Epoch 2092,Loss 2.949626\n",
      "Epoch 2092, Loss 2.949626\n",
      "    Params:  tensor([  5.2794, -16.8047])\n",
      "    Grad  :  tensor([-0.0150,  0.0851])\n",
      "Epoch 2093,Loss 2.949550\n",
      "Epoch 2093, Loss 2.949550\n",
      "    Params:  tensor([  5.2795, -16.8056])\n",
      "    Grad  :  tensor([-0.0150,  0.0850])\n",
      "Epoch 2094,Loss 2.949476\n",
      "Epoch 2094, Loss 2.949476\n",
      "    Params:  tensor([  5.2797, -16.8064])\n",
      "    Grad  :  tensor([-0.0150,  0.0848])\n",
      "Epoch 2095,Loss 2.949401\n",
      "Epoch 2095, Loss 2.949401\n",
      "    Params:  tensor([  5.2798, -16.8072])\n",
      "    Grad  :  tensor([-0.0149,  0.0847])\n",
      "Epoch 2096,Loss 2.949328\n",
      "Epoch 2096, Loss 2.949328\n",
      "    Params:  tensor([  5.2800, -16.8081])\n",
      "    Grad  :  tensor([-0.0150,  0.0845])\n",
      "Epoch 2097,Loss 2.949254\n",
      "Epoch 2097, Loss 2.949254\n",
      "    Params:  tensor([  5.2801, -16.8089])\n",
      "    Grad  :  tensor([-0.0149,  0.0844])\n",
      "Epoch 2098,Loss 2.949182\n",
      "Epoch 2098, Loss 2.949182\n",
      "    Params:  tensor([  5.2803, -16.8098])\n",
      "    Grad  :  tensor([-0.0149,  0.0842])\n",
      "Epoch 2099,Loss 2.949108\n",
      "Epoch 2099, Loss 2.949108\n",
      "    Params:  tensor([  5.2804, -16.8106])\n",
      "    Grad  :  tensor([-0.0149,  0.0841])\n",
      "Epoch 2100,Loss 2.949035\n",
      "Epoch 2100, Loss 2.949035\n",
      "    Params:  tensor([  5.2806, -16.8115])\n",
      "    Grad  :  tensor([-0.0148,  0.0839])\n",
      "Epoch 2101,Loss 2.948962\n",
      "Epoch 2101, Loss 2.948962\n",
      "    Params:  tensor([  5.2807, -16.8123])\n",
      "    Grad  :  tensor([-0.0148,  0.0838])\n",
      "Epoch 2102,Loss 2.948890\n",
      "Epoch 2102, Loss 2.948890\n",
      "    Params:  tensor([  5.2809, -16.8131])\n",
      "    Grad  :  tensor([-0.0148,  0.0837])\n",
      "Epoch 2103,Loss 2.948818\n",
      "Epoch 2103, Loss 2.948818\n",
      "    Params:  tensor([  5.2810, -16.8140])\n",
      "    Grad  :  tensor([-0.0148,  0.0835])\n",
      "Epoch 2104,Loss 2.948745\n",
      "Epoch 2104, Loss 2.948745\n",
      "    Params:  tensor([  5.2812, -16.8148])\n",
      "    Grad  :  tensor([-0.0148,  0.0834])\n",
      "Epoch 2105,Loss 2.948675\n",
      "Epoch 2105, Loss 2.948675\n",
      "    Params:  tensor([  5.2813, -16.8156])\n",
      "    Grad  :  tensor([-0.0147,  0.0832])\n",
      "Epoch 2106,Loss 2.948602\n",
      "Epoch 2106, Loss 2.948602\n",
      "    Params:  tensor([  5.2815, -16.8165])\n",
      "    Grad  :  tensor([-0.0147,  0.0831])\n",
      "Epoch 2107,Loss 2.948532\n",
      "Epoch 2107, Loss 2.948532\n",
      "    Params:  tensor([  5.2816, -16.8173])\n",
      "    Grad  :  tensor([-0.0146,  0.0830])\n",
      "Epoch 2108,Loss 2.948462\n",
      "Epoch 2108, Loss 2.948462\n",
      "    Params:  tensor([  5.2817, -16.8181])\n",
      "    Grad  :  tensor([-0.0146,  0.0828])\n",
      "Epoch 2109,Loss 2.948391\n",
      "Epoch 2109, Loss 2.948391\n",
      "    Params:  tensor([  5.2819, -16.8189])\n",
      "    Grad  :  tensor([-0.0146,  0.0827])\n",
      "Epoch 2110,Loss 2.948321\n",
      "Epoch 2110, Loss 2.948321\n",
      "    Params:  tensor([  5.2820, -16.8198])\n",
      "    Grad  :  tensor([-0.0146,  0.0825])\n",
      "Epoch 2111,Loss 2.948250\n",
      "Epoch 2111, Loss 2.948250\n",
      "    Params:  tensor([  5.2822, -16.8206])\n",
      "    Grad  :  tensor([-0.0145,  0.0824])\n",
      "Epoch 2112,Loss 2.948181\n",
      "Epoch 2112, Loss 2.948181\n",
      "    Params:  tensor([  5.2823, -16.8214])\n",
      "    Grad  :  tensor([-0.0145,  0.0823])\n",
      "Epoch 2113,Loss 2.948109\n",
      "Epoch 2113, Loss 2.948109\n",
      "    Params:  tensor([  5.2825, -16.8222])\n",
      "    Grad  :  tensor([-0.0145,  0.0821])\n",
      "Epoch 2114,Loss 2.948041\n",
      "Epoch 2114, Loss 2.948041\n",
      "    Params:  tensor([  5.2826, -16.8231])\n",
      "    Grad  :  tensor([-0.0145,  0.0820])\n",
      "Epoch 2115,Loss 2.947971\n",
      "Epoch 2115, Loss 2.947971\n",
      "    Params:  tensor([  5.2828, -16.8239])\n",
      "    Grad  :  tensor([-0.0144,  0.0818])\n",
      "Epoch 2116,Loss 2.947902\n",
      "Epoch 2116, Loss 2.947902\n",
      "    Params:  tensor([  5.2829, -16.8247])\n",
      "    Grad  :  tensor([-0.0144,  0.0817])\n",
      "Epoch 2117,Loss 2.947833\n",
      "Epoch 2117, Loss 2.947833\n",
      "    Params:  tensor([  5.2831, -16.8255])\n",
      "    Grad  :  tensor([-0.0144,  0.0816])\n",
      "Epoch 2118,Loss 2.947765\n",
      "Epoch 2118, Loss 2.947765\n",
      "    Params:  tensor([  5.2832, -16.8263])\n",
      "    Grad  :  tensor([-0.0144,  0.0814])\n",
      "Epoch 2119,Loss 2.947696\n",
      "Epoch 2119, Loss 2.947696\n",
      "    Params:  tensor([  5.2833, -16.8271])\n",
      "    Grad  :  tensor([-0.0144,  0.0813])\n",
      "Epoch 2120,Loss 2.947628\n",
      "Epoch 2120, Loss 2.947628\n",
      "    Params:  tensor([  5.2835, -16.8280])\n",
      "    Grad  :  tensor([-0.0143,  0.0811])\n",
      "Epoch 2121,Loss 2.947560\n",
      "Epoch 2121, Loss 2.947560\n",
      "    Params:  tensor([  5.2836, -16.8288])\n",
      "    Grad  :  tensor([-0.0143,  0.0810])\n",
      "Epoch 2122,Loss 2.947494\n",
      "Epoch 2122, Loss 2.947494\n",
      "    Params:  tensor([  5.2838, -16.8296])\n",
      "    Grad  :  tensor([-0.0143,  0.0809])\n",
      "Epoch 2123,Loss 2.947426\n",
      "Epoch 2123, Loss 2.947426\n",
      "    Params:  tensor([  5.2839, -16.8304])\n",
      "    Grad  :  tensor([-0.0143,  0.0807])\n",
      "Epoch 2124,Loss 2.947357\n",
      "Epoch 2124, Loss 2.947357\n",
      "    Params:  tensor([  5.2841, -16.8312])\n",
      "    Grad  :  tensor([-0.0142,  0.0806])\n",
      "Epoch 2125,Loss 2.947293\n",
      "Epoch 2125, Loss 2.947293\n",
      "    Params:  tensor([  5.2842, -16.8320])\n",
      "    Grad  :  tensor([-0.0142,  0.0805])\n",
      "Epoch 2126,Loss 2.947225\n",
      "Epoch 2126, Loss 2.947225\n",
      "    Params:  tensor([  5.2843, -16.8328])\n",
      "    Grad  :  tensor([-0.0142,  0.0803])\n",
      "Epoch 2127,Loss 2.947158\n",
      "Epoch 2127, Loss 2.947158\n",
      "    Params:  tensor([  5.2845, -16.8336])\n",
      "    Grad  :  tensor([-0.0142,  0.0802])\n",
      "Epoch 2128,Loss 2.947092\n",
      "Epoch 2128, Loss 2.947092\n",
      "    Params:  tensor([  5.2846, -16.8344])\n",
      "    Grad  :  tensor([-0.0141,  0.0800])\n",
      "Epoch 2129,Loss 2.947026\n",
      "Epoch 2129, Loss 2.947026\n",
      "    Params:  tensor([  5.2848, -16.8352])\n",
      "    Grad  :  tensor([-0.0141,  0.0799])\n",
      "Epoch 2130,Loss 2.946960\n",
      "Epoch 2130, Loss 2.946960\n",
      "    Params:  tensor([  5.2849, -16.8360])\n",
      "    Grad  :  tensor([-0.0141,  0.0798])\n",
      "Epoch 2131,Loss 2.946895\n",
      "Epoch 2131, Loss 2.946895\n",
      "    Params:  tensor([  5.2850, -16.8368])\n",
      "    Grad  :  tensor([-0.0141,  0.0796])\n",
      "Epoch 2132,Loss 2.946830\n",
      "Epoch 2132, Loss 2.946830\n",
      "    Params:  tensor([  5.2852, -16.8376])\n",
      "    Grad  :  tensor([-0.0141,  0.0795])\n",
      "Epoch 2133,Loss 2.946764\n",
      "Epoch 2133, Loss 2.946764\n",
      "    Params:  tensor([  5.2853, -16.8384])\n",
      "    Grad  :  tensor([-0.0140,  0.0794])\n",
      "Epoch 2134,Loss 2.946700\n",
      "Epoch 2134, Loss 2.946700\n",
      "    Params:  tensor([  5.2855, -16.8392])\n",
      "    Grad  :  tensor([-0.0140,  0.0792])\n",
      "Epoch 2135,Loss 2.946635\n",
      "Epoch 2135, Loss 2.946635\n",
      "    Params:  tensor([  5.2856, -16.8400])\n",
      "    Grad  :  tensor([-0.0140,  0.0791])\n",
      "Epoch 2136,Loss 2.946571\n",
      "Epoch 2136, Loss 2.946571\n",
      "    Params:  tensor([  5.2857, -16.8407])\n",
      "    Grad  :  tensor([-0.0139,  0.0790])\n",
      "Epoch 2137,Loss 2.946507\n",
      "Epoch 2137, Loss 2.946507\n",
      "    Params:  tensor([  5.2859, -16.8415])\n",
      "    Grad  :  tensor([-0.0139,  0.0788])\n",
      "Epoch 2138,Loss 2.946442\n",
      "Epoch 2138, Loss 2.946442\n",
      "    Params:  tensor([  5.2860, -16.8423])\n",
      "    Grad  :  tensor([-0.0139,  0.0787])\n",
      "Epoch 2139,Loss 2.946378\n",
      "Epoch 2139, Loss 2.946378\n",
      "    Params:  tensor([  5.2862, -16.8431])\n",
      "    Grad  :  tensor([-0.0139,  0.0786])\n",
      "Epoch 2140,Loss 2.946314\n",
      "Epoch 2140, Loss 2.946314\n",
      "    Params:  tensor([  5.2863, -16.8439])\n",
      "    Grad  :  tensor([-0.0138,  0.0784])\n",
      "Epoch 2141,Loss 2.946251\n",
      "Epoch 2141, Loss 2.946251\n",
      "    Params:  tensor([  5.2864, -16.8447])\n",
      "    Grad  :  tensor([-0.0138,  0.0783])\n",
      "Epoch 2142,Loss 2.946189\n",
      "Epoch 2142, Loss 2.946189\n",
      "    Params:  tensor([  5.2866, -16.8455])\n",
      "    Grad  :  tensor([-0.0138,  0.0782])\n",
      "Epoch 2143,Loss 2.946126\n",
      "Epoch 2143, Loss 2.946126\n",
      "    Params:  tensor([  5.2867, -16.8462])\n",
      "    Grad  :  tensor([-0.0138,  0.0780])\n",
      "Epoch 2144,Loss 2.946063\n",
      "Epoch 2144, Loss 2.946063\n",
      "    Params:  tensor([  5.2869, -16.8470])\n",
      "    Grad  :  tensor([-0.0138,  0.0779])\n",
      "Epoch 2145,Loss 2.946001\n",
      "Epoch 2145, Loss 2.946001\n",
      "    Params:  tensor([  5.2870, -16.8478])\n",
      "    Grad  :  tensor([-0.0137,  0.0778])\n",
      "Epoch 2146,Loss 2.945937\n",
      "Epoch 2146, Loss 2.945937\n",
      "    Params:  tensor([  5.2871, -16.8486])\n",
      "    Grad  :  tensor([-0.0137,  0.0776])\n",
      "Epoch 2147,Loss 2.945876\n",
      "Epoch 2147, Loss 2.945876\n",
      "    Params:  tensor([  5.2873, -16.8493])\n",
      "    Grad  :  tensor([-0.0137,  0.0775])\n",
      "Epoch 2148,Loss 2.945815\n",
      "Epoch 2148, Loss 2.945815\n",
      "    Params:  tensor([  5.2874, -16.8501])\n",
      "    Grad  :  tensor([-0.0137,  0.0774])\n",
      "Epoch 2149,Loss 2.945753\n",
      "Epoch 2149, Loss 2.945753\n",
      "    Params:  tensor([  5.2875, -16.8509])\n",
      "    Grad  :  tensor([-0.0136,  0.0772])\n",
      "Epoch 2150,Loss 2.945690\n",
      "Epoch 2150, Loss 2.945690\n",
      "    Params:  tensor([  5.2877, -16.8517])\n",
      "    Grad  :  tensor([-0.0136,  0.0771])\n",
      "Epoch 2151,Loss 2.945630\n",
      "Epoch 2151, Loss 2.945630\n",
      "    Params:  tensor([  5.2878, -16.8524])\n",
      "    Grad  :  tensor([-0.0136,  0.0770])\n",
      "Epoch 2152,Loss 2.945567\n",
      "Epoch 2152, Loss 2.945567\n",
      "    Params:  tensor([  5.2879, -16.8532])\n",
      "    Grad  :  tensor([-0.0136,  0.0768])\n",
      "Epoch 2153,Loss 2.945508\n",
      "Epoch 2153, Loss 2.945508\n",
      "    Params:  tensor([  5.2881, -16.8540])\n",
      "    Grad  :  tensor([-0.0135,  0.0767])\n",
      "Epoch 2154,Loss 2.945447\n",
      "Epoch 2154, Loss 2.945447\n",
      "    Params:  tensor([  5.2882, -16.8547])\n",
      "    Grad  :  tensor([-0.0135,  0.0766])\n",
      "Epoch 2155,Loss 2.945385\n",
      "Epoch 2155, Loss 2.945385\n",
      "    Params:  tensor([  5.2884, -16.8555])\n",
      "    Grad  :  tensor([-0.0135,  0.0765])\n",
      "Epoch 2156,Loss 2.945325\n",
      "Epoch 2156, Loss 2.945325\n",
      "    Params:  tensor([  5.2885, -16.8563])\n",
      "    Grad  :  tensor([-0.0135,  0.0763])\n",
      "Epoch 2157,Loss 2.945267\n",
      "Epoch 2157, Loss 2.945267\n",
      "    Params:  tensor([  5.2886, -16.8570])\n",
      "    Grad  :  tensor([-0.0135,  0.0762])\n",
      "Epoch 2158,Loss 2.945206\n",
      "Epoch 2158, Loss 2.945206\n",
      "    Params:  tensor([  5.2888, -16.8578])\n",
      "    Grad  :  tensor([-0.0134,  0.0761])\n",
      "Epoch 2159,Loss 2.945146\n",
      "Epoch 2159, Loss 2.945146\n",
      "    Params:  tensor([  5.2889, -16.8585])\n",
      "    Grad  :  tensor([-0.0134,  0.0759])\n",
      "Epoch 2160,Loss 2.945088\n",
      "Epoch 2160, Loss 2.945088\n",
      "    Params:  tensor([  5.2890, -16.8593])\n",
      "    Grad  :  tensor([-0.0134,  0.0758])\n",
      "Epoch 2161,Loss 2.945028\n",
      "Epoch 2161, Loss 2.945028\n",
      "    Params:  tensor([  5.2892, -16.8601])\n",
      "    Grad  :  tensor([-0.0134,  0.0757])\n",
      "Epoch 2162,Loss 2.944969\n",
      "Epoch 2162, Loss 2.944969\n",
      "    Params:  tensor([  5.2893, -16.8608])\n",
      "    Grad  :  tensor([-0.0133,  0.0755])\n",
      "Epoch 2163,Loss 2.944911\n",
      "Epoch 2163, Loss 2.944911\n",
      "    Params:  tensor([  5.2894, -16.8616])\n",
      "    Grad  :  tensor([-0.0133,  0.0754])\n",
      "Epoch 2164,Loss 2.944852\n",
      "Epoch 2164, Loss 2.944852\n",
      "    Params:  tensor([  5.2896, -16.8623])\n",
      "    Grad  :  tensor([-0.0133,  0.0753])\n",
      "Epoch 2165,Loss 2.944792\n",
      "Epoch 2165, Loss 2.944792\n",
      "    Params:  tensor([  5.2897, -16.8631])\n",
      "    Grad  :  tensor([-0.0133,  0.0752])\n",
      "Epoch 2166,Loss 2.944736\n",
      "Epoch 2166, Loss 2.944736\n",
      "    Params:  tensor([  5.2898, -16.8638])\n",
      "    Grad  :  tensor([-0.0133,  0.0750])\n",
      "Epoch 2167,Loss 2.944678\n",
      "Epoch 2167, Loss 2.944678\n",
      "    Params:  tensor([  5.2900, -16.8646])\n",
      "    Grad  :  tensor([-0.0132,  0.0749])\n",
      "Epoch 2168,Loss 2.944619\n",
      "Epoch 2168, Loss 2.944619\n",
      "    Params:  tensor([  5.2901, -16.8653])\n",
      "    Grad  :  tensor([-0.0132,  0.0748])\n",
      "Epoch 2169,Loss 2.944562\n",
      "Epoch 2169, Loss 2.944562\n",
      "    Params:  tensor([  5.2902, -16.8661])\n",
      "    Grad  :  tensor([-0.0132,  0.0747])\n",
      "Epoch 2170,Loss 2.944504\n",
      "Epoch 2170, Loss 2.944504\n",
      "    Params:  tensor([  5.2903, -16.8668])\n",
      "    Grad  :  tensor([-0.0132,  0.0745])\n",
      "Epoch 2171,Loss 2.944447\n",
      "Epoch 2171, Loss 2.944447\n",
      "    Params:  tensor([  5.2905, -16.8676])\n",
      "    Grad  :  tensor([-0.0132,  0.0744])\n",
      "Epoch 2172,Loss 2.944391\n",
      "Epoch 2172, Loss 2.944391\n",
      "    Params:  tensor([  5.2906, -16.8683])\n",
      "    Grad  :  tensor([-0.0131,  0.0743])\n",
      "Epoch 2173,Loss 2.944332\n",
      "Epoch 2173, Loss 2.944332\n",
      "    Params:  tensor([  5.2907, -16.8690])\n",
      "    Grad  :  tensor([-0.0131,  0.0742])\n",
      "Epoch 2174,Loss 2.944276\n",
      "Epoch 2174, Loss 2.944276\n",
      "    Params:  tensor([  5.2909, -16.8698])\n",
      "    Grad  :  tensor([-0.0131,  0.0740])\n",
      "Epoch 2175,Loss 2.944220\n",
      "Epoch 2175, Loss 2.944220\n",
      "    Params:  tensor([  5.2910, -16.8705])\n",
      "    Grad  :  tensor([-0.0131,  0.0739])\n",
      "Epoch 2176,Loss 2.944164\n",
      "Epoch 2176, Loss 2.944164\n",
      "    Params:  tensor([  5.2911, -16.8713])\n",
      "    Grad  :  tensor([-0.0130,  0.0738])\n",
      "Epoch 2177,Loss 2.944108\n",
      "Epoch 2177, Loss 2.944108\n",
      "    Params:  tensor([  5.2913, -16.8720])\n",
      "    Grad  :  tensor([-0.0130,  0.0736])\n",
      "Epoch 2178,Loss 2.944053\n",
      "Epoch 2178, Loss 2.944053\n",
      "    Params:  tensor([  5.2914, -16.8727])\n",
      "    Grad  :  tensor([-0.0130,  0.0735])\n",
      "Epoch 2179,Loss 2.943996\n",
      "Epoch 2179, Loss 2.943996\n",
      "    Params:  tensor([  5.2915, -16.8735])\n",
      "    Grad  :  tensor([-0.0130,  0.0734])\n",
      "Epoch 2180,Loss 2.943941\n",
      "Epoch 2180, Loss 2.943941\n",
      "    Params:  tensor([  5.2917, -16.8742])\n",
      "    Grad  :  tensor([-0.0129,  0.0733])\n",
      "Epoch 2181,Loss 2.943887\n",
      "Epoch 2181, Loss 2.943887\n",
      "    Params:  tensor([  5.2918, -16.8749])\n",
      "    Grad  :  tensor([-0.0129,  0.0731])\n",
      "Epoch 2182,Loss 2.943831\n",
      "Epoch 2182, Loss 2.943831\n",
      "    Params:  tensor([  5.2919, -16.8757])\n",
      "    Grad  :  tensor([-0.0129,  0.0730])\n",
      "Epoch 2183,Loss 2.943776\n",
      "Epoch 2183, Loss 2.943776\n",
      "    Params:  tensor([  5.2920, -16.8764])\n",
      "    Grad  :  tensor([-0.0129,  0.0729])\n",
      "Epoch 2184,Loss 2.943721\n",
      "Epoch 2184, Loss 2.943721\n",
      "    Params:  tensor([  5.2922, -16.8771])\n",
      "    Grad  :  tensor([-0.0129,  0.0728])\n",
      "Epoch 2185,Loss 2.943666\n",
      "Epoch 2185, Loss 2.943666\n",
      "    Params:  tensor([  5.2923, -16.8778])\n",
      "    Grad  :  tensor([-0.0128,  0.0727])\n",
      "Epoch 2186,Loss 2.943613\n",
      "Epoch 2186, Loss 2.943613\n",
      "    Params:  tensor([  5.2924, -16.8786])\n",
      "    Grad  :  tensor([-0.0128,  0.0725])\n",
      "Epoch 2187,Loss 2.943558\n",
      "Epoch 2187, Loss 2.943558\n",
      "    Params:  tensor([  5.2926, -16.8793])\n",
      "    Grad  :  tensor([-0.0128,  0.0724])\n",
      "Epoch 2188,Loss 2.943503\n",
      "Epoch 2188, Loss 2.943503\n",
      "    Params:  tensor([  5.2927, -16.8800])\n",
      "    Grad  :  tensor([-0.0128,  0.0723])\n",
      "Epoch 2189,Loss 2.943451\n",
      "Epoch 2189, Loss 2.943451\n",
      "    Params:  tensor([  5.2928, -16.8807])\n",
      "    Grad  :  tensor([-0.0127,  0.0722])\n",
      "Epoch 2190,Loss 2.943395\n",
      "Epoch 2190, Loss 2.943395\n",
      "    Params:  tensor([  5.2929, -16.8815])\n",
      "    Grad  :  tensor([-0.0127,  0.0720])\n",
      "Epoch 2191,Loss 2.943343\n",
      "Epoch 2191, Loss 2.943343\n",
      "    Params:  tensor([  5.2931, -16.8822])\n",
      "    Grad  :  tensor([-0.0127,  0.0719])\n",
      "Epoch 2192,Loss 2.943290\n",
      "Epoch 2192, Loss 2.943290\n",
      "    Params:  tensor([  5.2932, -16.8829])\n",
      "    Grad  :  tensor([-0.0127,  0.0718])\n",
      "Epoch 2193,Loss 2.943235\n",
      "Epoch 2193, Loss 2.943235\n",
      "    Params:  tensor([  5.2933, -16.8836])\n",
      "    Grad  :  tensor([-0.0127,  0.0717])\n",
      "Epoch 2194,Loss 2.943183\n",
      "Epoch 2194, Loss 2.943183\n",
      "    Params:  tensor([  5.2934, -16.8843])\n",
      "    Grad  :  tensor([-0.0126,  0.0715])\n",
      "Epoch 2195,Loss 2.943130\n",
      "Epoch 2195, Loss 2.943130\n",
      "    Params:  tensor([  5.2936, -16.8850])\n",
      "    Grad  :  tensor([-0.0126,  0.0714])\n",
      "Epoch 2196,Loss 2.943079\n",
      "Epoch 2196, Loss 2.943079\n",
      "    Params:  tensor([  5.2937, -16.8857])\n",
      "    Grad  :  tensor([-0.0126,  0.0713])\n",
      "Epoch 2197,Loss 2.943027\n",
      "Epoch 2197, Loss 2.943027\n",
      "    Params:  tensor([  5.2938, -16.8865])\n",
      "    Grad  :  tensor([-0.0126,  0.0712])\n",
      "Epoch 2198,Loss 2.942973\n",
      "Epoch 2198, Loss 2.942973\n",
      "    Params:  tensor([  5.2939, -16.8872])\n",
      "    Grad  :  tensor([-0.0126,  0.0711])\n",
      "Epoch 2199,Loss 2.942922\n",
      "Epoch 2199, Loss 2.942922\n",
      "    Params:  tensor([  5.2941, -16.8879])\n",
      "    Grad  :  tensor([-0.0125,  0.0709])\n",
      "Epoch 2200,Loss 2.942870\n",
      "Epoch 2200, Loss 2.942870\n",
      "    Params:  tensor([  5.2942, -16.8886])\n",
      "    Grad  :  tensor([-0.0125,  0.0708])\n",
      "Epoch 2201,Loss 2.942818\n",
      "Epoch 2201, Loss 2.942818\n",
      "    Params:  tensor([  5.2943, -16.8893])\n",
      "    Grad  :  tensor([-0.0125,  0.0707])\n",
      "Epoch 2202,Loss 2.942766\n",
      "Epoch 2202, Loss 2.942766\n",
      "    Params:  tensor([  5.2944, -16.8900])\n",
      "    Grad  :  tensor([-0.0125,  0.0706])\n",
      "Epoch 2203,Loss 2.942714\n",
      "Epoch 2203, Loss 2.942714\n",
      "    Params:  tensor([  5.2946, -16.8907])\n",
      "    Grad  :  tensor([-0.0124,  0.0705])\n",
      "Epoch 2204,Loss 2.942665\n",
      "Epoch 2204, Loss 2.942665\n",
      "    Params:  tensor([  5.2947, -16.8914])\n",
      "    Grad  :  tensor([-0.0124,  0.0703])\n",
      "Epoch 2205,Loss 2.942612\n",
      "Epoch 2205, Loss 2.942612\n",
      "    Params:  tensor([  5.2948, -16.8921])\n",
      "    Grad  :  tensor([-0.0124,  0.0702])\n",
      "Epoch 2206,Loss 2.942564\n",
      "Epoch 2206, Loss 2.942564\n",
      "    Params:  tensor([  5.2949, -16.8928])\n",
      "    Grad  :  tensor([-0.0124,  0.0701])\n",
      "Epoch 2207,Loss 2.942510\n",
      "Epoch 2207, Loss 2.942510\n",
      "    Params:  tensor([  5.2951, -16.8935])\n",
      "    Grad  :  tensor([-0.0124,  0.0700])\n",
      "Epoch 2208,Loss 2.942461\n",
      "Epoch 2208, Loss 2.942461\n",
      "    Params:  tensor([  5.2952, -16.8942])\n",
      "    Grad  :  tensor([-0.0123,  0.0699])\n",
      "Epoch 2209,Loss 2.942411\n",
      "Epoch 2209, Loss 2.942411\n",
      "    Params:  tensor([  5.2953, -16.8949])\n",
      "    Grad  :  tensor([-0.0123,  0.0697])\n",
      "Epoch 2210,Loss 2.942361\n",
      "Epoch 2210, Loss 2.942361\n",
      "    Params:  tensor([  5.2954, -16.8956])\n",
      "    Grad  :  tensor([-0.0123,  0.0696])\n",
      "Epoch 2211,Loss 2.942310\n",
      "Epoch 2211, Loss 2.942310\n",
      "    Params:  tensor([  5.2956, -16.8963])\n",
      "    Grad  :  tensor([-0.0123,  0.0695])\n",
      "Epoch 2212,Loss 2.942261\n",
      "Epoch 2212, Loss 2.942261\n",
      "    Params:  tensor([  5.2957, -16.8970])\n",
      "    Grad  :  tensor([-0.0122,  0.0694])\n",
      "Epoch 2213,Loss 2.942211\n",
      "Epoch 2213, Loss 2.942211\n",
      "    Params:  tensor([  5.2958, -16.8977])\n",
      "    Grad  :  tensor([-0.0122,  0.0693])\n",
      "Epoch 2214,Loss 2.942162\n",
      "Epoch 2214, Loss 2.942162\n",
      "    Params:  tensor([  5.2959, -16.8984])\n",
      "    Grad  :  tensor([-0.0122,  0.0692])\n",
      "Epoch 2215,Loss 2.942112\n",
      "Epoch 2215, Loss 2.942112\n",
      "    Params:  tensor([  5.2960, -16.8991])\n",
      "    Grad  :  tensor([-0.0122,  0.0690])\n",
      "Epoch 2216,Loss 2.942062\n",
      "Epoch 2216, Loss 2.942062\n",
      "    Params:  tensor([  5.2962, -16.8998])\n",
      "    Grad  :  tensor([-0.0122,  0.0689])\n",
      "Epoch 2217,Loss 2.942014\n",
      "Epoch 2217, Loss 2.942014\n",
      "    Params:  tensor([  5.2963, -16.9004])\n",
      "    Grad  :  tensor([-0.0122,  0.0688])\n",
      "Epoch 2218,Loss 2.941965\n",
      "Epoch 2218, Loss 2.941965\n",
      "    Params:  tensor([  5.2964, -16.9011])\n",
      "    Grad  :  tensor([-0.0121,  0.0687])\n",
      "Epoch 2219,Loss 2.941918\n",
      "Epoch 2219, Loss 2.941918\n",
      "    Params:  tensor([  5.2965, -16.9018])\n",
      "    Grad  :  tensor([-0.0121,  0.0686])\n",
      "Epoch 2220,Loss 2.941868\n",
      "Epoch 2220, Loss 2.941868\n",
      "    Params:  tensor([  5.2967, -16.9025])\n",
      "    Grad  :  tensor([-0.0121,  0.0685])\n",
      "Epoch 2221,Loss 2.941821\n",
      "Epoch 2221, Loss 2.941821\n",
      "    Params:  tensor([  5.2968, -16.9032])\n",
      "    Grad  :  tensor([-0.0121,  0.0683])\n",
      "Epoch 2222,Loss 2.941773\n",
      "Epoch 2222, Loss 2.941773\n",
      "    Params:  tensor([  5.2969, -16.9039])\n",
      "    Grad  :  tensor([-0.0120,  0.0682])\n",
      "Epoch 2223,Loss 2.941724\n",
      "Epoch 2223, Loss 2.941724\n",
      "    Params:  tensor([  5.2970, -16.9046])\n",
      "    Grad  :  tensor([-0.0120,  0.0681])\n",
      "Epoch 2224,Loss 2.941677\n",
      "Epoch 2224, Loss 2.941677\n",
      "    Params:  tensor([  5.2971, -16.9052])\n",
      "    Grad  :  tensor([-0.0120,  0.0680])\n",
      "Epoch 2225,Loss 2.941629\n",
      "Epoch 2225, Loss 2.941629\n",
      "    Params:  tensor([  5.2973, -16.9059])\n",
      "    Grad  :  tensor([-0.0120,  0.0679])\n",
      "Epoch 2226,Loss 2.941582\n",
      "Epoch 2226, Loss 2.941582\n",
      "    Params:  tensor([  5.2974, -16.9066])\n",
      "    Grad  :  tensor([-0.0120,  0.0678])\n",
      "Epoch 2227,Loss 2.941534\n",
      "Epoch 2227, Loss 2.941534\n",
      "    Params:  tensor([  5.2975, -16.9073])\n",
      "    Grad  :  tensor([-0.0119,  0.0676])\n",
      "Epoch 2228,Loss 2.941488\n",
      "Epoch 2228, Loss 2.941488\n",
      "    Params:  tensor([  5.2976, -16.9079])\n",
      "    Grad  :  tensor([-0.0119,  0.0675])\n",
      "Epoch 2229,Loss 2.941440\n",
      "Epoch 2229, Loss 2.941440\n",
      "    Params:  tensor([  5.2977, -16.9086])\n",
      "    Grad  :  tensor([-0.0119,  0.0674])\n",
      "Epoch 2230,Loss 2.941393\n",
      "Epoch 2230, Loss 2.941393\n",
      "    Params:  tensor([  5.2979, -16.9093])\n",
      "    Grad  :  tensor([-0.0119,  0.0673])\n",
      "Epoch 2231,Loss 2.941346\n",
      "Epoch 2231, Loss 2.941346\n",
      "    Params:  tensor([  5.2980, -16.9100])\n",
      "    Grad  :  tensor([-0.0119,  0.0672])\n",
      "Epoch 2232,Loss 2.941299\n",
      "Epoch 2232, Loss 2.941299\n",
      "    Params:  tensor([  5.2981, -16.9106])\n",
      "    Grad  :  tensor([-0.0118,  0.0671])\n",
      "Epoch 2233,Loss 2.941253\n",
      "Epoch 2233, Loss 2.941253\n",
      "    Params:  tensor([  5.2982, -16.9113])\n",
      "    Grad  :  tensor([-0.0118,  0.0670])\n",
      "Epoch 2234,Loss 2.941206\n",
      "Epoch 2234, Loss 2.941206\n",
      "    Params:  tensor([  5.2983, -16.9120])\n",
      "    Grad  :  tensor([-0.0118,  0.0668])\n",
      "Epoch 2235,Loss 2.941163\n",
      "Epoch 2235, Loss 2.941163\n",
      "    Params:  tensor([  5.2984, -16.9126])\n",
      "    Grad  :  tensor([-0.0118,  0.0667])\n",
      "Epoch 2236,Loss 2.941116\n",
      "Epoch 2236, Loss 2.941116\n",
      "    Params:  tensor([  5.2986, -16.9133])\n",
      "    Grad  :  tensor([-0.0118,  0.0666])\n",
      "Epoch 2237,Loss 2.941070\n",
      "Epoch 2237, Loss 2.941070\n",
      "    Params:  tensor([  5.2987, -16.9140])\n",
      "    Grad  :  tensor([-0.0117,  0.0665])\n",
      "Epoch 2238,Loss 2.941025\n",
      "Epoch 2238, Loss 2.941025\n",
      "    Params:  tensor([  5.2988, -16.9146])\n",
      "    Grad  :  tensor([-0.0117,  0.0664])\n",
      "Epoch 2239,Loss 2.940979\n",
      "Epoch 2239, Loss 2.940979\n",
      "    Params:  tensor([  5.2989, -16.9153])\n",
      "    Grad  :  tensor([-0.0117,  0.0663])\n",
      "Epoch 2240,Loss 2.940933\n",
      "Epoch 2240, Loss 2.940933\n",
      "    Params:  tensor([  5.2990, -16.9160])\n",
      "    Grad  :  tensor([-0.0117,  0.0662])\n",
      "Epoch 2241,Loss 2.940890\n",
      "Epoch 2241, Loss 2.940890\n",
      "    Params:  tensor([  5.2991, -16.9166])\n",
      "    Grad  :  tensor([-0.0117,  0.0661])\n",
      "Epoch 2242,Loss 2.940844\n",
      "Epoch 2242, Loss 2.940844\n",
      "    Params:  tensor([  5.2993, -16.9173])\n",
      "    Grad  :  tensor([-0.0117,  0.0659])\n",
      "Epoch 2243,Loss 2.940798\n",
      "Epoch 2243, Loss 2.940798\n",
      "    Params:  tensor([  5.2994, -16.9179])\n",
      "    Grad  :  tensor([-0.0116,  0.0658])\n",
      "Epoch 2244,Loss 2.940753\n",
      "Epoch 2244, Loss 2.940753\n",
      "    Params:  tensor([  5.2995, -16.9186])\n",
      "    Grad  :  tensor([-0.0116,  0.0657])\n",
      "Epoch 2245,Loss 2.940711\n",
      "Epoch 2245, Loss 2.940711\n",
      "    Params:  tensor([  5.2996, -16.9192])\n",
      "    Grad  :  tensor([-0.0116,  0.0656])\n",
      "Epoch 2246,Loss 2.940666\n",
      "Epoch 2246, Loss 2.940666\n",
      "    Params:  tensor([  5.2997, -16.9199])\n",
      "    Grad  :  tensor([-0.0116,  0.0655])\n",
      "Epoch 2247,Loss 2.940621\n",
      "Epoch 2247, Loss 2.940621\n",
      "    Params:  tensor([  5.2998, -16.9206])\n",
      "    Grad  :  tensor([-0.0115,  0.0654])\n",
      "Epoch 2248,Loss 2.940576\n",
      "Epoch 2248, Loss 2.940576\n",
      "    Params:  tensor([  5.3000, -16.9212])\n",
      "    Grad  :  tensor([-0.0115,  0.0653])\n",
      "Epoch 2249,Loss 2.940533\n",
      "Epoch 2249, Loss 2.940533\n",
      "    Params:  tensor([  5.3001, -16.9219])\n",
      "    Grad  :  tensor([-0.0115,  0.0652])\n",
      "Epoch 2250,Loss 2.940489\n",
      "Epoch 2250, Loss 2.940489\n",
      "    Params:  tensor([  5.3002, -16.9225])\n",
      "    Grad  :  tensor([-0.0115,  0.0650])\n",
      "Epoch 2251,Loss 2.940446\n",
      "Epoch 2251, Loss 2.940446\n",
      "    Params:  tensor([  5.3003, -16.9232])\n",
      "    Grad  :  tensor([-0.0115,  0.0649])\n",
      "Epoch 2252,Loss 2.940403\n",
      "Epoch 2252, Loss 2.940403\n",
      "    Params:  tensor([  5.3004, -16.9238])\n",
      "    Grad  :  tensor([-0.0114,  0.0648])\n",
      "Epoch 2253,Loss 2.940358\n",
      "Epoch 2253, Loss 2.940358\n",
      "    Params:  tensor([  5.3005, -16.9245])\n",
      "    Grad  :  tensor([-0.0114,  0.0647])\n",
      "Epoch 2254,Loss 2.940316\n",
      "Epoch 2254, Loss 2.940316\n",
      "    Params:  tensor([  5.3006, -16.9251])\n",
      "    Grad  :  tensor([-0.0114,  0.0646])\n",
      "Epoch 2255,Loss 2.940274\n",
      "Epoch 2255, Loss 2.940274\n",
      "    Params:  tensor([  5.3008, -16.9257])\n",
      "    Grad  :  tensor([-0.0114,  0.0645])\n",
      "Epoch 2256,Loss 2.940229\n",
      "Epoch 2256, Loss 2.940229\n",
      "    Params:  tensor([  5.3009, -16.9264])\n",
      "    Grad  :  tensor([-0.0114,  0.0644])\n",
      "Epoch 2257,Loss 2.940188\n",
      "Epoch 2257, Loss 2.940188\n",
      "    Params:  tensor([  5.3010, -16.9270])\n",
      "    Grad  :  tensor([-0.0114,  0.0643])\n",
      "Epoch 2258,Loss 2.940144\n",
      "Epoch 2258, Loss 2.940144\n",
      "    Params:  tensor([  5.3011, -16.9277])\n",
      "    Grad  :  tensor([-0.0114,  0.0642])\n",
      "Epoch 2259,Loss 2.940102\n",
      "Epoch 2259, Loss 2.940102\n",
      "    Params:  tensor([  5.3012, -16.9283])\n",
      "    Grad  :  tensor([-0.0113,  0.0641])\n",
      "Epoch 2260,Loss 2.940060\n",
      "Epoch 2260, Loss 2.940060\n",
      "    Params:  tensor([  5.3013, -16.9290])\n",
      "    Grad  :  tensor([-0.0113,  0.0640])\n",
      "Epoch 2261,Loss 2.940018\n",
      "Epoch 2261, Loss 2.940018\n",
      "    Params:  tensor([  5.3014, -16.9296])\n",
      "    Grad  :  tensor([-0.0113,  0.0638])\n",
      "Epoch 2262,Loss 2.939977\n",
      "Epoch 2262, Loss 2.939977\n",
      "    Params:  tensor([  5.3016, -16.9302])\n",
      "    Grad  :  tensor([-0.0113,  0.0637])\n",
      "Epoch 2263,Loss 2.939934\n",
      "Epoch 2263, Loss 2.939934\n",
      "    Params:  tensor([  5.3017, -16.9309])\n",
      "    Grad  :  tensor([-0.0112,  0.0636])\n",
      "Epoch 2264,Loss 2.939891\n",
      "Epoch 2264, Loss 2.939891\n",
      "    Params:  tensor([  5.3018, -16.9315])\n",
      "    Grad  :  tensor([-0.0112,  0.0635])\n",
      "Epoch 2265,Loss 2.939851\n",
      "Epoch 2265, Loss 2.939851\n",
      "    Params:  tensor([  5.3019, -16.9321])\n",
      "    Grad  :  tensor([-0.0112,  0.0634])\n",
      "Epoch 2266,Loss 2.939809\n",
      "Epoch 2266, Loss 2.939809\n",
      "    Params:  tensor([  5.3020, -16.9328])\n",
      "    Grad  :  tensor([-0.0112,  0.0633])\n",
      "Epoch 2267,Loss 2.939770\n",
      "Epoch 2267, Loss 2.939770\n",
      "    Params:  tensor([  5.3021, -16.9334])\n",
      "    Grad  :  tensor([-0.0112,  0.0632])\n",
      "Epoch 2268,Loss 2.939727\n",
      "Epoch 2268, Loss 2.939727\n",
      "    Params:  tensor([  5.3022, -16.9340])\n",
      "    Grad  :  tensor([-0.0111,  0.0631])\n",
      "Epoch 2269,Loss 2.939686\n",
      "Epoch 2269, Loss 2.939686\n",
      "    Params:  tensor([  5.3023, -16.9347])\n",
      "    Grad  :  tensor([-0.0111,  0.0630])\n",
      "Epoch 2270,Loss 2.939646\n",
      "Epoch 2270, Loss 2.939646\n",
      "    Params:  tensor([  5.3024, -16.9353])\n",
      "    Grad  :  tensor([-0.0111,  0.0629])\n",
      "Epoch 2271,Loss 2.939605\n",
      "Epoch 2271, Loss 2.939605\n",
      "    Params:  tensor([  5.3026, -16.9359])\n",
      "    Grad  :  tensor([-0.0111,  0.0628])\n",
      "Epoch 2272,Loss 2.939566\n",
      "Epoch 2272, Loss 2.939566\n",
      "    Params:  tensor([  5.3027, -16.9365])\n",
      "    Grad  :  tensor([-0.0111,  0.0627])\n",
      "Epoch 2273,Loss 2.939522\n",
      "Epoch 2273, Loss 2.939522\n",
      "    Params:  tensor([  5.3028, -16.9372])\n",
      "    Grad  :  tensor([-0.0111,  0.0626])\n",
      "Epoch 2274,Loss 2.939483\n",
      "Epoch 2274, Loss 2.939483\n",
      "    Params:  tensor([  5.3029, -16.9378])\n",
      "    Grad  :  tensor([-0.0110,  0.0624])\n",
      "Epoch 2275,Loss 2.939443\n",
      "Epoch 2275, Loss 2.939443\n",
      "    Params:  tensor([  5.3030, -16.9384])\n",
      "    Grad  :  tensor([-0.0110,  0.0623])\n",
      "Epoch 2276,Loss 2.939403\n",
      "Epoch 2276, Loss 2.939403\n",
      "    Params:  tensor([  5.3031, -16.9390])\n",
      "    Grad  :  tensor([-0.0110,  0.0622])\n",
      "Epoch 2277,Loss 2.939361\n",
      "Epoch 2277, Loss 2.939361\n",
      "    Params:  tensor([  5.3032, -16.9397])\n",
      "    Grad  :  tensor([-0.0110,  0.0621])\n",
      "Epoch 2278,Loss 2.939323\n",
      "Epoch 2278, Loss 2.939323\n",
      "    Params:  tensor([  5.3033, -16.9403])\n",
      "    Grad  :  tensor([-0.0110,  0.0620])\n",
      "Epoch 2279,Loss 2.939282\n",
      "Epoch 2279, Loss 2.939282\n",
      "    Params:  tensor([  5.3034, -16.9409])\n",
      "    Grad  :  tensor([-0.0109,  0.0619])\n",
      "Epoch 2280,Loss 2.939243\n",
      "Epoch 2280, Loss 2.939243\n",
      "    Params:  tensor([  5.3035, -16.9415])\n",
      "    Grad  :  tensor([-0.0109,  0.0618])\n",
      "Epoch 2281,Loss 2.939205\n",
      "Epoch 2281, Loss 2.939205\n",
      "    Params:  tensor([  5.3037, -16.9421])\n",
      "    Grad  :  tensor([-0.0109,  0.0617])\n",
      "Epoch 2282,Loss 2.939165\n",
      "Epoch 2282, Loss 2.939165\n",
      "    Params:  tensor([  5.3038, -16.9428])\n",
      "    Grad  :  tensor([-0.0109,  0.0616])\n",
      "Epoch 2283,Loss 2.939127\n",
      "Epoch 2283, Loss 2.939127\n",
      "    Params:  tensor([  5.3039, -16.9434])\n",
      "    Grad  :  tensor([-0.0109,  0.0615])\n",
      "Epoch 2284,Loss 2.939087\n",
      "Epoch 2284, Loss 2.939087\n",
      "    Params:  tensor([  5.3040, -16.9440])\n",
      "    Grad  :  tensor([-0.0108,  0.0614])\n",
      "Epoch 2285,Loss 2.939049\n",
      "Epoch 2285, Loss 2.939049\n",
      "    Params:  tensor([  5.3041, -16.9446])\n",
      "    Grad  :  tensor([-0.0108,  0.0613])\n",
      "Epoch 2286,Loss 2.939011\n",
      "Epoch 2286, Loss 2.939011\n",
      "    Params:  tensor([  5.3042, -16.9452])\n",
      "    Grad  :  tensor([-0.0108,  0.0612])\n",
      "Epoch 2287,Loss 2.938971\n",
      "Epoch 2287, Loss 2.938971\n",
      "    Params:  tensor([  5.3043, -16.9458])\n",
      "    Grad  :  tensor([-0.0108,  0.0611])\n",
      "Epoch 2288,Loss 2.938933\n",
      "Epoch 2288, Loss 2.938933\n",
      "    Params:  tensor([  5.3044, -16.9464])\n",
      "    Grad  :  tensor([-0.0108,  0.0610])\n",
      "Epoch 2289,Loss 2.938893\n",
      "Epoch 2289, Loss 2.938893\n",
      "    Params:  tensor([  5.3045, -16.9470])\n",
      "    Grad  :  tensor([-0.0108,  0.0609])\n",
      "Epoch 2290,Loss 2.938857\n",
      "Epoch 2290, Loss 2.938857\n",
      "    Params:  tensor([  5.3046, -16.9476])\n",
      "    Grad  :  tensor([-0.0107,  0.0608])\n",
      "Epoch 2291,Loss 2.938820\n",
      "Epoch 2291, Loss 2.938820\n",
      "    Params:  tensor([  5.3047, -16.9482])\n",
      "    Grad  :  tensor([-0.0107,  0.0607])\n",
      "Epoch 2292,Loss 2.938779\n",
      "Epoch 2292, Loss 2.938779\n",
      "    Params:  tensor([  5.3048, -16.9489])\n",
      "    Grad  :  tensor([-0.0107,  0.0606])\n",
      "Epoch 2293,Loss 2.938743\n",
      "Epoch 2293, Loss 2.938743\n",
      "    Params:  tensor([  5.3049, -16.9495])\n",
      "    Grad  :  tensor([-0.0107,  0.0605])\n",
      "Epoch 2294,Loss 2.938705\n",
      "Epoch 2294, Loss 2.938705\n",
      "    Params:  tensor([  5.3051, -16.9501])\n",
      "    Grad  :  tensor([-0.0107,  0.0604])\n",
      "Epoch 2295,Loss 2.938667\n",
      "Epoch 2295, Loss 2.938667\n",
      "    Params:  tensor([  5.3052, -16.9507])\n",
      "    Grad  :  tensor([-0.0106,  0.0603])\n",
      "Epoch 2296,Loss 2.938629\n",
      "Epoch 2296, Loss 2.938629\n",
      "    Params:  tensor([  5.3053, -16.9513])\n",
      "    Grad  :  tensor([-0.0106,  0.0602])\n",
      "Epoch 2297,Loss 2.938593\n",
      "Epoch 2297, Loss 2.938593\n",
      "    Params:  tensor([  5.3054, -16.9519])\n",
      "    Grad  :  tensor([-0.0106,  0.0601])\n",
      "Epoch 2298,Loss 2.938555\n",
      "Epoch 2298, Loss 2.938555\n",
      "    Params:  tensor([  5.3055, -16.9525])\n",
      "    Grad  :  tensor([-0.0106,  0.0600])\n",
      "Epoch 2299,Loss 2.938519\n",
      "Epoch 2299, Loss 2.938519\n",
      "    Params:  tensor([  5.3056, -16.9531])\n",
      "    Grad  :  tensor([-0.0106,  0.0598])\n",
      "Epoch 2300,Loss 2.938481\n",
      "Epoch 2300, Loss 2.938481\n",
      "    Params:  tensor([  5.3057, -16.9537])\n",
      "    Grad  :  tensor([-0.0106,  0.0597])\n",
      "Epoch 2301,Loss 2.938444\n",
      "Epoch 2301, Loss 2.938444\n",
      "    Params:  tensor([  5.3058, -16.9543])\n",
      "    Grad  :  tensor([-0.0105,  0.0596])\n",
      "Epoch 2302,Loss 2.938408\n",
      "Epoch 2302, Loss 2.938408\n",
      "    Params:  tensor([  5.3059, -16.9549])\n",
      "    Grad  :  tensor([-0.0105,  0.0595])\n",
      "Epoch 2303,Loss 2.938371\n",
      "Epoch 2303, Loss 2.938371\n",
      "    Params:  tensor([  5.3060, -16.9554])\n",
      "    Grad  :  tensor([-0.0105,  0.0594])\n",
      "Epoch 2304,Loss 2.938335\n",
      "Epoch 2304, Loss 2.938335\n",
      "    Params:  tensor([  5.3061, -16.9560])\n",
      "    Grad  :  tensor([-0.0105,  0.0593])\n",
      "Epoch 2305,Loss 2.938299\n",
      "Epoch 2305, Loss 2.938299\n",
      "    Params:  tensor([  5.3062, -16.9566])\n",
      "    Grad  :  tensor([-0.0105,  0.0592])\n",
      "Epoch 2306,Loss 2.938263\n",
      "Epoch 2306, Loss 2.938263\n",
      "    Params:  tensor([  5.3063, -16.9572])\n",
      "    Grad  :  tensor([-0.0104,  0.0591])\n",
      "Epoch 2307,Loss 2.938227\n",
      "Epoch 2307, Loss 2.938227\n",
      "    Params:  tensor([  5.3064, -16.9578])\n",
      "    Grad  :  tensor([-0.0104,  0.0590])\n",
      "Epoch 2308,Loss 2.938190\n",
      "Epoch 2308, Loss 2.938190\n",
      "    Params:  tensor([  5.3065, -16.9584])\n",
      "    Grad  :  tensor([-0.0104,  0.0589])\n",
      "Epoch 2309,Loss 2.938155\n",
      "Epoch 2309, Loss 2.938155\n",
      "    Params:  tensor([  5.3066, -16.9590])\n",
      "    Grad  :  tensor([-0.0104,  0.0588])\n",
      "Epoch 2310,Loss 2.938118\n",
      "Epoch 2310, Loss 2.938118\n",
      "    Params:  tensor([  5.3067, -16.9596])\n",
      "    Grad  :  tensor([-0.0104,  0.0587])\n",
      "Epoch 2311,Loss 2.938084\n",
      "Epoch 2311, Loss 2.938084\n",
      "    Params:  tensor([  5.3068, -16.9602])\n",
      "    Grad  :  tensor([-0.0104,  0.0586])\n",
      "Epoch 2312,Loss 2.938049\n",
      "Epoch 2312, Loss 2.938049\n",
      "    Params:  tensor([  5.3069, -16.9608])\n",
      "    Grad  :  tensor([-0.0103,  0.0585])\n",
      "Epoch 2313,Loss 2.938014\n",
      "Epoch 2313, Loss 2.938014\n",
      "    Params:  tensor([  5.3070, -16.9613])\n",
      "    Grad  :  tensor([-0.0103,  0.0584])\n",
      "Epoch 2314,Loss 2.937977\n",
      "Epoch 2314, Loss 2.937977\n",
      "    Params:  tensor([  5.3072, -16.9619])\n",
      "    Grad  :  tensor([-0.0103,  0.0583])\n",
      "Epoch 2315,Loss 2.937943\n",
      "Epoch 2315, Loss 2.937943\n",
      "    Params:  tensor([  5.3073, -16.9625])\n",
      "    Grad  :  tensor([-0.0103,  0.0582])\n",
      "Epoch 2316,Loss 2.937908\n",
      "Epoch 2316, Loss 2.937908\n",
      "    Params:  tensor([  5.3074, -16.9631])\n",
      "    Grad  :  tensor([-0.0103,  0.0581])\n",
      "Epoch 2317,Loss 2.937872\n",
      "Epoch 2317, Loss 2.937872\n",
      "    Params:  tensor([  5.3075, -16.9637])\n",
      "    Grad  :  tensor([-0.0103,  0.0580])\n",
      "Epoch 2318,Loss 2.937839\n",
      "Epoch 2318, Loss 2.937839\n",
      "    Params:  tensor([  5.3076, -16.9642])\n",
      "    Grad  :  tensor([-0.0102,  0.0580])\n",
      "Epoch 2319,Loss 2.937804\n",
      "Epoch 2319, Loss 2.937804\n",
      "    Params:  tensor([  5.3077, -16.9648])\n",
      "    Grad  :  tensor([-0.0102,  0.0578])\n",
      "Epoch 2320,Loss 2.937769\n",
      "Epoch 2320, Loss 2.937769\n",
      "    Params:  tensor([  5.3078, -16.9654])\n",
      "    Grad  :  tensor([-0.0102,  0.0578])\n",
      "Epoch 2321,Loss 2.937734\n",
      "Epoch 2321, Loss 2.937734\n",
      "    Params:  tensor([  5.3079, -16.9660])\n",
      "    Grad  :  tensor([-0.0102,  0.0577])\n",
      "Epoch 2322,Loss 2.937700\n",
      "Epoch 2322, Loss 2.937700\n",
      "    Params:  tensor([  5.3080, -16.9666])\n",
      "    Grad  :  tensor([-0.0102,  0.0576])\n",
      "Epoch 2323,Loss 2.937665\n",
      "Epoch 2323, Loss 2.937665\n",
      "    Params:  tensor([  5.3081, -16.9671])\n",
      "    Grad  :  tensor([-0.0102,  0.0575])\n",
      "Epoch 2324,Loss 2.937632\n",
      "Epoch 2324, Loss 2.937632\n",
      "    Params:  tensor([  5.3082, -16.9677])\n",
      "    Grad  :  tensor([-0.0101,  0.0574])\n",
      "Epoch 2325,Loss 2.937598\n",
      "Epoch 2325, Loss 2.937598\n",
      "    Params:  tensor([  5.3083, -16.9683])\n",
      "    Grad  :  tensor([-0.0101,  0.0573])\n",
      "Epoch 2326,Loss 2.937565\n",
      "Epoch 2326, Loss 2.937565\n",
      "    Params:  tensor([  5.3084, -16.9688])\n",
      "    Grad  :  tensor([-0.0101,  0.0572])\n",
      "Epoch 2327,Loss 2.937531\n",
      "Epoch 2327, Loss 2.937531\n",
      "    Params:  tensor([  5.3085, -16.9694])\n",
      "    Grad  :  tensor([-0.0101,  0.0571])\n",
      "Epoch 2328,Loss 2.937499\n",
      "Epoch 2328, Loss 2.937499\n",
      "    Params:  tensor([  5.3086, -16.9700])\n",
      "    Grad  :  tensor([-0.0101,  0.0570])\n",
      "Epoch 2329,Loss 2.937465\n",
      "Epoch 2329, Loss 2.937465\n",
      "    Params:  tensor([  5.3087, -16.9706])\n",
      "    Grad  :  tensor([-0.0101,  0.0569])\n",
      "Epoch 2330,Loss 2.937430\n",
      "Epoch 2330, Loss 2.937430\n",
      "    Params:  tensor([  5.3088, -16.9711])\n",
      "    Grad  :  tensor([-0.0100,  0.0568])\n",
      "Epoch 2331,Loss 2.937398\n",
      "Epoch 2331, Loss 2.937398\n",
      "    Params:  tensor([  5.3089, -16.9717])\n",
      "    Grad  :  tensor([-0.0100,  0.0567])\n",
      "Epoch 2332,Loss 2.937364\n",
      "Epoch 2332, Loss 2.937364\n",
      "    Params:  tensor([  5.3090, -16.9723])\n",
      "    Grad  :  tensor([-0.0100,  0.0566])\n",
      "Epoch 2333,Loss 2.937332\n",
      "Epoch 2333, Loss 2.937332\n",
      "    Params:  tensor([  5.3091, -16.9728])\n",
      "    Grad  :  tensor([-0.0100,  0.0565])\n",
      "Epoch 2334,Loss 2.937299\n",
      "Epoch 2334, Loss 2.937299\n",
      "    Params:  tensor([  5.3092, -16.9734])\n",
      "    Grad  :  tensor([-0.0100,  0.0564])\n",
      "Epoch 2335,Loss 2.937265\n",
      "Epoch 2335, Loss 2.937265\n",
      "    Params:  tensor([  5.3093, -16.9739])\n",
      "    Grad  :  tensor([-0.0100,  0.0563])\n",
      "Epoch 2336,Loss 2.937232\n",
      "Epoch 2336, Loss 2.937232\n",
      "    Params:  tensor([  5.3094, -16.9745])\n",
      "    Grad  :  tensor([-0.0099,  0.0562])\n",
      "Epoch 2337,Loss 2.937201\n",
      "Epoch 2337, Loss 2.937201\n",
      "    Params:  tensor([  5.3095, -16.9751])\n",
      "    Grad  :  tensor([-0.0099,  0.0561])\n",
      "Epoch 2338,Loss 2.937167\n",
      "Epoch 2338, Loss 2.937167\n",
      "    Params:  tensor([  5.3096, -16.9756])\n",
      "    Grad  :  tensor([-0.0099,  0.0560])\n",
      "Epoch 2339,Loss 2.937134\n",
      "Epoch 2339, Loss 2.937134\n",
      "    Params:  tensor([  5.3097, -16.9762])\n",
      "    Grad  :  tensor([-0.0099,  0.0559])\n",
      "Epoch 2340,Loss 2.937104\n",
      "Epoch 2340, Loss 2.937104\n",
      "    Params:  tensor([  5.3098, -16.9767])\n",
      "    Grad  :  tensor([-0.0099,  0.0558])\n",
      "Epoch 2341,Loss 2.937071\n",
      "Epoch 2341, Loss 2.937071\n",
      "    Params:  tensor([  5.3099, -16.9773])\n",
      "    Grad  :  tensor([-0.0098,  0.0557])\n",
      "Epoch 2342,Loss 2.937039\n",
      "Epoch 2342, Loss 2.937039\n",
      "    Params:  tensor([  5.3100, -16.9779])\n",
      "    Grad  :  tensor([-0.0098,  0.0556])\n",
      "Epoch 2343,Loss 2.937008\n",
      "Epoch 2343, Loss 2.937008\n",
      "    Params:  tensor([  5.3101, -16.9784])\n",
      "    Grad  :  tensor([-0.0098,  0.0555])\n",
      "Epoch 2344,Loss 2.936976\n",
      "Epoch 2344, Loss 2.936976\n",
      "    Params:  tensor([  5.3102, -16.9790])\n",
      "    Grad  :  tensor([-0.0098,  0.0554])\n",
      "Epoch 2345,Loss 2.936945\n",
      "Epoch 2345, Loss 2.936945\n",
      "    Params:  tensor([  5.3103, -16.9795])\n",
      "    Grad  :  tensor([-0.0098,  0.0553])\n",
      "Epoch 2346,Loss 2.936912\n",
      "Epoch 2346, Loss 2.936912\n",
      "    Params:  tensor([  5.3104, -16.9801])\n",
      "    Grad  :  tensor([-0.0098,  0.0553])\n",
      "Epoch 2347,Loss 2.936883\n",
      "Epoch 2347, Loss 2.936883\n",
      "    Params:  tensor([  5.3105, -16.9806])\n",
      "    Grad  :  tensor([-0.0097,  0.0552])\n",
      "Epoch 2348,Loss 2.936851\n",
      "Epoch 2348, Loss 2.936851\n",
      "    Params:  tensor([  5.3106, -16.9812])\n",
      "    Grad  :  tensor([-0.0097,  0.0551])\n",
      "Epoch 2349,Loss 2.936819\n",
      "Epoch 2349, Loss 2.936819\n",
      "    Params:  tensor([  5.3107, -16.9817])\n",
      "    Grad  :  tensor([-0.0097,  0.0550])\n",
      "Epoch 2350,Loss 2.936788\n",
      "Epoch 2350, Loss 2.936788\n",
      "    Params:  tensor([  5.3107, -16.9823])\n",
      "    Grad  :  tensor([-0.0097,  0.0549])\n",
      "Epoch 2351,Loss 2.936757\n",
      "Epoch 2351, Loss 2.936757\n",
      "    Params:  tensor([  5.3108, -16.9828])\n",
      "    Grad  :  tensor([-0.0097,  0.0548])\n",
      "Epoch 2352,Loss 2.936725\n",
      "Epoch 2352, Loss 2.936725\n",
      "    Params:  tensor([  5.3109, -16.9834])\n",
      "    Grad  :  tensor([-0.0097,  0.0547])\n",
      "Epoch 2353,Loss 2.936694\n",
      "Epoch 2353, Loss 2.936694\n",
      "    Params:  tensor([  5.3110, -16.9839])\n",
      "    Grad  :  tensor([-0.0096,  0.0546])\n",
      "Epoch 2354,Loss 2.936665\n",
      "Epoch 2354, Loss 2.936665\n",
      "    Params:  tensor([  5.3111, -16.9845])\n",
      "    Grad  :  tensor([-0.0096,  0.0545])\n",
      "Epoch 2355,Loss 2.936633\n",
      "Epoch 2355, Loss 2.936633\n",
      "    Params:  tensor([  5.3112, -16.9850])\n",
      "    Grad  :  tensor([-0.0096,  0.0544])\n",
      "Epoch 2356,Loss 2.936602\n",
      "Epoch 2356, Loss 2.936602\n",
      "    Params:  tensor([  5.3113, -16.9856])\n",
      "    Grad  :  tensor([-0.0096,  0.0543])\n",
      "Epoch 2357,Loss 2.936572\n",
      "Epoch 2357, Loss 2.936572\n",
      "    Params:  tensor([  5.3114, -16.9861])\n",
      "    Grad  :  tensor([-0.0096,  0.0542])\n",
      "Epoch 2358,Loss 2.936542\n",
      "Epoch 2358, Loss 2.936542\n",
      "    Params:  tensor([  5.3115, -16.9866])\n",
      "    Grad  :  tensor([-0.0095,  0.0541])\n",
      "Epoch 2359,Loss 2.936511\n",
      "Epoch 2359, Loss 2.936511\n",
      "    Params:  tensor([  5.3116, -16.9872])\n",
      "    Grad  :  tensor([-0.0096,  0.0540])\n",
      "Epoch 2360,Loss 2.936481\n",
      "Epoch 2360, Loss 2.936481\n",
      "    Params:  tensor([  5.3117, -16.9877])\n",
      "    Grad  :  tensor([-0.0095,  0.0540])\n",
      "Epoch 2361,Loss 2.936451\n",
      "Epoch 2361, Loss 2.936451\n",
      "    Params:  tensor([  5.3118, -16.9883])\n",
      "    Grad  :  tensor([-0.0095,  0.0539])\n",
      "Epoch 2362,Loss 2.936421\n",
      "Epoch 2362, Loss 2.936421\n",
      "    Params:  tensor([  5.3119, -16.9888])\n",
      "    Grad  :  tensor([-0.0095,  0.0538])\n",
      "Epoch 2363,Loss 2.936392\n",
      "Epoch 2363, Loss 2.936392\n",
      "    Params:  tensor([  5.3120, -16.9893])\n",
      "    Grad  :  tensor([-0.0095,  0.0537])\n",
      "Epoch 2364,Loss 2.936362\n",
      "Epoch 2364, Loss 2.936362\n",
      "    Params:  tensor([  5.3121, -16.9899])\n",
      "    Grad  :  tensor([-0.0094,  0.0536])\n",
      "Epoch 2365,Loss 2.936332\n",
      "Epoch 2365, Loss 2.936332\n",
      "    Params:  tensor([  5.3122, -16.9904])\n",
      "    Grad  :  tensor([-0.0094,  0.0535])\n",
      "Epoch 2366,Loss 2.936304\n",
      "Epoch 2366, Loss 2.936304\n",
      "    Params:  tensor([  5.3123, -16.9909])\n",
      "    Grad  :  tensor([-0.0094,  0.0534])\n",
      "Epoch 2367,Loss 2.936274\n",
      "Epoch 2367, Loss 2.936274\n",
      "    Params:  tensor([  5.3124, -16.9915])\n",
      "    Grad  :  tensor([-0.0094,  0.0533])\n",
      "Epoch 2368,Loss 2.936244\n",
      "Epoch 2368, Loss 2.936244\n",
      "    Params:  tensor([  5.3125, -16.9920])\n",
      "    Grad  :  tensor([-0.0094,  0.0532])\n",
      "Epoch 2369,Loss 2.936216\n",
      "Epoch 2369, Loss 2.936216\n",
      "    Params:  tensor([  5.3126, -16.9925])\n",
      "    Grad  :  tensor([-0.0094,  0.0531])\n",
      "Epoch 2370,Loss 2.936188\n",
      "Epoch 2370, Loss 2.936188\n",
      "    Params:  tensor([  5.3127, -16.9931])\n",
      "    Grad  :  tensor([-0.0094,  0.0530])\n",
      "Epoch 2371,Loss 2.936156\n",
      "Epoch 2371, Loss 2.936156\n",
      "    Params:  tensor([  5.3127, -16.9936])\n",
      "    Grad  :  tensor([-0.0094,  0.0530])\n",
      "Epoch 2372,Loss 2.936128\n",
      "Epoch 2372, Loss 2.936128\n",
      "    Params:  tensor([  5.3128, -16.9941])\n",
      "    Grad  :  tensor([-0.0093,  0.0529])\n",
      "Epoch 2373,Loss 2.936100\n",
      "Epoch 2373, Loss 2.936100\n",
      "    Params:  tensor([  5.3129, -16.9946])\n",
      "    Grad  :  tensor([-0.0093,  0.0528])\n",
      "Epoch 2374,Loss 2.936072\n",
      "Epoch 2374, Loss 2.936072\n",
      "    Params:  tensor([  5.3130, -16.9952])\n",
      "    Grad  :  tensor([-0.0093,  0.0527])\n",
      "Epoch 2375,Loss 2.936042\n",
      "Epoch 2375, Loss 2.936042\n",
      "    Params:  tensor([  5.3131, -16.9957])\n",
      "    Grad  :  tensor([-0.0093,  0.0526])\n",
      "Epoch 2376,Loss 2.936014\n",
      "Epoch 2376, Loss 2.936014\n",
      "    Params:  tensor([  5.3132, -16.9962])\n",
      "    Grad  :  tensor([-0.0093,  0.0525])\n",
      "Epoch 2377,Loss 2.935986\n",
      "Epoch 2377, Loss 2.935986\n",
      "    Params:  tensor([  5.3133, -16.9967])\n",
      "    Grad  :  tensor([-0.0093,  0.0524])\n",
      "Epoch 2378,Loss 2.935957\n",
      "Epoch 2378, Loss 2.935957\n",
      "    Params:  tensor([  5.3134, -16.9973])\n",
      "    Grad  :  tensor([-0.0093,  0.0523])\n",
      "Epoch 2379,Loss 2.935928\n",
      "Epoch 2379, Loss 2.935928\n",
      "    Params:  tensor([  5.3135, -16.9978])\n",
      "    Grad  :  tensor([-0.0092,  0.0522])\n",
      "Epoch 2380,Loss 2.935901\n",
      "Epoch 2380, Loss 2.935901\n",
      "    Params:  tensor([  5.3136, -16.9983])\n",
      "    Grad  :  tensor([-0.0092,  0.0522])\n",
      "Epoch 2381,Loss 2.935873\n",
      "Epoch 2381, Loss 2.935873\n",
      "    Params:  tensor([  5.3137, -16.9988])\n",
      "    Grad  :  tensor([-0.0092,  0.0521])\n",
      "Epoch 2382,Loss 2.935845\n",
      "Epoch 2382, Loss 2.935845\n",
      "    Params:  tensor([  5.3138, -16.9994])\n",
      "    Grad  :  tensor([-0.0092,  0.0520])\n",
      "Epoch 2383,Loss 2.935817\n",
      "Epoch 2383, Loss 2.935817\n",
      "    Params:  tensor([  5.3139, -16.9999])\n",
      "    Grad  :  tensor([-0.0092,  0.0519])\n",
      "Epoch 2384,Loss 2.935789\n",
      "Epoch 2384, Loss 2.935789\n",
      "    Params:  tensor([  5.3139, -17.0004])\n",
      "    Grad  :  tensor([-0.0092,  0.0518])\n",
      "Epoch 2385,Loss 2.935762\n",
      "Epoch 2385, Loss 2.935762\n",
      "    Params:  tensor([  5.3140, -17.0009])\n",
      "    Grad  :  tensor([-0.0092,  0.0517])\n",
      "Epoch 2386,Loss 2.935734\n",
      "Epoch 2386, Loss 2.935734\n",
      "    Params:  tensor([  5.3141, -17.0014])\n",
      "    Grad  :  tensor([-0.0091,  0.0516])\n",
      "Epoch 2387,Loss 2.935707\n",
      "Epoch 2387, Loss 2.935707\n",
      "    Params:  tensor([  5.3142, -17.0019])\n",
      "    Grad  :  tensor([-0.0091,  0.0515])\n",
      "Epoch 2388,Loss 2.935679\n",
      "Epoch 2388, Loss 2.935679\n",
      "    Params:  tensor([  5.3143, -17.0025])\n",
      "    Grad  :  tensor([-0.0091,  0.0514])\n",
      "Epoch 2389,Loss 2.935650\n",
      "Epoch 2389, Loss 2.935650\n",
      "    Params:  tensor([  5.3144, -17.0030])\n",
      "    Grad  :  tensor([-0.0091,  0.0514])\n",
      "Epoch 2390,Loss 2.935626\n",
      "Epoch 2390, Loss 2.935626\n",
      "    Params:  tensor([  5.3145, -17.0035])\n",
      "    Grad  :  tensor([-0.0090,  0.0513])\n",
      "Epoch 2391,Loss 2.935596\n",
      "Epoch 2391, Loss 2.935596\n",
      "    Params:  tensor([  5.3146, -17.0040])\n",
      "    Grad  :  tensor([-0.0090,  0.0512])\n",
      "Epoch 2392,Loss 2.935571\n",
      "Epoch 2392, Loss 2.935571\n",
      "    Params:  tensor([  5.3147, -17.0045])\n",
      "    Grad  :  tensor([-0.0090,  0.0511])\n",
      "Epoch 2393,Loss 2.935544\n",
      "Epoch 2393, Loss 2.935544\n",
      "    Params:  tensor([  5.3148, -17.0050])\n",
      "    Grad  :  tensor([-0.0090,  0.0510])\n",
      "Epoch 2394,Loss 2.935516\n",
      "Epoch 2394, Loss 2.935516\n",
      "    Params:  tensor([  5.3149, -17.0055])\n",
      "    Grad  :  tensor([-0.0090,  0.0509])\n",
      "Epoch 2395,Loss 2.935489\n",
      "Epoch 2395, Loss 2.935489\n",
      "    Params:  tensor([  5.3149, -17.0060])\n",
      "    Grad  :  tensor([-0.0090,  0.0508])\n",
      "Epoch 2396,Loss 2.935465\n",
      "Epoch 2396, Loss 2.935465\n",
      "    Params:  tensor([  5.3150, -17.0065])\n",
      "    Grad  :  tensor([-0.0090,  0.0507])\n",
      "Epoch 2397,Loss 2.935436\n",
      "Epoch 2397, Loss 2.935436\n",
      "    Params:  tensor([  5.3151, -17.0070])\n",
      "    Grad  :  tensor([-0.0090,  0.0507])\n",
      "Epoch 2398,Loss 2.935411\n",
      "Epoch 2398, Loss 2.935411\n",
      "    Params:  tensor([  5.3152, -17.0076])\n",
      "    Grad  :  tensor([-0.0089,  0.0506])\n",
      "Epoch 2399,Loss 2.935385\n",
      "Epoch 2399, Loss 2.935385\n",
      "    Params:  tensor([  5.3153, -17.0081])\n",
      "    Grad  :  tensor([-0.0089,  0.0505])\n",
      "Epoch 2400,Loss 2.935356\n",
      "Epoch 2400, Loss 2.935356\n",
      "    Params:  tensor([  5.3154, -17.0086])\n",
      "    Grad  :  tensor([-0.0089,  0.0504])\n",
      "Epoch 2401,Loss 2.935332\n",
      "Epoch 2401, Loss 2.935332\n",
      "    Params:  tensor([  5.3155, -17.0091])\n",
      "    Grad  :  tensor([-0.0089,  0.0503])\n",
      "Epoch 2402,Loss 2.935304\n",
      "Epoch 2402, Loss 2.935304\n",
      "    Params:  tensor([  5.3156, -17.0096])\n",
      "    Grad  :  tensor([-0.0089,  0.0502])\n",
      "Epoch 2403,Loss 2.935281\n",
      "Epoch 2403, Loss 2.935281\n",
      "    Params:  tensor([  5.3157, -17.0101])\n",
      "    Grad  :  tensor([-0.0088,  0.0502])\n",
      "Epoch 2404,Loss 2.935252\n",
      "Epoch 2404, Loss 2.935252\n",
      "    Params:  tensor([  5.3157, -17.0106])\n",
      "    Grad  :  tensor([-0.0088,  0.0501])\n",
      "Epoch 2405,Loss 2.935228\n",
      "Epoch 2405, Loss 2.935228\n",
      "    Params:  tensor([  5.3158, -17.0111])\n",
      "    Grad  :  tensor([-0.0088,  0.0500])\n",
      "Epoch 2406,Loss 2.935203\n",
      "Epoch 2406, Loss 2.935203\n",
      "    Params:  tensor([  5.3159, -17.0116])\n",
      "    Grad  :  tensor([-0.0088,  0.0499])\n",
      "Epoch 2407,Loss 2.935177\n",
      "Epoch 2407, Loss 2.935177\n",
      "    Params:  tensor([  5.3160, -17.0121])\n",
      "    Grad  :  tensor([-0.0088,  0.0498])\n",
      "Epoch 2408,Loss 2.935152\n",
      "Epoch 2408, Loss 2.935152\n",
      "    Params:  tensor([  5.3161, -17.0126])\n",
      "    Grad  :  tensor([-0.0088,  0.0497])\n",
      "Epoch 2409,Loss 2.935126\n",
      "Epoch 2409, Loss 2.935126\n",
      "    Params:  tensor([  5.3162, -17.0131])\n",
      "    Grad  :  tensor([-0.0088,  0.0496])\n",
      "Epoch 2410,Loss 2.935100\n",
      "Epoch 2410, Loss 2.935100\n",
      "    Params:  tensor([  5.3163, -17.0136])\n",
      "    Grad  :  tensor([-0.0088,  0.0496])\n",
      "Epoch 2411,Loss 2.935075\n",
      "Epoch 2411, Loss 2.935075\n",
      "    Params:  tensor([  5.3164, -17.0140])\n",
      "    Grad  :  tensor([-0.0087,  0.0495])\n",
      "Epoch 2412,Loss 2.935049\n",
      "Epoch 2412, Loss 2.935049\n",
      "    Params:  tensor([  5.3164, -17.0145])\n",
      "    Grad  :  tensor([-0.0087,  0.0494])\n",
      "Epoch 2413,Loss 2.935024\n",
      "Epoch 2413, Loss 2.935024\n",
      "    Params:  tensor([  5.3165, -17.0150])\n",
      "    Grad  :  tensor([-0.0087,  0.0493])\n",
      "Epoch 2414,Loss 2.935001\n",
      "Epoch 2414, Loss 2.935001\n",
      "    Params:  tensor([  5.3166, -17.0155])\n",
      "    Grad  :  tensor([-0.0087,  0.0492])\n",
      "Epoch 2415,Loss 2.934973\n",
      "Epoch 2415, Loss 2.934973\n",
      "    Params:  tensor([  5.3167, -17.0160])\n",
      "    Grad  :  tensor([-0.0087,  0.0491])\n",
      "Epoch 2416,Loss 2.934949\n",
      "Epoch 2416, Loss 2.934949\n",
      "    Params:  tensor([  5.3168, -17.0165])\n",
      "    Grad  :  tensor([-0.0087,  0.0491])\n",
      "Epoch 2417,Loss 2.934925\n",
      "Epoch 2417, Loss 2.934925\n",
      "    Params:  tensor([  5.3169, -17.0170])\n",
      "    Grad  :  tensor([-0.0086,  0.0490])\n",
      "Epoch 2418,Loss 2.934899\n",
      "Epoch 2418, Loss 2.934899\n",
      "    Params:  tensor([  5.3170, -17.0175])\n",
      "    Grad  :  tensor([-0.0086,  0.0489])\n",
      "Epoch 2419,Loss 2.934876\n",
      "Epoch 2419, Loss 2.934876\n",
      "    Params:  tensor([  5.3171, -17.0180])\n",
      "    Grad  :  tensor([-0.0086,  0.0488])\n",
      "Epoch 2420,Loss 2.934853\n",
      "Epoch 2420, Loss 2.934853\n",
      "    Params:  tensor([  5.3171, -17.0185])\n",
      "    Grad  :  tensor([-0.0086,  0.0487])\n",
      "Epoch 2421,Loss 2.934826\n",
      "Epoch 2421, Loss 2.934826\n",
      "    Params:  tensor([  5.3172, -17.0189])\n",
      "    Grad  :  tensor([-0.0086,  0.0486])\n",
      "Epoch 2422,Loss 2.934802\n",
      "Epoch 2422, Loss 2.934802\n",
      "    Params:  tensor([  5.3173, -17.0194])\n",
      "    Grad  :  tensor([-0.0086,  0.0486])\n",
      "Epoch 2423,Loss 2.934777\n",
      "Epoch 2423, Loss 2.934777\n",
      "    Params:  tensor([  5.3174, -17.0199])\n",
      "    Grad  :  tensor([-0.0086,  0.0485])\n",
      "Epoch 2424,Loss 2.934753\n",
      "Epoch 2424, Loss 2.934753\n",
      "    Params:  tensor([  5.3175, -17.0204])\n",
      "    Grad  :  tensor([-0.0086,  0.0484])\n",
      "Epoch 2425,Loss 2.934730\n",
      "Epoch 2425, Loss 2.934730\n",
      "    Params:  tensor([  5.3176, -17.0209])\n",
      "    Grad  :  tensor([-0.0086,  0.0483])\n",
      "Epoch 2426,Loss 2.934705\n",
      "Epoch 2426, Loss 2.934705\n",
      "    Params:  tensor([  5.3177, -17.0214])\n",
      "    Grad  :  tensor([-0.0085,  0.0482])\n",
      "Epoch 2427,Loss 2.934681\n",
      "Epoch 2427, Loss 2.934681\n",
      "    Params:  tensor([  5.3177, -17.0219])\n",
      "    Grad  :  tensor([-0.0085,  0.0481])\n",
      "Epoch 2428,Loss 2.934658\n",
      "Epoch 2428, Loss 2.934658\n",
      "    Params:  tensor([  5.3178, -17.0223])\n",
      "    Grad  :  tensor([-0.0085,  0.0481])\n",
      "Epoch 2429,Loss 2.934635\n",
      "Epoch 2429, Loss 2.934635\n",
      "    Params:  tensor([  5.3179, -17.0228])\n",
      "    Grad  :  tensor([-0.0085,  0.0480])\n",
      "Epoch 2430,Loss 2.934609\n",
      "Epoch 2430, Loss 2.934609\n",
      "    Params:  tensor([  5.3180, -17.0233])\n",
      "    Grad  :  tensor([-0.0085,  0.0479])\n",
      "Epoch 2431,Loss 2.934585\n",
      "Epoch 2431, Loss 2.934585\n",
      "    Params:  tensor([  5.3181, -17.0238])\n",
      "    Grad  :  tensor([-0.0084,  0.0478])\n",
      "Epoch 2432,Loss 2.934563\n",
      "Epoch 2432, Loss 2.934563\n",
      "    Params:  tensor([  5.3182, -17.0242])\n",
      "    Grad  :  tensor([-0.0084,  0.0477])\n",
      "Epoch 2433,Loss 2.934541\n",
      "Epoch 2433, Loss 2.934541\n",
      "    Params:  tensor([  5.3182, -17.0247])\n",
      "    Grad  :  tensor([-0.0084,  0.0477])\n",
      "Epoch 2434,Loss 2.934516\n",
      "Epoch 2434, Loss 2.934516\n",
      "    Params:  tensor([  5.3183, -17.0252])\n",
      "    Grad  :  tensor([-0.0084,  0.0476])\n",
      "Epoch 2435,Loss 2.934493\n",
      "Epoch 2435, Loss 2.934493\n",
      "    Params:  tensor([  5.3184, -17.0257])\n",
      "    Grad  :  tensor([-0.0084,  0.0475])\n",
      "Epoch 2436,Loss 2.934469\n",
      "Epoch 2436, Loss 2.934469\n",
      "    Params:  tensor([  5.3185, -17.0261])\n",
      "    Grad  :  tensor([-0.0084,  0.0474])\n",
      "Epoch 2437,Loss 2.934446\n",
      "Epoch 2437, Loss 2.934446\n",
      "    Params:  tensor([  5.3186, -17.0266])\n",
      "    Grad  :  tensor([-0.0084,  0.0473])\n",
      "Epoch 2438,Loss 2.934423\n",
      "Epoch 2438, Loss 2.934423\n",
      "    Params:  tensor([  5.3187, -17.0271])\n",
      "    Grad  :  tensor([-0.0083,  0.0473])\n",
      "Epoch 2439,Loss 2.934400\n",
      "Epoch 2439, Loss 2.934400\n",
      "    Params:  tensor([  5.3187, -17.0276])\n",
      "    Grad  :  tensor([-0.0083,  0.0472])\n",
      "Epoch 2440,Loss 2.934377\n",
      "Epoch 2440, Loss 2.934377\n",
      "    Params:  tensor([  5.3188, -17.0280])\n",
      "    Grad  :  tensor([-0.0083,  0.0471])\n",
      "Epoch 2441,Loss 2.934355\n",
      "Epoch 2441, Loss 2.934355\n",
      "    Params:  tensor([  5.3189, -17.0285])\n",
      "    Grad  :  tensor([-0.0083,  0.0470])\n",
      "Epoch 2442,Loss 2.934331\n",
      "Epoch 2442, Loss 2.934331\n",
      "    Params:  tensor([  5.3190, -17.0290])\n",
      "    Grad  :  tensor([-0.0083,  0.0469])\n",
      "Epoch 2443,Loss 2.934309\n",
      "Epoch 2443, Loss 2.934309\n",
      "    Params:  tensor([  5.3191, -17.0294])\n",
      "    Grad  :  tensor([-0.0083,  0.0469])\n",
      "Epoch 2444,Loss 2.934287\n",
      "Epoch 2444, Loss 2.934287\n",
      "    Params:  tensor([  5.3192, -17.0299])\n",
      "    Grad  :  tensor([-0.0083,  0.0468])\n",
      "Epoch 2445,Loss 2.934264\n",
      "Epoch 2445, Loss 2.934264\n",
      "    Params:  tensor([  5.3192, -17.0304])\n",
      "    Grad  :  tensor([-0.0083,  0.0467])\n",
      "Epoch 2446,Loss 2.934242\n",
      "Epoch 2446, Loss 2.934242\n",
      "    Params:  tensor([  5.3193, -17.0308])\n",
      "    Grad  :  tensor([-0.0083,  0.0466])\n",
      "Epoch 2447,Loss 2.934219\n",
      "Epoch 2447, Loss 2.934219\n",
      "    Params:  tensor([  5.3194, -17.0313])\n",
      "    Grad  :  tensor([-0.0082,  0.0465])\n",
      "Epoch 2448,Loss 2.934198\n",
      "Epoch 2448, Loss 2.934198\n",
      "    Params:  tensor([  5.3195, -17.0318])\n",
      "    Grad  :  tensor([-0.0082,  0.0465])\n",
      "Epoch 2449,Loss 2.934175\n",
      "Epoch 2449, Loss 2.934175\n",
      "    Params:  tensor([  5.3196, -17.0322])\n",
      "    Grad  :  tensor([-0.0082,  0.0464])\n",
      "Epoch 2450,Loss 2.934151\n",
      "Epoch 2450, Loss 2.934151\n",
      "    Params:  tensor([  5.3197, -17.0327])\n",
      "    Grad  :  tensor([-0.0082,  0.0463])\n",
      "Epoch 2451,Loss 2.934129\n",
      "Epoch 2451, Loss 2.934129\n",
      "    Params:  tensor([  5.3197, -17.0332])\n",
      "    Grad  :  tensor([-0.0082,  0.0462])\n",
      "Epoch 2452,Loss 2.934108\n",
      "Epoch 2452, Loss 2.934108\n",
      "    Params:  tensor([  5.3198, -17.0336])\n",
      "    Grad  :  tensor([-0.0082,  0.0461])\n",
      "Epoch 2453,Loss 2.934084\n",
      "Epoch 2453, Loss 2.934084\n",
      "    Params:  tensor([  5.3199, -17.0341])\n",
      "    Grad  :  tensor([-0.0081,  0.0461])\n",
      "Epoch 2454,Loss 2.934065\n",
      "Epoch 2454, Loss 2.934065\n",
      "    Params:  tensor([  5.3200, -17.0345])\n",
      "    Grad  :  tensor([-0.0081,  0.0460])\n",
      "Epoch 2455,Loss 2.934043\n",
      "Epoch 2455, Loss 2.934043\n",
      "    Params:  tensor([  5.3201, -17.0350])\n",
      "    Grad  :  tensor([-0.0081,  0.0459])\n",
      "Epoch 2456,Loss 2.934020\n",
      "Epoch 2456, Loss 2.934020\n",
      "    Params:  tensor([  5.3201, -17.0355])\n",
      "    Grad  :  tensor([-0.0081,  0.0458])\n",
      "Epoch 2457,Loss 2.934000\n",
      "Epoch 2457, Loss 2.934000\n",
      "    Params:  tensor([  5.3202, -17.0359])\n",
      "    Grad  :  tensor([-0.0081,  0.0457])\n",
      "Epoch 2458,Loss 2.933978\n",
      "Epoch 2458, Loss 2.933978\n",
      "    Params:  tensor([  5.3203, -17.0364])\n",
      "    Grad  :  tensor([-0.0081,  0.0457])\n",
      "Epoch 2459,Loss 2.933956\n",
      "Epoch 2459, Loss 2.933956\n",
      "    Params:  tensor([  5.3204, -17.0368])\n",
      "    Grad  :  tensor([-0.0080,  0.0456])\n",
      "Epoch 2460,Loss 2.933935\n",
      "Epoch 2460, Loss 2.933935\n",
      "    Params:  tensor([  5.3205, -17.0373])\n",
      "    Grad  :  tensor([-0.0080,  0.0455])\n",
      "Epoch 2461,Loss 2.933914\n",
      "Epoch 2461, Loss 2.933914\n",
      "    Params:  tensor([  5.3205, -17.0377])\n",
      "    Grad  :  tensor([-0.0080,  0.0454])\n",
      "Epoch 2462,Loss 2.933893\n",
      "Epoch 2462, Loss 2.933893\n",
      "    Params:  tensor([  5.3206, -17.0382])\n",
      "    Grad  :  tensor([-0.0080,  0.0454])\n",
      "Epoch 2463,Loss 2.933871\n",
      "Epoch 2463, Loss 2.933871\n",
      "    Params:  tensor([  5.3207, -17.0386])\n",
      "    Grad  :  tensor([-0.0080,  0.0453])\n",
      "Epoch 2464,Loss 2.933849\n",
      "Epoch 2464, Loss 2.933849\n",
      "    Params:  tensor([  5.3208, -17.0391])\n",
      "    Grad  :  tensor([-0.0080,  0.0452])\n",
      "Epoch 2465,Loss 2.933828\n",
      "Epoch 2465, Loss 2.933828\n",
      "    Params:  tensor([  5.3209, -17.0396])\n",
      "    Grad  :  tensor([-0.0080,  0.0451])\n",
      "Epoch 2466,Loss 2.933807\n",
      "Epoch 2466, Loss 2.933807\n",
      "    Params:  tensor([  5.3209, -17.0400])\n",
      "    Grad  :  tensor([-0.0080,  0.0451])\n",
      "Epoch 2467,Loss 2.933787\n",
      "Epoch 2467, Loss 2.933787\n",
      "    Params:  tensor([  5.3210, -17.0405])\n",
      "    Grad  :  tensor([-0.0079,  0.0450])\n",
      "Epoch 2468,Loss 2.933767\n",
      "Epoch 2468, Loss 2.933767\n",
      "    Params:  tensor([  5.3211, -17.0409])\n",
      "    Grad  :  tensor([-0.0079,  0.0449])\n",
      "Epoch 2469,Loss 2.933746\n",
      "Epoch 2469, Loss 2.933746\n",
      "    Params:  tensor([  5.3212, -17.0413])\n",
      "    Grad  :  tensor([-0.0079,  0.0448])\n",
      "Epoch 2470,Loss 2.933723\n",
      "Epoch 2470, Loss 2.933723\n",
      "    Params:  tensor([  5.3213, -17.0418])\n",
      "    Grad  :  tensor([-0.0079,  0.0448])\n",
      "Epoch 2471,Loss 2.933704\n",
      "Epoch 2471, Loss 2.933704\n",
      "    Params:  tensor([  5.3213, -17.0422])\n",
      "    Grad  :  tensor([-0.0079,  0.0447])\n",
      "Epoch 2472,Loss 2.933682\n",
      "Epoch 2472, Loss 2.933682\n",
      "    Params:  tensor([  5.3214, -17.0427])\n",
      "    Grad  :  tensor([-0.0079,  0.0446])\n",
      "Epoch 2473,Loss 2.933662\n",
      "Epoch 2473, Loss 2.933662\n",
      "    Params:  tensor([  5.3215, -17.0431])\n",
      "    Grad  :  tensor([-0.0079,  0.0445])\n",
      "Epoch 2474,Loss 2.933643\n",
      "Epoch 2474, Loss 2.933643\n",
      "    Params:  tensor([  5.3216, -17.0436])\n",
      "    Grad  :  tensor([-0.0079,  0.0444])\n",
      "Epoch 2475,Loss 2.933622\n",
      "Epoch 2475, Loss 2.933622\n",
      "    Params:  tensor([  5.3217, -17.0440])\n",
      "    Grad  :  tensor([-0.0078,  0.0444])\n",
      "Epoch 2476,Loss 2.933602\n",
      "Epoch 2476, Loss 2.933602\n",
      "    Params:  tensor([  5.3217, -17.0445])\n",
      "    Grad  :  tensor([-0.0078,  0.0443])\n",
      "Epoch 2477,Loss 2.933583\n",
      "Epoch 2477, Loss 2.933583\n",
      "    Params:  tensor([  5.3218, -17.0449])\n",
      "    Grad  :  tensor([-0.0078,  0.0442])\n",
      "Epoch 2478,Loss 2.933561\n",
      "Epoch 2478, Loss 2.933561\n",
      "    Params:  tensor([  5.3219, -17.0453])\n",
      "    Grad  :  tensor([-0.0078,  0.0441])\n",
      "Epoch 2479,Loss 2.933541\n",
      "Epoch 2479, Loss 2.933541\n",
      "    Params:  tensor([  5.3220, -17.0458])\n",
      "    Grad  :  tensor([-0.0078,  0.0441])\n",
      "Epoch 2480,Loss 2.933521\n",
      "Epoch 2480, Loss 2.933521\n",
      "    Params:  tensor([  5.3220, -17.0462])\n",
      "    Grad  :  tensor([-0.0078,  0.0440])\n",
      "Epoch 2481,Loss 2.933501\n",
      "Epoch 2481, Loss 2.933501\n",
      "    Params:  tensor([  5.3221, -17.0467])\n",
      "    Grad  :  tensor([-0.0078,  0.0439])\n",
      "Epoch 2482,Loss 2.933480\n",
      "Epoch 2482, Loss 2.933480\n",
      "    Params:  tensor([  5.3222, -17.0471])\n",
      "    Grad  :  tensor([-0.0077,  0.0438])\n",
      "Epoch 2483,Loss 2.933463\n",
      "Epoch 2483, Loss 2.933463\n",
      "    Params:  tensor([  5.3223, -17.0475])\n",
      "    Grad  :  tensor([-0.0077,  0.0438])\n",
      "Epoch 2484,Loss 2.933442\n",
      "Epoch 2484, Loss 2.933442\n",
      "    Params:  tensor([  5.3224, -17.0480])\n",
      "    Grad  :  tensor([-0.0077,  0.0437])\n",
      "Epoch 2485,Loss 2.933422\n",
      "Epoch 2485, Loss 2.933422\n",
      "    Params:  tensor([  5.3224, -17.0484])\n",
      "    Grad  :  tensor([-0.0077,  0.0436])\n",
      "Epoch 2486,Loss 2.933403\n",
      "Epoch 2486, Loss 2.933403\n",
      "    Params:  tensor([  5.3225, -17.0489])\n",
      "    Grad  :  tensor([-0.0077,  0.0436])\n",
      "Epoch 2487,Loss 2.933382\n",
      "Epoch 2487, Loss 2.933382\n",
      "    Params:  tensor([  5.3226, -17.0493])\n",
      "    Grad  :  tensor([-0.0077,  0.0435])\n",
      "Epoch 2488,Loss 2.933365\n",
      "Epoch 2488, Loss 2.933365\n",
      "    Params:  tensor([  5.3227, -17.0497])\n",
      "    Grad  :  tensor([-0.0077,  0.0434])\n",
      "Epoch 2489,Loss 2.933345\n",
      "Epoch 2489, Loss 2.933345\n",
      "    Params:  tensor([  5.3227, -17.0502])\n",
      "    Grad  :  tensor([-0.0077,  0.0433])\n",
      "Epoch 2490,Loss 2.933325\n",
      "Epoch 2490, Loss 2.933325\n",
      "    Params:  tensor([  5.3228, -17.0506])\n",
      "    Grad  :  tensor([-0.0076,  0.0433])\n",
      "Epoch 2491,Loss 2.933306\n",
      "Epoch 2491, Loss 2.933306\n",
      "    Params:  tensor([  5.3229, -17.0510])\n",
      "    Grad  :  tensor([-0.0076,  0.0432])\n",
      "Epoch 2492,Loss 2.933287\n",
      "Epoch 2492, Loss 2.933287\n",
      "    Params:  tensor([  5.3230, -17.0515])\n",
      "    Grad  :  tensor([-0.0076,  0.0431])\n",
      "Epoch 2493,Loss 2.933266\n",
      "Epoch 2493, Loss 2.933266\n",
      "    Params:  tensor([  5.3230, -17.0519])\n",
      "    Grad  :  tensor([-0.0076,  0.0430])\n",
      "Epoch 2494,Loss 2.933249\n",
      "Epoch 2494, Loss 2.933249\n",
      "    Params:  tensor([  5.3231, -17.0523])\n",
      "    Grad  :  tensor([-0.0076,  0.0430])\n",
      "Epoch 2495,Loss 2.933229\n",
      "Epoch 2495, Loss 2.933229\n",
      "    Params:  tensor([  5.3232, -17.0527])\n",
      "    Grad  :  tensor([-0.0076,  0.0429])\n",
      "Epoch 2496,Loss 2.933209\n",
      "Epoch 2496, Loss 2.933209\n",
      "    Params:  tensor([  5.3233, -17.0532])\n",
      "    Grad  :  tensor([-0.0076,  0.0428])\n",
      "Epoch 2497,Loss 2.933190\n",
      "Epoch 2497, Loss 2.933190\n",
      "    Params:  tensor([  5.3233, -17.0536])\n",
      "    Grad  :  tensor([-0.0075,  0.0427])\n",
      "Epoch 2498,Loss 2.933172\n",
      "Epoch 2498, Loss 2.933172\n",
      "    Params:  tensor([  5.3234, -17.0540])\n",
      "    Grad  :  tensor([-0.0075,  0.0427])\n",
      "Epoch 2499,Loss 2.933154\n",
      "Epoch 2499, Loss 2.933154\n",
      "    Params:  tensor([  5.3235, -17.0544])\n",
      "    Grad  :  tensor([-0.0075,  0.0426])\n",
      "Epoch 2500,Loss 2.933134\n",
      "Epoch 2500, Loss 2.933134\n",
      "    Params:  tensor([  5.3236, -17.0549])\n",
      "    Grad  :  tensor([-0.0075,  0.0425])\n",
      "Epoch 2501,Loss 2.933116\n",
      "Epoch 2501, Loss 2.933116\n",
      "    Params:  tensor([  5.3236, -17.0553])\n",
      "    Grad  :  tensor([-0.0075,  0.0425])\n",
      "Epoch 2502,Loss 2.933097\n",
      "Epoch 2502, Loss 2.933097\n",
      "    Params:  tensor([  5.3237, -17.0557])\n",
      "    Grad  :  tensor([-0.0075,  0.0424])\n",
      "Epoch 2503,Loss 2.933079\n",
      "Epoch 2503, Loss 2.933079\n",
      "    Params:  tensor([  5.3238, -17.0561])\n",
      "    Grad  :  tensor([-0.0075,  0.0423])\n",
      "Epoch 2504,Loss 2.933060\n",
      "Epoch 2504, Loss 2.933060\n",
      "    Params:  tensor([  5.3239, -17.0566])\n",
      "    Grad  :  tensor([-0.0075,  0.0422])\n",
      "Epoch 2505,Loss 2.933043\n",
      "Epoch 2505, Loss 2.933043\n",
      "    Params:  tensor([  5.3239, -17.0570])\n",
      "    Grad  :  tensor([-0.0074,  0.0422])\n",
      "Epoch 2506,Loss 2.933025\n",
      "Epoch 2506, Loss 2.933025\n",
      "    Params:  tensor([  5.3240, -17.0574])\n",
      "    Grad  :  tensor([-0.0074,  0.0421])\n",
      "Epoch 2507,Loss 2.933007\n",
      "Epoch 2507, Loss 2.933007\n",
      "    Params:  tensor([  5.3241, -17.0578])\n",
      "    Grad  :  tensor([-0.0074,  0.0420])\n",
      "Epoch 2508,Loss 2.932988\n",
      "Epoch 2508, Loss 2.932988\n",
      "    Params:  tensor([  5.3242, -17.0582])\n",
      "    Grad  :  tensor([-0.0074,  0.0420])\n",
      "Epoch 2509,Loss 2.932970\n",
      "Epoch 2509, Loss 2.932970\n",
      "    Params:  tensor([  5.3242, -17.0587])\n",
      "    Grad  :  tensor([-0.0074,  0.0419])\n",
      "Epoch 2510,Loss 2.932952\n",
      "Epoch 2510, Loss 2.932952\n",
      "    Params:  tensor([  5.3243, -17.0591])\n",
      "    Grad  :  tensor([-0.0074,  0.0418])\n",
      "Epoch 2511,Loss 2.932932\n",
      "Epoch 2511, Loss 2.932932\n",
      "    Params:  tensor([  5.3244, -17.0595])\n",
      "    Grad  :  tensor([-0.0074,  0.0417])\n",
      "Epoch 2512,Loss 2.932915\n",
      "Epoch 2512, Loss 2.932915\n",
      "    Params:  tensor([  5.3245, -17.0599])\n",
      "    Grad  :  tensor([-0.0073,  0.0417])\n",
      "Epoch 2513,Loss 2.932898\n",
      "Epoch 2513, Loss 2.932898\n",
      "    Params:  tensor([  5.3245, -17.0603])\n",
      "    Grad  :  tensor([-0.0073,  0.0416])\n",
      "Epoch 2514,Loss 2.932880\n",
      "Epoch 2514, Loss 2.932880\n",
      "    Params:  tensor([  5.3246, -17.0608])\n",
      "    Grad  :  tensor([-0.0073,  0.0415])\n",
      "Epoch 2515,Loss 2.932862\n",
      "Epoch 2515, Loss 2.932862\n",
      "    Params:  tensor([  5.3247, -17.0612])\n",
      "    Grad  :  tensor([-0.0073,  0.0415])\n",
      "Epoch 2516,Loss 2.932846\n",
      "Epoch 2516, Loss 2.932846\n",
      "    Params:  tensor([  5.3248, -17.0616])\n",
      "    Grad  :  tensor([-0.0073,  0.0414])\n",
      "Epoch 2517,Loss 2.932826\n",
      "Epoch 2517, Loss 2.932826\n",
      "    Params:  tensor([  5.3248, -17.0620])\n",
      "    Grad  :  tensor([-0.0073,  0.0413])\n",
      "Epoch 2518,Loss 2.932810\n",
      "Epoch 2518, Loss 2.932810\n",
      "    Params:  tensor([  5.3249, -17.0624])\n",
      "    Grad  :  tensor([-0.0073,  0.0412])\n",
      "Epoch 2519,Loss 2.932790\n",
      "Epoch 2519, Loss 2.932790\n",
      "    Params:  tensor([  5.3250, -17.0628])\n",
      "    Grad  :  tensor([-0.0073,  0.0412])\n",
      "Epoch 2520,Loss 2.932774\n",
      "Epoch 2520, Loss 2.932774\n",
      "    Params:  tensor([  5.3250, -17.0632])\n",
      "    Grad  :  tensor([-0.0073,  0.0411])\n",
      "Epoch 2521,Loss 2.932758\n",
      "Epoch 2521, Loss 2.932758\n",
      "    Params:  tensor([  5.3251, -17.0636])\n",
      "    Grad  :  tensor([-0.0073,  0.0410])\n",
      "Epoch 2522,Loss 2.932739\n",
      "Epoch 2522, Loss 2.932739\n",
      "    Params:  tensor([  5.3252, -17.0640])\n",
      "    Grad  :  tensor([-0.0073,  0.0410])\n",
      "Epoch 2523,Loss 2.932723\n",
      "Epoch 2523, Loss 2.932723\n",
      "    Params:  tensor([  5.3253, -17.0645])\n",
      "    Grad  :  tensor([-0.0072,  0.0409])\n",
      "Epoch 2524,Loss 2.932706\n",
      "Epoch 2524, Loss 2.932706\n",
      "    Params:  tensor([  5.3253, -17.0649])\n",
      "    Grad  :  tensor([-0.0072,  0.0408])\n",
      "Epoch 2525,Loss 2.932689\n",
      "Epoch 2525, Loss 2.932689\n",
      "    Params:  tensor([  5.3254, -17.0653])\n",
      "    Grad  :  tensor([-0.0072,  0.0408])\n",
      "Epoch 2526,Loss 2.932671\n",
      "Epoch 2526, Loss 2.932671\n",
      "    Params:  tensor([  5.3255, -17.0657])\n",
      "    Grad  :  tensor([-0.0072,  0.0407])\n",
      "Epoch 2527,Loss 2.932654\n",
      "Epoch 2527, Loss 2.932654\n",
      "    Params:  tensor([  5.3256, -17.0661])\n",
      "    Grad  :  tensor([-0.0072,  0.0406])\n",
      "Epoch 2528,Loss 2.932637\n",
      "Epoch 2528, Loss 2.932637\n",
      "    Params:  tensor([  5.3256, -17.0665])\n",
      "    Grad  :  tensor([-0.0072,  0.0405])\n",
      "Epoch 2529,Loss 2.932619\n",
      "Epoch 2529, Loss 2.932619\n",
      "    Params:  tensor([  5.3257, -17.0669])\n",
      "    Grad  :  tensor([-0.0072,  0.0405])\n",
      "Epoch 2530,Loss 2.932603\n",
      "Epoch 2530, Loss 2.932603\n",
      "    Params:  tensor([  5.3258, -17.0673])\n",
      "    Grad  :  tensor([-0.0071,  0.0404])\n",
      "Epoch 2531,Loss 2.932585\n",
      "Epoch 2531, Loss 2.932585\n",
      "    Params:  tensor([  5.3258, -17.0677])\n",
      "    Grad  :  tensor([-0.0071,  0.0403])\n",
      "Epoch 2532,Loss 2.932569\n",
      "Epoch 2532, Loss 2.932569\n",
      "    Params:  tensor([  5.3259, -17.0681])\n",
      "    Grad  :  tensor([-0.0071,  0.0403])\n",
      "Epoch 2533,Loss 2.932553\n",
      "Epoch 2533, Loss 2.932553\n",
      "    Params:  tensor([  5.3260, -17.0685])\n",
      "    Grad  :  tensor([-0.0071,  0.0402])\n",
      "Epoch 2534,Loss 2.932535\n",
      "Epoch 2534, Loss 2.932535\n",
      "    Params:  tensor([  5.3261, -17.0689])\n",
      "    Grad  :  tensor([-0.0071,  0.0401])\n",
      "Epoch 2535,Loss 2.932520\n",
      "Epoch 2535, Loss 2.932520\n",
      "    Params:  tensor([  5.3261, -17.0693])\n",
      "    Grad  :  tensor([-0.0071,  0.0401])\n",
      "Epoch 2536,Loss 2.932502\n",
      "Epoch 2536, Loss 2.932502\n",
      "    Params:  tensor([  5.3262, -17.0697])\n",
      "    Grad  :  tensor([-0.0071,  0.0400])\n",
      "Epoch 2537,Loss 2.932487\n",
      "Epoch 2537, Loss 2.932487\n",
      "    Params:  tensor([  5.3263, -17.0701])\n",
      "    Grad  :  tensor([-0.0071,  0.0399])\n",
      "Epoch 2538,Loss 2.932469\n",
      "Epoch 2538, Loss 2.932469\n",
      "    Params:  tensor([  5.3263, -17.0705])\n",
      "    Grad  :  tensor([-0.0070,  0.0399])\n",
      "Epoch 2539,Loss 2.932455\n",
      "Epoch 2539, Loss 2.932455\n",
      "    Params:  tensor([  5.3264, -17.0709])\n",
      "    Grad  :  tensor([-0.0070,  0.0398])\n",
      "Epoch 2540,Loss 2.932438\n",
      "Epoch 2540, Loss 2.932438\n",
      "    Params:  tensor([  5.3265, -17.0713])\n",
      "    Grad  :  tensor([-0.0070,  0.0397])\n",
      "Epoch 2541,Loss 2.932421\n",
      "Epoch 2541, Loss 2.932421\n",
      "    Params:  tensor([  5.3265, -17.0717])\n",
      "    Grad  :  tensor([-0.0070,  0.0397])\n",
      "Epoch 2542,Loss 2.932404\n",
      "Epoch 2542, Loss 2.932404\n",
      "    Params:  tensor([  5.3266, -17.0721])\n",
      "    Grad  :  tensor([-0.0070,  0.0396])\n",
      "Epoch 2543,Loss 2.932387\n",
      "Epoch 2543, Loss 2.932387\n",
      "    Params:  tensor([  5.3267, -17.0725])\n",
      "    Grad  :  tensor([-0.0070,  0.0395])\n",
      "Epoch 2544,Loss 2.932371\n",
      "Epoch 2544, Loss 2.932371\n",
      "    Params:  tensor([  5.3268, -17.0729])\n",
      "    Grad  :  tensor([-0.0070,  0.0395])\n",
      "Epoch 2545,Loss 2.932358\n",
      "Epoch 2545, Loss 2.932358\n",
      "    Params:  tensor([  5.3268, -17.0733])\n",
      "    Grad  :  tensor([-0.0070,  0.0394])\n",
      "Epoch 2546,Loss 2.932340\n",
      "Epoch 2546, Loss 2.932340\n",
      "    Params:  tensor([  5.3269, -17.0737])\n",
      "    Grad  :  tensor([-0.0069,  0.0393])\n",
      "Epoch 2547,Loss 2.932324\n",
      "Epoch 2547, Loss 2.932324\n",
      "    Params:  tensor([  5.3270, -17.0741])\n",
      "    Grad  :  tensor([-0.0069,  0.0393])\n",
      "Epoch 2548,Loss 2.932310\n",
      "Epoch 2548, Loss 2.932310\n",
      "    Params:  tensor([  5.3270, -17.0745])\n",
      "    Grad  :  tensor([-0.0069,  0.0392])\n",
      "Epoch 2549,Loss 2.932293\n",
      "Epoch 2549, Loss 2.932293\n",
      "    Params:  tensor([  5.3271, -17.0749])\n",
      "    Grad  :  tensor([-0.0069,  0.0391])\n",
      "Epoch 2550,Loss 2.932277\n",
      "Epoch 2550, Loss 2.932277\n",
      "    Params:  tensor([  5.3272, -17.0752])\n",
      "    Grad  :  tensor([-0.0069,  0.0391])\n",
      "Epoch 2551,Loss 2.932261\n",
      "Epoch 2551, Loss 2.932261\n",
      "    Params:  tensor([  5.3272, -17.0756])\n",
      "    Grad  :  tensor([-0.0069,  0.0390])\n",
      "Epoch 2552,Loss 2.932246\n",
      "Epoch 2552, Loss 2.932246\n",
      "    Params:  tensor([  5.3273, -17.0760])\n",
      "    Grad  :  tensor([-0.0069,  0.0389])\n",
      "Epoch 2553,Loss 2.932229\n",
      "Epoch 2553, Loss 2.932229\n",
      "    Params:  tensor([  5.3274, -17.0764])\n",
      "    Grad  :  tensor([-0.0069,  0.0389])\n",
      "Epoch 2554,Loss 2.932215\n",
      "Epoch 2554, Loss 2.932215\n",
      "    Params:  tensor([  5.3274, -17.0768])\n",
      "    Grad  :  tensor([-0.0069,  0.0388])\n",
      "Epoch 2555,Loss 2.932198\n",
      "Epoch 2555, Loss 2.932198\n",
      "    Params:  tensor([  5.3275, -17.0772])\n",
      "    Grad  :  tensor([-0.0068,  0.0387])\n",
      "Epoch 2556,Loss 2.932183\n",
      "Epoch 2556, Loss 2.932183\n",
      "    Params:  tensor([  5.3276, -17.0776])\n",
      "    Grad  :  tensor([-0.0068,  0.0387])\n",
      "Epoch 2557,Loss 2.932167\n",
      "Epoch 2557, Loss 2.932167\n",
      "    Params:  tensor([  5.3276, -17.0780])\n",
      "    Grad  :  tensor([-0.0068,  0.0386])\n",
      "Epoch 2558,Loss 2.932153\n",
      "Epoch 2558, Loss 2.932153\n",
      "    Params:  tensor([  5.3277, -17.0783])\n",
      "    Grad  :  tensor([-0.0068,  0.0385])\n",
      "Epoch 2559,Loss 2.932137\n",
      "Epoch 2559, Loss 2.932137\n",
      "    Params:  tensor([  5.3278, -17.0787])\n",
      "    Grad  :  tensor([-0.0068,  0.0385])\n",
      "Epoch 2560,Loss 2.932122\n",
      "Epoch 2560, Loss 2.932122\n",
      "    Params:  tensor([  5.3279, -17.0791])\n",
      "    Grad  :  tensor([-0.0068,  0.0384])\n",
      "Epoch 2561,Loss 2.932107\n",
      "Epoch 2561, Loss 2.932107\n",
      "    Params:  tensor([  5.3279, -17.0795])\n",
      "    Grad  :  tensor([-0.0068,  0.0383])\n",
      "Epoch 2562,Loss 2.932092\n",
      "Epoch 2562, Loss 2.932092\n",
      "    Params:  tensor([  5.3280, -17.0799])\n",
      "    Grad  :  tensor([-0.0068,  0.0383])\n",
      "Epoch 2563,Loss 2.932076\n",
      "Epoch 2563, Loss 2.932076\n",
      "    Params:  tensor([  5.3281, -17.0803])\n",
      "    Grad  :  tensor([-0.0067,  0.0382])\n",
      "Epoch 2564,Loss 2.932061\n",
      "Epoch 2564, Loss 2.932061\n",
      "    Params:  tensor([  5.3281, -17.0806])\n",
      "    Grad  :  tensor([-0.0067,  0.0381])\n",
      "Epoch 2565,Loss 2.932047\n",
      "Epoch 2565, Loss 2.932047\n",
      "    Params:  tensor([  5.3282, -17.0810])\n",
      "    Grad  :  tensor([-0.0067,  0.0381])\n",
      "Epoch 2566,Loss 2.932031\n",
      "Epoch 2566, Loss 2.932031\n",
      "    Params:  tensor([  5.3283, -17.0814])\n",
      "    Grad  :  tensor([-0.0067,  0.0380])\n",
      "Epoch 2567,Loss 2.932017\n",
      "Epoch 2567, Loss 2.932017\n",
      "    Params:  tensor([  5.3283, -17.0818])\n",
      "    Grad  :  tensor([-0.0067,  0.0379])\n",
      "Epoch 2568,Loss 2.932002\n",
      "Epoch 2568, Loss 2.932002\n",
      "    Params:  tensor([  5.3284, -17.0822])\n",
      "    Grad  :  tensor([-0.0067,  0.0379])\n",
      "Epoch 2569,Loss 2.931986\n",
      "Epoch 2569, Loss 2.931986\n",
      "    Params:  tensor([  5.3285, -17.0825])\n",
      "    Grad  :  tensor([-0.0067,  0.0378])\n",
      "Epoch 2570,Loss 2.931972\n",
      "Epoch 2570, Loss 2.931972\n",
      "    Params:  tensor([  5.3285, -17.0829])\n",
      "    Grad  :  tensor([-0.0067,  0.0378])\n",
      "Epoch 2571,Loss 2.931957\n",
      "Epoch 2571, Loss 2.931957\n",
      "    Params:  tensor([  5.3286, -17.0833])\n",
      "    Grad  :  tensor([-0.0067,  0.0377])\n",
      "Epoch 2572,Loss 2.931941\n",
      "Epoch 2572, Loss 2.931941\n",
      "    Params:  tensor([  5.3287, -17.0837])\n",
      "    Grad  :  tensor([-0.0067,  0.0376])\n",
      "Epoch 2573,Loss 2.931929\n",
      "Epoch 2573, Loss 2.931929\n",
      "    Params:  tensor([  5.3287, -17.0840])\n",
      "    Grad  :  tensor([-0.0066,  0.0376])\n",
      "Epoch 2574,Loss 2.931914\n",
      "Epoch 2574, Loss 2.931914\n",
      "    Params:  tensor([  5.3288, -17.0844])\n",
      "    Grad  :  tensor([-0.0066,  0.0375])\n",
      "Epoch 2575,Loss 2.931900\n",
      "Epoch 2575, Loss 2.931900\n",
      "    Params:  tensor([  5.3289, -17.0848])\n",
      "    Grad  :  tensor([-0.0066,  0.0374])\n",
      "Epoch 2576,Loss 2.931885\n",
      "Epoch 2576, Loss 2.931885\n",
      "    Params:  tensor([  5.3289, -17.0852])\n",
      "    Grad  :  tensor([-0.0066,  0.0374])\n",
      "Epoch 2577,Loss 2.931870\n",
      "Epoch 2577, Loss 2.931870\n",
      "    Params:  tensor([  5.3290, -17.0855])\n",
      "    Grad  :  tensor([-0.0066,  0.0373])\n",
      "Epoch 2578,Loss 2.931855\n",
      "Epoch 2578, Loss 2.931855\n",
      "    Params:  tensor([  5.3291, -17.0859])\n",
      "    Grad  :  tensor([-0.0066,  0.0372])\n",
      "Epoch 2579,Loss 2.931842\n",
      "Epoch 2579, Loss 2.931842\n",
      "    Params:  tensor([  5.3291, -17.0863])\n",
      "    Grad  :  tensor([-0.0066,  0.0372])\n",
      "Epoch 2580,Loss 2.931828\n",
      "Epoch 2580, Loss 2.931828\n",
      "    Params:  tensor([  5.3292, -17.0867])\n",
      "    Grad  :  tensor([-0.0066,  0.0371])\n",
      "Epoch 2581,Loss 2.931813\n",
      "Epoch 2581, Loss 2.931813\n",
      "    Params:  tensor([  5.3293, -17.0870])\n",
      "    Grad  :  tensor([-0.0065,  0.0371])\n",
      "Epoch 2582,Loss 2.931799\n",
      "Epoch 2582, Loss 2.931799\n",
      "    Params:  tensor([  5.3293, -17.0874])\n",
      "    Grad  :  tensor([-0.0065,  0.0370])\n",
      "Epoch 2583,Loss 2.931786\n",
      "Epoch 2583, Loss 2.931786\n",
      "    Params:  tensor([  5.3294, -17.0878])\n",
      "    Grad  :  tensor([-0.0065,  0.0369])\n",
      "Epoch 2584,Loss 2.931771\n",
      "Epoch 2584, Loss 2.931771\n",
      "    Params:  tensor([  5.3294, -17.0881])\n",
      "    Grad  :  tensor([-0.0065,  0.0369])\n",
      "Epoch 2585,Loss 2.931759\n",
      "Epoch 2585, Loss 2.931759\n",
      "    Params:  tensor([  5.3295, -17.0885])\n",
      "    Grad  :  tensor([-0.0065,  0.0368])\n",
      "Epoch 2586,Loss 2.931742\n",
      "Epoch 2586, Loss 2.931742\n",
      "    Params:  tensor([  5.3296, -17.0889])\n",
      "    Grad  :  tensor([-0.0065,  0.0367])\n",
      "Epoch 2587,Loss 2.931729\n",
      "Epoch 2587, Loss 2.931729\n",
      "    Params:  tensor([  5.3296, -17.0892])\n",
      "    Grad  :  tensor([-0.0065,  0.0367])\n",
      "Epoch 2588,Loss 2.931717\n",
      "Epoch 2588, Loss 2.931717\n",
      "    Params:  tensor([  5.3297, -17.0896])\n",
      "    Grad  :  tensor([-0.0065,  0.0366])\n",
      "Epoch 2589,Loss 2.931701\n",
      "Epoch 2589, Loss 2.931701\n",
      "    Params:  tensor([  5.3298, -17.0900])\n",
      "    Grad  :  tensor([-0.0065,  0.0366])\n",
      "Epoch 2590,Loss 2.931687\n",
      "Epoch 2590, Loss 2.931687\n",
      "    Params:  tensor([  5.3298, -17.0903])\n",
      "    Grad  :  tensor([-0.0065,  0.0365])\n",
      "Epoch 2591,Loss 2.931674\n",
      "Epoch 2591, Loss 2.931674\n",
      "    Params:  tensor([  5.3299, -17.0907])\n",
      "    Grad  :  tensor([-0.0064,  0.0364])\n",
      "Epoch 2592,Loss 2.931660\n",
      "Epoch 2592, Loss 2.931660\n",
      "    Params:  tensor([  5.3300, -17.0911])\n",
      "    Grad  :  tensor([-0.0064,  0.0364])\n",
      "Epoch 2593,Loss 2.931648\n",
      "Epoch 2593, Loss 2.931648\n",
      "    Params:  tensor([  5.3300, -17.0914])\n",
      "    Grad  :  tensor([-0.0064,  0.0363])\n",
      "Epoch 2594,Loss 2.931632\n",
      "Epoch 2594, Loss 2.931632\n",
      "    Params:  tensor([  5.3301, -17.0918])\n",
      "    Grad  :  tensor([-0.0064,  0.0362])\n",
      "Epoch 2595,Loss 2.931619\n",
      "Epoch 2595, Loss 2.931619\n",
      "    Params:  tensor([  5.3302, -17.0921])\n",
      "    Grad  :  tensor([-0.0064,  0.0362])\n",
      "Epoch 2596,Loss 2.931606\n",
      "Epoch 2596, Loss 2.931606\n",
      "    Params:  tensor([  5.3302, -17.0925])\n",
      "    Grad  :  tensor([-0.0064,  0.0361])\n",
      "Epoch 2597,Loss 2.931593\n",
      "Epoch 2597, Loss 2.931593\n",
      "    Params:  tensor([  5.3303, -17.0929])\n",
      "    Grad  :  tensor([-0.0064,  0.0361])\n",
      "Epoch 2598,Loss 2.931580\n",
      "Epoch 2598, Loss 2.931580\n",
      "    Params:  tensor([  5.3303, -17.0932])\n",
      "    Grad  :  tensor([-0.0064,  0.0360])\n",
      "Epoch 2599,Loss 2.931566\n",
      "Epoch 2599, Loss 2.931566\n",
      "    Params:  tensor([  5.3304, -17.0936])\n",
      "    Grad  :  tensor([-0.0064,  0.0359])\n",
      "Epoch 2600,Loss 2.931554\n",
      "Epoch 2600, Loss 2.931554\n",
      "    Params:  tensor([  5.3305, -17.0939])\n",
      "    Grad  :  tensor([-0.0064,  0.0359])\n",
      "Epoch 2601,Loss 2.931538\n",
      "Epoch 2601, Loss 2.931538\n",
      "    Params:  tensor([  5.3305, -17.0943])\n",
      "    Grad  :  tensor([-0.0063,  0.0358])\n",
      "Epoch 2602,Loss 2.931526\n",
      "Epoch 2602, Loss 2.931526\n",
      "    Params:  tensor([  5.3306, -17.0947])\n",
      "    Grad  :  tensor([-0.0063,  0.0358])\n",
      "Epoch 2603,Loss 2.931512\n",
      "Epoch 2603, Loss 2.931512\n",
      "    Params:  tensor([  5.3307, -17.0950])\n",
      "    Grad  :  tensor([-0.0063,  0.0357])\n",
      "Epoch 2604,Loss 2.931499\n",
      "Epoch 2604, Loss 2.931499\n",
      "    Params:  tensor([  5.3307, -17.0954])\n",
      "    Grad  :  tensor([-0.0063,  0.0356])\n",
      "Epoch 2605,Loss 2.931488\n",
      "Epoch 2605, Loss 2.931488\n",
      "    Params:  tensor([  5.3308, -17.0957])\n",
      "    Grad  :  tensor([-0.0063,  0.0356])\n",
      "Epoch 2606,Loss 2.931474\n",
      "Epoch 2606, Loss 2.931474\n",
      "    Params:  tensor([  5.3309, -17.0961])\n",
      "    Grad  :  tensor([-0.0063,  0.0355])\n",
      "Epoch 2607,Loss 2.931462\n",
      "Epoch 2607, Loss 2.931462\n",
      "    Params:  tensor([  5.3309, -17.0964])\n",
      "    Grad  :  tensor([-0.0062,  0.0355])\n",
      "Epoch 2608,Loss 2.931448\n",
      "Epoch 2608, Loss 2.931448\n",
      "    Params:  tensor([  5.3310, -17.0968])\n",
      "    Grad  :  tensor([-0.0062,  0.0354])\n",
      "Epoch 2609,Loss 2.931436\n",
      "Epoch 2609, Loss 2.931436\n",
      "    Params:  tensor([  5.3310, -17.0971])\n",
      "    Grad  :  tensor([-0.0062,  0.0353])\n",
      "Epoch 2610,Loss 2.931423\n",
      "Epoch 2610, Loss 2.931423\n",
      "    Params:  tensor([  5.3311, -17.0975])\n",
      "    Grad  :  tensor([-0.0062,  0.0353])\n",
      "Epoch 2611,Loss 2.931411\n",
      "Epoch 2611, Loss 2.931411\n",
      "    Params:  tensor([  5.3312, -17.0979])\n",
      "    Grad  :  tensor([-0.0062,  0.0352])\n",
      "Epoch 2612,Loss 2.931397\n",
      "Epoch 2612, Loss 2.931397\n",
      "    Params:  tensor([  5.3312, -17.0982])\n",
      "    Grad  :  tensor([-0.0062,  0.0352])\n",
      "Epoch 2613,Loss 2.931384\n",
      "Epoch 2613, Loss 2.931384\n",
      "    Params:  tensor([  5.3313, -17.0986])\n",
      "    Grad  :  tensor([-0.0062,  0.0351])\n",
      "Epoch 2614,Loss 2.931371\n",
      "Epoch 2614, Loss 2.931371\n",
      "    Params:  tensor([  5.3313, -17.0989])\n",
      "    Grad  :  tensor([-0.0062,  0.0350])\n",
      "Epoch 2615,Loss 2.931358\n",
      "Epoch 2615, Loss 2.931358\n",
      "    Params:  tensor([  5.3314, -17.0993])\n",
      "    Grad  :  tensor([-0.0062,  0.0350])\n",
      "Epoch 2616,Loss 2.931346\n",
      "Epoch 2616, Loss 2.931346\n",
      "    Params:  tensor([  5.3315, -17.0996])\n",
      "    Grad  :  tensor([-0.0062,  0.0349])\n",
      "Epoch 2617,Loss 2.931335\n",
      "Epoch 2617, Loss 2.931335\n",
      "    Params:  tensor([  5.3315, -17.1000])\n",
      "    Grad  :  tensor([-0.0062,  0.0349])\n",
      "Epoch 2618,Loss 2.931322\n",
      "Epoch 2618, Loss 2.931322\n",
      "    Params:  tensor([  5.3316, -17.1003])\n",
      "    Grad  :  tensor([-0.0062,  0.0348])\n",
      "Epoch 2619,Loss 2.931308\n",
      "Epoch 2619, Loss 2.931308\n",
      "    Params:  tensor([  5.3317, -17.1006])\n",
      "    Grad  :  tensor([-0.0061,  0.0347])\n",
      "Epoch 2620,Loss 2.931296\n",
      "Epoch 2620, Loss 2.931296\n",
      "    Params:  tensor([  5.3317, -17.1010])\n",
      "    Grad  :  tensor([-0.0061,  0.0347])\n",
      "Epoch 2621,Loss 2.931282\n",
      "Epoch 2621, Loss 2.931282\n",
      "    Params:  tensor([  5.3318, -17.1013])\n",
      "    Grad  :  tensor([-0.0061,  0.0346])\n",
      "Epoch 2622,Loss 2.931272\n",
      "Epoch 2622, Loss 2.931272\n",
      "    Params:  tensor([  5.3318, -17.1017])\n",
      "    Grad  :  tensor([-0.0061,  0.0346])\n",
      "Epoch 2623,Loss 2.931258\n",
      "Epoch 2623, Loss 2.931258\n",
      "    Params:  tensor([  5.3319, -17.1020])\n",
      "    Grad  :  tensor([-0.0061,  0.0345])\n",
      "Epoch 2624,Loss 2.931245\n",
      "Epoch 2624, Loss 2.931245\n",
      "    Params:  tensor([  5.3320, -17.1024])\n",
      "    Grad  :  tensor([-0.0061,  0.0344])\n",
      "Epoch 2625,Loss 2.931234\n",
      "Epoch 2625, Loss 2.931234\n",
      "    Params:  tensor([  5.3320, -17.1027])\n",
      "    Grad  :  tensor([-0.0061,  0.0344])\n",
      "Epoch 2626,Loss 2.931222\n",
      "Epoch 2626, Loss 2.931222\n",
      "    Params:  tensor([  5.3321, -17.1031])\n",
      "    Grad  :  tensor([-0.0061,  0.0343])\n",
      "Epoch 2627,Loss 2.931211\n",
      "Epoch 2627, Loss 2.931211\n",
      "    Params:  tensor([  5.3321, -17.1034])\n",
      "    Grad  :  tensor([-0.0060,  0.0343])\n",
      "Epoch 2628,Loss 2.931196\n",
      "Epoch 2628, Loss 2.931196\n",
      "    Params:  tensor([  5.3322, -17.1038])\n",
      "    Grad  :  tensor([-0.0060,  0.0342])\n",
      "Epoch 2629,Loss 2.931185\n",
      "Epoch 2629, Loss 2.931185\n",
      "    Params:  tensor([  5.3323, -17.1041])\n",
      "    Grad  :  tensor([-0.0060,  0.0342])\n",
      "Epoch 2630,Loss 2.931173\n",
      "Epoch 2630, Loss 2.931173\n",
      "    Params:  tensor([  5.3323, -17.1044])\n",
      "    Grad  :  tensor([-0.0060,  0.0341])\n",
      "Epoch 2631,Loss 2.931162\n",
      "Epoch 2631, Loss 2.931162\n",
      "    Params:  tensor([  5.3324, -17.1048])\n",
      "    Grad  :  tensor([-0.0060,  0.0340])\n",
      "Epoch 2632,Loss 2.931149\n",
      "Epoch 2632, Loss 2.931149\n",
      "    Params:  tensor([  5.3324, -17.1051])\n",
      "    Grad  :  tensor([-0.0060,  0.0340])\n",
      "Epoch 2633,Loss 2.931138\n",
      "Epoch 2633, Loss 2.931138\n",
      "    Params:  tensor([  5.3325, -17.1055])\n",
      "    Grad  :  tensor([-0.0060,  0.0339])\n",
      "Epoch 2634,Loss 2.931126\n",
      "Epoch 2634, Loss 2.931126\n",
      "    Params:  tensor([  5.3326, -17.1058])\n",
      "    Grad  :  tensor([-0.0060,  0.0339])\n",
      "Epoch 2635,Loss 2.931114\n",
      "Epoch 2635, Loss 2.931114\n",
      "    Params:  tensor([  5.3326, -17.1061])\n",
      "    Grad  :  tensor([-0.0060,  0.0338])\n",
      "Epoch 2636,Loss 2.931101\n",
      "Epoch 2636, Loss 2.931101\n",
      "    Params:  tensor([  5.3327, -17.1065])\n",
      "    Grad  :  tensor([-0.0060,  0.0337])\n",
      "Epoch 2637,Loss 2.931090\n",
      "Epoch 2637, Loss 2.931090\n",
      "    Params:  tensor([  5.3327, -17.1068])\n",
      "    Grad  :  tensor([-0.0059,  0.0337])\n",
      "Epoch 2638,Loss 2.931079\n",
      "Epoch 2638, Loss 2.931079\n",
      "    Params:  tensor([  5.3328, -17.1071])\n",
      "    Grad  :  tensor([-0.0059,  0.0336])\n",
      "Epoch 2639,Loss 2.931067\n",
      "Epoch 2639, Loss 2.931067\n",
      "    Params:  tensor([  5.3329, -17.1075])\n",
      "    Grad  :  tensor([-0.0059,  0.0336])\n",
      "Epoch 2640,Loss 2.931054\n",
      "Epoch 2640, Loss 2.931054\n",
      "    Params:  tensor([  5.3329, -17.1078])\n",
      "    Grad  :  tensor([-0.0059,  0.0335])\n",
      "Epoch 2641,Loss 2.931044\n",
      "Epoch 2641, Loss 2.931044\n",
      "    Params:  tensor([  5.3330, -17.1081])\n",
      "    Grad  :  tensor([-0.0059,  0.0335])\n",
      "Epoch 2642,Loss 2.931034\n",
      "Epoch 2642, Loss 2.931034\n",
      "    Params:  tensor([  5.3330, -17.1085])\n",
      "    Grad  :  tensor([-0.0059,  0.0334])\n",
      "Epoch 2643,Loss 2.931021\n",
      "Epoch 2643, Loss 2.931021\n",
      "    Params:  tensor([  5.3331, -17.1088])\n",
      "    Grad  :  tensor([-0.0059,  0.0333])\n",
      "Epoch 2644,Loss 2.931010\n",
      "Epoch 2644, Loss 2.931010\n",
      "    Params:  tensor([  5.3332, -17.1091])\n",
      "    Grad  :  tensor([-0.0059,  0.0333])\n",
      "Epoch 2645,Loss 2.930999\n",
      "Epoch 2645, Loss 2.930999\n",
      "    Params:  tensor([  5.3332, -17.1095])\n",
      "    Grad  :  tensor([-0.0059,  0.0332])\n",
      "Epoch 2646,Loss 2.930987\n",
      "Epoch 2646, Loss 2.930987\n",
      "    Params:  tensor([  5.3333, -17.1098])\n",
      "    Grad  :  tensor([-0.0059,  0.0332])\n",
      "Epoch 2647,Loss 2.930976\n",
      "Epoch 2647, Loss 2.930976\n",
      "    Params:  tensor([  5.3333, -17.1101])\n",
      "    Grad  :  tensor([-0.0059,  0.0331])\n",
      "Epoch 2648,Loss 2.930964\n",
      "Epoch 2648, Loss 2.930964\n",
      "    Params:  tensor([  5.3334, -17.1105])\n",
      "    Grad  :  tensor([-0.0059,  0.0331])\n",
      "Epoch 2649,Loss 2.930953\n",
      "Epoch 2649, Loss 2.930953\n",
      "    Params:  tensor([  5.3335, -17.1108])\n",
      "    Grad  :  tensor([-0.0058,  0.0330])\n",
      "Epoch 2650,Loss 2.930941\n",
      "Epoch 2650, Loss 2.930941\n",
      "    Params:  tensor([  5.3335, -17.1111])\n",
      "    Grad  :  tensor([-0.0058,  0.0330])\n",
      "Epoch 2651,Loss 2.930932\n",
      "Epoch 2651, Loss 2.930932\n",
      "    Params:  tensor([  5.3336, -17.1115])\n",
      "    Grad  :  tensor([-0.0058,  0.0329])\n",
      "Epoch 2652,Loss 2.930921\n",
      "Epoch 2652, Loss 2.930921\n",
      "    Params:  tensor([  5.3336, -17.1118])\n",
      "    Grad  :  tensor([-0.0058,  0.0328])\n",
      "Epoch 2653,Loss 2.930908\n",
      "Epoch 2653, Loss 2.930908\n",
      "    Params:  tensor([  5.3337, -17.1121])\n",
      "    Grad  :  tensor([-0.0058,  0.0328])\n",
      "Epoch 2654,Loss 2.930899\n",
      "Epoch 2654, Loss 2.930899\n",
      "    Params:  tensor([  5.3337, -17.1124])\n",
      "    Grad  :  tensor([-0.0058,  0.0327])\n",
      "Epoch 2655,Loss 2.930885\n",
      "Epoch 2655, Loss 2.930885\n",
      "    Params:  tensor([  5.3338, -17.1128])\n",
      "    Grad  :  tensor([-0.0058,  0.0327])\n",
      "Epoch 2656,Loss 2.930876\n",
      "Epoch 2656, Loss 2.930876\n",
      "    Params:  tensor([  5.3339, -17.1131])\n",
      "    Grad  :  tensor([-0.0058,  0.0326])\n",
      "Epoch 2657,Loss 2.930863\n",
      "Epoch 2657, Loss 2.930863\n",
      "    Params:  tensor([  5.3339, -17.1134])\n",
      "    Grad  :  tensor([-0.0057,  0.0326])\n",
      "Epoch 2658,Loss 2.930854\n",
      "Epoch 2658, Loss 2.930854\n",
      "    Params:  tensor([  5.3340, -17.1137])\n",
      "    Grad  :  tensor([-0.0057,  0.0325])\n",
      "Epoch 2659,Loss 2.930841\n",
      "Epoch 2659, Loss 2.930841\n",
      "    Params:  tensor([  5.3340, -17.1141])\n",
      "    Grad  :  tensor([-0.0057,  0.0325])\n",
      "Epoch 2660,Loss 2.930833\n",
      "Epoch 2660, Loss 2.930833\n",
      "    Params:  tensor([  5.3341, -17.1144])\n",
      "    Grad  :  tensor([-0.0057,  0.0324])\n",
      "Epoch 2661,Loss 2.930821\n",
      "Epoch 2661, Loss 2.930821\n",
      "    Params:  tensor([  5.3341, -17.1147])\n",
      "    Grad  :  tensor([-0.0057,  0.0323])\n",
      "Epoch 2662,Loss 2.930811\n",
      "Epoch 2662, Loss 2.930811\n",
      "    Params:  tensor([  5.3342, -17.1150])\n",
      "    Grad  :  tensor([-0.0057,  0.0323])\n",
      "Epoch 2663,Loss 2.930801\n",
      "Epoch 2663, Loss 2.930801\n",
      "    Params:  tensor([  5.3343, -17.1154])\n",
      "    Grad  :  tensor([-0.0057,  0.0322])\n",
      "Epoch 2664,Loss 2.930788\n",
      "Epoch 2664, Loss 2.930788\n",
      "    Params:  tensor([  5.3343, -17.1157])\n",
      "    Grad  :  tensor([-0.0057,  0.0322])\n",
      "Epoch 2665,Loss 2.930778\n",
      "Epoch 2665, Loss 2.930778\n",
      "    Params:  tensor([  5.3344, -17.1160])\n",
      "    Grad  :  tensor([-0.0057,  0.0321])\n",
      "Epoch 2666,Loss 2.930767\n",
      "Epoch 2666, Loss 2.930767\n",
      "    Params:  tensor([  5.3344, -17.1163])\n",
      "    Grad  :  tensor([-0.0057,  0.0321])\n",
      "Epoch 2667,Loss 2.930757\n",
      "Epoch 2667, Loss 2.930757\n",
      "    Params:  tensor([  5.3345, -17.1166])\n",
      "    Grad  :  tensor([-0.0057,  0.0320])\n",
      "Epoch 2668,Loss 2.930746\n",
      "Epoch 2668, Loss 2.930746\n",
      "    Params:  tensor([  5.3345, -17.1170])\n",
      "    Grad  :  tensor([-0.0056,  0.0320])\n",
      "Epoch 2669,Loss 2.930736\n",
      "Epoch 2669, Loss 2.930736\n",
      "    Params:  tensor([  5.3346, -17.1173])\n",
      "    Grad  :  tensor([-0.0056,  0.0319])\n",
      "Epoch 2670,Loss 2.930724\n",
      "Epoch 2670, Loss 2.930724\n",
      "    Params:  tensor([  5.3347, -17.1176])\n",
      "    Grad  :  tensor([-0.0056,  0.0319])\n",
      "Epoch 2671,Loss 2.930715\n",
      "Epoch 2671, Loss 2.930715\n",
      "    Params:  tensor([  5.3347, -17.1179])\n",
      "    Grad  :  tensor([-0.0056,  0.0318])\n",
      "Epoch 2672,Loss 2.930704\n",
      "Epoch 2672, Loss 2.930704\n",
      "    Params:  tensor([  5.3348, -17.1182])\n",
      "    Grad  :  tensor([-0.0056,  0.0317])\n",
      "Epoch 2673,Loss 2.930694\n",
      "Epoch 2673, Loss 2.930694\n",
      "    Params:  tensor([  5.3348, -17.1186])\n",
      "    Grad  :  tensor([-0.0056,  0.0317])\n",
      "Epoch 2674,Loss 2.930685\n",
      "Epoch 2674, Loss 2.930685\n",
      "    Params:  tensor([  5.3349, -17.1189])\n",
      "    Grad  :  tensor([-0.0056,  0.0316])\n",
      "Epoch 2675,Loss 2.930674\n",
      "Epoch 2675, Loss 2.930674\n",
      "    Params:  tensor([  5.3349, -17.1192])\n",
      "    Grad  :  tensor([-0.0056,  0.0316])\n",
      "Epoch 2676,Loss 2.930663\n",
      "Epoch 2676, Loss 2.930663\n",
      "    Params:  tensor([  5.3350, -17.1195])\n",
      "    Grad  :  tensor([-0.0056,  0.0315])\n",
      "Epoch 2677,Loss 2.930654\n",
      "Epoch 2677, Loss 2.930654\n",
      "    Params:  tensor([  5.3350, -17.1198])\n",
      "    Grad  :  tensor([-0.0056,  0.0315])\n",
      "Epoch 2678,Loss 2.930644\n",
      "Epoch 2678, Loss 2.930644\n",
      "    Params:  tensor([  5.3351, -17.1201])\n",
      "    Grad  :  tensor([-0.0055,  0.0314])\n",
      "Epoch 2679,Loss 2.930631\n",
      "Epoch 2679, Loss 2.930631\n",
      "    Params:  tensor([  5.3352, -17.1204])\n",
      "    Grad  :  tensor([-0.0055,  0.0314])\n",
      "Epoch 2680,Loss 2.930621\n",
      "Epoch 2680, Loss 2.930621\n",
      "    Params:  tensor([  5.3352, -17.1208])\n",
      "    Grad  :  tensor([-0.0055,  0.0313])\n",
      "Epoch 2681,Loss 2.930613\n",
      "Epoch 2681, Loss 2.930613\n",
      "    Params:  tensor([  5.3353, -17.1211])\n",
      "    Grad  :  tensor([-0.0055,  0.0313])\n",
      "Epoch 2682,Loss 2.930603\n",
      "Epoch 2682, Loss 2.930603\n",
      "    Params:  tensor([  5.3353, -17.1214])\n",
      "    Grad  :  tensor([-0.0055,  0.0312])\n",
      "Epoch 2683,Loss 2.930593\n",
      "Epoch 2683, Loss 2.930593\n",
      "    Params:  tensor([  5.3354, -17.1217])\n",
      "    Grad  :  tensor([-0.0055,  0.0312])\n",
      "Epoch 2684,Loss 2.930582\n",
      "Epoch 2684, Loss 2.930582\n",
      "    Params:  tensor([  5.3354, -17.1220])\n",
      "    Grad  :  tensor([-0.0055,  0.0311])\n",
      "Epoch 2685,Loss 2.930571\n",
      "Epoch 2685, Loss 2.930571\n",
      "    Params:  tensor([  5.3355, -17.1223])\n",
      "    Grad  :  tensor([-0.0055,  0.0310])\n",
      "Epoch 2686,Loss 2.930562\n",
      "Epoch 2686, Loss 2.930562\n",
      "    Params:  tensor([  5.3355, -17.1226])\n",
      "    Grad  :  tensor([-0.0055,  0.0310])\n",
      "Epoch 2687,Loss 2.930552\n",
      "Epoch 2687, Loss 2.930552\n",
      "    Params:  tensor([  5.3356, -17.1229])\n",
      "    Grad  :  tensor([-0.0055,  0.0309])\n",
      "Epoch 2688,Loss 2.930543\n",
      "Epoch 2688, Loss 2.930543\n",
      "    Params:  tensor([  5.3356, -17.1232])\n",
      "    Grad  :  tensor([-0.0055,  0.0309])\n",
      "Epoch 2689,Loss 2.930534\n",
      "Epoch 2689, Loss 2.930534\n",
      "    Params:  tensor([  5.3357, -17.1236])\n",
      "    Grad  :  tensor([-0.0055,  0.0308])\n",
      "Epoch 2690,Loss 2.930523\n",
      "Epoch 2690, Loss 2.930523\n",
      "    Params:  tensor([  5.3358, -17.1239])\n",
      "    Grad  :  tensor([-0.0054,  0.0308])\n",
      "Epoch 2691,Loss 2.930514\n",
      "Epoch 2691, Loss 2.930514\n",
      "    Params:  tensor([  5.3358, -17.1242])\n",
      "    Grad  :  tensor([-0.0054,  0.0307])\n",
      "Epoch 2692,Loss 2.930502\n",
      "Epoch 2692, Loss 2.930502\n",
      "    Params:  tensor([  5.3359, -17.1245])\n",
      "    Grad  :  tensor([-0.0054,  0.0307])\n",
      "Epoch 2693,Loss 2.930493\n",
      "Epoch 2693, Loss 2.930493\n",
      "    Params:  tensor([  5.3359, -17.1248])\n",
      "    Grad  :  tensor([-0.0054,  0.0306])\n",
      "Epoch 2694,Loss 2.930482\n",
      "Epoch 2694, Loss 2.930482\n",
      "    Params:  tensor([  5.3360, -17.1251])\n",
      "    Grad  :  tensor([-0.0054,  0.0306])\n",
      "Epoch 2695,Loss 2.930474\n",
      "Epoch 2695, Loss 2.930474\n",
      "    Params:  tensor([  5.3360, -17.1254])\n",
      "    Grad  :  tensor([-0.0054,  0.0305])\n",
      "Epoch 2696,Loss 2.930464\n",
      "Epoch 2696, Loss 2.930464\n",
      "    Params:  tensor([  5.3361, -17.1257])\n",
      "    Grad  :  tensor([-0.0054,  0.0305])\n",
      "Epoch 2697,Loss 2.930454\n",
      "Epoch 2697, Loss 2.930454\n",
      "    Params:  tensor([  5.3361, -17.1260])\n",
      "    Grad  :  tensor([-0.0054,  0.0304])\n",
      "Epoch 2698,Loss 2.930445\n",
      "Epoch 2698, Loss 2.930445\n",
      "    Params:  tensor([  5.3362, -17.1263])\n",
      "    Grad  :  tensor([-0.0054,  0.0304])\n",
      "Epoch 2699,Loss 2.930436\n",
      "Epoch 2699, Loss 2.930436\n",
      "    Params:  tensor([  5.3362, -17.1266])\n",
      "    Grad  :  tensor([-0.0054,  0.0303])\n",
      "Epoch 2700,Loss 2.930426\n",
      "Epoch 2700, Loss 2.930426\n",
      "    Params:  tensor([  5.3363, -17.1269])\n",
      "    Grad  :  tensor([-0.0054,  0.0303])\n",
      "Epoch 2701,Loss 2.930416\n",
      "Epoch 2701, Loss 2.930416\n",
      "    Params:  tensor([  5.3364, -17.1272])\n",
      "    Grad  :  tensor([-0.0054,  0.0302])\n",
      "Epoch 2702,Loss 2.930408\n",
      "Epoch 2702, Loss 2.930408\n",
      "    Params:  tensor([  5.3364, -17.1275])\n",
      "    Grad  :  tensor([-0.0053,  0.0302])\n",
      "Epoch 2703,Loss 2.930398\n",
      "Epoch 2703, Loss 2.930398\n",
      "    Params:  tensor([  5.3365, -17.1278])\n",
      "    Grad  :  tensor([-0.0053,  0.0301])\n",
      "Epoch 2704,Loss 2.930388\n",
      "Epoch 2704, Loss 2.930388\n",
      "    Params:  tensor([  5.3365, -17.1281])\n",
      "    Grad  :  tensor([-0.0053,  0.0301])\n",
      "Epoch 2705,Loss 2.930380\n",
      "Epoch 2705, Loss 2.930380\n",
      "    Params:  tensor([  5.3366, -17.1284])\n",
      "    Grad  :  tensor([-0.0053,  0.0300])\n",
      "Epoch 2706,Loss 2.930370\n",
      "Epoch 2706, Loss 2.930370\n",
      "    Params:  tensor([  5.3366, -17.1287])\n",
      "    Grad  :  tensor([-0.0053,  0.0300])\n",
      "Epoch 2707,Loss 2.930360\n",
      "Epoch 2707, Loss 2.930360\n",
      "    Params:  tensor([  5.3367, -17.1290])\n",
      "    Grad  :  tensor([-0.0053,  0.0299])\n",
      "Epoch 2708,Loss 2.930353\n",
      "Epoch 2708, Loss 2.930353\n",
      "    Params:  tensor([  5.3367, -17.1293])\n",
      "    Grad  :  tensor([-0.0053,  0.0299])\n",
      "Epoch 2709,Loss 2.930342\n",
      "Epoch 2709, Loss 2.930342\n",
      "    Params:  tensor([  5.3368, -17.1296])\n",
      "    Grad  :  tensor([-0.0053,  0.0298])\n",
      "Epoch 2710,Loss 2.930335\n",
      "Epoch 2710, Loss 2.930335\n",
      "    Params:  tensor([  5.3368, -17.1299])\n",
      "    Grad  :  tensor([-0.0053,  0.0298])\n",
      "Epoch 2711,Loss 2.930325\n",
      "Epoch 2711, Loss 2.930325\n",
      "    Params:  tensor([  5.3369, -17.1302])\n",
      "    Grad  :  tensor([-0.0053,  0.0297])\n",
      "Epoch 2712,Loss 2.930315\n",
      "Epoch 2712, Loss 2.930315\n",
      "    Params:  tensor([  5.3369, -17.1305])\n",
      "    Grad  :  tensor([-0.0053,  0.0297])\n",
      "Epoch 2713,Loss 2.930306\n",
      "Epoch 2713, Loss 2.930306\n",
      "    Params:  tensor([  5.3370, -17.1308])\n",
      "    Grad  :  tensor([-0.0052,  0.0296])\n",
      "Epoch 2714,Loss 2.930298\n",
      "Epoch 2714, Loss 2.930298\n",
      "    Params:  tensor([  5.3370, -17.1311])\n",
      "    Grad  :  tensor([-0.0052,  0.0296])\n",
      "Epoch 2715,Loss 2.930288\n",
      "Epoch 2715, Loss 2.930288\n",
      "    Params:  tensor([  5.3371, -17.1314])\n",
      "    Grad  :  tensor([-0.0052,  0.0295])\n",
      "Epoch 2716,Loss 2.930279\n",
      "Epoch 2716, Loss 2.930279\n",
      "    Params:  tensor([  5.3371, -17.1317])\n",
      "    Grad  :  tensor([-0.0052,  0.0295])\n",
      "Epoch 2717,Loss 2.930270\n",
      "Epoch 2717, Loss 2.930270\n",
      "    Params:  tensor([  5.3372, -17.1320])\n",
      "    Grad  :  tensor([-0.0052,  0.0294])\n",
      "Epoch 2718,Loss 2.930262\n",
      "Epoch 2718, Loss 2.930262\n",
      "    Params:  tensor([  5.3372, -17.1323])\n",
      "    Grad  :  tensor([-0.0052,  0.0294])\n",
      "Epoch 2719,Loss 2.930254\n",
      "Epoch 2719, Loss 2.930254\n",
      "    Params:  tensor([  5.3373, -17.1326])\n",
      "    Grad  :  tensor([-0.0052,  0.0293])\n",
      "Epoch 2720,Loss 2.930244\n",
      "Epoch 2720, Loss 2.930244\n",
      "    Params:  tensor([  5.3373, -17.1329])\n",
      "    Grad  :  tensor([-0.0052,  0.0293])\n",
      "Epoch 2721,Loss 2.930235\n",
      "Epoch 2721, Loss 2.930235\n",
      "    Params:  tensor([  5.3374, -17.1332])\n",
      "    Grad  :  tensor([-0.0052,  0.0292])\n",
      "Epoch 2722,Loss 2.930226\n",
      "Epoch 2722, Loss 2.930226\n",
      "    Params:  tensor([  5.3375, -17.1334])\n",
      "    Grad  :  tensor([-0.0052,  0.0292])\n",
      "Epoch 2723,Loss 2.930218\n",
      "Epoch 2723, Loss 2.930218\n",
      "    Params:  tensor([  5.3375, -17.1337])\n",
      "    Grad  :  tensor([-0.0051,  0.0291])\n",
      "Epoch 2724,Loss 2.930209\n",
      "Epoch 2724, Loss 2.930209\n",
      "    Params:  tensor([  5.3376, -17.1340])\n",
      "    Grad  :  tensor([-0.0051,  0.0291])\n",
      "Epoch 2725,Loss 2.930201\n",
      "Epoch 2725, Loss 2.930201\n",
      "    Params:  tensor([  5.3376, -17.1343])\n",
      "    Grad  :  tensor([-0.0051,  0.0290])\n",
      "Epoch 2726,Loss 2.930190\n",
      "Epoch 2726, Loss 2.930190\n",
      "    Params:  tensor([  5.3377, -17.1346])\n",
      "    Grad  :  tensor([-0.0051,  0.0290])\n",
      "Epoch 2727,Loss 2.930183\n",
      "Epoch 2727, Loss 2.930183\n",
      "    Params:  tensor([  5.3377, -17.1349])\n",
      "    Grad  :  tensor([-0.0051,  0.0289])\n",
      "Epoch 2728,Loss 2.930173\n",
      "Epoch 2728, Loss 2.930173\n",
      "    Params:  tensor([  5.3378, -17.1352])\n",
      "    Grad  :  tensor([-0.0051,  0.0289])\n",
      "Epoch 2729,Loss 2.930166\n",
      "Epoch 2729, Loss 2.930166\n",
      "    Params:  tensor([  5.3378, -17.1355])\n",
      "    Grad  :  tensor([-0.0051,  0.0288])\n",
      "Epoch 2730,Loss 2.930156\n",
      "Epoch 2730, Loss 2.930156\n",
      "    Params:  tensor([  5.3379, -17.1358])\n",
      "    Grad  :  tensor([-0.0051,  0.0288])\n",
      "Epoch 2731,Loss 2.930149\n",
      "Epoch 2731, Loss 2.930149\n",
      "    Params:  tensor([  5.3379, -17.1360])\n",
      "    Grad  :  tensor([-0.0051,  0.0287])\n",
      "Epoch 2732,Loss 2.930139\n",
      "Epoch 2732, Loss 2.930139\n",
      "    Params:  tensor([  5.3380, -17.1363])\n",
      "    Grad  :  tensor([-0.0051,  0.0287])\n",
      "Epoch 2733,Loss 2.930131\n",
      "Epoch 2733, Loss 2.930131\n",
      "    Params:  tensor([  5.3380, -17.1366])\n",
      "    Grad  :  tensor([-0.0050,  0.0286])\n",
      "Epoch 2734,Loss 2.930123\n",
      "Epoch 2734, Loss 2.930123\n",
      "    Params:  tensor([  5.3381, -17.1369])\n",
      "    Grad  :  tensor([-0.0050,  0.0286])\n",
      "Epoch 2735,Loss 2.930113\n",
      "Epoch 2735, Loss 2.930113\n",
      "    Params:  tensor([  5.3381, -17.1372])\n",
      "    Grad  :  tensor([-0.0050,  0.0285])\n",
      "Epoch 2736,Loss 2.930107\n",
      "Epoch 2736, Loss 2.930107\n",
      "    Params:  tensor([  5.3382, -17.1375])\n",
      "    Grad  :  tensor([-0.0051,  0.0285])\n",
      "Epoch 2737,Loss 2.930099\n",
      "Epoch 2737, Loss 2.930099\n",
      "    Params:  tensor([  5.3382, -17.1378])\n",
      "    Grad  :  tensor([-0.0050,  0.0284])\n",
      "Epoch 2738,Loss 2.930090\n",
      "Epoch 2738, Loss 2.930090\n",
      "    Params:  tensor([  5.3383, -17.1380])\n",
      "    Grad  :  tensor([-0.0050,  0.0284])\n",
      "Epoch 2739,Loss 2.930081\n",
      "Epoch 2739, Loss 2.930081\n",
      "    Params:  tensor([  5.3383, -17.1383])\n",
      "    Grad  :  tensor([-0.0050,  0.0283])\n",
      "Epoch 2740,Loss 2.930073\n",
      "Epoch 2740, Loss 2.930073\n",
      "    Params:  tensor([  5.3384, -17.1386])\n",
      "    Grad  :  tensor([-0.0050,  0.0283])\n",
      "Epoch 2741,Loss 2.930064\n",
      "Epoch 2741, Loss 2.930064\n",
      "    Params:  tensor([  5.3384, -17.1389])\n",
      "    Grad  :  tensor([-0.0050,  0.0282])\n",
      "Epoch 2742,Loss 2.930056\n",
      "Epoch 2742, Loss 2.930056\n",
      "    Params:  tensor([  5.3385, -17.1392])\n",
      "    Grad  :  tensor([-0.0050,  0.0282])\n",
      "Epoch 2743,Loss 2.930048\n",
      "Epoch 2743, Loss 2.930048\n",
      "    Params:  tensor([  5.3385, -17.1395])\n",
      "    Grad  :  tensor([-0.0050,  0.0281])\n",
      "Epoch 2744,Loss 2.930041\n",
      "Epoch 2744, Loss 2.930041\n",
      "    Params:  tensor([  5.3386, -17.1397])\n",
      "    Grad  :  tensor([-0.0050,  0.0281])\n",
      "Epoch 2745,Loss 2.930032\n",
      "Epoch 2745, Loss 2.930032\n",
      "    Params:  tensor([  5.3386, -17.1400])\n",
      "    Grad  :  tensor([-0.0050,  0.0280])\n",
      "Epoch 2746,Loss 2.930022\n",
      "Epoch 2746, Loss 2.930022\n",
      "    Params:  tensor([  5.3387, -17.1403])\n",
      "    Grad  :  tensor([-0.0050,  0.0280])\n",
      "Epoch 2747,Loss 2.930016\n",
      "Epoch 2747, Loss 2.930016\n",
      "    Params:  tensor([  5.3387, -17.1406])\n",
      "    Grad  :  tensor([-0.0049,  0.0279])\n",
      "Epoch 2748,Loss 2.930008\n",
      "Epoch 2748, Loss 2.930008\n",
      "    Params:  tensor([  5.3388, -17.1409])\n",
      "    Grad  :  tensor([-0.0049,  0.0279])\n",
      "Epoch 2749,Loss 2.930000\n",
      "Epoch 2749, Loss 2.930000\n",
      "    Params:  tensor([  5.3388, -17.1411])\n",
      "    Grad  :  tensor([-0.0049,  0.0279])\n",
      "Epoch 2750,Loss 2.929992\n",
      "Epoch 2750, Loss 2.929992\n",
      "    Params:  tensor([  5.3389, -17.1414])\n",
      "    Grad  :  tensor([-0.0049,  0.0278])\n",
      "Epoch 2751,Loss 2.929983\n",
      "Epoch 2751, Loss 2.929983\n",
      "    Params:  tensor([  5.3389, -17.1417])\n",
      "    Grad  :  tensor([-0.0049,  0.0278])\n",
      "Epoch 2752,Loss 2.929975\n",
      "Epoch 2752, Loss 2.929975\n",
      "    Params:  tensor([  5.3390, -17.1420])\n",
      "    Grad  :  tensor([-0.0049,  0.0277])\n",
      "Epoch 2753,Loss 2.929968\n",
      "Epoch 2753, Loss 2.929968\n",
      "    Params:  tensor([  5.3390, -17.1422])\n",
      "    Grad  :  tensor([-0.0049,  0.0277])\n",
      "Epoch 2754,Loss 2.929960\n",
      "Epoch 2754, Loss 2.929960\n",
      "    Params:  tensor([  5.3391, -17.1425])\n",
      "    Grad  :  tensor([-0.0049,  0.0276])\n",
      "Epoch 2755,Loss 2.929953\n",
      "Epoch 2755, Loss 2.929953\n",
      "    Params:  tensor([  5.3391, -17.1428])\n",
      "    Grad  :  tensor([-0.0049,  0.0276])\n",
      "Epoch 2756,Loss 2.929945\n",
      "Epoch 2756, Loss 2.929945\n",
      "    Params:  tensor([  5.3392, -17.1431])\n",
      "    Grad  :  tensor([-0.0049,  0.0275])\n",
      "Epoch 2757,Loss 2.929936\n",
      "Epoch 2757, Loss 2.929936\n",
      "    Params:  tensor([  5.3392, -17.1433])\n",
      "    Grad  :  tensor([-0.0049,  0.0275])\n",
      "Epoch 2758,Loss 2.929929\n",
      "Epoch 2758, Loss 2.929929\n",
      "    Params:  tensor([  5.3392, -17.1436])\n",
      "    Grad  :  tensor([-0.0049,  0.0274])\n",
      "Epoch 2759,Loss 2.929921\n",
      "Epoch 2759, Loss 2.929921\n",
      "    Params:  tensor([  5.3393, -17.1439])\n",
      "    Grad  :  tensor([-0.0048,  0.0274])\n",
      "Epoch 2760,Loss 2.929914\n",
      "Epoch 2760, Loss 2.929914\n",
      "    Params:  tensor([  5.3393, -17.1442])\n",
      "    Grad  :  tensor([-0.0049,  0.0273])\n",
      "Epoch 2761,Loss 2.929905\n",
      "Epoch 2761, Loss 2.929905\n",
      "    Params:  tensor([  5.3394, -17.1444])\n",
      "    Grad  :  tensor([-0.0048,  0.0273])\n",
      "Epoch 2762,Loss 2.929896\n",
      "Epoch 2762, Loss 2.929896\n",
      "    Params:  tensor([  5.3394, -17.1447])\n",
      "    Grad  :  tensor([-0.0048,  0.0272])\n",
      "Epoch 2763,Loss 2.929891\n",
      "Epoch 2763, Loss 2.929891\n",
      "    Params:  tensor([  5.3395, -17.1450])\n",
      "    Grad  :  tensor([-0.0048,  0.0272])\n",
      "Epoch 2764,Loss 2.929882\n",
      "Epoch 2764, Loss 2.929882\n",
      "    Params:  tensor([  5.3395, -17.1453])\n",
      "    Grad  :  tensor([-0.0048,  0.0271])\n",
      "Epoch 2765,Loss 2.929875\n",
      "Epoch 2765, Loss 2.929875\n",
      "    Params:  tensor([  5.3396, -17.1455])\n",
      "    Grad  :  tensor([-0.0048,  0.0271])\n",
      "Epoch 2766,Loss 2.929868\n",
      "Epoch 2766, Loss 2.929868\n",
      "    Params:  tensor([  5.3396, -17.1458])\n",
      "    Grad  :  tensor([-0.0048,  0.0271])\n",
      "Epoch 2767,Loss 2.929859\n",
      "Epoch 2767, Loss 2.929859\n",
      "    Params:  tensor([  5.3397, -17.1461])\n",
      "    Grad  :  tensor([-0.0048,  0.0270])\n",
      "Epoch 2768,Loss 2.929852\n",
      "Epoch 2768, Loss 2.929852\n",
      "    Params:  tensor([  5.3397, -17.1463])\n",
      "    Grad  :  tensor([-0.0048,  0.0270])\n",
      "Epoch 2769,Loss 2.929845\n",
      "Epoch 2769, Loss 2.929845\n",
      "    Params:  tensor([  5.3398, -17.1466])\n",
      "    Grad  :  tensor([-0.0048,  0.0269])\n",
      "Epoch 2770,Loss 2.929838\n",
      "Epoch 2770, Loss 2.929838\n",
      "    Params:  tensor([  5.3398, -17.1469])\n",
      "    Grad  :  tensor([-0.0047,  0.0269])\n",
      "Epoch 2771,Loss 2.929830\n",
      "Epoch 2771, Loss 2.929830\n",
      "    Params:  tensor([  5.3399, -17.1471])\n",
      "    Grad  :  tensor([-0.0047,  0.0268])\n",
      "Epoch 2772,Loss 2.929822\n",
      "Epoch 2772, Loss 2.929822\n",
      "    Params:  tensor([  5.3399, -17.1474])\n",
      "    Grad  :  tensor([-0.0047,  0.0268])\n",
      "Epoch 2773,Loss 2.929816\n",
      "Epoch 2773, Loss 2.929816\n",
      "    Params:  tensor([  5.3400, -17.1477])\n",
      "    Grad  :  tensor([-0.0047,  0.0267])\n",
      "Epoch 2774,Loss 2.929807\n",
      "Epoch 2774, Loss 2.929807\n",
      "    Params:  tensor([  5.3400, -17.1479])\n",
      "    Grad  :  tensor([-0.0047,  0.0267])\n",
      "Epoch 2775,Loss 2.929800\n",
      "Epoch 2775, Loss 2.929800\n",
      "    Params:  tensor([  5.3401, -17.1482])\n",
      "    Grad  :  tensor([-0.0047,  0.0266])\n",
      "Epoch 2776,Loss 2.929794\n",
      "Epoch 2776, Loss 2.929794\n",
      "    Params:  tensor([  5.3401, -17.1485])\n",
      "    Grad  :  tensor([-0.0047,  0.0266])\n",
      "Epoch 2777,Loss 2.929786\n",
      "Epoch 2777, Loss 2.929786\n",
      "    Params:  tensor([  5.3402, -17.1487])\n",
      "    Grad  :  tensor([-0.0047,  0.0266])\n",
      "Epoch 2778,Loss 2.929778\n",
      "Epoch 2778, Loss 2.929778\n",
      "    Params:  tensor([  5.3402, -17.1490])\n",
      "    Grad  :  tensor([-0.0047,  0.0265])\n",
      "Epoch 2779,Loss 2.929771\n",
      "Epoch 2779, Loss 2.929771\n",
      "    Params:  tensor([  5.3402, -17.1493])\n",
      "    Grad  :  tensor([-0.0047,  0.0265])\n",
      "Epoch 2780,Loss 2.929765\n",
      "Epoch 2780, Loss 2.929765\n",
      "    Params:  tensor([  5.3403, -17.1495])\n",
      "    Grad  :  tensor([-0.0047,  0.0264])\n",
      "Epoch 2781,Loss 2.929757\n",
      "Epoch 2781, Loss 2.929757\n",
      "    Params:  tensor([  5.3403, -17.1498])\n",
      "    Grad  :  tensor([-0.0047,  0.0264])\n",
      "Epoch 2782,Loss 2.929750\n",
      "Epoch 2782, Loss 2.929750\n",
      "    Params:  tensor([  5.3404, -17.1501])\n",
      "    Grad  :  tensor([-0.0046,  0.0263])\n",
      "Epoch 2783,Loss 2.929743\n",
      "Epoch 2783, Loss 2.929743\n",
      "    Params:  tensor([  5.3404, -17.1503])\n",
      "    Grad  :  tensor([-0.0046,  0.0263])\n",
      "Epoch 2784,Loss 2.929735\n",
      "Epoch 2784, Loss 2.929735\n",
      "    Params:  tensor([  5.3405, -17.1506])\n",
      "    Grad  :  tensor([-0.0046,  0.0262])\n",
      "Epoch 2785,Loss 2.929729\n",
      "Epoch 2785, Loss 2.929729\n",
      "    Params:  tensor([  5.3405, -17.1508])\n",
      "    Grad  :  tensor([-0.0047,  0.0262])\n",
      "Epoch 2786,Loss 2.929722\n",
      "Epoch 2786, Loss 2.929722\n",
      "    Params:  tensor([  5.3406, -17.1511])\n",
      "    Grad  :  tensor([-0.0046,  0.0262])\n",
      "Epoch 2787,Loss 2.929714\n",
      "Epoch 2787, Loss 2.929714\n",
      "    Params:  tensor([  5.3406, -17.1514])\n",
      "    Grad  :  tensor([-0.0046,  0.0261])\n",
      "Epoch 2788,Loss 2.929707\n",
      "Epoch 2788, Loss 2.929707\n",
      "    Params:  tensor([  5.3407, -17.1516])\n",
      "    Grad  :  tensor([-0.0046,  0.0261])\n",
      "Epoch 2789,Loss 2.929701\n",
      "Epoch 2789, Loss 2.929701\n",
      "    Params:  tensor([  5.3407, -17.1519])\n",
      "    Grad  :  tensor([-0.0046,  0.0260])\n",
      "Epoch 2790,Loss 2.929692\n",
      "Epoch 2790, Loss 2.929692\n",
      "    Params:  tensor([  5.3408, -17.1522])\n",
      "    Grad  :  tensor([-0.0046,  0.0260])\n",
      "Epoch 2791,Loss 2.929685\n",
      "Epoch 2791, Loss 2.929685\n",
      "    Params:  tensor([  5.3408, -17.1524])\n",
      "    Grad  :  tensor([-0.0046,  0.0259])\n",
      "Epoch 2792,Loss 2.929681\n",
      "Epoch 2792, Loss 2.929681\n",
      "    Params:  tensor([  5.3408, -17.1527])\n",
      "    Grad  :  tensor([-0.0046,  0.0259])\n",
      "Epoch 2793,Loss 2.929672\n",
      "Epoch 2793, Loss 2.929672\n",
      "    Params:  tensor([  5.3409, -17.1529])\n",
      "    Grad  :  tensor([-0.0046,  0.0258])\n",
      "Epoch 2794,Loss 2.929666\n",
      "Epoch 2794, Loss 2.929666\n",
      "    Params:  tensor([  5.3409, -17.1532])\n",
      "    Grad  :  tensor([-0.0046,  0.0258])\n",
      "Epoch 2795,Loss 2.929659\n",
      "Epoch 2795, Loss 2.929659\n",
      "    Params:  tensor([  5.3410, -17.1534])\n",
      "    Grad  :  tensor([-0.0045,  0.0258])\n",
      "Epoch 2796,Loss 2.929653\n",
      "Epoch 2796, Loss 2.929653\n",
      "    Params:  tensor([  5.3410, -17.1537])\n",
      "    Grad  :  tensor([-0.0045,  0.0257])\n",
      "Epoch 2797,Loss 2.929646\n",
      "Epoch 2797, Loss 2.929646\n",
      "    Params:  tensor([  5.3411, -17.1540])\n",
      "    Grad  :  tensor([-0.0045,  0.0257])\n",
      "Epoch 2798,Loss 2.929638\n",
      "Epoch 2798, Loss 2.929638\n",
      "    Params:  tensor([  5.3411, -17.1542])\n",
      "    Grad  :  tensor([-0.0045,  0.0256])\n",
      "Epoch 2799,Loss 2.929632\n",
      "Epoch 2799, Loss 2.929632\n",
      "    Params:  tensor([  5.3412, -17.1545])\n",
      "    Grad  :  tensor([-0.0045,  0.0256])\n",
      "Epoch 2800,Loss 2.929626\n",
      "Epoch 2800, Loss 2.929626\n",
      "    Params:  tensor([  5.3412, -17.1547])\n",
      "    Grad  :  tensor([-0.0045,  0.0255])\n",
      "Epoch 2801,Loss 2.929620\n",
      "Epoch 2801, Loss 2.929620\n",
      "    Params:  tensor([  5.3413, -17.1550])\n",
      "    Grad  :  tensor([-0.0045,  0.0255])\n",
      "Epoch 2802,Loss 2.929611\n",
      "Epoch 2802, Loss 2.929611\n",
      "    Params:  tensor([  5.3413, -17.1552])\n",
      "    Grad  :  tensor([-0.0045,  0.0254])\n",
      "Epoch 2803,Loss 2.929605\n",
      "Epoch 2803, Loss 2.929605\n",
      "    Params:  tensor([  5.3413, -17.1555])\n",
      "    Grad  :  tensor([-0.0045,  0.0254])\n",
      "Epoch 2804,Loss 2.929600\n",
      "Epoch 2804, Loss 2.929600\n",
      "    Params:  tensor([  5.3414, -17.1557])\n",
      "    Grad  :  tensor([-0.0045,  0.0254])\n",
      "Epoch 2805,Loss 2.929592\n",
      "Epoch 2805, Loss 2.929592\n",
      "    Params:  tensor([  5.3414, -17.1560])\n",
      "    Grad  :  tensor([-0.0045,  0.0253])\n",
      "Epoch 2806,Loss 2.929586\n",
      "Epoch 2806, Loss 2.929586\n",
      "    Params:  tensor([  5.3415, -17.1562])\n",
      "    Grad  :  tensor([-0.0045,  0.0253])\n",
      "Epoch 2807,Loss 2.929579\n",
      "Epoch 2807, Loss 2.929579\n",
      "    Params:  tensor([  5.3415, -17.1565])\n",
      "    Grad  :  tensor([-0.0045,  0.0252])\n",
      "Epoch 2808,Loss 2.929572\n",
      "Epoch 2808, Loss 2.929572\n",
      "    Params:  tensor([  5.3416, -17.1568])\n",
      "    Grad  :  tensor([-0.0044,  0.0252])\n",
      "Epoch 2809,Loss 2.929566\n",
      "Epoch 2809, Loss 2.929566\n",
      "    Params:  tensor([  5.3416, -17.1570])\n",
      "    Grad  :  tensor([-0.0044,  0.0251])\n",
      "Epoch 2810,Loss 2.929559\n",
      "Epoch 2810, Loss 2.929559\n",
      "    Params:  tensor([  5.3417, -17.1573])\n",
      "    Grad  :  tensor([-0.0044,  0.0251])\n",
      "Epoch 2811,Loss 2.929551\n",
      "Epoch 2811, Loss 2.929551\n",
      "    Params:  tensor([  5.3417, -17.1575])\n",
      "    Grad  :  tensor([-0.0044,  0.0251])\n",
      "Epoch 2812,Loss 2.929545\n",
      "Epoch 2812, Loss 2.929545\n",
      "    Params:  tensor([  5.3417, -17.1578])\n",
      "    Grad  :  tensor([-0.0044,  0.0250])\n",
      "Epoch 2813,Loss 2.929540\n",
      "Epoch 2813, Loss 2.929540\n",
      "    Params:  tensor([  5.3418, -17.1580])\n",
      "    Grad  :  tensor([-0.0044,  0.0250])\n",
      "Epoch 2814,Loss 2.929533\n",
      "Epoch 2814, Loss 2.929533\n",
      "    Params:  tensor([  5.3418, -17.1583])\n",
      "    Grad  :  tensor([-0.0044,  0.0249])\n",
      "Epoch 2815,Loss 2.929528\n",
      "Epoch 2815, Loss 2.929528\n",
      "    Params:  tensor([  5.3419, -17.1585])\n",
      "    Grad  :  tensor([-0.0044,  0.0249])\n",
      "Epoch 2816,Loss 2.929521\n",
      "Epoch 2816, Loss 2.929521\n",
      "    Params:  tensor([  5.3419, -17.1588])\n",
      "    Grad  :  tensor([-0.0044,  0.0249])\n",
      "Epoch 2817,Loss 2.929513\n",
      "Epoch 2817, Loss 2.929513\n",
      "    Params:  tensor([  5.3420, -17.1590])\n",
      "    Grad  :  tensor([-0.0044,  0.0248])\n",
      "Epoch 2818,Loss 2.929507\n",
      "Epoch 2818, Loss 2.929507\n",
      "    Params:  tensor([  5.3420, -17.1592])\n",
      "    Grad  :  tensor([-0.0043,  0.0248])\n",
      "Epoch 2819,Loss 2.929501\n",
      "Epoch 2819, Loss 2.929501\n",
      "    Params:  tensor([  5.3421, -17.1595])\n",
      "    Grad  :  tensor([-0.0044,  0.0247])\n",
      "Epoch 2820,Loss 2.929496\n",
      "Epoch 2820, Loss 2.929496\n",
      "    Params:  tensor([  5.3421, -17.1597])\n",
      "    Grad  :  tensor([-0.0044,  0.0247])\n",
      "Epoch 2821,Loss 2.929489\n",
      "Epoch 2821, Loss 2.929489\n",
      "    Params:  tensor([  5.3421, -17.1600])\n",
      "    Grad  :  tensor([-0.0044,  0.0246])\n",
      "Epoch 2822,Loss 2.929482\n",
      "Epoch 2822, Loss 2.929482\n",
      "    Params:  tensor([  5.3422, -17.1602])\n",
      "    Grad  :  tensor([-0.0043,  0.0246])\n",
      "Epoch 2823,Loss 2.929476\n",
      "Epoch 2823, Loss 2.929476\n",
      "    Params:  tensor([  5.3422, -17.1605])\n",
      "    Grad  :  tensor([-0.0043,  0.0246])\n",
      "Epoch 2824,Loss 2.929471\n",
      "Epoch 2824, Loss 2.929471\n",
      "    Params:  tensor([  5.3423, -17.1607])\n",
      "    Grad  :  tensor([-0.0043,  0.0245])\n",
      "Epoch 2825,Loss 2.929463\n",
      "Epoch 2825, Loss 2.929463\n",
      "    Params:  tensor([  5.3423, -17.1610])\n",
      "    Grad  :  tensor([-0.0043,  0.0245])\n",
      "Epoch 2826,Loss 2.929458\n",
      "Epoch 2826, Loss 2.929458\n",
      "    Params:  tensor([  5.3424, -17.1612])\n",
      "    Grad  :  tensor([-0.0043,  0.0244])\n",
      "Epoch 2827,Loss 2.929452\n",
      "Epoch 2827, Loss 2.929452\n",
      "    Params:  tensor([  5.3424, -17.1615])\n",
      "    Grad  :  tensor([-0.0043,  0.0244])\n",
      "Epoch 2828,Loss 2.929445\n",
      "Epoch 2828, Loss 2.929445\n",
      "    Params:  tensor([  5.3424, -17.1617])\n",
      "    Grad  :  tensor([-0.0043,  0.0243])\n",
      "Epoch 2829,Loss 2.929439\n",
      "Epoch 2829, Loss 2.929439\n",
      "    Params:  tensor([  5.3425, -17.1619])\n",
      "    Grad  :  tensor([-0.0043,  0.0243])\n",
      "Epoch 2830,Loss 2.929433\n",
      "Epoch 2830, Loss 2.929433\n",
      "    Params:  tensor([  5.3425, -17.1622])\n",
      "    Grad  :  tensor([-0.0043,  0.0243])\n",
      "Epoch 2831,Loss 2.929427\n",
      "Epoch 2831, Loss 2.929427\n",
      "    Params:  tensor([  5.3426, -17.1624])\n",
      "    Grad  :  tensor([-0.0043,  0.0242])\n",
      "Epoch 2832,Loss 2.929421\n",
      "Epoch 2832, Loss 2.929421\n",
      "    Params:  tensor([  5.3426, -17.1627])\n",
      "    Grad  :  tensor([-0.0043,  0.0242])\n",
      "Epoch 2833,Loss 2.929415\n",
      "Epoch 2833, Loss 2.929415\n",
      "    Params:  tensor([  5.3427, -17.1629])\n",
      "    Grad  :  tensor([-0.0043,  0.0241])\n",
      "Epoch 2834,Loss 2.929409\n",
      "Epoch 2834, Loss 2.929409\n",
      "    Params:  tensor([  5.3427, -17.1632])\n",
      "    Grad  :  tensor([-0.0043,  0.0241])\n",
      "Epoch 2835,Loss 2.929404\n",
      "Epoch 2835, Loss 2.929404\n",
      "    Params:  tensor([  5.3427, -17.1634])\n",
      "    Grad  :  tensor([-0.0043,  0.0241])\n",
      "Epoch 2836,Loss 2.929396\n",
      "Epoch 2836, Loss 2.929396\n",
      "    Params:  tensor([  5.3428, -17.1636])\n",
      "    Grad  :  tensor([-0.0042,  0.0240])\n",
      "Epoch 2837,Loss 2.929391\n",
      "Epoch 2837, Loss 2.929391\n",
      "    Params:  tensor([  5.3428, -17.1639])\n",
      "    Grad  :  tensor([-0.0042,  0.0240])\n",
      "Epoch 2838,Loss 2.929383\n",
      "Epoch 2838, Loss 2.929383\n",
      "    Params:  tensor([  5.3429, -17.1641])\n",
      "    Grad  :  tensor([-0.0042,  0.0239])\n",
      "Epoch 2839,Loss 2.929380\n",
      "Epoch 2839, Loss 2.929380\n",
      "    Params:  tensor([  5.3429, -17.1644])\n",
      "    Grad  :  tensor([-0.0042,  0.0239])\n",
      "Epoch 2840,Loss 2.929373\n",
      "Epoch 2840, Loss 2.929373\n",
      "    Params:  tensor([  5.3430, -17.1646])\n",
      "    Grad  :  tensor([-0.0042,  0.0239])\n",
      "Epoch 2841,Loss 2.929368\n",
      "Epoch 2841, Loss 2.929368\n",
      "    Params:  tensor([  5.3430, -17.1648])\n",
      "    Grad  :  tensor([-0.0042,  0.0238])\n",
      "Epoch 2842,Loss 2.929361\n",
      "Epoch 2842, Loss 2.929361\n",
      "    Params:  tensor([  5.3430, -17.1651])\n",
      "    Grad  :  tensor([-0.0042,  0.0238])\n",
      "Epoch 2843,Loss 2.929356\n",
      "Epoch 2843, Loss 2.929356\n",
      "    Params:  tensor([  5.3431, -17.1653])\n",
      "    Grad  :  tensor([-0.0042,  0.0237])\n",
      "Epoch 2844,Loss 2.929351\n",
      "Epoch 2844, Loss 2.929351\n",
      "    Params:  tensor([  5.3431, -17.1655])\n",
      "    Grad  :  tensor([-0.0042,  0.0237])\n",
      "Epoch 2845,Loss 2.929345\n",
      "Epoch 2845, Loss 2.929345\n",
      "    Params:  tensor([  5.3432, -17.1658])\n",
      "    Grad  :  tensor([-0.0042,  0.0237])\n",
      "Epoch 2846,Loss 2.929338\n",
      "Epoch 2846, Loss 2.929338\n",
      "    Params:  tensor([  5.3432, -17.1660])\n",
      "    Grad  :  tensor([-0.0042,  0.0236])\n",
      "Epoch 2847,Loss 2.929332\n",
      "Epoch 2847, Loss 2.929332\n",
      "    Params:  tensor([  5.3432, -17.1662])\n",
      "    Grad  :  tensor([-0.0042,  0.0236])\n",
      "Epoch 2848,Loss 2.929328\n",
      "Epoch 2848, Loss 2.929328\n",
      "    Params:  tensor([  5.3433, -17.1665])\n",
      "    Grad  :  tensor([-0.0042,  0.0235])\n",
      "Epoch 2849,Loss 2.929321\n",
      "Epoch 2849, Loss 2.929321\n",
      "    Params:  tensor([  5.3433, -17.1667])\n",
      "    Grad  :  tensor([-0.0041,  0.0235])\n",
      "Epoch 2850,Loss 2.929316\n",
      "Epoch 2850, Loss 2.929316\n",
      "    Params:  tensor([  5.3434, -17.1670])\n",
      "    Grad  :  tensor([-0.0041,  0.0235])\n",
      "Epoch 2851,Loss 2.929309\n",
      "Epoch 2851, Loss 2.929309\n",
      "    Params:  tensor([  5.3434, -17.1672])\n",
      "    Grad  :  tensor([-0.0041,  0.0234])\n",
      "Epoch 2852,Loss 2.929304\n",
      "Epoch 2852, Loss 2.929304\n",
      "    Params:  tensor([  5.3435, -17.1674])\n",
      "    Grad  :  tensor([-0.0041,  0.0234])\n",
      "Epoch 2853,Loss 2.929300\n",
      "Epoch 2853, Loss 2.929300\n",
      "    Params:  tensor([  5.3435, -17.1677])\n",
      "    Grad  :  tensor([-0.0041,  0.0233])\n",
      "Epoch 2854,Loss 2.929293\n",
      "Epoch 2854, Loss 2.929293\n",
      "    Params:  tensor([  5.3435, -17.1679])\n",
      "    Grad  :  tensor([-0.0041,  0.0233])\n",
      "Epoch 2855,Loss 2.929288\n",
      "Epoch 2855, Loss 2.929288\n",
      "    Params:  tensor([  5.3436, -17.1681])\n",
      "    Grad  :  tensor([-0.0041,  0.0233])\n",
      "Epoch 2856,Loss 2.929282\n",
      "Epoch 2856, Loss 2.929282\n",
      "    Params:  tensor([  5.3436, -17.1684])\n",
      "    Grad  :  tensor([-0.0041,  0.0232])\n",
      "Epoch 2857,Loss 2.929277\n",
      "Epoch 2857, Loss 2.929277\n",
      "    Params:  tensor([  5.3437, -17.1686])\n",
      "    Grad  :  tensor([-0.0041,  0.0232])\n",
      "Epoch 2858,Loss 2.929271\n",
      "Epoch 2858, Loss 2.929271\n",
      "    Params:  tensor([  5.3437, -17.1688])\n",
      "    Grad  :  tensor([-0.0041,  0.0231])\n",
      "Epoch 2859,Loss 2.929266\n",
      "Epoch 2859, Loss 2.929266\n",
      "    Params:  tensor([  5.3437, -17.1690])\n",
      "    Grad  :  tensor([-0.0041,  0.0231])\n",
      "Epoch 2860,Loss 2.929260\n",
      "Epoch 2860, Loss 2.929260\n",
      "    Params:  tensor([  5.3438, -17.1693])\n",
      "    Grad  :  tensor([-0.0041,  0.0231])\n",
      "Epoch 2861,Loss 2.929255\n",
      "Epoch 2861, Loss 2.929255\n",
      "    Params:  tensor([  5.3438, -17.1695])\n",
      "    Grad  :  tensor([-0.0041,  0.0230])\n",
      "Epoch 2862,Loss 2.929250\n",
      "Epoch 2862, Loss 2.929250\n",
      "    Params:  tensor([  5.3439, -17.1697])\n",
      "    Grad  :  tensor([-0.0041,  0.0230])\n",
      "Epoch 2863,Loss 2.929244\n",
      "Epoch 2863, Loss 2.929244\n",
      "    Params:  tensor([  5.3439, -17.1700])\n",
      "    Grad  :  tensor([-0.0040,  0.0229])\n",
      "Epoch 2864,Loss 2.929238\n",
      "Epoch 2864, Loss 2.929238\n",
      "    Params:  tensor([  5.3439, -17.1702])\n",
      "    Grad  :  tensor([-0.0040,  0.0229])\n",
      "Epoch 2865,Loss 2.929234\n",
      "Epoch 2865, Loss 2.929234\n",
      "    Params:  tensor([  5.3440, -17.1704])\n",
      "    Grad  :  tensor([-0.0040,  0.0229])\n",
      "Epoch 2866,Loss 2.929228\n",
      "Epoch 2866, Loss 2.929228\n",
      "    Params:  tensor([  5.3440, -17.1707])\n",
      "    Grad  :  tensor([-0.0040,  0.0228])\n",
      "Epoch 2867,Loss 2.929222\n",
      "Epoch 2867, Loss 2.929222\n",
      "    Params:  tensor([  5.3441, -17.1709])\n",
      "    Grad  :  tensor([-0.0040,  0.0228])\n",
      "Epoch 2868,Loss 2.929217\n",
      "Epoch 2868, Loss 2.929217\n",
      "    Params:  tensor([  5.3441, -17.1711])\n",
      "    Grad  :  tensor([-0.0040,  0.0227])\n",
      "Epoch 2869,Loss 2.929211\n",
      "Epoch 2869, Loss 2.929211\n",
      "    Params:  tensor([  5.3441, -17.1713])\n",
      "    Grad  :  tensor([-0.0040,  0.0227])\n",
      "Epoch 2870,Loss 2.929208\n",
      "Epoch 2870, Loss 2.929208\n",
      "    Params:  tensor([  5.3442, -17.1716])\n",
      "    Grad  :  tensor([-0.0040,  0.0227])\n",
      "Epoch 2871,Loss 2.929201\n",
      "Epoch 2871, Loss 2.929201\n",
      "    Params:  tensor([  5.3442, -17.1718])\n",
      "    Grad  :  tensor([-0.0040,  0.0226])\n",
      "Epoch 2872,Loss 2.929195\n",
      "Epoch 2872, Loss 2.929195\n",
      "    Params:  tensor([  5.3443, -17.1720])\n",
      "    Grad  :  tensor([-0.0040,  0.0226])\n",
      "Epoch 2873,Loss 2.929191\n",
      "Epoch 2873, Loss 2.929191\n",
      "    Params:  tensor([  5.3443, -17.1722])\n",
      "    Grad  :  tensor([-0.0040,  0.0226])\n",
      "Epoch 2874,Loss 2.929185\n",
      "Epoch 2874, Loss 2.929185\n",
      "    Params:  tensor([  5.3443, -17.1725])\n",
      "    Grad  :  tensor([-0.0040,  0.0225])\n",
      "Epoch 2875,Loss 2.929180\n",
      "Epoch 2875, Loss 2.929180\n",
      "    Params:  tensor([  5.3444, -17.1727])\n",
      "    Grad  :  tensor([-0.0040,  0.0225])\n",
      "Epoch 2876,Loss 2.929175\n",
      "Epoch 2876, Loss 2.929175\n",
      "    Params:  tensor([  5.3444, -17.1729])\n",
      "    Grad  :  tensor([-0.0040,  0.0224])\n",
      "Epoch 2877,Loss 2.929170\n",
      "Epoch 2877, Loss 2.929170\n",
      "    Params:  tensor([  5.3445, -17.1731])\n",
      "    Grad  :  tensor([-0.0040,  0.0224])\n",
      "Epoch 2878,Loss 2.929165\n",
      "Epoch 2878, Loss 2.929165\n",
      "    Params:  tensor([  5.3445, -17.1734])\n",
      "    Grad  :  tensor([-0.0040,  0.0224])\n",
      "Epoch 2879,Loss 2.929160\n",
      "Epoch 2879, Loss 2.929160\n",
      "    Params:  tensor([  5.3445, -17.1736])\n",
      "    Grad  :  tensor([-0.0039,  0.0223])\n",
      "Epoch 2880,Loss 2.929155\n",
      "Epoch 2880, Loss 2.929155\n",
      "    Params:  tensor([  5.3446, -17.1738])\n",
      "    Grad  :  tensor([-0.0039,  0.0223])\n",
      "Epoch 2881,Loss 2.929149\n",
      "Epoch 2881, Loss 2.929149\n",
      "    Params:  tensor([  5.3446, -17.1740])\n",
      "    Grad  :  tensor([-0.0039,  0.0223])\n",
      "Epoch 2882,Loss 2.929143\n",
      "Epoch 2882, Loss 2.929143\n",
      "    Params:  tensor([  5.3447, -17.1742])\n",
      "    Grad  :  tensor([-0.0039,  0.0222])\n",
      "Epoch 2883,Loss 2.929139\n",
      "Epoch 2883, Loss 2.929139\n",
      "    Params:  tensor([  5.3447, -17.1745])\n",
      "    Grad  :  tensor([-0.0039,  0.0222])\n",
      "Epoch 2884,Loss 2.929133\n",
      "Epoch 2884, Loss 2.929133\n",
      "    Params:  tensor([  5.3447, -17.1747])\n",
      "    Grad  :  tensor([-0.0039,  0.0221])\n",
      "Epoch 2885,Loss 2.929128\n",
      "Epoch 2885, Loss 2.929128\n",
      "    Params:  tensor([  5.3448, -17.1749])\n",
      "    Grad  :  tensor([-0.0039,  0.0221])\n",
      "Epoch 2886,Loss 2.929122\n",
      "Epoch 2886, Loss 2.929122\n",
      "    Params:  tensor([  5.3448, -17.1751])\n",
      "    Grad  :  tensor([-0.0039,  0.0221])\n",
      "Epoch 2887,Loss 2.929119\n",
      "Epoch 2887, Loss 2.929119\n",
      "    Params:  tensor([  5.3449, -17.1754])\n",
      "    Grad  :  tensor([-0.0039,  0.0220])\n",
      "Epoch 2888,Loss 2.929113\n",
      "Epoch 2888, Loss 2.929113\n",
      "    Params:  tensor([  5.3449, -17.1756])\n",
      "    Grad  :  tensor([-0.0039,  0.0220])\n",
      "Epoch 2889,Loss 2.929108\n",
      "Epoch 2889, Loss 2.929108\n",
      "    Params:  tensor([  5.3449, -17.1758])\n",
      "    Grad  :  tensor([-0.0039,  0.0220])\n",
      "Epoch 2890,Loss 2.929104\n",
      "Epoch 2890, Loss 2.929104\n",
      "    Params:  tensor([  5.3450, -17.1760])\n",
      "    Grad  :  tensor([-0.0039,  0.0219])\n",
      "Epoch 2891,Loss 2.929099\n",
      "Epoch 2891, Loss 2.929099\n",
      "    Params:  tensor([  5.3450, -17.1762])\n",
      "    Grad  :  tensor([-0.0039,  0.0219])\n",
      "Epoch 2892,Loss 2.929093\n",
      "Epoch 2892, Loss 2.929093\n",
      "    Params:  tensor([  5.3450, -17.1764])\n",
      "    Grad  :  tensor([-0.0039,  0.0218])\n",
      "Epoch 2893,Loss 2.929088\n",
      "Epoch 2893, Loss 2.929088\n",
      "    Params:  tensor([  5.3451, -17.1767])\n",
      "    Grad  :  tensor([-0.0039,  0.0218])\n",
      "Epoch 2894,Loss 2.929083\n",
      "Epoch 2894, Loss 2.929083\n",
      "    Params:  tensor([  5.3451, -17.1769])\n",
      "    Grad  :  tensor([-0.0038,  0.0218])\n",
      "Epoch 2895,Loss 2.929079\n",
      "Epoch 2895, Loss 2.929079\n",
      "    Params:  tensor([  5.3452, -17.1771])\n",
      "    Grad  :  tensor([-0.0038,  0.0217])\n",
      "Epoch 2896,Loss 2.929074\n",
      "Epoch 2896, Loss 2.929074\n",
      "    Params:  tensor([  5.3452, -17.1773])\n",
      "    Grad  :  tensor([-0.0038,  0.0217])\n",
      "Epoch 2897,Loss 2.929069\n",
      "Epoch 2897, Loss 2.929069\n",
      "    Params:  tensor([  5.3452, -17.1775])\n",
      "    Grad  :  tensor([-0.0038,  0.0217])\n",
      "Epoch 2898,Loss 2.929065\n",
      "Epoch 2898, Loss 2.929065\n",
      "    Params:  tensor([  5.3453, -17.1777])\n",
      "    Grad  :  tensor([-0.0038,  0.0216])\n",
      "Epoch 2899,Loss 2.929058\n",
      "Epoch 2899, Loss 2.929058\n",
      "    Params:  tensor([  5.3453, -17.1780])\n",
      "    Grad  :  tensor([-0.0038,  0.0216])\n",
      "Epoch 2900,Loss 2.929054\n",
      "Epoch 2900, Loss 2.929054\n",
      "    Params:  tensor([  5.3454, -17.1782])\n",
      "    Grad  :  tensor([-0.0038,  0.0215])\n",
      "Epoch 2901,Loss 2.929050\n",
      "Epoch 2901, Loss 2.929050\n",
      "    Params:  tensor([  5.3454, -17.1784])\n",
      "    Grad  :  tensor([-0.0038,  0.0215])\n",
      "Epoch 2902,Loss 2.929044\n",
      "Epoch 2902, Loss 2.929044\n",
      "    Params:  tensor([  5.3454, -17.1786])\n",
      "    Grad  :  tensor([-0.0038,  0.0215])\n",
      "Epoch 2903,Loss 2.929041\n",
      "Epoch 2903, Loss 2.929041\n",
      "    Params:  tensor([  5.3455, -17.1788])\n",
      "    Grad  :  tensor([-0.0038,  0.0214])\n",
      "Epoch 2904,Loss 2.929036\n",
      "Epoch 2904, Loss 2.929036\n",
      "    Params:  tensor([  5.3455, -17.1790])\n",
      "    Grad  :  tensor([-0.0038,  0.0214])\n",
      "Epoch 2905,Loss 2.929031\n",
      "Epoch 2905, Loss 2.929031\n",
      "    Params:  tensor([  5.3455, -17.1793])\n",
      "    Grad  :  tensor([-0.0038,  0.0214])\n",
      "Epoch 2906,Loss 2.929025\n",
      "Epoch 2906, Loss 2.929025\n",
      "    Params:  tensor([  5.3456, -17.1795])\n",
      "    Grad  :  tensor([-0.0038,  0.0213])\n",
      "Epoch 2907,Loss 2.929021\n",
      "Epoch 2907, Loss 2.929021\n",
      "    Params:  tensor([  5.3456, -17.1797])\n",
      "    Grad  :  tensor([-0.0038,  0.0213])\n",
      "Epoch 2908,Loss 2.929017\n",
      "Epoch 2908, Loss 2.929017\n",
      "    Params:  tensor([  5.3457, -17.1799])\n",
      "    Grad  :  tensor([-0.0037,  0.0213])\n",
      "Epoch 2909,Loss 2.929012\n",
      "Epoch 2909, Loss 2.929012\n",
      "    Params:  tensor([  5.3457, -17.1801])\n",
      "    Grad  :  tensor([-0.0037,  0.0212])\n",
      "Epoch 2910,Loss 2.929007\n",
      "Epoch 2910, Loss 2.929007\n",
      "    Params:  tensor([  5.3457, -17.1803])\n",
      "    Grad  :  tensor([-0.0037,  0.0212])\n",
      "Epoch 2911,Loss 2.929003\n",
      "Epoch 2911, Loss 2.929003\n",
      "    Params:  tensor([  5.3458, -17.1805])\n",
      "    Grad  :  tensor([-0.0037,  0.0211])\n",
      "Epoch 2912,Loss 2.928999\n",
      "Epoch 2912, Loss 2.928999\n",
      "    Params:  tensor([  5.3458, -17.1807])\n",
      "    Grad  :  tensor([-0.0037,  0.0211])\n",
      "Epoch 2913,Loss 2.928993\n",
      "Epoch 2913, Loss 2.928993\n",
      "    Params:  tensor([  5.3458, -17.1809])\n",
      "    Grad  :  tensor([-0.0037,  0.0211])\n",
      "Epoch 2914,Loss 2.928989\n",
      "Epoch 2914, Loss 2.928989\n",
      "    Params:  tensor([  5.3459, -17.1812])\n",
      "    Grad  :  tensor([-0.0037,  0.0210])\n",
      "Epoch 2915,Loss 2.928985\n",
      "Epoch 2915, Loss 2.928985\n",
      "    Params:  tensor([  5.3459, -17.1814])\n",
      "    Grad  :  tensor([-0.0037,  0.0210])\n",
      "Epoch 2916,Loss 2.928980\n",
      "Epoch 2916, Loss 2.928980\n",
      "    Params:  tensor([  5.3460, -17.1816])\n",
      "    Grad  :  tensor([-0.0037,  0.0210])\n",
      "Epoch 2917,Loss 2.928976\n",
      "Epoch 2917, Loss 2.928976\n",
      "    Params:  tensor([  5.3460, -17.1818])\n",
      "    Grad  :  tensor([-0.0037,  0.0209])\n",
      "Epoch 2918,Loss 2.928971\n",
      "Epoch 2918, Loss 2.928971\n",
      "    Params:  tensor([  5.3460, -17.1820])\n",
      "    Grad  :  tensor([-0.0037,  0.0209])\n",
      "Epoch 2919,Loss 2.928967\n",
      "Epoch 2919, Loss 2.928967\n",
      "    Params:  tensor([  5.3461, -17.1822])\n",
      "    Grad  :  tensor([-0.0037,  0.0209])\n",
      "Epoch 2920,Loss 2.928962\n",
      "Epoch 2920, Loss 2.928962\n",
      "    Params:  tensor([  5.3461, -17.1824])\n",
      "    Grad  :  tensor([-0.0037,  0.0208])\n",
      "Epoch 2921,Loss 2.928958\n",
      "Epoch 2921, Loss 2.928958\n",
      "    Params:  tensor([  5.3461, -17.1826])\n",
      "    Grad  :  tensor([-0.0037,  0.0208])\n",
      "Epoch 2922,Loss 2.928953\n",
      "Epoch 2922, Loss 2.928953\n",
      "    Params:  tensor([  5.3462, -17.1828])\n",
      "    Grad  :  tensor([-0.0037,  0.0208])\n",
      "Epoch 2923,Loss 2.928947\n",
      "Epoch 2923, Loss 2.928947\n",
      "    Params:  tensor([  5.3462, -17.1830])\n",
      "    Grad  :  tensor([-0.0036,  0.0207])\n",
      "Epoch 2924,Loss 2.928943\n",
      "Epoch 2924, Loss 2.928943\n",
      "    Params:  tensor([  5.3462, -17.1832])\n",
      "    Grad  :  tensor([-0.0037,  0.0207])\n",
      "Epoch 2925,Loss 2.928940\n",
      "Epoch 2925, Loss 2.928940\n",
      "    Params:  tensor([  5.3463, -17.1834])\n",
      "    Grad  :  tensor([-0.0036,  0.0206])\n",
      "Epoch 2926,Loss 2.928935\n",
      "Epoch 2926, Loss 2.928935\n",
      "    Params:  tensor([  5.3463, -17.1837])\n",
      "    Grad  :  tensor([-0.0036,  0.0206])\n",
      "Epoch 2927,Loss 2.928932\n",
      "Epoch 2927, Loss 2.928932\n",
      "    Params:  tensor([  5.3464, -17.1839])\n",
      "    Grad  :  tensor([-0.0036,  0.0206])\n",
      "Epoch 2928,Loss 2.928926\n",
      "Epoch 2928, Loss 2.928926\n",
      "    Params:  tensor([  5.3464, -17.1841])\n",
      "    Grad  :  tensor([-0.0036,  0.0205])\n",
      "Epoch 2929,Loss 2.928923\n",
      "Epoch 2929, Loss 2.928923\n",
      "    Params:  tensor([  5.3464, -17.1843])\n",
      "    Grad  :  tensor([-0.0036,  0.0205])\n",
      "Epoch 2930,Loss 2.928919\n",
      "Epoch 2930, Loss 2.928919\n",
      "    Params:  tensor([  5.3465, -17.1845])\n",
      "    Grad  :  tensor([-0.0036,  0.0205])\n",
      "Epoch 2931,Loss 2.928913\n",
      "Epoch 2931, Loss 2.928913\n",
      "    Params:  tensor([  5.3465, -17.1847])\n",
      "    Grad  :  tensor([-0.0036,  0.0204])\n",
      "Epoch 2932,Loss 2.928909\n",
      "Epoch 2932, Loss 2.928909\n",
      "    Params:  tensor([  5.3465, -17.1849])\n",
      "    Grad  :  tensor([-0.0036,  0.0204])\n",
      "Epoch 2933,Loss 2.928904\n",
      "Epoch 2933, Loss 2.928904\n",
      "    Params:  tensor([  5.3466, -17.1851])\n",
      "    Grad  :  tensor([-0.0036,  0.0204])\n",
      "Epoch 2934,Loss 2.928902\n",
      "Epoch 2934, Loss 2.928902\n",
      "    Params:  tensor([  5.3466, -17.1853])\n",
      "    Grad  :  tensor([-0.0036,  0.0203])\n",
      "Epoch 2935,Loss 2.928897\n",
      "Epoch 2935, Loss 2.928897\n",
      "    Params:  tensor([  5.3466, -17.1855])\n",
      "    Grad  :  tensor([-0.0036,  0.0203])\n",
      "Epoch 2936,Loss 2.928893\n",
      "Epoch 2936, Loss 2.928893\n",
      "    Params:  tensor([  5.3467, -17.1857])\n",
      "    Grad  :  tensor([-0.0036,  0.0203])\n",
      "Epoch 2937,Loss 2.928887\n",
      "Epoch 2937, Loss 2.928887\n",
      "    Params:  tensor([  5.3467, -17.1859])\n",
      "    Grad  :  tensor([-0.0036,  0.0202])\n",
      "Epoch 2938,Loss 2.928883\n",
      "Epoch 2938, Loss 2.928883\n",
      "    Params:  tensor([  5.3468, -17.1861])\n",
      "    Grad  :  tensor([-0.0035,  0.0202])\n",
      "Epoch 2939,Loss 2.928880\n",
      "Epoch 2939, Loss 2.928880\n",
      "    Params:  tensor([  5.3468, -17.1863])\n",
      "    Grad  :  tensor([-0.0036,  0.0202])\n",
      "Epoch 2940,Loss 2.928878\n",
      "Epoch 2940, Loss 2.928878\n",
      "    Params:  tensor([  5.3468, -17.1865])\n",
      "    Grad  :  tensor([-0.0036,  0.0201])\n",
      "Epoch 2941,Loss 2.928871\n",
      "Epoch 2941, Loss 2.928871\n",
      "    Params:  tensor([  5.3469, -17.1867])\n",
      "    Grad  :  tensor([-0.0035,  0.0201])\n",
      "Epoch 2942,Loss 2.928867\n",
      "Epoch 2942, Loss 2.928867\n",
      "    Params:  tensor([  5.3469, -17.1869])\n",
      "    Grad  :  tensor([-0.0035,  0.0201])\n",
      "Epoch 2943,Loss 2.928864\n",
      "Epoch 2943, Loss 2.928864\n",
      "    Params:  tensor([  5.3469, -17.1871])\n",
      "    Grad  :  tensor([-0.0035,  0.0200])\n",
      "Epoch 2944,Loss 2.928860\n",
      "Epoch 2944, Loss 2.928860\n",
      "    Params:  tensor([  5.3470, -17.1873])\n",
      "    Grad  :  tensor([-0.0035,  0.0200])\n",
      "Epoch 2945,Loss 2.928855\n",
      "Epoch 2945, Loss 2.928855\n",
      "    Params:  tensor([  5.3470, -17.1875])\n",
      "    Grad  :  tensor([-0.0035,  0.0200])\n",
      "Epoch 2946,Loss 2.928850\n",
      "Epoch 2946, Loss 2.928850\n",
      "    Params:  tensor([  5.3470, -17.1877])\n",
      "    Grad  :  tensor([-0.0035,  0.0199])\n",
      "Epoch 2947,Loss 2.928845\n",
      "Epoch 2947, Loss 2.928845\n",
      "    Params:  tensor([  5.3471, -17.1879])\n",
      "    Grad  :  tensor([-0.0035,  0.0199])\n",
      "Epoch 2948,Loss 2.928843\n",
      "Epoch 2948, Loss 2.928843\n",
      "    Params:  tensor([  5.3471, -17.1881])\n",
      "    Grad  :  tensor([-0.0035,  0.0199])\n",
      "Epoch 2949,Loss 2.928838\n",
      "Epoch 2949, Loss 2.928838\n",
      "    Params:  tensor([  5.3471, -17.1883])\n",
      "    Grad  :  tensor([-0.0035,  0.0198])\n",
      "Epoch 2950,Loss 2.928833\n",
      "Epoch 2950, Loss 2.928833\n",
      "    Params:  tensor([  5.3472, -17.1885])\n",
      "    Grad  :  tensor([-0.0035,  0.0198])\n",
      "Epoch 2951,Loss 2.928830\n",
      "Epoch 2951, Loss 2.928830\n",
      "    Params:  tensor([  5.3472, -17.1887])\n",
      "    Grad  :  tensor([-0.0035,  0.0198])\n",
      "Epoch 2952,Loss 2.928826\n",
      "Epoch 2952, Loss 2.928826\n",
      "    Params:  tensor([  5.3472, -17.1889])\n",
      "    Grad  :  tensor([-0.0035,  0.0197])\n",
      "Epoch 2953,Loss 2.928823\n",
      "Epoch 2953, Loss 2.928823\n",
      "    Params:  tensor([  5.3473, -17.1891])\n",
      "    Grad  :  tensor([-0.0035,  0.0197])\n",
      "Epoch 2954,Loss 2.928818\n",
      "Epoch 2954, Loss 2.928818\n",
      "    Params:  tensor([  5.3473, -17.1893])\n",
      "    Grad  :  tensor([-0.0035,  0.0197])\n",
      "Epoch 2955,Loss 2.928816\n",
      "Epoch 2955, Loss 2.928816\n",
      "    Params:  tensor([  5.3474, -17.1895])\n",
      "    Grad  :  tensor([-0.0035,  0.0196])\n",
      "Epoch 2956,Loss 2.928811\n",
      "Epoch 2956, Loss 2.928811\n",
      "    Params:  tensor([  5.3474, -17.1897])\n",
      "    Grad  :  tensor([-0.0035,  0.0196])\n",
      "Epoch 2957,Loss 2.928805\n",
      "Epoch 2957, Loss 2.928805\n",
      "    Params:  tensor([  5.3474, -17.1899])\n",
      "    Grad  :  tensor([-0.0034,  0.0196])\n",
      "Epoch 2958,Loss 2.928802\n",
      "Epoch 2958, Loss 2.928802\n",
      "    Params:  tensor([  5.3475, -17.1901])\n",
      "    Grad  :  tensor([-0.0035,  0.0195])\n",
      "Epoch 2959,Loss 2.928799\n",
      "Epoch 2959, Loss 2.928799\n",
      "    Params:  tensor([  5.3475, -17.1903])\n",
      "    Grad  :  tensor([-0.0034,  0.0195])\n",
      "Epoch 2960,Loss 2.928795\n",
      "Epoch 2960, Loss 2.928795\n",
      "    Params:  tensor([  5.3475, -17.1905])\n",
      "    Grad  :  tensor([-0.0034,  0.0195])\n",
      "Epoch 2961,Loss 2.928789\n",
      "Epoch 2961, Loss 2.928789\n",
      "    Params:  tensor([  5.3476, -17.1907])\n",
      "    Grad  :  tensor([-0.0034,  0.0194])\n",
      "Epoch 2962,Loss 2.928789\n",
      "Epoch 2962, Loss 2.928789\n",
      "    Params:  tensor([  5.3476, -17.1908])\n",
      "    Grad  :  tensor([-0.0034,  0.0194])\n",
      "Epoch 2963,Loss 2.928783\n",
      "Epoch 2963, Loss 2.928783\n",
      "    Params:  tensor([  5.3476, -17.1910])\n",
      "    Grad  :  tensor([-0.0034,  0.0194])\n",
      "Epoch 2964,Loss 2.928779\n",
      "Epoch 2964, Loss 2.928779\n",
      "    Params:  tensor([  5.3477, -17.1912])\n",
      "    Grad  :  tensor([-0.0034,  0.0193])\n",
      "Epoch 2965,Loss 2.928775\n",
      "Epoch 2965, Loss 2.928775\n",
      "    Params:  tensor([  5.3477, -17.1914])\n",
      "    Grad  :  tensor([-0.0034,  0.0193])\n",
      "Epoch 2966,Loss 2.928771\n",
      "Epoch 2966, Loss 2.928771\n",
      "    Params:  tensor([  5.3477, -17.1916])\n",
      "    Grad  :  tensor([-0.0034,  0.0193])\n",
      "Epoch 2967,Loss 2.928767\n",
      "Epoch 2967, Loss 2.928767\n",
      "    Params:  tensor([  5.3478, -17.1918])\n",
      "    Grad  :  tensor([-0.0034,  0.0192])\n",
      "Epoch 2968,Loss 2.928765\n",
      "Epoch 2968, Loss 2.928765\n",
      "    Params:  tensor([  5.3478, -17.1920])\n",
      "    Grad  :  tensor([-0.0034,  0.0192])\n",
      "Epoch 2969,Loss 2.928761\n",
      "Epoch 2969, Loss 2.928761\n",
      "    Params:  tensor([  5.3478, -17.1922])\n",
      "    Grad  :  tensor([-0.0034,  0.0192])\n",
      "Epoch 2970,Loss 2.928758\n",
      "Epoch 2970, Loss 2.928758\n",
      "    Params:  tensor([  5.3479, -17.1924])\n",
      "    Grad  :  tensor([-0.0034,  0.0191])\n",
      "Epoch 2971,Loss 2.928752\n",
      "Epoch 2971, Loss 2.928752\n",
      "    Params:  tensor([  5.3479, -17.1926])\n",
      "    Grad  :  tensor([-0.0034,  0.0191])\n",
      "Epoch 2972,Loss 2.928750\n",
      "Epoch 2972, Loss 2.928750\n",
      "    Params:  tensor([  5.3479, -17.1928])\n",
      "    Grad  :  tensor([-0.0034,  0.0191])\n",
      "Epoch 2973,Loss 2.928745\n",
      "Epoch 2973, Loss 2.928745\n",
      "    Params:  tensor([  5.3480, -17.1930])\n",
      "    Grad  :  tensor([-0.0034,  0.0190])\n",
      "Epoch 2974,Loss 2.928741\n",
      "Epoch 2974, Loss 2.928741\n",
      "    Params:  tensor([  5.3480, -17.1931])\n",
      "    Grad  :  tensor([-0.0034,  0.0190])\n",
      "Epoch 2975,Loss 2.928737\n",
      "Epoch 2975, Loss 2.928737\n",
      "    Params:  tensor([  5.3480, -17.1933])\n",
      "    Grad  :  tensor([-0.0034,  0.0190])\n",
      "Epoch 2976,Loss 2.928735\n",
      "Epoch 2976, Loss 2.928735\n",
      "    Params:  tensor([  5.3481, -17.1935])\n",
      "    Grad  :  tensor([-0.0033,  0.0189])\n",
      "Epoch 2977,Loss 2.928730\n",
      "Epoch 2977, Loss 2.928730\n",
      "    Params:  tensor([  5.3481, -17.1937])\n",
      "    Grad  :  tensor([-0.0033,  0.0189])\n",
      "Epoch 2978,Loss 2.928727\n",
      "Epoch 2978, Loss 2.928727\n",
      "    Params:  tensor([  5.3481, -17.1939])\n",
      "    Grad  :  tensor([-0.0033,  0.0189])\n",
      "Epoch 2979,Loss 2.928723\n",
      "Epoch 2979, Loss 2.928723\n",
      "    Params:  tensor([  5.3482, -17.1941])\n",
      "    Grad  :  tensor([-0.0033,  0.0188])\n",
      "Epoch 2980,Loss 2.928719\n",
      "Epoch 2980, Loss 2.928719\n",
      "    Params:  tensor([  5.3482, -17.1943])\n",
      "    Grad  :  tensor([-0.0033,  0.0188])\n",
      "Epoch 2981,Loss 2.928716\n",
      "Epoch 2981, Loss 2.928716\n",
      "    Params:  tensor([  5.3482, -17.1945])\n",
      "    Grad  :  tensor([-0.0033,  0.0188])\n",
      "Epoch 2982,Loss 2.928712\n",
      "Epoch 2982, Loss 2.928712\n",
      "    Params:  tensor([  5.3483, -17.1947])\n",
      "    Grad  :  tensor([-0.0033,  0.0187])\n",
      "Epoch 2983,Loss 2.928708\n",
      "Epoch 2983, Loss 2.928708\n",
      "    Params:  tensor([  5.3483, -17.1948])\n",
      "    Grad  :  tensor([-0.0033,  0.0187])\n",
      "Epoch 2984,Loss 2.928705\n",
      "Epoch 2984, Loss 2.928705\n",
      "    Params:  tensor([  5.3483, -17.1950])\n",
      "    Grad  :  tensor([-0.0033,  0.0187])\n",
      "Epoch 2985,Loss 2.928700\n",
      "Epoch 2985, Loss 2.928700\n",
      "    Params:  tensor([  5.3484, -17.1952])\n",
      "    Grad  :  tensor([-0.0033,  0.0186])\n",
      "Epoch 2986,Loss 2.928698\n",
      "Epoch 2986, Loss 2.928698\n",
      "    Params:  tensor([  5.3484, -17.1954])\n",
      "    Grad  :  tensor([-0.0033,  0.0186])\n",
      "Epoch 2987,Loss 2.928695\n",
      "Epoch 2987, Loss 2.928695\n",
      "    Params:  tensor([  5.3484, -17.1956])\n",
      "    Grad  :  tensor([-0.0033,  0.0186])\n",
      "Epoch 2988,Loss 2.928690\n",
      "Epoch 2988, Loss 2.928690\n",
      "    Params:  tensor([  5.3485, -17.1958])\n",
      "    Grad  :  tensor([-0.0033,  0.0186])\n",
      "Epoch 2989,Loss 2.928687\n",
      "Epoch 2989, Loss 2.928687\n",
      "    Params:  tensor([  5.3485, -17.1960])\n",
      "    Grad  :  tensor([-0.0033,  0.0185])\n",
      "Epoch 2990,Loss 2.928684\n",
      "Epoch 2990, Loss 2.928684\n",
      "    Params:  tensor([  5.3485, -17.1961])\n",
      "    Grad  :  tensor([-0.0033,  0.0185])\n",
      "Epoch 2991,Loss 2.928679\n",
      "Epoch 2991, Loss 2.928679\n",
      "    Params:  tensor([  5.3486, -17.1963])\n",
      "    Grad  :  tensor([-0.0032,  0.0185])\n",
      "Epoch 2992,Loss 2.928677\n",
      "Epoch 2992, Loss 2.928677\n",
      "    Params:  tensor([  5.3486, -17.1965])\n",
      "    Grad  :  tensor([-0.0033,  0.0184])\n",
      "Epoch 2993,Loss 2.928673\n",
      "Epoch 2993, Loss 2.928673\n",
      "    Params:  tensor([  5.3486, -17.1967])\n",
      "    Grad  :  tensor([-0.0033,  0.0184])\n",
      "Epoch 2994,Loss 2.928669\n",
      "Epoch 2994, Loss 2.928669\n",
      "    Params:  tensor([  5.3487, -17.1969])\n",
      "    Grad  :  tensor([-0.0033,  0.0184])\n",
      "Epoch 2995,Loss 2.928666\n",
      "Epoch 2995, Loss 2.928666\n",
      "    Params:  tensor([  5.3487, -17.1971])\n",
      "    Grad  :  tensor([-0.0032,  0.0183])\n",
      "Epoch 2996,Loss 2.928662\n",
      "Epoch 2996, Loss 2.928662\n",
      "    Params:  tensor([  5.3487, -17.1972])\n",
      "    Grad  :  tensor([-0.0032,  0.0183])\n",
      "Epoch 2997,Loss 2.928660\n",
      "Epoch 2997, Loss 2.928660\n",
      "    Params:  tensor([  5.3488, -17.1974])\n",
      "    Grad  :  tensor([-0.0032,  0.0183])\n",
      "Epoch 2998,Loss 2.928656\n",
      "Epoch 2998, Loss 2.928656\n",
      "    Params:  tensor([  5.3488, -17.1976])\n",
      "    Grad  :  tensor([-0.0032,  0.0182])\n",
      "Epoch 2999,Loss 2.928651\n",
      "Epoch 2999, Loss 2.928651\n",
      "    Params:  tensor([  5.3488, -17.1978])\n",
      "    Grad  :  tensor([-0.0032,  0.0182])\n",
      "Epoch 3000,Loss 2.928648\n",
      "Epoch 3000, Loss 2.928648\n",
      "    Params:  tensor([  5.3489, -17.1980])\n",
      "    Grad  :  tensor([-0.0032,  0.0182])\n",
      "Epoch 3001,Loss 2.928646\n",
      "Epoch 3001, Loss 2.928646\n",
      "    Params:  tensor([  5.3489, -17.1982])\n",
      "    Grad  :  tensor([-0.0032,  0.0181])\n",
      "Epoch 3002,Loss 2.928643\n",
      "Epoch 3002, Loss 2.928643\n",
      "    Params:  tensor([  5.3489, -17.1983])\n",
      "    Grad  :  tensor([-0.0032,  0.0181])\n",
      "Epoch 3003,Loss 2.928638\n",
      "Epoch 3003, Loss 2.928638\n",
      "    Params:  tensor([  5.3489, -17.1985])\n",
      "    Grad  :  tensor([-0.0032,  0.0181])\n",
      "Epoch 3004,Loss 2.928635\n",
      "Epoch 3004, Loss 2.928635\n",
      "    Params:  tensor([  5.3490, -17.1987])\n",
      "    Grad  :  tensor([-0.0032,  0.0181])\n",
      "Epoch 3005,Loss 2.928632\n",
      "Epoch 3005, Loss 2.928632\n",
      "    Params:  tensor([  5.3490, -17.1989])\n",
      "    Grad  :  tensor([-0.0032,  0.0180])\n",
      "Epoch 3006,Loss 2.928629\n",
      "Epoch 3006, Loss 2.928629\n",
      "    Params:  tensor([  5.3490, -17.1991])\n",
      "    Grad  :  tensor([-0.0032,  0.0180])\n",
      "Epoch 3007,Loss 2.928625\n",
      "Epoch 3007, Loss 2.928625\n",
      "    Params:  tensor([  5.3491, -17.1992])\n",
      "    Grad  :  tensor([-0.0032,  0.0180])\n",
      "Epoch 3008,Loss 2.928621\n",
      "Epoch 3008, Loss 2.928621\n",
      "    Params:  tensor([  5.3491, -17.1994])\n",
      "    Grad  :  tensor([-0.0032,  0.0179])\n",
      "Epoch 3009,Loss 2.928617\n",
      "Epoch 3009, Loss 2.928617\n",
      "    Params:  tensor([  5.3491, -17.1996])\n",
      "    Grad  :  tensor([-0.0032,  0.0179])\n",
      "Epoch 3010,Loss 2.928616\n",
      "Epoch 3010, Loss 2.928616\n",
      "    Params:  tensor([  5.3492, -17.1998])\n",
      "    Grad  :  tensor([-0.0032,  0.0179])\n",
      "Epoch 3011,Loss 2.928612\n",
      "Epoch 3011, Loss 2.928612\n",
      "    Params:  tensor([  5.3492, -17.2000])\n",
      "    Grad  :  tensor([-0.0032,  0.0178])\n",
      "Epoch 3012,Loss 2.928608\n",
      "Epoch 3012, Loss 2.928608\n",
      "    Params:  tensor([  5.3492, -17.2001])\n",
      "    Grad  :  tensor([-0.0032,  0.0178])\n",
      "Epoch 3013,Loss 2.928604\n",
      "Epoch 3013, Loss 2.928604\n",
      "    Params:  tensor([  5.3493, -17.2003])\n",
      "    Grad  :  tensor([-0.0031,  0.0178])\n",
      "Epoch 3014,Loss 2.928601\n",
      "Epoch 3014, Loss 2.928601\n",
      "    Params:  tensor([  5.3493, -17.2005])\n",
      "    Grad  :  tensor([-0.0031,  0.0177])\n",
      "Epoch 3015,Loss 2.928599\n",
      "Epoch 3015, Loss 2.928599\n",
      "    Params:  tensor([  5.3493, -17.2007])\n",
      "    Grad  :  tensor([-0.0031,  0.0177])\n",
      "Epoch 3016,Loss 2.928596\n",
      "Epoch 3016, Loss 2.928596\n",
      "    Params:  tensor([  5.3494, -17.2008])\n",
      "    Grad  :  tensor([-0.0031,  0.0177])\n",
      "Epoch 3017,Loss 2.928592\n",
      "Epoch 3017, Loss 2.928592\n",
      "    Params:  tensor([  5.3494, -17.2010])\n",
      "    Grad  :  tensor([-0.0031,  0.0177])\n",
      "Epoch 3018,Loss 2.928588\n",
      "Epoch 3018, Loss 2.928588\n",
      "    Params:  tensor([  5.3494, -17.2012])\n",
      "    Grad  :  tensor([-0.0031,  0.0176])\n",
      "Epoch 3019,Loss 2.928586\n",
      "Epoch 3019, Loss 2.928586\n",
      "    Params:  tensor([  5.3495, -17.2014])\n",
      "    Grad  :  tensor([-0.0031,  0.0176])\n",
      "Epoch 3020,Loss 2.928583\n",
      "Epoch 3020, Loss 2.928583\n",
      "    Params:  tensor([  5.3495, -17.2015])\n",
      "    Grad  :  tensor([-0.0031,  0.0176])\n",
      "Epoch 3021,Loss 2.928580\n",
      "Epoch 3021, Loss 2.928580\n",
      "    Params:  tensor([  5.3495, -17.2017])\n",
      "    Grad  :  tensor([-0.0031,  0.0175])\n",
      "Epoch 3022,Loss 2.928576\n",
      "Epoch 3022, Loss 2.928576\n",
      "    Params:  tensor([  5.3495, -17.2019])\n",
      "    Grad  :  tensor([-0.0031,  0.0175])\n",
      "Epoch 3023,Loss 2.928574\n",
      "Epoch 3023, Loss 2.928574\n",
      "    Params:  tensor([  5.3496, -17.2021])\n",
      "    Grad  :  tensor([-0.0031,  0.0175])\n",
      "Epoch 3024,Loss 2.928570\n",
      "Epoch 3024, Loss 2.928570\n",
      "    Params:  tensor([  5.3496, -17.2022])\n",
      "    Grad  :  tensor([-0.0031,  0.0175])\n",
      "Epoch 3025,Loss 2.928567\n",
      "Epoch 3025, Loss 2.928567\n",
      "    Params:  tensor([  5.3496, -17.2024])\n",
      "    Grad  :  tensor([-0.0031,  0.0174])\n",
      "Epoch 3026,Loss 2.928564\n",
      "Epoch 3026, Loss 2.928564\n",
      "    Params:  tensor([  5.3497, -17.2026])\n",
      "    Grad  :  tensor([-0.0031,  0.0174])\n",
      "Epoch 3027,Loss 2.928561\n",
      "Epoch 3027, Loss 2.928561\n",
      "    Params:  tensor([  5.3497, -17.2028])\n",
      "    Grad  :  tensor([-0.0030,  0.0174])\n",
      "Epoch 3028,Loss 2.928557\n",
      "Epoch 3028, Loss 2.928557\n",
      "    Params:  tensor([  5.3497, -17.2029])\n",
      "    Grad  :  tensor([-0.0031,  0.0173])\n",
      "Epoch 3029,Loss 2.928555\n",
      "Epoch 3029, Loss 2.928555\n",
      "    Params:  tensor([  5.3498, -17.2031])\n",
      "    Grad  :  tensor([-0.0031,  0.0173])\n",
      "Epoch 3030,Loss 2.928551\n",
      "Epoch 3030, Loss 2.928551\n",
      "    Params:  tensor([  5.3498, -17.2033])\n",
      "    Grad  :  tensor([-0.0031,  0.0173])\n",
      "Epoch 3031,Loss 2.928548\n",
      "Epoch 3031, Loss 2.928548\n",
      "    Params:  tensor([  5.3498, -17.2035])\n",
      "    Grad  :  tensor([-0.0031,  0.0172])\n",
      "Epoch 3032,Loss 2.928545\n",
      "Epoch 3032, Loss 2.928545\n",
      "    Params:  tensor([  5.3498, -17.2036])\n",
      "    Grad  :  tensor([-0.0030,  0.0172])\n",
      "Epoch 3033,Loss 2.928543\n",
      "Epoch 3033, Loss 2.928543\n",
      "    Params:  tensor([  5.3499, -17.2038])\n",
      "    Grad  :  tensor([-0.0030,  0.0172])\n",
      "Epoch 3034,Loss 2.928539\n",
      "Epoch 3034, Loss 2.928539\n",
      "    Params:  tensor([  5.3499, -17.2040])\n",
      "    Grad  :  tensor([-0.0030,  0.0172])\n",
      "Epoch 3035,Loss 2.928536\n",
      "Epoch 3035, Loss 2.928536\n",
      "    Params:  tensor([  5.3499, -17.2041])\n",
      "    Grad  :  tensor([-0.0030,  0.0171])\n",
      "Epoch 3036,Loss 2.928532\n",
      "Epoch 3036, Loss 2.928532\n",
      "    Params:  tensor([  5.3500, -17.2043])\n",
      "    Grad  :  tensor([-0.0030,  0.0171])\n",
      "Epoch 3037,Loss 2.928531\n",
      "Epoch 3037, Loss 2.928531\n",
      "    Params:  tensor([  5.3500, -17.2045])\n",
      "    Grad  :  tensor([-0.0030,  0.0171])\n",
      "Epoch 3038,Loss 2.928528\n",
      "Epoch 3038, Loss 2.928528\n",
      "    Params:  tensor([  5.3500, -17.2047])\n",
      "    Grad  :  tensor([-0.0030,  0.0170])\n",
      "Epoch 3039,Loss 2.928524\n",
      "Epoch 3039, Loss 2.928524\n",
      "    Params:  tensor([  5.3501, -17.2048])\n",
      "    Grad  :  tensor([-0.0030,  0.0170])\n",
      "Epoch 3040,Loss 2.928521\n",
      "Epoch 3040, Loss 2.928521\n",
      "    Params:  tensor([  5.3501, -17.2050])\n",
      "    Grad  :  tensor([-0.0030,  0.0170])\n",
      "Epoch 3041,Loss 2.928519\n",
      "Epoch 3041, Loss 2.928519\n",
      "    Params:  tensor([  5.3501, -17.2052])\n",
      "    Grad  :  tensor([-0.0030,  0.0170])\n",
      "Epoch 3042,Loss 2.928514\n",
      "Epoch 3042, Loss 2.928514\n",
      "    Params:  tensor([  5.3502, -17.2053])\n",
      "    Grad  :  tensor([-0.0030,  0.0169])\n",
      "Epoch 3043,Loss 2.928512\n",
      "Epoch 3043, Loss 2.928512\n",
      "    Params:  tensor([  5.3502, -17.2055])\n",
      "    Grad  :  tensor([-0.0030,  0.0169])\n",
      "Epoch 3044,Loss 2.928509\n",
      "Epoch 3044, Loss 2.928509\n",
      "    Params:  tensor([  5.3502, -17.2057])\n",
      "    Grad  :  tensor([-0.0030,  0.0169])\n",
      "Epoch 3045,Loss 2.928505\n",
      "Epoch 3045, Loss 2.928505\n",
      "    Params:  tensor([  5.3502, -17.2058])\n",
      "    Grad  :  tensor([-0.0030,  0.0168])\n",
      "Epoch 3046,Loss 2.928503\n",
      "Epoch 3046, Loss 2.928503\n",
      "    Params:  tensor([  5.3503, -17.2060])\n",
      "    Grad  :  tensor([-0.0030,  0.0168])\n",
      "Epoch 3047,Loss 2.928500\n",
      "Epoch 3047, Loss 2.928500\n",
      "    Params:  tensor([  5.3503, -17.2062])\n",
      "    Grad  :  tensor([-0.0030,  0.0168])\n",
      "Epoch 3048,Loss 2.928498\n",
      "Epoch 3048, Loss 2.928498\n",
      "    Params:  tensor([  5.3503, -17.2063])\n",
      "    Grad  :  tensor([-0.0030,  0.0168])\n",
      "Epoch 3049,Loss 2.928495\n",
      "Epoch 3049, Loss 2.928495\n",
      "    Params:  tensor([  5.3504, -17.2065])\n",
      "    Grad  :  tensor([-0.0030,  0.0167])\n",
      "Epoch 3050,Loss 2.928491\n",
      "Epoch 3050, Loss 2.928491\n",
      "    Params:  tensor([  5.3504, -17.2067])\n",
      "    Grad  :  tensor([-0.0030,  0.0167])\n",
      "Epoch 3051,Loss 2.928489\n",
      "Epoch 3051, Loss 2.928489\n",
      "    Params:  tensor([  5.3504, -17.2068])\n",
      "    Grad  :  tensor([-0.0030,  0.0167])\n",
      "Epoch 3052,Loss 2.928486\n",
      "Epoch 3052, Loss 2.928486\n",
      "    Params:  tensor([  5.3504, -17.2070])\n",
      "    Grad  :  tensor([-0.0029,  0.0166])\n",
      "Epoch 3053,Loss 2.928484\n",
      "Epoch 3053, Loss 2.928484\n",
      "    Params:  tensor([  5.3505, -17.2072])\n",
      "    Grad  :  tensor([-0.0029,  0.0166])\n",
      "Epoch 3054,Loss 2.928481\n",
      "Epoch 3054, Loss 2.928481\n",
      "    Params:  tensor([  5.3505, -17.2073])\n",
      "    Grad  :  tensor([-0.0029,  0.0166])\n",
      "Epoch 3055,Loss 2.928477\n",
      "Epoch 3055, Loss 2.928477\n",
      "    Params:  tensor([  5.3505, -17.2075])\n",
      "    Grad  :  tensor([-0.0029,  0.0165])\n",
      "Epoch 3056,Loss 2.928474\n",
      "Epoch 3056, Loss 2.928474\n",
      "    Params:  tensor([  5.3506, -17.2077])\n",
      "    Grad  :  tensor([-0.0029,  0.0165])\n",
      "Epoch 3057,Loss 2.928472\n",
      "Epoch 3057, Loss 2.928472\n",
      "    Params:  tensor([  5.3506, -17.2078])\n",
      "    Grad  :  tensor([-0.0029,  0.0165])\n",
      "Epoch 3058,Loss 2.928469\n",
      "Epoch 3058, Loss 2.928469\n",
      "    Params:  tensor([  5.3506, -17.2080])\n",
      "    Grad  :  tensor([-0.0029,  0.0165])\n",
      "Epoch 3059,Loss 2.928468\n",
      "Epoch 3059, Loss 2.928468\n",
      "    Params:  tensor([  5.3507, -17.2082])\n",
      "    Grad  :  tensor([-0.0029,  0.0164])\n",
      "Epoch 3060,Loss 2.928463\n",
      "Epoch 3060, Loss 2.928463\n",
      "    Params:  tensor([  5.3507, -17.2083])\n",
      "    Grad  :  tensor([-0.0029,  0.0164])\n",
      "Epoch 3061,Loss 2.928460\n",
      "Epoch 3061, Loss 2.928460\n",
      "    Params:  tensor([  5.3507, -17.2085])\n",
      "    Grad  :  tensor([-0.0029,  0.0164])\n",
      "Epoch 3062,Loss 2.928458\n",
      "Epoch 3062, Loss 2.928458\n",
      "    Params:  tensor([  5.3507, -17.2087])\n",
      "    Grad  :  tensor([-0.0029,  0.0164])\n",
      "Epoch 3063,Loss 2.928456\n",
      "Epoch 3063, Loss 2.928456\n",
      "    Params:  tensor([  5.3508, -17.2088])\n",
      "    Grad  :  tensor([-0.0029,  0.0163])\n",
      "Epoch 3064,Loss 2.928452\n",
      "Epoch 3064, Loss 2.928452\n",
      "    Params:  tensor([  5.3508, -17.2090])\n",
      "    Grad  :  tensor([-0.0029,  0.0163])\n",
      "Epoch 3065,Loss 2.928449\n",
      "Epoch 3065, Loss 2.928449\n",
      "    Params:  tensor([  5.3508, -17.2091])\n",
      "    Grad  :  tensor([-0.0029,  0.0163])\n",
      "Epoch 3066,Loss 2.928447\n",
      "Epoch 3066, Loss 2.928447\n",
      "    Params:  tensor([  5.3509, -17.2093])\n",
      "    Grad  :  tensor([-0.0029,  0.0162])\n",
      "Epoch 3067,Loss 2.928443\n",
      "Epoch 3067, Loss 2.928443\n",
      "    Params:  tensor([  5.3509, -17.2095])\n",
      "    Grad  :  tensor([-0.0029,  0.0162])\n",
      "Epoch 3068,Loss 2.928444\n",
      "Epoch 3068, Loss 2.928444\n",
      "    Params:  tensor([  5.3509, -17.2096])\n",
      "    Grad  :  tensor([-0.0029,  0.0162])\n",
      "Epoch 3069,Loss 2.928440\n",
      "Epoch 3069, Loss 2.928440\n",
      "    Params:  tensor([  5.3509, -17.2098])\n",
      "    Grad  :  tensor([-0.0029,  0.0162])\n",
      "Epoch 3070,Loss 2.928435\n",
      "Epoch 3070, Loss 2.928435\n",
      "    Params:  tensor([  5.3510, -17.2100])\n",
      "    Grad  :  tensor([-0.0029,  0.0161])\n",
      "Epoch 3071,Loss 2.928435\n",
      "Epoch 3071, Loss 2.928435\n",
      "    Params:  tensor([  5.3510, -17.2101])\n",
      "    Grad  :  tensor([-0.0029,  0.0161])\n",
      "Epoch 3072,Loss 2.928430\n",
      "Epoch 3072, Loss 2.928430\n",
      "    Params:  tensor([  5.3510, -17.2103])\n",
      "    Grad  :  tensor([-0.0028,  0.0161])\n",
      "Epoch 3073,Loss 2.928428\n",
      "Epoch 3073, Loss 2.928428\n",
      "    Params:  tensor([  5.3511, -17.2104])\n",
      "    Grad  :  tensor([-0.0028,  0.0161])\n",
      "Epoch 3074,Loss 2.928426\n",
      "Epoch 3074, Loss 2.928426\n",
      "    Params:  tensor([  5.3511, -17.2106])\n",
      "    Grad  :  tensor([-0.0028,  0.0160])\n",
      "Epoch 3075,Loss 2.928423\n",
      "Epoch 3075, Loss 2.928423\n",
      "    Params:  tensor([  5.3511, -17.2108])\n",
      "    Grad  :  tensor([-0.0028,  0.0160])\n",
      "Epoch 3076,Loss 2.928421\n",
      "Epoch 3076, Loss 2.928421\n",
      "    Params:  tensor([  5.3511, -17.2109])\n",
      "    Grad  :  tensor([-0.0028,  0.0160])\n",
      "Epoch 3077,Loss 2.928417\n",
      "Epoch 3077, Loss 2.928417\n",
      "    Params:  tensor([  5.3512, -17.2111])\n",
      "    Grad  :  tensor([-0.0028,  0.0159])\n",
      "Epoch 3078,Loss 2.928416\n",
      "Epoch 3078, Loss 2.928416\n",
      "    Params:  tensor([  5.3512, -17.2112])\n",
      "    Grad  :  tensor([-0.0028,  0.0159])\n",
      "Epoch 3079,Loss 2.928411\n",
      "Epoch 3079, Loss 2.928411\n",
      "    Params:  tensor([  5.3512, -17.2114])\n",
      "    Grad  :  tensor([-0.0028,  0.0159])\n",
      "Epoch 3080,Loss 2.928410\n",
      "Epoch 3080, Loss 2.928410\n",
      "    Params:  tensor([  5.3512, -17.2116])\n",
      "    Grad  :  tensor([-0.0028,  0.0159])\n",
      "Epoch 3081,Loss 2.928407\n",
      "Epoch 3081, Loss 2.928407\n",
      "    Params:  tensor([  5.3513, -17.2117])\n",
      "    Grad  :  tensor([-0.0028,  0.0158])\n",
      "Epoch 3082,Loss 2.928404\n",
      "Epoch 3082, Loss 2.928404\n",
      "    Params:  tensor([  5.3513, -17.2119])\n",
      "    Grad  :  tensor([-0.0028,  0.0158])\n",
      "Epoch 3083,Loss 2.928402\n",
      "Epoch 3083, Loss 2.928402\n",
      "    Params:  tensor([  5.3513, -17.2120])\n",
      "    Grad  :  tensor([-0.0028,  0.0158])\n",
      "Epoch 3084,Loss 2.928399\n",
      "Epoch 3084, Loss 2.928399\n",
      "    Params:  tensor([  5.3514, -17.2122])\n",
      "    Grad  :  tensor([-0.0028,  0.0158])\n",
      "Epoch 3085,Loss 2.928396\n",
      "Epoch 3085, Loss 2.928396\n",
      "    Params:  tensor([  5.3514, -17.2123])\n",
      "    Grad  :  tensor([-0.0028,  0.0157])\n",
      "Epoch 3086,Loss 2.928395\n",
      "Epoch 3086, Loss 2.928395\n",
      "    Params:  tensor([  5.3514, -17.2125])\n",
      "    Grad  :  tensor([-0.0028,  0.0157])\n",
      "Epoch 3087,Loss 2.928392\n",
      "Epoch 3087, Loss 2.928392\n",
      "    Params:  tensor([  5.3514, -17.2127])\n",
      "    Grad  :  tensor([-0.0027,  0.0157])\n",
      "Epoch 3088,Loss 2.928389\n",
      "Epoch 3088, Loss 2.928389\n",
      "    Params:  tensor([  5.3515, -17.2128])\n",
      "    Grad  :  tensor([-0.0027,  0.0157])\n",
      "Epoch 3089,Loss 2.928386\n",
      "Epoch 3089, Loss 2.928386\n",
      "    Params:  tensor([  5.3515, -17.2130])\n",
      "    Grad  :  tensor([-0.0027,  0.0156])\n",
      "Epoch 3090,Loss 2.928383\n",
      "Epoch 3090, Loss 2.928383\n",
      "    Params:  tensor([  5.3515, -17.2131])\n",
      "    Grad  :  tensor([-0.0028,  0.0156])\n",
      "Epoch 3091,Loss 2.928382\n",
      "Epoch 3091, Loss 2.928382\n",
      "    Params:  tensor([  5.3516, -17.2133])\n",
      "    Grad  :  tensor([-0.0028,  0.0156])\n",
      "Epoch 3092,Loss 2.928379\n",
      "Epoch 3092, Loss 2.928379\n",
      "    Params:  tensor([  5.3516, -17.2134])\n",
      "    Grad  :  tensor([-0.0027,  0.0155])\n",
      "Epoch 3093,Loss 2.928378\n",
      "Epoch 3093, Loss 2.928378\n",
      "    Params:  tensor([  5.3516, -17.2136])\n",
      "    Grad  :  tensor([-0.0027,  0.0155])\n",
      "Epoch 3094,Loss 2.928375\n",
      "Epoch 3094, Loss 2.928375\n",
      "    Params:  tensor([  5.3516, -17.2137])\n",
      "    Grad  :  tensor([-0.0027,  0.0155])\n",
      "Epoch 3095,Loss 2.928372\n",
      "Epoch 3095, Loss 2.928372\n",
      "    Params:  tensor([  5.3517, -17.2139])\n",
      "    Grad  :  tensor([-0.0027,  0.0155])\n",
      "Epoch 3096,Loss 2.928370\n",
      "Epoch 3096, Loss 2.928370\n",
      "    Params:  tensor([  5.3517, -17.2141])\n",
      "    Grad  :  tensor([-0.0027,  0.0154])\n",
      "Epoch 3097,Loss 2.928368\n",
      "Epoch 3097, Loss 2.928368\n",
      "    Params:  tensor([  5.3517, -17.2142])\n",
      "    Grad  :  tensor([-0.0027,  0.0154])\n",
      "Epoch 3098,Loss 2.928364\n",
      "Epoch 3098, Loss 2.928364\n",
      "    Params:  tensor([  5.3517, -17.2144])\n",
      "    Grad  :  tensor([-0.0027,  0.0154])\n",
      "Epoch 3099,Loss 2.928362\n",
      "Epoch 3099, Loss 2.928362\n",
      "    Params:  tensor([  5.3518, -17.2145])\n",
      "    Grad  :  tensor([-0.0027,  0.0154])\n",
      "Epoch 3100,Loss 2.928361\n",
      "Epoch 3100, Loss 2.928361\n",
      "    Params:  tensor([  5.3518, -17.2147])\n",
      "    Grad  :  tensor([-0.0027,  0.0153])\n",
      "Epoch 3101,Loss 2.928356\n",
      "Epoch 3101, Loss 2.928356\n",
      "    Params:  tensor([  5.3518, -17.2148])\n",
      "    Grad  :  tensor([-0.0027,  0.0153])\n",
      "Epoch 3102,Loss 2.928355\n",
      "Epoch 3102, Loss 2.928355\n",
      "    Params:  tensor([  5.3519, -17.2150])\n",
      "    Grad  :  tensor([-0.0027,  0.0153])\n",
      "Epoch 3103,Loss 2.928353\n",
      "Epoch 3103, Loss 2.928353\n",
      "    Params:  tensor([  5.3519, -17.2151])\n",
      "    Grad  :  tensor([-0.0027,  0.0153])\n",
      "Epoch 3104,Loss 2.928349\n",
      "Epoch 3104, Loss 2.928349\n",
      "    Params:  tensor([  5.3519, -17.2153])\n",
      "    Grad  :  tensor([-0.0027,  0.0152])\n",
      "Epoch 3105,Loss 2.928348\n",
      "Epoch 3105, Loss 2.928348\n",
      "    Params:  tensor([  5.3519, -17.2154])\n",
      "    Grad  :  tensor([-0.0027,  0.0152])\n",
      "Epoch 3106,Loss 2.928345\n",
      "Epoch 3106, Loss 2.928345\n",
      "    Params:  tensor([  5.3520, -17.2156])\n",
      "    Grad  :  tensor([-0.0027,  0.0152])\n",
      "Epoch 3107,Loss 2.928343\n",
      "Epoch 3107, Loss 2.928343\n",
      "    Params:  tensor([  5.3520, -17.2157])\n",
      "    Grad  :  tensor([-0.0027,  0.0152])\n",
      "Epoch 3108,Loss 2.928340\n",
      "Epoch 3108, Loss 2.928340\n",
      "    Params:  tensor([  5.3520, -17.2159])\n",
      "    Grad  :  tensor([-0.0027,  0.0151])\n",
      "Epoch 3109,Loss 2.928339\n",
      "Epoch 3109, Loss 2.928339\n",
      "    Params:  tensor([  5.3520, -17.2160])\n",
      "    Grad  :  tensor([-0.0027,  0.0151])\n",
      "Epoch 3110,Loss 2.928337\n",
      "Epoch 3110, Loss 2.928337\n",
      "    Params:  tensor([  5.3521, -17.2162])\n",
      "    Grad  :  tensor([-0.0027,  0.0151])\n",
      "Epoch 3111,Loss 2.928333\n",
      "Epoch 3111, Loss 2.928333\n",
      "    Params:  tensor([  5.3521, -17.2163])\n",
      "    Grad  :  tensor([-0.0027,  0.0151])\n",
      "Epoch 3112,Loss 2.928332\n",
      "Epoch 3112, Loss 2.928332\n",
      "    Params:  tensor([  5.3521, -17.2165])\n",
      "    Grad  :  tensor([-0.0027,  0.0150])\n",
      "Epoch 3113,Loss 2.928328\n",
      "Epoch 3113, Loss 2.928328\n",
      "    Params:  tensor([  5.3521, -17.2166])\n",
      "    Grad  :  tensor([-0.0026,  0.0150])\n",
      "Epoch 3114,Loss 2.928329\n",
      "Epoch 3114, Loss 2.928329\n",
      "    Params:  tensor([  5.3522, -17.2168])\n",
      "    Grad  :  tensor([-0.0027,  0.0150])\n",
      "Epoch 3115,Loss 2.928324\n",
      "Epoch 3115, Loss 2.928324\n",
      "    Params:  tensor([  5.3522, -17.2169])\n",
      "    Grad  :  tensor([-0.0026,  0.0149])\n",
      "Epoch 3116,Loss 2.928323\n",
      "Epoch 3116, Loss 2.928323\n",
      "    Params:  tensor([  5.3522, -17.2171])\n",
      "    Grad  :  tensor([-0.0026,  0.0149])\n",
      "Epoch 3117,Loss 2.928320\n",
      "Epoch 3117, Loss 2.928320\n",
      "    Params:  tensor([  5.3523, -17.2172])\n",
      "    Grad  :  tensor([-0.0026,  0.0149])\n",
      "Epoch 3118,Loss 2.928319\n",
      "Epoch 3118, Loss 2.928319\n",
      "    Params:  tensor([  5.3523, -17.2174])\n",
      "    Grad  :  tensor([-0.0026,  0.0149])\n",
      "Epoch 3119,Loss 2.928315\n",
      "Epoch 3119, Loss 2.928315\n",
      "    Params:  tensor([  5.3523, -17.2175])\n",
      "    Grad  :  tensor([-0.0026,  0.0148])\n",
      "Epoch 3120,Loss 2.928313\n",
      "Epoch 3120, Loss 2.928313\n",
      "    Params:  tensor([  5.3523, -17.2177])\n",
      "    Grad  :  tensor([-0.0026,  0.0148])\n",
      "Epoch 3121,Loss 2.928310\n",
      "Epoch 3121, Loss 2.928310\n",
      "    Params:  tensor([  5.3524, -17.2178])\n",
      "    Grad  :  tensor([-0.0026,  0.0148])\n",
      "Epoch 3122,Loss 2.928308\n",
      "Epoch 3122, Loss 2.928308\n",
      "    Params:  tensor([  5.3524, -17.2180])\n",
      "    Grad  :  tensor([-0.0026,  0.0148])\n",
      "Epoch 3123,Loss 2.928306\n",
      "Epoch 3123, Loss 2.928306\n",
      "    Params:  tensor([  5.3524, -17.2181])\n",
      "    Grad  :  tensor([-0.0026,  0.0147])\n",
      "Epoch 3124,Loss 2.928304\n",
      "Epoch 3124, Loss 2.928304\n",
      "    Params:  tensor([  5.3524, -17.2183])\n",
      "    Grad  :  tensor([-0.0026,  0.0147])\n",
      "Epoch 3125,Loss 2.928303\n",
      "Epoch 3125, Loss 2.928303\n",
      "    Params:  tensor([  5.3525, -17.2184])\n",
      "    Grad  :  tensor([-0.0026,  0.0147])\n",
      "Epoch 3126,Loss 2.928299\n",
      "Epoch 3126, Loss 2.928299\n",
      "    Params:  tensor([  5.3525, -17.2186])\n",
      "    Grad  :  tensor([-0.0026,  0.0147])\n",
      "Epoch 3127,Loss 2.928296\n",
      "Epoch 3127, Loss 2.928296\n",
      "    Params:  tensor([  5.3525, -17.2187])\n",
      "    Grad  :  tensor([-0.0026,  0.0146])\n",
      "Epoch 3128,Loss 2.928295\n",
      "Epoch 3128, Loss 2.928295\n",
      "    Params:  tensor([  5.3525, -17.2189])\n",
      "    Grad  :  tensor([-0.0026,  0.0146])\n",
      "Epoch 3129,Loss 2.928293\n",
      "Epoch 3129, Loss 2.928293\n",
      "    Params:  tensor([  5.3526, -17.2190])\n",
      "    Grad  :  tensor([-0.0026,  0.0146])\n",
      "Epoch 3130,Loss 2.928291\n",
      "Epoch 3130, Loss 2.928291\n",
      "    Params:  tensor([  5.3526, -17.2192])\n",
      "    Grad  :  tensor([-0.0026,  0.0146])\n",
      "Epoch 3131,Loss 2.928288\n",
      "Epoch 3131, Loss 2.928288\n",
      "    Params:  tensor([  5.3526, -17.2193])\n",
      "    Grad  :  tensor([-0.0026,  0.0145])\n",
      "Epoch 3132,Loss 2.928287\n",
      "Epoch 3132, Loss 2.928287\n",
      "    Params:  tensor([  5.3526, -17.2194])\n",
      "    Grad  :  tensor([-0.0026,  0.0145])\n",
      "Epoch 3133,Loss 2.928285\n",
      "Epoch 3133, Loss 2.928285\n",
      "    Params:  tensor([  5.3527, -17.2196])\n",
      "    Grad  :  tensor([-0.0025,  0.0145])\n",
      "Epoch 3134,Loss 2.928282\n",
      "Epoch 3134, Loss 2.928282\n",
      "    Params:  tensor([  5.3527, -17.2197])\n",
      "    Grad  :  tensor([-0.0026,  0.0145])\n",
      "Epoch 3135,Loss 2.928280\n",
      "Epoch 3135, Loss 2.928280\n",
      "    Params:  tensor([  5.3527, -17.2199])\n",
      "    Grad  :  tensor([-0.0026,  0.0144])\n",
      "Epoch 3136,Loss 2.928276\n",
      "Epoch 3136, Loss 2.928276\n",
      "    Params:  tensor([  5.3527, -17.2200])\n",
      "    Grad  :  tensor([-0.0025,  0.0144])\n",
      "Epoch 3137,Loss 2.928275\n",
      "Epoch 3137, Loss 2.928275\n",
      "    Params:  tensor([  5.3528, -17.2202])\n",
      "    Grad  :  tensor([-0.0026,  0.0144])\n",
      "Epoch 3138,Loss 2.928273\n",
      "Epoch 3138, Loss 2.928273\n",
      "    Params:  tensor([  5.3528, -17.2203])\n",
      "    Grad  :  tensor([-0.0025,  0.0144])\n",
      "Epoch 3139,Loss 2.928271\n",
      "Epoch 3139, Loss 2.928271\n",
      "    Params:  tensor([  5.3528, -17.2205])\n",
      "    Grad  :  tensor([-0.0025,  0.0144])\n",
      "Epoch 3140,Loss 2.928268\n",
      "Epoch 3140, Loss 2.928268\n",
      "    Params:  tensor([  5.3528, -17.2206])\n",
      "    Grad  :  tensor([-0.0025,  0.0143])\n",
      "Epoch 3141,Loss 2.928267\n",
      "Epoch 3141, Loss 2.928267\n",
      "    Params:  tensor([  5.3529, -17.2207])\n",
      "    Grad  :  tensor([-0.0025,  0.0143])\n",
      "Epoch 3142,Loss 2.928264\n",
      "Epoch 3142, Loss 2.928264\n",
      "    Params:  tensor([  5.3529, -17.2209])\n",
      "    Grad  :  tensor([-0.0025,  0.0143])\n",
      "Epoch 3143,Loss 2.928263\n",
      "Epoch 3143, Loss 2.928263\n",
      "    Params:  tensor([  5.3529, -17.2210])\n",
      "    Grad  :  tensor([-0.0025,  0.0143])\n",
      "Epoch 3144,Loss 2.928260\n",
      "Epoch 3144, Loss 2.928260\n",
      "    Params:  tensor([  5.3529, -17.2212])\n",
      "    Grad  :  tensor([-0.0025,  0.0142])\n",
      "Epoch 3145,Loss 2.928259\n",
      "Epoch 3145, Loss 2.928259\n",
      "    Params:  tensor([  5.3530, -17.2213])\n",
      "    Grad  :  tensor([-0.0025,  0.0142])\n",
      "Epoch 3146,Loss 2.928256\n",
      "Epoch 3146, Loss 2.928256\n",
      "    Params:  tensor([  5.3530, -17.2214])\n",
      "    Grad  :  tensor([-0.0025,  0.0142])\n",
      "Epoch 3147,Loss 2.928255\n",
      "Epoch 3147, Loss 2.928255\n",
      "    Params:  tensor([  5.3530, -17.2216])\n",
      "    Grad  :  tensor([-0.0025,  0.0142])\n",
      "Epoch 3148,Loss 2.928252\n",
      "Epoch 3148, Loss 2.928252\n",
      "    Params:  tensor([  5.3530, -17.2217])\n",
      "    Grad  :  tensor([-0.0025,  0.0141])\n",
      "Epoch 3149,Loss 2.928250\n",
      "Epoch 3149, Loss 2.928250\n",
      "    Params:  tensor([  5.3531, -17.2219])\n",
      "    Grad  :  tensor([-0.0025,  0.0141])\n",
      "Epoch 3150,Loss 2.928249\n",
      "Epoch 3150, Loss 2.928249\n",
      "    Params:  tensor([  5.3531, -17.2220])\n",
      "    Grad  :  tensor([-0.0025,  0.0141])\n",
      "Epoch 3151,Loss 2.928246\n",
      "Epoch 3151, Loss 2.928246\n",
      "    Params:  tensor([  5.3531, -17.2222])\n",
      "    Grad  :  tensor([-0.0025,  0.0141])\n",
      "Epoch 3152,Loss 2.928245\n",
      "Epoch 3152, Loss 2.928245\n",
      "    Params:  tensor([  5.3531, -17.2223])\n",
      "    Grad  :  tensor([-0.0025,  0.0140])\n",
      "Epoch 3153,Loss 2.928242\n",
      "Epoch 3153, Loss 2.928242\n",
      "    Params:  tensor([  5.3532, -17.2224])\n",
      "    Grad  :  tensor([-0.0025,  0.0140])\n",
      "Epoch 3154,Loss 2.928239\n",
      "Epoch 3154, Loss 2.928239\n",
      "    Params:  tensor([  5.3532, -17.2226])\n",
      "    Grad  :  tensor([-0.0025,  0.0140])\n",
      "Epoch 3155,Loss 2.928236\n",
      "Epoch 3155, Loss 2.928236\n",
      "    Params:  tensor([  5.3532, -17.2227])\n",
      "    Grad  :  tensor([-0.0025,  0.0140])\n",
      "Epoch 3156,Loss 2.928236\n",
      "Epoch 3156, Loss 2.928236\n",
      "    Params:  tensor([  5.3532, -17.2229])\n",
      "    Grad  :  tensor([-0.0024,  0.0139])\n",
      "Epoch 3157,Loss 2.928233\n",
      "Epoch 3157, Loss 2.928233\n",
      "    Params:  tensor([  5.3533, -17.2230])\n",
      "    Grad  :  tensor([-0.0025,  0.0139])\n",
      "Epoch 3158,Loss 2.928231\n",
      "Epoch 3158, Loss 2.928231\n",
      "    Params:  tensor([  5.3533, -17.2231])\n",
      "    Grad  :  tensor([-0.0024,  0.0139])\n",
      "Epoch 3159,Loss 2.928230\n",
      "Epoch 3159, Loss 2.928230\n",
      "    Params:  tensor([  5.3533, -17.2233])\n",
      "    Grad  :  tensor([-0.0025,  0.0139])\n",
      "Epoch 3160,Loss 2.928227\n",
      "Epoch 3160, Loss 2.928227\n",
      "    Params:  tensor([  5.3533, -17.2234])\n",
      "    Grad  :  tensor([-0.0024,  0.0138])\n",
      "Epoch 3161,Loss 2.928226\n",
      "Epoch 3161, Loss 2.928226\n",
      "    Params:  tensor([  5.3534, -17.2235])\n",
      "    Grad  :  tensor([-0.0025,  0.0138])\n",
      "Epoch 3162,Loss 2.928225\n",
      "Epoch 3162, Loss 2.928225\n",
      "    Params:  tensor([  5.3534, -17.2237])\n",
      "    Grad  :  tensor([-0.0024,  0.0138])\n",
      "Epoch 3163,Loss 2.928222\n",
      "Epoch 3163, Loss 2.928222\n",
      "    Params:  tensor([  5.3534, -17.2238])\n",
      "    Grad  :  tensor([-0.0024,  0.0138])\n",
      "Epoch 3164,Loss 2.928219\n",
      "Epoch 3164, Loss 2.928219\n",
      "    Params:  tensor([  5.3534, -17.2240])\n",
      "    Grad  :  tensor([-0.0024,  0.0138])\n",
      "Epoch 3165,Loss 2.928218\n",
      "Epoch 3165, Loss 2.928218\n",
      "    Params:  tensor([  5.3535, -17.2241])\n",
      "    Grad  :  tensor([-0.0024,  0.0137])\n",
      "Epoch 3166,Loss 2.928216\n",
      "Epoch 3166, Loss 2.928216\n",
      "    Params:  tensor([  5.3535, -17.2242])\n",
      "    Grad  :  tensor([-0.0024,  0.0137])\n",
      "Epoch 3167,Loss 2.928215\n",
      "Epoch 3167, Loss 2.928215\n",
      "    Params:  tensor([  5.3535, -17.2244])\n",
      "    Grad  :  tensor([-0.0024,  0.0137])\n",
      "Epoch 3168,Loss 2.928212\n",
      "Epoch 3168, Loss 2.928212\n",
      "    Params:  tensor([  5.3535, -17.2245])\n",
      "    Grad  :  tensor([-0.0024,  0.0137])\n",
      "Epoch 3169,Loss 2.928211\n",
      "Epoch 3169, Loss 2.928211\n",
      "    Params:  tensor([  5.3536, -17.2246])\n",
      "    Grad  :  tensor([-0.0024,  0.0136])\n",
      "Epoch 3170,Loss 2.928209\n",
      "Epoch 3170, Loss 2.928209\n",
      "    Params:  tensor([  5.3536, -17.2248])\n",
      "    Grad  :  tensor([-0.0024,  0.0136])\n",
      "Epoch 3171,Loss 2.928206\n",
      "Epoch 3171, Loss 2.928206\n",
      "    Params:  tensor([  5.3536, -17.2249])\n",
      "    Grad  :  tensor([-0.0024,  0.0136])\n",
      "Epoch 3172,Loss 2.928205\n",
      "Epoch 3172, Loss 2.928205\n",
      "    Params:  tensor([  5.3536, -17.2250])\n",
      "    Grad  :  tensor([-0.0024,  0.0136])\n",
      "Epoch 3173,Loss 2.928204\n",
      "Epoch 3173, Loss 2.928204\n",
      "    Params:  tensor([  5.3537, -17.2252])\n",
      "    Grad  :  tensor([-0.0024,  0.0135])\n",
      "Epoch 3174,Loss 2.928202\n",
      "Epoch 3174, Loss 2.928202\n",
      "    Params:  tensor([  5.3537, -17.2253])\n",
      "    Grad  :  tensor([-0.0024,  0.0135])\n",
      "Epoch 3175,Loss 2.928200\n",
      "Epoch 3175, Loss 2.928200\n",
      "    Params:  tensor([  5.3537, -17.2255])\n",
      "    Grad  :  tensor([-0.0024,  0.0135])\n",
      "Epoch 3176,Loss 2.928196\n",
      "Epoch 3176, Loss 2.928196\n",
      "    Params:  tensor([  5.3537, -17.2256])\n",
      "    Grad  :  tensor([-0.0024,  0.0135])\n",
      "Epoch 3177,Loss 2.928195\n",
      "Epoch 3177, Loss 2.928195\n",
      "    Params:  tensor([  5.3538, -17.2257])\n",
      "    Grad  :  tensor([-0.0024,  0.0134])\n",
      "Epoch 3178,Loss 2.928195\n",
      "Epoch 3178, Loss 2.928195\n",
      "    Params:  tensor([  5.3538, -17.2259])\n",
      "    Grad  :  tensor([-0.0024,  0.0134])\n",
      "Epoch 3179,Loss 2.928191\n",
      "Epoch 3179, Loss 2.928191\n",
      "    Params:  tensor([  5.3538, -17.2260])\n",
      "    Grad  :  tensor([-0.0024,  0.0134])\n",
      "Epoch 3180,Loss 2.928190\n",
      "Epoch 3180, Loss 2.928190\n",
      "    Params:  tensor([  5.3538, -17.2261])\n",
      "    Grad  :  tensor([-0.0024,  0.0134])\n",
      "Epoch 3181,Loss 2.928188\n",
      "Epoch 3181, Loss 2.928188\n",
      "    Params:  tensor([  5.3538, -17.2263])\n",
      "    Grad  :  tensor([-0.0023,  0.0134])\n",
      "Epoch 3182,Loss 2.928186\n",
      "Epoch 3182, Loss 2.928186\n",
      "    Params:  tensor([  5.3539, -17.2264])\n",
      "    Grad  :  tensor([-0.0023,  0.0133])\n",
      "Epoch 3183,Loss 2.928185\n",
      "Epoch 3183, Loss 2.928185\n",
      "    Params:  tensor([  5.3539, -17.2265])\n",
      "    Grad  :  tensor([-0.0024,  0.0133])\n",
      "Epoch 3184,Loss 2.928184\n",
      "Epoch 3184, Loss 2.928184\n",
      "    Params:  tensor([  5.3539, -17.2267])\n",
      "    Grad  :  tensor([-0.0023,  0.0133])\n",
      "Epoch 3185,Loss 2.928182\n",
      "Epoch 3185, Loss 2.928182\n",
      "    Params:  tensor([  5.3539, -17.2268])\n",
      "    Grad  :  tensor([-0.0024,  0.0133])\n",
      "Epoch 3186,Loss 2.928180\n",
      "Epoch 3186, Loss 2.928180\n",
      "    Params:  tensor([  5.3540, -17.2269])\n",
      "    Grad  :  tensor([-0.0024,  0.0132])\n",
      "Epoch 3187,Loss 2.928178\n",
      "Epoch 3187, Loss 2.928178\n",
      "    Params:  tensor([  5.3540, -17.2271])\n",
      "    Grad  :  tensor([-0.0023,  0.0132])\n",
      "Epoch 3188,Loss 2.928175\n",
      "Epoch 3188, Loss 2.928175\n",
      "    Params:  tensor([  5.3540, -17.2272])\n",
      "    Grad  :  tensor([-0.0023,  0.0132])\n",
      "Epoch 3189,Loss 2.928172\n",
      "Epoch 3189, Loss 2.928172\n",
      "    Params:  tensor([  5.3540, -17.2273])\n",
      "    Grad  :  tensor([-0.0023,  0.0132])\n",
      "Epoch 3190,Loss 2.928171\n",
      "Epoch 3190, Loss 2.928171\n",
      "    Params:  tensor([  5.3541, -17.2275])\n",
      "    Grad  :  tensor([-0.0023,  0.0132])\n",
      "Epoch 3191,Loss 2.928170\n",
      "Epoch 3191, Loss 2.928170\n",
      "    Params:  tensor([  5.3541, -17.2276])\n",
      "    Grad  :  tensor([-0.0023,  0.0131])\n",
      "Epoch 3192,Loss 2.928169\n",
      "Epoch 3192, Loss 2.928169\n",
      "    Params:  tensor([  5.3541, -17.2277])\n",
      "    Grad  :  tensor([-0.0023,  0.0131])\n",
      "Epoch 3193,Loss 2.928167\n",
      "Epoch 3193, Loss 2.928167\n",
      "    Params:  tensor([  5.3541, -17.2278])\n",
      "    Grad  :  tensor([-0.0023,  0.0131])\n",
      "Epoch 3194,Loss 2.928164\n",
      "Epoch 3194, Loss 2.928164\n",
      "    Params:  tensor([  5.3542, -17.2280])\n",
      "    Grad  :  tensor([-0.0023,  0.0131])\n",
      "Epoch 3195,Loss 2.928163\n",
      "Epoch 3195, Loss 2.928163\n",
      "    Params:  tensor([  5.3542, -17.2281])\n",
      "    Grad  :  tensor([-0.0023,  0.0130])\n",
      "Epoch 3196,Loss 2.928162\n",
      "Epoch 3196, Loss 2.928162\n",
      "    Params:  tensor([  5.3542, -17.2282])\n",
      "    Grad  :  tensor([-0.0023,  0.0130])\n",
      "Epoch 3197,Loss 2.928160\n",
      "Epoch 3197, Loss 2.928160\n",
      "    Params:  tensor([  5.3542, -17.2284])\n",
      "    Grad  :  tensor([-0.0023,  0.0130])\n",
      "Epoch 3198,Loss 2.928158\n",
      "Epoch 3198, Loss 2.928158\n",
      "    Params:  tensor([  5.3542, -17.2285])\n",
      "    Grad  :  tensor([-0.0023,  0.0130])\n",
      "Epoch 3199,Loss 2.928157\n",
      "Epoch 3199, Loss 2.928157\n",
      "    Params:  tensor([  5.3543, -17.2286])\n",
      "    Grad  :  tensor([-0.0023,  0.0130])\n",
      "Epoch 3200,Loss 2.928154\n",
      "Epoch 3200, Loss 2.928154\n",
      "    Params:  tensor([  5.3543, -17.2288])\n",
      "    Grad  :  tensor([-0.0023,  0.0129])\n",
      "Epoch 3201,Loss 2.928152\n",
      "Epoch 3201, Loss 2.928152\n",
      "    Params:  tensor([  5.3543, -17.2289])\n",
      "    Grad  :  tensor([-0.0023,  0.0129])\n",
      "Epoch 3202,Loss 2.928149\n",
      "Epoch 3202, Loss 2.928149\n",
      "    Params:  tensor([  5.3543, -17.2290])\n",
      "    Grad  :  tensor([-0.0023,  0.0129])\n",
      "Epoch 3203,Loss 2.928150\n",
      "Epoch 3203, Loss 2.928150\n",
      "    Params:  tensor([  5.3544, -17.2291])\n",
      "    Grad  :  tensor([-0.0023,  0.0129])\n",
      "Epoch 3204,Loss 2.928147\n",
      "Epoch 3204, Loss 2.928147\n",
      "    Params:  tensor([  5.3544, -17.2293])\n",
      "    Grad  :  tensor([-0.0022,  0.0129])\n",
      "Epoch 3205,Loss 2.928146\n",
      "Epoch 3205, Loss 2.928146\n",
      "    Params:  tensor([  5.3544, -17.2294])\n",
      "    Grad  :  tensor([-0.0023,  0.0128])\n",
      "Epoch 3206,Loss 2.928144\n",
      "Epoch 3206, Loss 2.928144\n",
      "    Params:  tensor([  5.3544, -17.2295])\n",
      "    Grad  :  tensor([-0.0023,  0.0128])\n",
      "Epoch 3207,Loss 2.928142\n",
      "Epoch 3207, Loss 2.928142\n",
      "    Params:  tensor([  5.3544, -17.2297])\n",
      "    Grad  :  tensor([-0.0023,  0.0128])\n",
      "Epoch 3208,Loss 2.928140\n",
      "Epoch 3208, Loss 2.928140\n",
      "    Params:  tensor([  5.3545, -17.2298])\n",
      "    Grad  :  tensor([-0.0022,  0.0128])\n",
      "Epoch 3209,Loss 2.928138\n",
      "Epoch 3209, Loss 2.928138\n",
      "    Params:  tensor([  5.3545, -17.2299])\n",
      "    Grad  :  tensor([-0.0022,  0.0127])\n",
      "Epoch 3210,Loss 2.928137\n",
      "Epoch 3210, Loss 2.928137\n",
      "    Params:  tensor([  5.3545, -17.2300])\n",
      "    Grad  :  tensor([-0.0023,  0.0127])\n",
      "Epoch 3211,Loss 2.928135\n",
      "Epoch 3211, Loss 2.928135\n",
      "    Params:  tensor([  5.3545, -17.2302])\n",
      "    Grad  :  tensor([-0.0023,  0.0127])\n",
      "Epoch 3212,Loss 2.928135\n",
      "Epoch 3212, Loss 2.928135\n",
      "    Params:  tensor([  5.3546, -17.2303])\n",
      "    Grad  :  tensor([-0.0023,  0.0127])\n",
      "Epoch 3213,Loss 2.928133\n",
      "Epoch 3213, Loss 2.928133\n",
      "    Params:  tensor([  5.3546, -17.2304])\n",
      "    Grad  :  tensor([-0.0022,  0.0127])\n",
      "Epoch 3214,Loss 2.928131\n",
      "Epoch 3214, Loss 2.928131\n",
      "    Params:  tensor([  5.3546, -17.2305])\n",
      "    Grad  :  tensor([-0.0022,  0.0126])\n",
      "Epoch 3215,Loss 2.928130\n",
      "Epoch 3215, Loss 2.928130\n",
      "    Params:  tensor([  5.3546, -17.2307])\n",
      "    Grad  :  tensor([-0.0022,  0.0126])\n",
      "Epoch 3216,Loss 2.928126\n",
      "Epoch 3216, Loss 2.928126\n",
      "    Params:  tensor([  5.3546, -17.2308])\n",
      "    Grad  :  tensor([-0.0022,  0.0126])\n",
      "Epoch 3217,Loss 2.928125\n",
      "Epoch 3217, Loss 2.928125\n",
      "    Params:  tensor([  5.3547, -17.2309])\n",
      "    Grad  :  tensor([-0.0022,  0.0126])\n",
      "Epoch 3218,Loss 2.928124\n",
      "Epoch 3218, Loss 2.928124\n",
      "    Params:  tensor([  5.3547, -17.2310])\n",
      "    Grad  :  tensor([-0.0022,  0.0125])\n",
      "Epoch 3219,Loss 2.928121\n",
      "Epoch 3219, Loss 2.928121\n",
      "    Params:  tensor([  5.3547, -17.2312])\n",
      "    Grad  :  tensor([-0.0022,  0.0125])\n",
      "Epoch 3220,Loss 2.928121\n",
      "Epoch 3220, Loss 2.928121\n",
      "    Params:  tensor([  5.3547, -17.2313])\n",
      "    Grad  :  tensor([-0.0022,  0.0125])\n",
      "Epoch 3221,Loss 2.928120\n",
      "Epoch 3221, Loss 2.928120\n",
      "    Params:  tensor([  5.3548, -17.2314])\n",
      "    Grad  :  tensor([-0.0022,  0.0125])\n",
      "Epoch 3222,Loss 2.928118\n",
      "Epoch 3222, Loss 2.928118\n",
      "    Params:  tensor([  5.3548, -17.2315])\n",
      "    Grad  :  tensor([-0.0022,  0.0125])\n",
      "Epoch 3223,Loss 2.928117\n",
      "Epoch 3223, Loss 2.928117\n",
      "    Params:  tensor([  5.3548, -17.2317])\n",
      "    Grad  :  tensor([-0.0022,  0.0124])\n",
      "Epoch 3224,Loss 2.928115\n",
      "Epoch 3224, Loss 2.928115\n",
      "    Params:  tensor([  5.3548, -17.2318])\n",
      "    Grad  :  tensor([-0.0022,  0.0124])\n",
      "Epoch 3225,Loss 2.928113\n",
      "Epoch 3225, Loss 2.928113\n",
      "    Params:  tensor([  5.3548, -17.2319])\n",
      "    Grad  :  tensor([-0.0022,  0.0124])\n",
      "Epoch 3226,Loss 2.928110\n",
      "Epoch 3226, Loss 2.928110\n",
      "    Params:  tensor([  5.3549, -17.2320])\n",
      "    Grad  :  tensor([-0.0022,  0.0124])\n",
      "Epoch 3227,Loss 2.928109\n",
      "Epoch 3227, Loss 2.928109\n",
      "    Params:  tensor([  5.3549, -17.2322])\n",
      "    Grad  :  tensor([-0.0022,  0.0124])\n",
      "Epoch 3228,Loss 2.928108\n",
      "Epoch 3228, Loss 2.928108\n",
      "    Params:  tensor([  5.3549, -17.2323])\n",
      "    Grad  :  tensor([-0.0022,  0.0123])\n",
      "Epoch 3229,Loss 2.928105\n",
      "Epoch 3229, Loss 2.928105\n",
      "    Params:  tensor([  5.3549, -17.2324])\n",
      "    Grad  :  tensor([-0.0022,  0.0123])\n",
      "Epoch 3230,Loss 2.928105\n",
      "Epoch 3230, Loss 2.928105\n",
      "    Params:  tensor([  5.3550, -17.2325])\n",
      "    Grad  :  tensor([-0.0022,  0.0123])\n",
      "Epoch 3231,Loss 2.928104\n",
      "Epoch 3231, Loss 2.928104\n",
      "    Params:  tensor([  5.3550, -17.2327])\n",
      "    Grad  :  tensor([-0.0021,  0.0123])\n",
      "Epoch 3232,Loss 2.928102\n",
      "Epoch 3232, Loss 2.928102\n",
      "    Params:  tensor([  5.3550, -17.2328])\n",
      "    Grad  :  tensor([-0.0021,  0.0123])\n",
      "Epoch 3233,Loss 2.928101\n",
      "Epoch 3233, Loss 2.928101\n",
      "    Params:  tensor([  5.3550, -17.2329])\n",
      "    Grad  :  tensor([-0.0022,  0.0122])\n",
      "Epoch 3234,Loss 2.928098\n",
      "Epoch 3234, Loss 2.928098\n",
      "    Params:  tensor([  5.3550, -17.2330])\n",
      "    Grad  :  tensor([-0.0022,  0.0122])\n",
      "Epoch 3235,Loss 2.928097\n",
      "Epoch 3235, Loss 2.928097\n",
      "    Params:  tensor([  5.3551, -17.2331])\n",
      "    Grad  :  tensor([-0.0022,  0.0122])\n",
      "Epoch 3236,Loss 2.928095\n",
      "Epoch 3236, Loss 2.928095\n",
      "    Params:  tensor([  5.3551, -17.2333])\n",
      "    Grad  :  tensor([-0.0022,  0.0122])\n",
      "Epoch 3237,Loss 2.928094\n",
      "Epoch 3237, Loss 2.928094\n",
      "    Params:  tensor([  5.3551, -17.2334])\n",
      "    Grad  :  tensor([-0.0022,  0.0121])\n",
      "Epoch 3238,Loss 2.928093\n",
      "Epoch 3238, Loss 2.928093\n",
      "    Params:  tensor([  5.3551, -17.2335])\n",
      "    Grad  :  tensor([-0.0022,  0.0121])\n",
      "Epoch 3239,Loss 2.928091\n",
      "Epoch 3239, Loss 2.928091\n",
      "    Params:  tensor([  5.3551, -17.2336])\n",
      "    Grad  :  tensor([-0.0022,  0.0121])\n",
      "Epoch 3240,Loss 2.928090\n",
      "Epoch 3240, Loss 2.928090\n",
      "    Params:  tensor([  5.3552, -17.2338])\n",
      "    Grad  :  tensor([-0.0021,  0.0121])\n",
      "Epoch 3241,Loss 2.928088\n",
      "Epoch 3241, Loss 2.928088\n",
      "    Params:  tensor([  5.3552, -17.2339])\n",
      "    Grad  :  tensor([-0.0021,  0.0121])\n",
      "Epoch 3242,Loss 2.928086\n",
      "Epoch 3242, Loss 2.928086\n",
      "    Params:  tensor([  5.3552, -17.2340])\n",
      "    Grad  :  tensor([-0.0021,  0.0120])\n",
      "Epoch 3243,Loss 2.928085\n",
      "Epoch 3243, Loss 2.928085\n",
      "    Params:  tensor([  5.3552, -17.2341])\n",
      "    Grad  :  tensor([-0.0021,  0.0120])\n",
      "Epoch 3244,Loss 2.928084\n",
      "Epoch 3244, Loss 2.928084\n",
      "    Params:  tensor([  5.3553, -17.2342])\n",
      "    Grad  :  tensor([-0.0021,  0.0120])\n",
      "Epoch 3245,Loss 2.928082\n",
      "Epoch 3245, Loss 2.928082\n",
      "    Params:  tensor([  5.3553, -17.2344])\n",
      "    Grad  :  tensor([-0.0021,  0.0120])\n",
      "Epoch 3246,Loss 2.928080\n",
      "Epoch 3246, Loss 2.928080\n",
      "    Params:  tensor([  5.3553, -17.2345])\n",
      "    Grad  :  tensor([-0.0021,  0.0120])\n",
      "Epoch 3247,Loss 2.928079\n",
      "Epoch 3247, Loss 2.928079\n",
      "    Params:  tensor([  5.3553, -17.2346])\n",
      "    Grad  :  tensor([-0.0021,  0.0119])\n",
      "Epoch 3248,Loss 2.928076\n",
      "Epoch 3248, Loss 2.928076\n",
      "    Params:  tensor([  5.3553, -17.2347])\n",
      "    Grad  :  tensor([-0.0021,  0.0119])\n",
      "Epoch 3249,Loss 2.928077\n",
      "Epoch 3249, Loss 2.928077\n",
      "    Params:  tensor([  5.3554, -17.2348])\n",
      "    Grad  :  tensor([-0.0021,  0.0119])\n",
      "Epoch 3250,Loss 2.928075\n",
      "Epoch 3250, Loss 2.928075\n",
      "    Params:  tensor([  5.3554, -17.2350])\n",
      "    Grad  :  tensor([-0.0021,  0.0119])\n",
      "Epoch 3251,Loss 2.928072\n",
      "Epoch 3251, Loss 2.928072\n",
      "    Params:  tensor([  5.3554, -17.2351])\n",
      "    Grad  :  tensor([-0.0021,  0.0119])\n",
      "Epoch 3252,Loss 2.928072\n",
      "Epoch 3252, Loss 2.928072\n",
      "    Params:  tensor([  5.3554, -17.2352])\n",
      "    Grad  :  tensor([-0.0021,  0.0118])\n",
      "Epoch 3253,Loss 2.928071\n",
      "Epoch 3253, Loss 2.928071\n",
      "    Params:  tensor([  5.3554, -17.2353])\n",
      "    Grad  :  tensor([-0.0021,  0.0118])\n",
      "Epoch 3254,Loss 2.928068\n",
      "Epoch 3254, Loss 2.928068\n",
      "    Params:  tensor([  5.3555, -17.2354])\n",
      "    Grad  :  tensor([-0.0021,  0.0118])\n",
      "Epoch 3255,Loss 2.928069\n",
      "Epoch 3255, Loss 2.928069\n",
      "    Params:  tensor([  5.3555, -17.2355])\n",
      "    Grad  :  tensor([-0.0021,  0.0118])\n",
      "Epoch 3256,Loss 2.928066\n",
      "Epoch 3256, Loss 2.928066\n",
      "    Params:  tensor([  5.3555, -17.2357])\n",
      "    Grad  :  tensor([-0.0021,  0.0118])\n",
      "Epoch 3257,Loss 2.928065\n",
      "Epoch 3257, Loss 2.928065\n",
      "    Params:  tensor([  5.3555, -17.2358])\n",
      "    Grad  :  tensor([-0.0021,  0.0117])\n",
      "Epoch 3258,Loss 2.928064\n",
      "Epoch 3258, Loss 2.928064\n",
      "    Params:  tensor([  5.3555, -17.2359])\n",
      "    Grad  :  tensor([-0.0021,  0.0117])\n",
      "Epoch 3259,Loss 2.928061\n",
      "Epoch 3259, Loss 2.928061\n",
      "    Params:  tensor([  5.3556, -17.2360])\n",
      "    Grad  :  tensor([-0.0021,  0.0117])\n",
      "Epoch 3260,Loss 2.928060\n",
      "Epoch 3260, Loss 2.928060\n",
      "    Params:  tensor([  5.3556, -17.2361])\n",
      "    Grad  :  tensor([-0.0021,  0.0117])\n",
      "Epoch 3261,Loss 2.928057\n",
      "Epoch 3261, Loss 2.928057\n",
      "    Params:  tensor([  5.3556, -17.2362])\n",
      "    Grad  :  tensor([-0.0021,  0.0117])\n",
      "Epoch 3262,Loss 2.928058\n",
      "Epoch 3262, Loss 2.928058\n",
      "    Params:  tensor([  5.3556, -17.2364])\n",
      "    Grad  :  tensor([-0.0021,  0.0116])\n",
      "Epoch 3263,Loss 2.928056\n",
      "Epoch 3263, Loss 2.928056\n",
      "    Params:  tensor([  5.3557, -17.2365])\n",
      "    Grad  :  tensor([-0.0021,  0.0116])\n",
      "Epoch 3264,Loss 2.928055\n",
      "Epoch 3264, Loss 2.928055\n",
      "    Params:  tensor([  5.3557, -17.2366])\n",
      "    Grad  :  tensor([-0.0021,  0.0116])\n",
      "Epoch 3265,Loss 2.928052\n",
      "Epoch 3265, Loss 2.928052\n",
      "    Params:  tensor([  5.3557, -17.2367])\n",
      "    Grad  :  tensor([-0.0021,  0.0116])\n",
      "Epoch 3266,Loss 2.928053\n",
      "Epoch 3266, Loss 2.928053\n",
      "    Params:  tensor([  5.3557, -17.2368])\n",
      "    Grad  :  tensor([-0.0021,  0.0116])\n",
      "Epoch 3267,Loss 2.928051\n",
      "Epoch 3267, Loss 2.928051\n",
      "    Params:  tensor([  5.3557, -17.2369])\n",
      "    Grad  :  tensor([-0.0021,  0.0115])\n",
      "Epoch 3268,Loss 2.928050\n",
      "Epoch 3268, Loss 2.928050\n",
      "    Params:  tensor([  5.3558, -17.2371])\n",
      "    Grad  :  tensor([-0.0021,  0.0115])\n",
      "Epoch 3269,Loss 2.928047\n",
      "Epoch 3269, Loss 2.928047\n",
      "    Params:  tensor([  5.3558, -17.2372])\n",
      "    Grad  :  tensor([-0.0020,  0.0115])\n",
      "Epoch 3270,Loss 2.928046\n",
      "Epoch 3270, Loss 2.928046\n",
      "    Params:  tensor([  5.3558, -17.2373])\n",
      "    Grad  :  tensor([-0.0020,  0.0115])\n",
      "Epoch 3271,Loss 2.928046\n",
      "Epoch 3271, Loss 2.928046\n",
      "    Params:  tensor([  5.3558, -17.2374])\n",
      "    Grad  :  tensor([-0.0020,  0.0115])\n",
      "Epoch 3272,Loss 2.928044\n",
      "Epoch 3272, Loss 2.928044\n",
      "    Params:  tensor([  5.3558, -17.2375])\n",
      "    Grad  :  tensor([-0.0020,  0.0115])\n",
      "Epoch 3273,Loss 2.928042\n",
      "Epoch 3273, Loss 2.928042\n",
      "    Params:  tensor([  5.3559, -17.2376])\n",
      "    Grad  :  tensor([-0.0020,  0.0114])\n",
      "Epoch 3274,Loss 2.928040\n",
      "Epoch 3274, Loss 2.928040\n",
      "    Params:  tensor([  5.3559, -17.2377])\n",
      "    Grad  :  tensor([-0.0020,  0.0114])\n",
      "Epoch 3275,Loss 2.928040\n",
      "Epoch 3275, Loss 2.928040\n",
      "    Params:  tensor([  5.3559, -17.2379])\n",
      "    Grad  :  tensor([-0.0020,  0.0114])\n",
      "Epoch 3276,Loss 2.928036\n",
      "Epoch 3276, Loss 2.928036\n",
      "    Params:  tensor([  5.3559, -17.2380])\n",
      "    Grad  :  tensor([-0.0020,  0.0114])\n",
      "Epoch 3277,Loss 2.928036\n",
      "Epoch 3277, Loss 2.928036\n",
      "    Params:  tensor([  5.3559, -17.2381])\n",
      "    Grad  :  tensor([-0.0020,  0.0113])\n",
      "Epoch 3278,Loss 2.928037\n",
      "Epoch 3278, Loss 2.928037\n",
      "    Params:  tensor([  5.3560, -17.2382])\n",
      "    Grad  :  tensor([-0.0020,  0.0113])\n",
      "Epoch 3279,Loss 2.928034\n",
      "Epoch 3279, Loss 2.928034\n",
      "    Params:  tensor([  5.3560, -17.2383])\n",
      "    Grad  :  tensor([-0.0020,  0.0113])\n",
      "Epoch 3280,Loss 2.928034\n",
      "Epoch 3280, Loss 2.928034\n",
      "    Params:  tensor([  5.3560, -17.2384])\n",
      "    Grad  :  tensor([-0.0020,  0.0113])\n",
      "Epoch 3281,Loss 2.928031\n",
      "Epoch 3281, Loss 2.928031\n",
      "    Params:  tensor([  5.3560, -17.2385])\n",
      "    Grad  :  tensor([-0.0020,  0.0113])\n",
      "Epoch 3282,Loss 2.928032\n",
      "Epoch 3282, Loss 2.928032\n",
      "    Params:  tensor([  5.3560, -17.2386])\n",
      "    Grad  :  tensor([-0.0020,  0.0113])\n",
      "Epoch 3283,Loss 2.928028\n",
      "Epoch 3283, Loss 2.928028\n",
      "    Params:  tensor([  5.3561, -17.2388])\n",
      "    Grad  :  tensor([-0.0020,  0.0112])\n",
      "Epoch 3284,Loss 2.928027\n",
      "Epoch 3284, Loss 2.928027\n",
      "    Params:  tensor([  5.3561, -17.2389])\n",
      "    Grad  :  tensor([-0.0020,  0.0112])\n",
      "Epoch 3285,Loss 2.928026\n",
      "Epoch 3285, Loss 2.928026\n",
      "    Params:  tensor([  5.3561, -17.2390])\n",
      "    Grad  :  tensor([-0.0020,  0.0112])\n",
      "Epoch 3286,Loss 2.928025\n",
      "Epoch 3286, Loss 2.928025\n",
      "    Params:  tensor([  5.3561, -17.2391])\n",
      "    Grad  :  tensor([-0.0020,  0.0112])\n",
      "Epoch 3287,Loss 2.928024\n",
      "Epoch 3287, Loss 2.928024\n",
      "    Params:  tensor([  5.3561, -17.2392])\n",
      "    Grad  :  tensor([-0.0020,  0.0112])\n",
      "Epoch 3288,Loss 2.928022\n",
      "Epoch 3288, Loss 2.928022\n",
      "    Params:  tensor([  5.3562, -17.2393])\n",
      "    Grad  :  tensor([-0.0020,  0.0111])\n",
      "Epoch 3289,Loss 2.928023\n",
      "Epoch 3289, Loss 2.928023\n",
      "    Params:  tensor([  5.3562, -17.2394])\n",
      "    Grad  :  tensor([-0.0020,  0.0111])\n",
      "Epoch 3290,Loss 2.928021\n",
      "Epoch 3290, Loss 2.928021\n",
      "    Params:  tensor([  5.3562, -17.2395])\n",
      "    Grad  :  tensor([-0.0020,  0.0111])\n",
      "Epoch 3291,Loss 2.928019\n",
      "Epoch 3291, Loss 2.928019\n",
      "    Params:  tensor([  5.3562, -17.2397])\n",
      "    Grad  :  tensor([-0.0020,  0.0111])\n",
      "Epoch 3292,Loss 2.928018\n",
      "Epoch 3292, Loss 2.928018\n",
      "    Params:  tensor([  5.3562, -17.2398])\n",
      "    Grad  :  tensor([-0.0020,  0.0111])\n",
      "Epoch 3293,Loss 2.928017\n",
      "Epoch 3293, Loss 2.928017\n",
      "    Params:  tensor([  5.3563, -17.2399])\n",
      "    Grad  :  tensor([-0.0020,  0.0110])\n",
      "Epoch 3294,Loss 2.928015\n",
      "Epoch 3294, Loss 2.928015\n",
      "    Params:  tensor([  5.3563, -17.2400])\n",
      "    Grad  :  tensor([-0.0020,  0.0110])\n",
      "Epoch 3295,Loss 2.928013\n",
      "Epoch 3295, Loss 2.928013\n",
      "    Params:  tensor([  5.3563, -17.2401])\n",
      "    Grad  :  tensor([-0.0020,  0.0110])\n",
      "Epoch 3296,Loss 2.928013\n",
      "Epoch 3296, Loss 2.928013\n",
      "    Params:  tensor([  5.3563, -17.2402])\n",
      "    Grad  :  tensor([-0.0019,  0.0110])\n",
      "Epoch 3297,Loss 2.928011\n",
      "Epoch 3297, Loss 2.928011\n",
      "    Params:  tensor([  5.3563, -17.2403])\n",
      "    Grad  :  tensor([-0.0019,  0.0110])\n",
      "Epoch 3298,Loss 2.928009\n",
      "Epoch 3298, Loss 2.928009\n",
      "    Params:  tensor([  5.3563, -17.2404])\n",
      "    Grad  :  tensor([-0.0019,  0.0110])\n",
      "Epoch 3299,Loss 2.928008\n",
      "Epoch 3299, Loss 2.928008\n",
      "    Params:  tensor([  5.3564, -17.2405])\n",
      "    Grad  :  tensor([-0.0019,  0.0109])\n",
      "Epoch 3300,Loss 2.928006\n",
      "Epoch 3300, Loss 2.928006\n",
      "    Params:  tensor([  5.3564, -17.2406])\n",
      "    Grad  :  tensor([-0.0019,  0.0109])\n",
      "Epoch 3301,Loss 2.928007\n",
      "Epoch 3301, Loss 2.928007\n",
      "    Params:  tensor([  5.3564, -17.2407])\n",
      "    Grad  :  tensor([-0.0019,  0.0109])\n",
      "Epoch 3302,Loss 2.928007\n",
      "Epoch 3302, Loss 2.928007\n",
      "    Params:  tensor([  5.3564, -17.2409])\n",
      "    Grad  :  tensor([-0.0019,  0.0109])\n",
      "Epoch 3303,Loss 2.928005\n",
      "Epoch 3303, Loss 2.928005\n",
      "    Params:  tensor([  5.3564, -17.2410])\n",
      "    Grad  :  tensor([-0.0019,  0.0109])\n",
      "Epoch 3304,Loss 2.928002\n",
      "Epoch 3304, Loss 2.928002\n",
      "    Params:  tensor([  5.3565, -17.2411])\n",
      "    Grad  :  tensor([-0.0019,  0.0108])\n",
      "Epoch 3305,Loss 2.928002\n",
      "Epoch 3305, Loss 2.928002\n",
      "    Params:  tensor([  5.3565, -17.2412])\n",
      "    Grad  :  tensor([-0.0019,  0.0108])\n",
      "Epoch 3306,Loss 2.928000\n",
      "Epoch 3306, Loss 2.928000\n",
      "    Params:  tensor([  5.3565, -17.2413])\n",
      "    Grad  :  tensor([-0.0019,  0.0108])\n",
      "Epoch 3307,Loss 2.928000\n",
      "Epoch 3307, Loss 2.928000\n",
      "    Params:  tensor([  5.3565, -17.2414])\n",
      "    Grad  :  tensor([-0.0019,  0.0108])\n",
      "Epoch 3308,Loss 2.927998\n",
      "Epoch 3308, Loss 2.927998\n",
      "    Params:  tensor([  5.3565, -17.2415])\n",
      "    Grad  :  tensor([-0.0019,  0.0108])\n",
      "Epoch 3309,Loss 2.927995\n",
      "Epoch 3309, Loss 2.927995\n",
      "    Params:  tensor([  5.3566, -17.2416])\n",
      "    Grad  :  tensor([-0.0019,  0.0107])\n",
      "Epoch 3310,Loss 2.927995\n",
      "Epoch 3310, Loss 2.927995\n",
      "    Params:  tensor([  5.3566, -17.2417])\n",
      "    Grad  :  tensor([-0.0019,  0.0107])\n",
      "Epoch 3311,Loss 2.927994\n",
      "Epoch 3311, Loss 2.927994\n",
      "    Params:  tensor([  5.3566, -17.2418])\n",
      "    Grad  :  tensor([-0.0019,  0.0107])\n",
      "Epoch 3312,Loss 2.927994\n",
      "Epoch 3312, Loss 2.927994\n",
      "    Params:  tensor([  5.3566, -17.2419])\n",
      "    Grad  :  tensor([-0.0019,  0.0107])\n",
      "Epoch 3313,Loss 2.927991\n",
      "Epoch 3313, Loss 2.927991\n",
      "    Params:  tensor([  5.3566, -17.2420])\n",
      "    Grad  :  tensor([-0.0019,  0.0107])\n",
      "Epoch 3314,Loss 2.927991\n",
      "Epoch 3314, Loss 2.927991\n",
      "    Params:  tensor([  5.3567, -17.2421])\n",
      "    Grad  :  tensor([-0.0019,  0.0107])\n",
      "Epoch 3315,Loss 2.927990\n",
      "Epoch 3315, Loss 2.927990\n",
      "    Params:  tensor([  5.3567, -17.2423])\n",
      "    Grad  :  tensor([-0.0019,  0.0106])\n",
      "Epoch 3316,Loss 2.927989\n",
      "Epoch 3316, Loss 2.927989\n",
      "    Params:  tensor([  5.3567, -17.2424])\n",
      "    Grad  :  tensor([-0.0019,  0.0106])\n",
      "Epoch 3317,Loss 2.927988\n",
      "Epoch 3317, Loss 2.927988\n",
      "    Params:  tensor([  5.3567, -17.2425])\n",
      "    Grad  :  tensor([-0.0019,  0.0106])\n",
      "Epoch 3318,Loss 2.927986\n",
      "Epoch 3318, Loss 2.927986\n",
      "    Params:  tensor([  5.3567, -17.2426])\n",
      "    Grad  :  tensor([-0.0019,  0.0106])\n",
      "Epoch 3319,Loss 2.927985\n",
      "Epoch 3319, Loss 2.927985\n",
      "    Params:  tensor([  5.3567, -17.2427])\n",
      "    Grad  :  tensor([-0.0019,  0.0106])\n",
      "Epoch 3320,Loss 2.927983\n",
      "Epoch 3320, Loss 2.927983\n",
      "    Params:  tensor([  5.3568, -17.2428])\n",
      "    Grad  :  tensor([-0.0018,  0.0106])\n",
      "Epoch 3321,Loss 2.927983\n",
      "Epoch 3321, Loss 2.927983\n",
      "    Params:  tensor([  5.3568, -17.2429])\n",
      "    Grad  :  tensor([-0.0018,  0.0105])\n",
      "Epoch 3322,Loss 2.927981\n",
      "Epoch 3322, Loss 2.927981\n",
      "    Params:  tensor([  5.3568, -17.2430])\n",
      "    Grad  :  tensor([-0.0018,  0.0105])\n",
      "Epoch 3323,Loss 2.927980\n",
      "Epoch 3323, Loss 2.927980\n",
      "    Params:  tensor([  5.3568, -17.2431])\n",
      "    Grad  :  tensor([-0.0018,  0.0105])\n",
      "Epoch 3324,Loss 2.927979\n",
      "Epoch 3324, Loss 2.927979\n",
      "    Params:  tensor([  5.3568, -17.2432])\n",
      "    Grad  :  tensor([-0.0018,  0.0105])\n",
      "Epoch 3325,Loss 2.927979\n",
      "Epoch 3325, Loss 2.927979\n",
      "    Params:  tensor([  5.3569, -17.2433])\n",
      "    Grad  :  tensor([-0.0018,  0.0105])\n",
      "Epoch 3326,Loss 2.927977\n",
      "Epoch 3326, Loss 2.927977\n",
      "    Params:  tensor([  5.3569, -17.2434])\n",
      "    Grad  :  tensor([-0.0018,  0.0104])\n",
      "Epoch 3327,Loss 2.927975\n",
      "Epoch 3327, Loss 2.927975\n",
      "    Params:  tensor([  5.3569, -17.2435])\n",
      "    Grad  :  tensor([-0.0019,  0.0104])\n",
      "Epoch 3328,Loss 2.927973\n",
      "Epoch 3328, Loss 2.927973\n",
      "    Params:  tensor([  5.3569, -17.2436])\n",
      "    Grad  :  tensor([-0.0018,  0.0104])\n",
      "Epoch 3329,Loss 2.927974\n",
      "Epoch 3329, Loss 2.927974\n",
      "    Params:  tensor([  5.3569, -17.2437])\n",
      "    Grad  :  tensor([-0.0018,  0.0104])\n",
      "Epoch 3330,Loss 2.927974\n",
      "Epoch 3330, Loss 2.927974\n",
      "    Params:  tensor([  5.3570, -17.2438])\n",
      "    Grad  :  tensor([-0.0018,  0.0104])\n",
      "Epoch 3331,Loss 2.927972\n",
      "Epoch 3331, Loss 2.927972\n",
      "    Params:  tensor([  5.3570, -17.2439])\n",
      "    Grad  :  tensor([-0.0018,  0.0104])\n",
      "Epoch 3332,Loss 2.927972\n",
      "Epoch 3332, Loss 2.927972\n",
      "    Params:  tensor([  5.3570, -17.2440])\n",
      "    Grad  :  tensor([-0.0018,  0.0103])\n",
      "Epoch 3333,Loss 2.927969\n",
      "Epoch 3333, Loss 2.927969\n",
      "    Params:  tensor([  5.3570, -17.2441])\n",
      "    Grad  :  tensor([-0.0018,  0.0103])\n",
      "Epoch 3334,Loss 2.927969\n",
      "Epoch 3334, Loss 2.927969\n",
      "    Params:  tensor([  5.3570, -17.2442])\n",
      "    Grad  :  tensor([-0.0018,  0.0103])\n",
      "Epoch 3335,Loss 2.927967\n",
      "Epoch 3335, Loss 2.927967\n",
      "    Params:  tensor([  5.3570, -17.2443])\n",
      "    Grad  :  tensor([-0.0018,  0.0103])\n",
      "Epoch 3336,Loss 2.927967\n",
      "Epoch 3336, Loss 2.927967\n",
      "    Params:  tensor([  5.3571, -17.2444])\n",
      "    Grad  :  tensor([-0.0018,  0.0103])\n",
      "Epoch 3337,Loss 2.927963\n",
      "Epoch 3337, Loss 2.927963\n",
      "    Params:  tensor([  5.3571, -17.2446])\n",
      "    Grad  :  tensor([-0.0018,  0.0102])\n",
      "Epoch 3338,Loss 2.927963\n",
      "Epoch 3338, Loss 2.927963\n",
      "    Params:  tensor([  5.3571, -17.2447])\n",
      "    Grad  :  tensor([-0.0018,  0.0102])\n",
      "Epoch 3339,Loss 2.927962\n",
      "Epoch 3339, Loss 2.927962\n",
      "    Params:  tensor([  5.3571, -17.2448])\n",
      "    Grad  :  tensor([-0.0018,  0.0102])\n",
      "Epoch 3340,Loss 2.927962\n",
      "Epoch 3340, Loss 2.927962\n",
      "    Params:  tensor([  5.3571, -17.2449])\n",
      "    Grad  :  tensor([-0.0018,  0.0102])\n",
      "Epoch 3341,Loss 2.927960\n",
      "Epoch 3341, Loss 2.927960\n",
      "    Params:  tensor([  5.3572, -17.2450])\n",
      "    Grad  :  tensor([-0.0018,  0.0102])\n",
      "Epoch 3342,Loss 2.927960\n",
      "Epoch 3342, Loss 2.927960\n",
      "    Params:  tensor([  5.3572, -17.2451])\n",
      "    Grad  :  tensor([-0.0018,  0.0102])\n",
      "Epoch 3343,Loss 2.927959\n",
      "Epoch 3343, Loss 2.927959\n",
      "    Params:  tensor([  5.3572, -17.2452])\n",
      "    Grad  :  tensor([-0.0018,  0.0101])\n",
      "Epoch 3344,Loss 2.927958\n",
      "Epoch 3344, Loss 2.927958\n",
      "    Params:  tensor([  5.3572, -17.2453])\n",
      "    Grad  :  tensor([-0.0018,  0.0101])\n",
      "Epoch 3345,Loss 2.927956\n",
      "Epoch 3345, Loss 2.927956\n",
      "    Params:  tensor([  5.3572, -17.2454])\n",
      "    Grad  :  tensor([-0.0018,  0.0101])\n",
      "Epoch 3346,Loss 2.927956\n",
      "Epoch 3346, Loss 2.927956\n",
      "    Params:  tensor([  5.3572, -17.2455])\n",
      "    Grad  :  tensor([-0.0018,  0.0101])\n",
      "Epoch 3347,Loss 2.927955\n",
      "Epoch 3347, Loss 2.927955\n",
      "    Params:  tensor([  5.3573, -17.2456])\n",
      "    Grad  :  tensor([-0.0018,  0.0101])\n",
      "Epoch 3348,Loss 2.927953\n",
      "Epoch 3348, Loss 2.927953\n",
      "    Params:  tensor([  5.3573, -17.2457])\n",
      "    Grad  :  tensor([-0.0018,  0.0101])\n",
      "Epoch 3349,Loss 2.927953\n",
      "Epoch 3349, Loss 2.927953\n",
      "    Params:  tensor([  5.3573, -17.2458])\n",
      "    Grad  :  tensor([-0.0018,  0.0100])\n",
      "Epoch 3350,Loss 2.927951\n",
      "Epoch 3350, Loss 2.927951\n",
      "    Params:  tensor([  5.3573, -17.2459])\n",
      "    Grad  :  tensor([-0.0018,  0.0100])\n",
      "Epoch 3351,Loss 2.927950\n",
      "Epoch 3351, Loss 2.927950\n",
      "    Params:  tensor([  5.3573, -17.2460])\n",
      "    Grad  :  tensor([-0.0018,  0.0100])\n",
      "Epoch 3352,Loss 2.927948\n",
      "Epoch 3352, Loss 2.927948\n",
      "    Params:  tensor([  5.3573, -17.2461])\n",
      "    Grad  :  tensor([-0.0018,  0.0100])\n",
      "Epoch 3353,Loss 2.927947\n",
      "Epoch 3353, Loss 2.927947\n",
      "    Params:  tensor([  5.3574, -17.2462])\n",
      "    Grad  :  tensor([-0.0017,  0.0100])\n",
      "Epoch 3354,Loss 2.927948\n",
      "Epoch 3354, Loss 2.927948\n",
      "    Params:  tensor([  5.3574, -17.2463])\n",
      "    Grad  :  tensor([-0.0018,  0.0100])\n",
      "Epoch 3355,Loss 2.927945\n",
      "Epoch 3355, Loss 2.927945\n",
      "    Params:  tensor([  5.3574, -17.2464])\n",
      "    Grad  :  tensor([-0.0017,  0.0099])\n",
      "Epoch 3356,Loss 2.927944\n",
      "Epoch 3356, Loss 2.927944\n",
      "    Params:  tensor([  5.3574, -17.2465])\n",
      "    Grad  :  tensor([-0.0017,  0.0099])\n",
      "Epoch 3357,Loss 2.927943\n",
      "Epoch 3357, Loss 2.927943\n",
      "    Params:  tensor([  5.3574, -17.2466])\n",
      "    Grad  :  tensor([-0.0018,  0.0099])\n",
      "Epoch 3358,Loss 2.927944\n",
      "Epoch 3358, Loss 2.927944\n",
      "    Params:  tensor([  5.3575, -17.2467])\n",
      "    Grad  :  tensor([-0.0017,  0.0099])\n",
      "Epoch 3359,Loss 2.927942\n",
      "Epoch 3359, Loss 2.927942\n",
      "    Params:  tensor([  5.3575, -17.2468])\n",
      "    Grad  :  tensor([-0.0017,  0.0099])\n",
      "Epoch 3360,Loss 2.927941\n",
      "Epoch 3360, Loss 2.927941\n",
      "    Params:  tensor([  5.3575, -17.2469])\n",
      "    Grad  :  tensor([-0.0018,  0.0099])\n",
      "Epoch 3361,Loss 2.927940\n",
      "Epoch 3361, Loss 2.927940\n",
      "    Params:  tensor([  5.3575, -17.2470])\n",
      "    Grad  :  tensor([-0.0017,  0.0098])\n",
      "Epoch 3362,Loss 2.927938\n",
      "Epoch 3362, Loss 2.927938\n",
      "    Params:  tensor([  5.3575, -17.2471])\n",
      "    Grad  :  tensor([-0.0017,  0.0098])\n",
      "Epoch 3363,Loss 2.927938\n",
      "Epoch 3363, Loss 2.927938\n",
      "    Params:  tensor([  5.3575, -17.2472])\n",
      "    Grad  :  tensor([-0.0018,  0.0098])\n",
      "Epoch 3364,Loss 2.927936\n",
      "Epoch 3364, Loss 2.927936\n",
      "    Params:  tensor([  5.3576, -17.2473])\n",
      "    Grad  :  tensor([-0.0017,  0.0098])\n",
      "Epoch 3365,Loss 2.927936\n",
      "Epoch 3365, Loss 2.927936\n",
      "    Params:  tensor([  5.3576, -17.2474])\n",
      "    Grad  :  tensor([-0.0017,  0.0098])\n",
      "Epoch 3366,Loss 2.927937\n",
      "Epoch 3366, Loss 2.927937\n",
      "    Params:  tensor([  5.3576, -17.2474])\n",
      "    Grad  :  tensor([-0.0017,  0.0098])\n",
      "Epoch 3367,Loss 2.927934\n",
      "Epoch 3367, Loss 2.927934\n",
      "    Params:  tensor([  5.3576, -17.2475])\n",
      "    Grad  :  tensor([-0.0017,  0.0097])\n",
      "Epoch 3368,Loss 2.927933\n",
      "Epoch 3368, Loss 2.927933\n",
      "    Params:  tensor([  5.3576, -17.2476])\n",
      "    Grad  :  tensor([-0.0017,  0.0097])\n",
      "Epoch 3369,Loss 2.927932\n",
      "Epoch 3369, Loss 2.927932\n",
      "    Params:  tensor([  5.3576, -17.2477])\n",
      "    Grad  :  tensor([-0.0017,  0.0097])\n",
      "Epoch 3370,Loss 2.927930\n",
      "Epoch 3370, Loss 2.927930\n",
      "    Params:  tensor([  5.3577, -17.2478])\n",
      "    Grad  :  tensor([-0.0017,  0.0097])\n",
      "Epoch 3371,Loss 2.927928\n",
      "Epoch 3371, Loss 2.927928\n",
      "    Params:  tensor([  5.3577, -17.2479])\n",
      "    Grad  :  tensor([-0.0017,  0.0097])\n",
      "Epoch 3372,Loss 2.927931\n",
      "Epoch 3372, Loss 2.927931\n",
      "    Params:  tensor([  5.3577, -17.2480])\n",
      "    Grad  :  tensor([-0.0017,  0.0097])\n",
      "Epoch 3373,Loss 2.927929\n",
      "Epoch 3373, Loss 2.927929\n",
      "    Params:  tensor([  5.3577, -17.2481])\n",
      "    Grad  :  tensor([-0.0017,  0.0096])\n",
      "Epoch 3374,Loss 2.927927\n",
      "Epoch 3374, Loss 2.927927\n",
      "    Params:  tensor([  5.3577, -17.2482])\n",
      "    Grad  :  tensor([-0.0017,  0.0096])\n",
      "Epoch 3375,Loss 2.927926\n",
      "Epoch 3375, Loss 2.927926\n",
      "    Params:  tensor([  5.3577, -17.2483])\n",
      "    Grad  :  tensor([-0.0017,  0.0096])\n",
      "Epoch 3376,Loss 2.927925\n",
      "Epoch 3376, Loss 2.927925\n",
      "    Params:  tensor([  5.3578, -17.2484])\n",
      "    Grad  :  tensor([-0.0017,  0.0096])\n",
      "Epoch 3377,Loss 2.927924\n",
      "Epoch 3377, Loss 2.927924\n",
      "    Params:  tensor([  5.3578, -17.2485])\n",
      "    Grad  :  tensor([-0.0017,  0.0096])\n",
      "Epoch 3378,Loss 2.927923\n",
      "Epoch 3378, Loss 2.927923\n",
      "    Params:  tensor([  5.3578, -17.2486])\n",
      "    Grad  :  tensor([-0.0017,  0.0096])\n",
      "Epoch 3379,Loss 2.927924\n",
      "Epoch 3379, Loss 2.927924\n",
      "    Params:  tensor([  5.3578, -17.2487])\n",
      "    Grad  :  tensor([-0.0017,  0.0095])\n",
      "Epoch 3380,Loss 2.927922\n",
      "Epoch 3380, Loss 2.927922\n",
      "    Params:  tensor([  5.3578, -17.2488])\n",
      "    Grad  :  tensor([-0.0017,  0.0095])\n",
      "Epoch 3381,Loss 2.927922\n",
      "Epoch 3381, Loss 2.927922\n",
      "    Params:  tensor([  5.3578, -17.2489])\n",
      "    Grad  :  tensor([-0.0017,  0.0095])\n",
      "Epoch 3382,Loss 2.927920\n",
      "Epoch 3382, Loss 2.927920\n",
      "    Params:  tensor([  5.3579, -17.2490])\n",
      "    Grad  :  tensor([-0.0017,  0.0095])\n",
      "Epoch 3383,Loss 2.927918\n",
      "Epoch 3383, Loss 2.927918\n",
      "    Params:  tensor([  5.3579, -17.2491])\n",
      "    Grad  :  tensor([-0.0017,  0.0095])\n",
      "Epoch 3384,Loss 2.927917\n",
      "Epoch 3384, Loss 2.927917\n",
      "    Params:  tensor([  5.3579, -17.2492])\n",
      "    Grad  :  tensor([-0.0017,  0.0095])\n",
      "Epoch 3385,Loss 2.927917\n",
      "Epoch 3385, Loss 2.927917\n",
      "    Params:  tensor([  5.3579, -17.2493])\n",
      "    Grad  :  tensor([-0.0017,  0.0094])\n",
      "Epoch 3386,Loss 2.927915\n",
      "Epoch 3386, Loss 2.927915\n",
      "    Params:  tensor([  5.3579, -17.2494])\n",
      "    Grad  :  tensor([-0.0017,  0.0094])\n",
      "Epoch 3387,Loss 2.927915\n",
      "Epoch 3387, Loss 2.927915\n",
      "    Params:  tensor([  5.3579, -17.2495])\n",
      "    Grad  :  tensor([-0.0017,  0.0094])\n",
      "Epoch 3388,Loss 2.927914\n",
      "Epoch 3388, Loss 2.927914\n",
      "    Params:  tensor([  5.3580, -17.2496])\n",
      "    Grad  :  tensor([-0.0016,  0.0094])\n",
      "Epoch 3389,Loss 2.927913\n",
      "Epoch 3389, Loss 2.927913\n",
      "    Params:  tensor([  5.3580, -17.2496])\n",
      "    Grad  :  tensor([-0.0017,  0.0094])\n",
      "Epoch 3390,Loss 2.927911\n",
      "Epoch 3390, Loss 2.927911\n",
      "    Params:  tensor([  5.3580, -17.2497])\n",
      "    Grad  :  tensor([-0.0016,  0.0094])\n",
      "Epoch 3391,Loss 2.927913\n",
      "Epoch 3391, Loss 2.927913\n",
      "    Params:  tensor([  5.3580, -17.2498])\n",
      "    Grad  :  tensor([-0.0017,  0.0093])\n",
      "Epoch 3392,Loss 2.927911\n",
      "Epoch 3392, Loss 2.927911\n",
      "    Params:  tensor([  5.3580, -17.2499])\n",
      "    Grad  :  tensor([-0.0016,  0.0093])\n",
      "Epoch 3393,Loss 2.927910\n",
      "Epoch 3393, Loss 2.927910\n",
      "    Params:  tensor([  5.3580, -17.2500])\n",
      "    Grad  :  tensor([-0.0016,  0.0093])\n",
      "Epoch 3394,Loss 2.927909\n",
      "Epoch 3394, Loss 2.927909\n",
      "    Params:  tensor([  5.3581, -17.2501])\n",
      "    Grad  :  tensor([-0.0016,  0.0093])\n",
      "Epoch 3395,Loss 2.927908\n",
      "Epoch 3395, Loss 2.927908\n",
      "    Params:  tensor([  5.3581, -17.2502])\n",
      "    Grad  :  tensor([-0.0016,  0.0093])\n",
      "Epoch 3396,Loss 2.927907\n",
      "Epoch 3396, Loss 2.927907\n",
      "    Params:  tensor([  5.3581, -17.2503])\n",
      "    Grad  :  tensor([-0.0017,  0.0093])\n",
      "Epoch 3397,Loss 2.927906\n",
      "Epoch 3397, Loss 2.927906\n",
      "    Params:  tensor([  5.3581, -17.2504])\n",
      "    Grad  :  tensor([-0.0016,  0.0093])\n",
      "Epoch 3398,Loss 2.927905\n",
      "Epoch 3398, Loss 2.927905\n",
      "    Params:  tensor([  5.3581, -17.2505])\n",
      "    Grad  :  tensor([-0.0017,  0.0092])\n",
      "Epoch 3399,Loss 2.927905\n",
      "Epoch 3399, Loss 2.927905\n",
      "    Params:  tensor([  5.3581, -17.2506])\n",
      "    Grad  :  tensor([-0.0016,  0.0092])\n",
      "Epoch 3400,Loss 2.927904\n",
      "Epoch 3400, Loss 2.927904\n",
      "    Params:  tensor([  5.3582, -17.2507])\n",
      "    Grad  :  tensor([-0.0016,  0.0092])\n",
      "Epoch 3401,Loss 2.927902\n",
      "Epoch 3401, Loss 2.927902\n",
      "    Params:  tensor([  5.3582, -17.2508])\n",
      "    Grad  :  tensor([-0.0016,  0.0092])\n",
      "Epoch 3402,Loss 2.927902\n",
      "Epoch 3402, Loss 2.927902\n",
      "    Params:  tensor([  5.3582, -17.2509])\n",
      "    Grad  :  tensor([-0.0016,  0.0092])\n",
      "Epoch 3403,Loss 2.927902\n",
      "Epoch 3403, Loss 2.927902\n",
      "    Params:  tensor([  5.3582, -17.2509])\n",
      "    Grad  :  tensor([-0.0016,  0.0092])\n",
      "Epoch 3404,Loss 2.927899\n",
      "Epoch 3404, Loss 2.927899\n",
      "    Params:  tensor([  5.3582, -17.2510])\n",
      "    Grad  :  tensor([-0.0016,  0.0091])\n",
      "Epoch 3405,Loss 2.927899\n",
      "Epoch 3405, Loss 2.927899\n",
      "    Params:  tensor([  5.3582, -17.2511])\n",
      "    Grad  :  tensor([-0.0016,  0.0091])\n",
      "Epoch 3406,Loss 2.927898\n",
      "Epoch 3406, Loss 2.927898\n",
      "    Params:  tensor([  5.3583, -17.2512])\n",
      "    Grad  :  tensor([-0.0016,  0.0091])\n",
      "Epoch 3407,Loss 2.927899\n",
      "Epoch 3407, Loss 2.927899\n",
      "    Params:  tensor([  5.3583, -17.2513])\n",
      "    Grad  :  tensor([-0.0016,  0.0091])\n",
      "Epoch 3408,Loss 2.927896\n",
      "Epoch 3408, Loss 2.927896\n",
      "    Params:  tensor([  5.3583, -17.2514])\n",
      "    Grad  :  tensor([-0.0016,  0.0091])\n",
      "Epoch 3409,Loss 2.927895\n",
      "Epoch 3409, Loss 2.927895\n",
      "    Params:  tensor([  5.3583, -17.2515])\n",
      "    Grad  :  tensor([-0.0016,  0.0091])\n",
      "Epoch 3410,Loss 2.927896\n",
      "Epoch 3410, Loss 2.927896\n",
      "    Params:  tensor([  5.3583, -17.2516])\n",
      "    Grad  :  tensor([-0.0016,  0.0091])\n",
      "Epoch 3411,Loss 2.927894\n",
      "Epoch 3411, Loss 2.927894\n",
      "    Params:  tensor([  5.3583, -17.2517])\n",
      "    Grad  :  tensor([-0.0016,  0.0090])\n",
      "Epoch 3412,Loss 2.927892\n",
      "Epoch 3412, Loss 2.927892\n",
      "    Params:  tensor([  5.3584, -17.2518])\n",
      "    Grad  :  tensor([-0.0016,  0.0090])\n",
      "Epoch 3413,Loss 2.927892\n",
      "Epoch 3413, Loss 2.927892\n",
      "    Params:  tensor([  5.3584, -17.2519])\n",
      "    Grad  :  tensor([-0.0016,  0.0090])\n",
      "Epoch 3414,Loss 2.927891\n",
      "Epoch 3414, Loss 2.927891\n",
      "    Params:  tensor([  5.3584, -17.2519])\n",
      "    Grad  :  tensor([-0.0016,  0.0090])\n",
      "Epoch 3415,Loss 2.927891\n",
      "Epoch 3415, Loss 2.927891\n",
      "    Params:  tensor([  5.3584, -17.2520])\n",
      "    Grad  :  tensor([-0.0016,  0.0090])\n",
      "Epoch 3416,Loss 2.927890\n",
      "Epoch 3416, Loss 2.927890\n",
      "    Params:  tensor([  5.3584, -17.2521])\n",
      "    Grad  :  tensor([-0.0016,  0.0090])\n",
      "Epoch 3417,Loss 2.927891\n",
      "Epoch 3417, Loss 2.927891\n",
      "    Params:  tensor([  5.3584, -17.2522])\n",
      "    Grad  :  tensor([-0.0016,  0.0089])\n",
      "Epoch 3418,Loss 2.927888\n",
      "Epoch 3418, Loss 2.927888\n",
      "    Params:  tensor([  5.3584, -17.2523])\n",
      "    Grad  :  tensor([-0.0016,  0.0089])\n",
      "Epoch 3419,Loss 2.927888\n",
      "Epoch 3419, Loss 2.927888\n",
      "    Params:  tensor([  5.3585, -17.2524])\n",
      "    Grad  :  tensor([-0.0016,  0.0089])\n",
      "Epoch 3420,Loss 2.927886\n",
      "Epoch 3420, Loss 2.927886\n",
      "    Params:  tensor([  5.3585, -17.2525])\n",
      "    Grad  :  tensor([-0.0016,  0.0089])\n",
      "Epoch 3421,Loss 2.927887\n",
      "Epoch 3421, Loss 2.927887\n",
      "    Params:  tensor([  5.3585, -17.2526])\n",
      "    Grad  :  tensor([-0.0016,  0.0089])\n",
      "Epoch 3422,Loss 2.927886\n",
      "Epoch 3422, Loss 2.927886\n",
      "    Params:  tensor([  5.3585, -17.2527])\n",
      "    Grad  :  tensor([-0.0016,  0.0089])\n",
      "Epoch 3423,Loss 2.927884\n",
      "Epoch 3423, Loss 2.927884\n",
      "    Params:  tensor([  5.3585, -17.2527])\n",
      "    Grad  :  tensor([-0.0016,  0.0089])\n",
      "Epoch 3424,Loss 2.927883\n",
      "Epoch 3424, Loss 2.927883\n",
      "    Params:  tensor([  5.3585, -17.2528])\n",
      "    Grad  :  tensor([-0.0016,  0.0088])\n",
      "Epoch 3425,Loss 2.927882\n",
      "Epoch 3425, Loss 2.927882\n",
      "    Params:  tensor([  5.3586, -17.2529])\n",
      "    Grad  :  tensor([-0.0015,  0.0088])\n",
      "Epoch 3426,Loss 2.927882\n",
      "Epoch 3426, Loss 2.927882\n",
      "    Params:  tensor([  5.3586, -17.2530])\n",
      "    Grad  :  tensor([-0.0016,  0.0088])\n",
      "Epoch 3427,Loss 2.927880\n",
      "Epoch 3427, Loss 2.927880\n",
      "    Params:  tensor([  5.3586, -17.2531])\n",
      "    Grad  :  tensor([-0.0015,  0.0088])\n",
      "Epoch 3428,Loss 2.927880\n",
      "Epoch 3428, Loss 2.927880\n",
      "    Params:  tensor([  5.3586, -17.2532])\n",
      "    Grad  :  tensor([-0.0015,  0.0088])\n",
      "Epoch 3429,Loss 2.927879\n",
      "Epoch 3429, Loss 2.927879\n",
      "    Params:  tensor([  5.3586, -17.2533])\n",
      "    Grad  :  tensor([-0.0016,  0.0088])\n",
      "Epoch 3430,Loss 2.927879\n",
      "Epoch 3430, Loss 2.927879\n",
      "    Params:  tensor([  5.3586, -17.2534])\n",
      "    Grad  :  tensor([-0.0015,  0.0088])\n",
      "Epoch 3431,Loss 2.927877\n",
      "Epoch 3431, Loss 2.927877\n",
      "    Params:  tensor([  5.3587, -17.2534])\n",
      "    Grad  :  tensor([-0.0016,  0.0087])\n",
      "Epoch 3432,Loss 2.927876\n",
      "Epoch 3432, Loss 2.927876\n",
      "    Params:  tensor([  5.3587, -17.2535])\n",
      "    Grad  :  tensor([-0.0015,  0.0087])\n",
      "Epoch 3433,Loss 2.927876\n",
      "Epoch 3433, Loss 2.927876\n",
      "    Params:  tensor([  5.3587, -17.2536])\n",
      "    Grad  :  tensor([-0.0016,  0.0087])\n",
      "Epoch 3434,Loss 2.927875\n",
      "Epoch 3434, Loss 2.927875\n",
      "    Params:  tensor([  5.3587, -17.2537])\n",
      "    Grad  :  tensor([-0.0015,  0.0087])\n",
      "Epoch 3435,Loss 2.927875\n",
      "Epoch 3435, Loss 2.927875\n",
      "    Params:  tensor([  5.3587, -17.2538])\n",
      "    Grad  :  tensor([-0.0015,  0.0087])\n",
      "Epoch 3436,Loss 2.927875\n",
      "Epoch 3436, Loss 2.927875\n",
      "    Params:  tensor([  5.3587, -17.2539])\n",
      "    Grad  :  tensor([-0.0015,  0.0087])\n",
      "Epoch 3437,Loss 2.927873\n",
      "Epoch 3437, Loss 2.927873\n",
      "    Params:  tensor([  5.3587, -17.2540])\n",
      "    Grad  :  tensor([-0.0015,  0.0086])\n",
      "Epoch 3438,Loss 2.927872\n",
      "Epoch 3438, Loss 2.927872\n",
      "    Params:  tensor([  5.3588, -17.2541])\n",
      "    Grad  :  tensor([-0.0015,  0.0086])\n",
      "Epoch 3439,Loss 2.927872\n",
      "Epoch 3439, Loss 2.927872\n",
      "    Params:  tensor([  5.3588, -17.2541])\n",
      "    Grad  :  tensor([-0.0015,  0.0086])\n",
      "Epoch 3440,Loss 2.927870\n",
      "Epoch 3440, Loss 2.927870\n",
      "    Params:  tensor([  5.3588, -17.2542])\n",
      "    Grad  :  tensor([-0.0015,  0.0086])\n",
      "Epoch 3441,Loss 2.927870\n",
      "Epoch 3441, Loss 2.927870\n",
      "    Params:  tensor([  5.3588, -17.2543])\n",
      "    Grad  :  tensor([-0.0015,  0.0086])\n",
      "Epoch 3442,Loss 2.927869\n",
      "Epoch 3442, Loss 2.927869\n",
      "    Params:  tensor([  5.3588, -17.2544])\n",
      "    Grad  :  tensor([-0.0015,  0.0086])\n",
      "Epoch 3443,Loss 2.927869\n",
      "Epoch 3443, Loss 2.927869\n",
      "    Params:  tensor([  5.3588, -17.2545])\n",
      "    Grad  :  tensor([-0.0015,  0.0086])\n",
      "Epoch 3444,Loss 2.927869\n",
      "Epoch 3444, Loss 2.927869\n",
      "    Params:  tensor([  5.3588, -17.2546])\n",
      "    Grad  :  tensor([-0.0015,  0.0085])\n",
      "Epoch 3445,Loss 2.927865\n",
      "Epoch 3445, Loss 2.927865\n",
      "    Params:  tensor([  5.3589, -17.2547])\n",
      "    Grad  :  tensor([-0.0015,  0.0085])\n",
      "Epoch 3446,Loss 2.927866\n",
      "Epoch 3446, Loss 2.927866\n",
      "    Params:  tensor([  5.3589, -17.2547])\n",
      "    Grad  :  tensor([-0.0015,  0.0085])\n",
      "Epoch 3447,Loss 2.927865\n",
      "Epoch 3447, Loss 2.927865\n",
      "    Params:  tensor([  5.3589, -17.2548])\n",
      "    Grad  :  tensor([-0.0015,  0.0085])\n",
      "Epoch 3448,Loss 2.927864\n",
      "Epoch 3448, Loss 2.927864\n",
      "    Params:  tensor([  5.3589, -17.2549])\n",
      "    Grad  :  tensor([-0.0015,  0.0085])\n",
      "Epoch 3449,Loss 2.927863\n",
      "Epoch 3449, Loss 2.927863\n",
      "    Params:  tensor([  5.3589, -17.2550])\n",
      "    Grad  :  tensor([-0.0015,  0.0085])\n",
      "Epoch 3450,Loss 2.927863\n",
      "Epoch 3450, Loss 2.927863\n",
      "    Params:  tensor([  5.3589, -17.2551])\n",
      "    Grad  :  tensor([-0.0015,  0.0085])\n",
      "Epoch 3451,Loss 2.927862\n",
      "Epoch 3451, Loss 2.927862\n",
      "    Params:  tensor([  5.3590, -17.2552])\n",
      "    Grad  :  tensor([-0.0015,  0.0084])\n",
      "Epoch 3452,Loss 2.927863\n",
      "Epoch 3452, Loss 2.927863\n",
      "    Params:  tensor([  5.3590, -17.2552])\n",
      "    Grad  :  tensor([-0.0015,  0.0084])\n",
      "Epoch 3453,Loss 2.927860\n",
      "Epoch 3453, Loss 2.927860\n",
      "    Params:  tensor([  5.3590, -17.2553])\n",
      "    Grad  :  tensor([-0.0015,  0.0084])\n",
      "Epoch 3454,Loss 2.927860\n",
      "Epoch 3454, Loss 2.927860\n",
      "    Params:  tensor([  5.3590, -17.2554])\n",
      "    Grad  :  tensor([-0.0015,  0.0084])\n",
      "Epoch 3455,Loss 2.927860\n",
      "Epoch 3455, Loss 2.927860\n",
      "    Params:  tensor([  5.3590, -17.2555])\n",
      "    Grad  :  tensor([-0.0015,  0.0084])\n",
      "Epoch 3456,Loss 2.927859\n",
      "Epoch 3456, Loss 2.927859\n",
      "    Params:  tensor([  5.3590, -17.2556])\n",
      "    Grad  :  tensor([-0.0015,  0.0084])\n",
      "Epoch 3457,Loss 2.927859\n",
      "Epoch 3457, Loss 2.927859\n",
      "    Params:  tensor([  5.3590, -17.2557])\n",
      "    Grad  :  tensor([-0.0015,  0.0084])\n",
      "Epoch 3458,Loss 2.927858\n",
      "Epoch 3458, Loss 2.927858\n",
      "    Params:  tensor([  5.3591, -17.2558])\n",
      "    Grad  :  tensor([-0.0015,  0.0083])\n",
      "Epoch 3459,Loss 2.927855\n",
      "Epoch 3459, Loss 2.927855\n",
      "    Params:  tensor([  5.3591, -17.2558])\n",
      "    Grad  :  tensor([-0.0015,  0.0083])\n",
      "Epoch 3460,Loss 2.927857\n",
      "Epoch 3460, Loss 2.927857\n",
      "    Params:  tensor([  5.3591, -17.2559])\n",
      "    Grad  :  tensor([-0.0015,  0.0083])\n",
      "Epoch 3461,Loss 2.927854\n",
      "Epoch 3461, Loss 2.927854\n",
      "    Params:  tensor([  5.3591, -17.2560])\n",
      "    Grad  :  tensor([-0.0015,  0.0083])\n",
      "Epoch 3462,Loss 2.927855\n",
      "Epoch 3462, Loss 2.927855\n",
      "    Params:  tensor([  5.3591, -17.2561])\n",
      "    Grad  :  tensor([-0.0015,  0.0083])\n",
      "Epoch 3463,Loss 2.927854\n",
      "Epoch 3463, Loss 2.927854\n",
      "    Params:  tensor([  5.3591, -17.2562])\n",
      "    Grad  :  tensor([-0.0015,  0.0083])\n",
      "Epoch 3464,Loss 2.927853\n",
      "Epoch 3464, Loss 2.927853\n",
      "    Params:  tensor([  5.3591, -17.2562])\n",
      "    Grad  :  tensor([-0.0015,  0.0083])\n",
      "Epoch 3465,Loss 2.927851\n",
      "Epoch 3465, Loss 2.927851\n",
      "    Params:  tensor([  5.3592, -17.2563])\n",
      "    Grad  :  tensor([-0.0015,  0.0082])\n",
      "Epoch 3466,Loss 2.927852\n",
      "Epoch 3466, Loss 2.927852\n",
      "    Params:  tensor([  5.3592, -17.2564])\n",
      "    Grad  :  tensor([-0.0014,  0.0082])\n",
      "Epoch 3467,Loss 2.927852\n",
      "Epoch 3467, Loss 2.927852\n",
      "    Params:  tensor([  5.3592, -17.2565])\n",
      "    Grad  :  tensor([-0.0014,  0.0082])\n",
      "Epoch 3468,Loss 2.927850\n",
      "Epoch 3468, Loss 2.927850\n",
      "    Params:  tensor([  5.3592, -17.2566])\n",
      "    Grad  :  tensor([-0.0015,  0.0082])\n",
      "Epoch 3469,Loss 2.927849\n",
      "Epoch 3469, Loss 2.927849\n",
      "    Params:  tensor([  5.3592, -17.2567])\n",
      "    Grad  :  tensor([-0.0015,  0.0082])\n",
      "Epoch 3470,Loss 2.927849\n",
      "Epoch 3470, Loss 2.927849\n",
      "    Params:  tensor([  5.3592, -17.2567])\n",
      "    Grad  :  tensor([-0.0014,  0.0082])\n",
      "Epoch 3471,Loss 2.927848\n",
      "Epoch 3471, Loss 2.927848\n",
      "    Params:  tensor([  5.3592, -17.2568])\n",
      "    Grad  :  tensor([-0.0015,  0.0082])\n",
      "Epoch 3472,Loss 2.927848\n",
      "Epoch 3472, Loss 2.927848\n",
      "    Params:  tensor([  5.3593, -17.2569])\n",
      "    Grad  :  tensor([-0.0014,  0.0081])\n",
      "Epoch 3473,Loss 2.927847\n",
      "Epoch 3473, Loss 2.927847\n",
      "    Params:  tensor([  5.3593, -17.2570])\n",
      "    Grad  :  tensor([-0.0014,  0.0081])\n",
      "Epoch 3474,Loss 2.927846\n",
      "Epoch 3474, Loss 2.927846\n",
      "    Params:  tensor([  5.3593, -17.2571])\n",
      "    Grad  :  tensor([-0.0015,  0.0081])\n",
      "Epoch 3475,Loss 2.927846\n",
      "Epoch 3475, Loss 2.927846\n",
      "    Params:  tensor([  5.3593, -17.2572])\n",
      "    Grad  :  tensor([-0.0014,  0.0081])\n",
      "Epoch 3476,Loss 2.927844\n",
      "Epoch 3476, Loss 2.927844\n",
      "    Params:  tensor([  5.3593, -17.2572])\n",
      "    Grad  :  tensor([-0.0014,  0.0081])\n",
      "Epoch 3477,Loss 2.927844\n",
      "Epoch 3477, Loss 2.927844\n",
      "    Params:  tensor([  5.3593, -17.2573])\n",
      "    Grad  :  tensor([-0.0014,  0.0081])\n",
      "Epoch 3478,Loss 2.927843\n",
      "Epoch 3478, Loss 2.927843\n",
      "    Params:  tensor([  5.3593, -17.2574])\n",
      "    Grad  :  tensor([-0.0014,  0.0081])\n",
      "Epoch 3479,Loss 2.927843\n",
      "Epoch 3479, Loss 2.927843\n",
      "    Params:  tensor([  5.3594, -17.2575])\n",
      "    Grad  :  tensor([-0.0014,  0.0081])\n",
      "Epoch 3480,Loss 2.927841\n",
      "Epoch 3480, Loss 2.927841\n",
      "    Params:  tensor([  5.3594, -17.2576])\n",
      "    Grad  :  tensor([-0.0014,  0.0080])\n",
      "Epoch 3481,Loss 2.927842\n",
      "Epoch 3481, Loss 2.927842\n",
      "    Params:  tensor([  5.3594, -17.2576])\n",
      "    Grad  :  tensor([-0.0014,  0.0080])\n",
      "Epoch 3482,Loss 2.927840\n",
      "Epoch 3482, Loss 2.927840\n",
      "    Params:  tensor([  5.3594, -17.2577])\n",
      "    Grad  :  tensor([-0.0014,  0.0080])\n",
      "Epoch 3483,Loss 2.927841\n",
      "Epoch 3483, Loss 2.927841\n",
      "    Params:  tensor([  5.3594, -17.2578])\n",
      "    Grad  :  tensor([-0.0014,  0.0080])\n",
      "Epoch 3484,Loss 2.927839\n",
      "Epoch 3484, Loss 2.927839\n",
      "    Params:  tensor([  5.3594, -17.2579])\n",
      "    Grad  :  tensor([-0.0014,  0.0080])\n",
      "Epoch 3485,Loss 2.927839\n",
      "Epoch 3485, Loss 2.927839\n",
      "    Params:  tensor([  5.3594, -17.2580])\n",
      "    Grad  :  tensor([-0.0014,  0.0080])\n",
      "Epoch 3486,Loss 2.927837\n",
      "Epoch 3486, Loss 2.927837\n",
      "    Params:  tensor([  5.3595, -17.2580])\n",
      "    Grad  :  tensor([-0.0014,  0.0080])\n",
      "Epoch 3487,Loss 2.927837\n",
      "Epoch 3487, Loss 2.927837\n",
      "    Params:  tensor([  5.3595, -17.2581])\n",
      "    Grad  :  tensor([-0.0014,  0.0079])\n",
      "Epoch 3488,Loss 2.927836\n",
      "Epoch 3488, Loss 2.927836\n",
      "    Params:  tensor([  5.3595, -17.2582])\n",
      "    Grad  :  tensor([-0.0014,  0.0079])\n",
      "Epoch 3489,Loss 2.927836\n",
      "Epoch 3489, Loss 2.927836\n",
      "    Params:  tensor([  5.3595, -17.2583])\n",
      "    Grad  :  tensor([-0.0014,  0.0079])\n",
      "Epoch 3490,Loss 2.927837\n",
      "Epoch 3490, Loss 2.927837\n",
      "    Params:  tensor([  5.3595, -17.2583])\n",
      "    Grad  :  tensor([-0.0014,  0.0079])\n",
      "Epoch 3491,Loss 2.927834\n",
      "Epoch 3491, Loss 2.927834\n",
      "    Params:  tensor([  5.3595, -17.2584])\n",
      "    Grad  :  tensor([-0.0014,  0.0079])\n",
      "Epoch 3492,Loss 2.927834\n",
      "Epoch 3492, Loss 2.927834\n",
      "    Params:  tensor([  5.3595, -17.2585])\n",
      "    Grad  :  tensor([-0.0014,  0.0079])\n",
      "Epoch 3493,Loss 2.927833\n",
      "Epoch 3493, Loss 2.927833\n",
      "    Params:  tensor([  5.3596, -17.2586])\n",
      "    Grad  :  tensor([-0.0014,  0.0079])\n",
      "Epoch 3494,Loss 2.927834\n",
      "Epoch 3494, Loss 2.927834\n",
      "    Params:  tensor([  5.3596, -17.2587])\n",
      "    Grad  :  tensor([-0.0014,  0.0078])\n",
      "Epoch 3495,Loss 2.927833\n",
      "Epoch 3495, Loss 2.927833\n",
      "    Params:  tensor([  5.3596, -17.2587])\n",
      "    Grad  :  tensor([-0.0014,  0.0078])\n",
      "Epoch 3496,Loss 2.927831\n",
      "Epoch 3496, Loss 2.927831\n",
      "    Params:  tensor([  5.3596, -17.2588])\n",
      "    Grad  :  tensor([-0.0014,  0.0078])\n",
      "Epoch 3497,Loss 2.927831\n",
      "Epoch 3497, Loss 2.927831\n",
      "    Params:  tensor([  5.3596, -17.2589])\n",
      "    Grad  :  tensor([-0.0014,  0.0078])\n",
      "Epoch 3498,Loss 2.927831\n",
      "Epoch 3498, Loss 2.927831\n",
      "    Params:  tensor([  5.3596, -17.2590])\n",
      "    Grad  :  tensor([-0.0014,  0.0078])\n",
      "Epoch 3499,Loss 2.927830\n",
      "Epoch 3499, Loss 2.927830\n",
      "    Params:  tensor([  5.3596, -17.2591])\n",
      "    Grad  :  tensor([-0.0014,  0.0078])\n",
      "Epoch 3500,Loss 2.927831\n",
      "Epoch 3500, Loss 2.927831\n",
      "    Params:  tensor([  5.3597, -17.2591])\n",
      "    Grad  :  tensor([-0.0014,  0.0078])\n",
      "Epoch 3501,Loss 2.927828\n",
      "Epoch 3501, Loss 2.927828\n",
      "    Params:  tensor([  5.3597, -17.2592])\n",
      "    Grad  :  tensor([-0.0014,  0.0078])\n",
      "Epoch 3502,Loss 2.927826\n",
      "Epoch 3502, Loss 2.927826\n",
      "    Params:  tensor([  5.3597, -17.2593])\n",
      "    Grad  :  tensor([-0.0014,  0.0077])\n",
      "Epoch 3503,Loss 2.927828\n",
      "Epoch 3503, Loss 2.927828\n",
      "    Params:  tensor([  5.3597, -17.2594])\n",
      "    Grad  :  tensor([-0.0014,  0.0077])\n",
      "Epoch 3504,Loss 2.927827\n",
      "Epoch 3504, Loss 2.927827\n",
      "    Params:  tensor([  5.3597, -17.2594])\n",
      "    Grad  :  tensor([-0.0014,  0.0077])\n",
      "Epoch 3505,Loss 2.927825\n",
      "Epoch 3505, Loss 2.927825\n",
      "    Params:  tensor([  5.3597, -17.2595])\n",
      "    Grad  :  tensor([-0.0014,  0.0077])\n",
      "Epoch 3506,Loss 2.927827\n",
      "Epoch 3506, Loss 2.927827\n",
      "    Params:  tensor([  5.3597, -17.2596])\n",
      "    Grad  :  tensor([-0.0013,  0.0077])\n",
      "Epoch 3507,Loss 2.927824\n",
      "Epoch 3507, Loss 2.927824\n",
      "    Params:  tensor([  5.3597, -17.2597])\n",
      "    Grad  :  tensor([-0.0013,  0.0077])\n",
      "Epoch 3508,Loss 2.927822\n",
      "Epoch 3508, Loss 2.927822\n",
      "    Params:  tensor([  5.3598, -17.2597])\n",
      "    Grad  :  tensor([-0.0013,  0.0077])\n",
      "Epoch 3509,Loss 2.927824\n",
      "Epoch 3509, Loss 2.927824\n",
      "    Params:  tensor([  5.3598, -17.2598])\n",
      "    Grad  :  tensor([-0.0014,  0.0077])\n",
      "Epoch 3510,Loss 2.927823\n",
      "Epoch 3510, Loss 2.927823\n",
      "    Params:  tensor([  5.3598, -17.2599])\n",
      "    Grad  :  tensor([-0.0014,  0.0076])\n",
      "Epoch 3511,Loss 2.927822\n",
      "Epoch 3511, Loss 2.927822\n",
      "    Params:  tensor([  5.3598, -17.2600])\n",
      "    Grad  :  tensor([-0.0014,  0.0076])\n",
      "Epoch 3512,Loss 2.927823\n",
      "Epoch 3512, Loss 2.927823\n",
      "    Params:  tensor([  5.3598, -17.2601])\n",
      "    Grad  :  tensor([-0.0013,  0.0076])\n",
      "Epoch 3513,Loss 2.927822\n",
      "Epoch 3513, Loss 2.927822\n",
      "    Params:  tensor([  5.3598, -17.2601])\n",
      "    Grad  :  tensor([-0.0013,  0.0076])\n",
      "Epoch 3514,Loss 2.927821\n",
      "Epoch 3514, Loss 2.927821\n",
      "    Params:  tensor([  5.3598, -17.2602])\n",
      "    Grad  :  tensor([-0.0014,  0.0076])\n",
      "Epoch 3515,Loss 2.927821\n",
      "Epoch 3515, Loss 2.927821\n",
      "    Params:  tensor([  5.3599, -17.2603])\n",
      "    Grad  :  tensor([-0.0014,  0.0076])\n",
      "Epoch 3516,Loss 2.927820\n",
      "Epoch 3516, Loss 2.927820\n",
      "    Params:  tensor([  5.3599, -17.2604])\n",
      "    Grad  :  tensor([-0.0013,  0.0076])\n",
      "Epoch 3517,Loss 2.927819\n",
      "Epoch 3517, Loss 2.927819\n",
      "    Params:  tensor([  5.3599, -17.2604])\n",
      "    Grad  :  tensor([-0.0013,  0.0075])\n",
      "Epoch 3518,Loss 2.927818\n",
      "Epoch 3518, Loss 2.927818\n",
      "    Params:  tensor([  5.3599, -17.2605])\n",
      "    Grad  :  tensor([-0.0013,  0.0075])\n",
      "Epoch 3519,Loss 2.927817\n",
      "Epoch 3519, Loss 2.927817\n",
      "    Params:  tensor([  5.3599, -17.2606])\n",
      "    Grad  :  tensor([-0.0013,  0.0075])\n",
      "Epoch 3520,Loss 2.927817\n",
      "Epoch 3520, Loss 2.927817\n",
      "    Params:  tensor([  5.3599, -17.2607])\n",
      "    Grad  :  tensor([-0.0013,  0.0075])\n",
      "Epoch 3521,Loss 2.927817\n",
      "Epoch 3521, Loss 2.927817\n",
      "    Params:  tensor([  5.3599, -17.2607])\n",
      "    Grad  :  tensor([-0.0013,  0.0075])\n",
      "Epoch 3522,Loss 2.927817\n",
      "Epoch 3522, Loss 2.927817\n",
      "    Params:  tensor([  5.3600, -17.2608])\n",
      "    Grad  :  tensor([-0.0013,  0.0075])\n",
      "Epoch 3523,Loss 2.927815\n",
      "Epoch 3523, Loss 2.927815\n",
      "    Params:  tensor([  5.3600, -17.2609])\n",
      "    Grad  :  tensor([-0.0013,  0.0075])\n",
      "Epoch 3524,Loss 2.927815\n",
      "Epoch 3524, Loss 2.927815\n",
      "    Params:  tensor([  5.3600, -17.2610])\n",
      "    Grad  :  tensor([-0.0013,  0.0075])\n",
      "Epoch 3525,Loss 2.927814\n",
      "Epoch 3525, Loss 2.927814\n",
      "    Params:  tensor([  5.3600, -17.2610])\n",
      "    Grad  :  tensor([-0.0013,  0.0074])\n",
      "Epoch 3526,Loss 2.927813\n",
      "Epoch 3526, Loss 2.927813\n",
      "    Params:  tensor([  5.3600, -17.2611])\n",
      "    Grad  :  tensor([-0.0013,  0.0074])\n",
      "Epoch 3527,Loss 2.927814\n",
      "Epoch 3527, Loss 2.927814\n",
      "    Params:  tensor([  5.3600, -17.2612])\n",
      "    Grad  :  tensor([-0.0013,  0.0074])\n",
      "Epoch 3528,Loss 2.927814\n",
      "Epoch 3528, Loss 2.927814\n",
      "    Params:  tensor([  5.3600, -17.2613])\n",
      "    Grad  :  tensor([-0.0013,  0.0074])\n",
      "Epoch 3529,Loss 2.927812\n",
      "Epoch 3529, Loss 2.927812\n",
      "    Params:  tensor([  5.3600, -17.2613])\n",
      "    Grad  :  tensor([-0.0013,  0.0074])\n",
      "Epoch 3530,Loss 2.927811\n",
      "Epoch 3530, Loss 2.927811\n",
      "    Params:  tensor([  5.3601, -17.2614])\n",
      "    Grad  :  tensor([-0.0013,  0.0074])\n",
      "Epoch 3531,Loss 2.927811\n",
      "Epoch 3531, Loss 2.927811\n",
      "    Params:  tensor([  5.3601, -17.2615])\n",
      "    Grad  :  tensor([-0.0013,  0.0074])\n",
      "Epoch 3532,Loss 2.927810\n",
      "Epoch 3532, Loss 2.927810\n",
      "    Params:  tensor([  5.3601, -17.2615])\n",
      "    Grad  :  tensor([-0.0013,  0.0074])\n",
      "Epoch 3533,Loss 2.927810\n",
      "Epoch 3533, Loss 2.927810\n",
      "    Params:  tensor([  5.3601, -17.2616])\n",
      "    Grad  :  tensor([-0.0013,  0.0073])\n",
      "Epoch 3534,Loss 2.927808\n",
      "Epoch 3534, Loss 2.927808\n",
      "    Params:  tensor([  5.3601, -17.2617])\n",
      "    Grad  :  tensor([-0.0013,  0.0073])\n",
      "Epoch 3535,Loss 2.927808\n",
      "Epoch 3535, Loss 2.927808\n",
      "    Params:  tensor([  5.3601, -17.2618])\n",
      "    Grad  :  tensor([-0.0013,  0.0073])\n",
      "Epoch 3536,Loss 2.927808\n",
      "Epoch 3536, Loss 2.927808\n",
      "    Params:  tensor([  5.3601, -17.2618])\n",
      "    Grad  :  tensor([-0.0013,  0.0073])\n",
      "Epoch 3537,Loss 2.927807\n",
      "Epoch 3537, Loss 2.927807\n",
      "    Params:  tensor([  5.3601, -17.2619])\n",
      "    Grad  :  tensor([-0.0013,  0.0073])\n",
      "Epoch 3538,Loss 2.927808\n",
      "Epoch 3538, Loss 2.927808\n",
      "    Params:  tensor([  5.3602, -17.2620])\n",
      "    Grad  :  tensor([-0.0013,  0.0073])\n",
      "Epoch 3539,Loss 2.927806\n",
      "Epoch 3539, Loss 2.927806\n",
      "    Params:  tensor([  5.3602, -17.2621])\n",
      "    Grad  :  tensor([-0.0013,  0.0073])\n",
      "Epoch 3540,Loss 2.927805\n",
      "Epoch 3540, Loss 2.927805\n",
      "    Params:  tensor([  5.3602, -17.2621])\n",
      "    Grad  :  tensor([-0.0013,  0.0073])\n",
      "Epoch 3541,Loss 2.927806\n",
      "Epoch 3541, Loss 2.927806\n",
      "    Params:  tensor([  5.3602, -17.2622])\n",
      "    Grad  :  tensor([-0.0013,  0.0072])\n",
      "Epoch 3542,Loss 2.927805\n",
      "Epoch 3542, Loss 2.927805\n",
      "    Params:  tensor([  5.3602, -17.2623])\n",
      "    Grad  :  tensor([-0.0013,  0.0072])\n",
      "Epoch 3543,Loss 2.927804\n",
      "Epoch 3543, Loss 2.927804\n",
      "    Params:  tensor([  5.3602, -17.2623])\n",
      "    Grad  :  tensor([-0.0013,  0.0072])\n",
      "Epoch 3544,Loss 2.927805\n",
      "Epoch 3544, Loss 2.927805\n",
      "    Params:  tensor([  5.3602, -17.2624])\n",
      "    Grad  :  tensor([-0.0013,  0.0072])\n",
      "Epoch 3545,Loss 2.927804\n",
      "Epoch 3545, Loss 2.927804\n",
      "    Params:  tensor([  5.3602, -17.2625])\n",
      "    Grad  :  tensor([-0.0013,  0.0072])\n",
      "Epoch 3546,Loss 2.927802\n",
      "Epoch 3546, Loss 2.927802\n",
      "    Params:  tensor([  5.3603, -17.2626])\n",
      "    Grad  :  tensor([-0.0013,  0.0072])\n",
      "Epoch 3547,Loss 2.927803\n",
      "Epoch 3547, Loss 2.927803\n",
      "    Params:  tensor([  5.3603, -17.2626])\n",
      "    Grad  :  tensor([-0.0013,  0.0072])\n",
      "Epoch 3548,Loss 2.927800\n",
      "Epoch 3548, Loss 2.927800\n",
      "    Params:  tensor([  5.3603, -17.2627])\n",
      "    Grad  :  tensor([-0.0013,  0.0072])\n",
      "Epoch 3549,Loss 2.927802\n",
      "Epoch 3549, Loss 2.927802\n",
      "    Params:  tensor([  5.3603, -17.2628])\n",
      "    Grad  :  tensor([-0.0013,  0.0071])\n",
      "Epoch 3550,Loss 2.927800\n",
      "Epoch 3550, Loss 2.927800\n",
      "    Params:  tensor([  5.3603, -17.2628])\n",
      "    Grad  :  tensor([-0.0013,  0.0071])\n",
      "Epoch 3551,Loss 2.927800\n",
      "Epoch 3551, Loss 2.927800\n",
      "    Params:  tensor([  5.3603, -17.2629])\n",
      "    Grad  :  tensor([-0.0012,  0.0071])\n",
      "Epoch 3552,Loss 2.927799\n",
      "Epoch 3552, Loss 2.927799\n",
      "    Params:  tensor([  5.3603, -17.2630])\n",
      "    Grad  :  tensor([-0.0013,  0.0071])\n",
      "Epoch 3553,Loss 2.927799\n",
      "Epoch 3553, Loss 2.927799\n",
      "    Params:  tensor([  5.3603, -17.2631])\n",
      "    Grad  :  tensor([-0.0013,  0.0071])\n",
      "Epoch 3554,Loss 2.927798\n",
      "Epoch 3554, Loss 2.927798\n",
      "    Params:  tensor([  5.3604, -17.2631])\n",
      "    Grad  :  tensor([-0.0013,  0.0071])\n",
      "Epoch 3555,Loss 2.927798\n",
      "Epoch 3555, Loss 2.927798\n",
      "    Params:  tensor([  5.3604, -17.2632])\n",
      "    Grad  :  tensor([-0.0013,  0.0071])\n",
      "Epoch 3556,Loss 2.927797\n",
      "Epoch 3556, Loss 2.927797\n",
      "    Params:  tensor([  5.3604, -17.2633])\n",
      "    Grad  :  tensor([-0.0013,  0.0071])\n",
      "Epoch 3557,Loss 2.927799\n",
      "Epoch 3557, Loss 2.927799\n",
      "    Params:  tensor([  5.3604, -17.2633])\n",
      "    Grad  :  tensor([-0.0012,  0.0071])\n",
      "Epoch 3558,Loss 2.927796\n",
      "Epoch 3558, Loss 2.927796\n",
      "    Params:  tensor([  5.3604, -17.2634])\n",
      "    Grad  :  tensor([-0.0012,  0.0070])\n",
      "Epoch 3559,Loss 2.927796\n",
      "Epoch 3559, Loss 2.927796\n",
      "    Params:  tensor([  5.3604, -17.2635])\n",
      "    Grad  :  tensor([-0.0012,  0.0070])\n",
      "Epoch 3560,Loss 2.927795\n",
      "Epoch 3560, Loss 2.927795\n",
      "    Params:  tensor([  5.3604, -17.2636])\n",
      "    Grad  :  tensor([-0.0012,  0.0070])\n",
      "Epoch 3561,Loss 2.927796\n",
      "Epoch 3561, Loss 2.927796\n",
      "    Params:  tensor([  5.3604, -17.2636])\n",
      "    Grad  :  tensor([-0.0012,  0.0070])\n",
      "Epoch 3562,Loss 2.927794\n",
      "Epoch 3562, Loss 2.927794\n",
      "    Params:  tensor([  5.3605, -17.2637])\n",
      "    Grad  :  tensor([-0.0012,  0.0070])\n",
      "Epoch 3563,Loss 2.927793\n",
      "Epoch 3563, Loss 2.927793\n",
      "    Params:  tensor([  5.3605, -17.2638])\n",
      "    Grad  :  tensor([-0.0012,  0.0070])\n",
      "Epoch 3564,Loss 2.927793\n",
      "Epoch 3564, Loss 2.927793\n",
      "    Params:  tensor([  5.3605, -17.2638])\n",
      "    Grad  :  tensor([-0.0012,  0.0070])\n",
      "Epoch 3565,Loss 2.927793\n",
      "Epoch 3565, Loss 2.927793\n",
      "    Params:  tensor([  5.3605, -17.2639])\n",
      "    Grad  :  tensor([-0.0013,  0.0070])\n",
      "Epoch 3566,Loss 2.927793\n",
      "Epoch 3566, Loss 2.927793\n",
      "    Params:  tensor([  5.3605, -17.2640])\n",
      "    Grad  :  tensor([-0.0012,  0.0069])\n",
      "Epoch 3567,Loss 2.927791\n",
      "Epoch 3567, Loss 2.927791\n",
      "    Params:  tensor([  5.3605, -17.2640])\n",
      "    Grad  :  tensor([-0.0012,  0.0069])\n",
      "Epoch 3568,Loss 2.927793\n",
      "Epoch 3568, Loss 2.927793\n",
      "    Params:  tensor([  5.3605, -17.2641])\n",
      "    Grad  :  tensor([-0.0012,  0.0069])\n",
      "Epoch 3569,Loss 2.927791\n",
      "Epoch 3569, Loss 2.927791\n",
      "    Params:  tensor([  5.3605, -17.2642])\n",
      "    Grad  :  tensor([-0.0012,  0.0069])\n",
      "Epoch 3570,Loss 2.927789\n",
      "Epoch 3570, Loss 2.927789\n",
      "    Params:  tensor([  5.3606, -17.2642])\n",
      "    Grad  :  tensor([-0.0012,  0.0069])\n",
      "Epoch 3571,Loss 2.927790\n",
      "Epoch 3571, Loss 2.927790\n",
      "    Params:  tensor([  5.3606, -17.2643])\n",
      "    Grad  :  tensor([-0.0012,  0.0069])\n",
      "Epoch 3572,Loss 2.927790\n",
      "Epoch 3572, Loss 2.927790\n",
      "    Params:  tensor([  5.3606, -17.2644])\n",
      "    Grad  :  tensor([-0.0012,  0.0069])\n",
      "Epoch 3573,Loss 2.927788\n",
      "Epoch 3573, Loss 2.927788\n",
      "    Params:  tensor([  5.3606, -17.2645])\n",
      "    Grad  :  tensor([-0.0012,  0.0069])\n",
      "Epoch 3574,Loss 2.927788\n",
      "Epoch 3574, Loss 2.927788\n",
      "    Params:  tensor([  5.3606, -17.2645])\n",
      "    Grad  :  tensor([-0.0012,  0.0069])\n",
      "Epoch 3575,Loss 2.927789\n",
      "Epoch 3575, Loss 2.927789\n",
      "    Params:  tensor([  5.3606, -17.2646])\n",
      "    Grad  :  tensor([-0.0012,  0.0068])\n",
      "Epoch 3576,Loss 2.927788\n",
      "Epoch 3576, Loss 2.927788\n",
      "    Params:  tensor([  5.3606, -17.2647])\n",
      "    Grad  :  tensor([-0.0012,  0.0068])\n",
      "Epoch 3577,Loss 2.927787\n",
      "Epoch 3577, Loss 2.927787\n",
      "    Params:  tensor([  5.3606, -17.2647])\n",
      "    Grad  :  tensor([-0.0012,  0.0068])\n",
      "Epoch 3578,Loss 2.927787\n",
      "Epoch 3578, Loss 2.927787\n",
      "    Params:  tensor([  5.3607, -17.2648])\n",
      "    Grad  :  tensor([-0.0012,  0.0068])\n",
      "Epoch 3579,Loss 2.927786\n",
      "Epoch 3579, Loss 2.927786\n",
      "    Params:  tensor([  5.3607, -17.2649])\n",
      "    Grad  :  tensor([-0.0012,  0.0068])\n",
      "Epoch 3580,Loss 2.927787\n",
      "Epoch 3580, Loss 2.927787\n",
      "    Params:  tensor([  5.3607, -17.2649])\n",
      "    Grad  :  tensor([-0.0012,  0.0068])\n",
      "Epoch 3581,Loss 2.927785\n",
      "Epoch 3581, Loss 2.927785\n",
      "    Params:  tensor([  5.3607, -17.2650])\n",
      "    Grad  :  tensor([-0.0012,  0.0068])\n",
      "Epoch 3582,Loss 2.927784\n",
      "Epoch 3582, Loss 2.927784\n",
      "    Params:  tensor([  5.3607, -17.2651])\n",
      "    Grad  :  tensor([-0.0012,  0.0068])\n",
      "Epoch 3583,Loss 2.927785\n",
      "Epoch 3583, Loss 2.927785\n",
      "    Params:  tensor([  5.3607, -17.2651])\n",
      "    Grad  :  tensor([-0.0012,  0.0068])\n",
      "Epoch 3584,Loss 2.927784\n",
      "Epoch 3584, Loss 2.927784\n",
      "    Params:  tensor([  5.3607, -17.2652])\n",
      "    Grad  :  tensor([-0.0012,  0.0067])\n",
      "Epoch 3585,Loss 2.927784\n",
      "Epoch 3585, Loss 2.927784\n",
      "    Params:  tensor([  5.3607, -17.2653])\n",
      "    Grad  :  tensor([-0.0012,  0.0067])\n",
      "Epoch 3586,Loss 2.927783\n",
      "Epoch 3586, Loss 2.927783\n",
      "    Params:  tensor([  5.3608, -17.2653])\n",
      "    Grad  :  tensor([-0.0012,  0.0067])\n",
      "Epoch 3587,Loss 2.927783\n",
      "Epoch 3587, Loss 2.927783\n",
      "    Params:  tensor([  5.3608, -17.2654])\n",
      "    Grad  :  tensor([-0.0012,  0.0067])\n",
      "Epoch 3588,Loss 2.927781\n",
      "Epoch 3588, Loss 2.927781\n",
      "    Params:  tensor([  5.3608, -17.2655])\n",
      "    Grad  :  tensor([-0.0012,  0.0067])\n",
      "Epoch 3589,Loss 2.927782\n",
      "Epoch 3589, Loss 2.927782\n",
      "    Params:  tensor([  5.3608, -17.2655])\n",
      "    Grad  :  tensor([-0.0012,  0.0067])\n",
      "Epoch 3590,Loss 2.927781\n",
      "Epoch 3590, Loss 2.927781\n",
      "    Params:  tensor([  5.3608, -17.2656])\n",
      "    Grad  :  tensor([-0.0012,  0.0067])\n",
      "Epoch 3591,Loss 2.927781\n",
      "Epoch 3591, Loss 2.927781\n",
      "    Params:  tensor([  5.3608, -17.2657])\n",
      "    Grad  :  tensor([-0.0012,  0.0067])\n",
      "Epoch 3592,Loss 2.927779\n",
      "Epoch 3592, Loss 2.927779\n",
      "    Params:  tensor([  5.3608, -17.2657])\n",
      "    Grad  :  tensor([-0.0012,  0.0066])\n",
      "Epoch 3593,Loss 2.927779\n",
      "Epoch 3593, Loss 2.927779\n",
      "    Params:  tensor([  5.3608, -17.2658])\n",
      "    Grad  :  tensor([-0.0012,  0.0066])\n",
      "Epoch 3594,Loss 2.927779\n",
      "Epoch 3594, Loss 2.927779\n",
      "    Params:  tensor([  5.3608, -17.2659])\n",
      "    Grad  :  tensor([-0.0012,  0.0066])\n",
      "Epoch 3595,Loss 2.927780\n",
      "Epoch 3595, Loss 2.927780\n",
      "    Params:  tensor([  5.3609, -17.2659])\n",
      "    Grad  :  tensor([-0.0012,  0.0066])\n",
      "Epoch 3596,Loss 2.927779\n",
      "Epoch 3596, Loss 2.927779\n",
      "    Params:  tensor([  5.3609, -17.2660])\n",
      "    Grad  :  tensor([-0.0012,  0.0066])\n",
      "Epoch 3597,Loss 2.927778\n",
      "Epoch 3597, Loss 2.927778\n",
      "    Params:  tensor([  5.3609, -17.2661])\n",
      "    Grad  :  tensor([-0.0012,  0.0066])\n",
      "Epoch 3598,Loss 2.927778\n",
      "Epoch 3598, Loss 2.927778\n",
      "    Params:  tensor([  5.3609, -17.2661])\n",
      "    Grad  :  tensor([-0.0012,  0.0066])\n",
      "Epoch 3599,Loss 2.927776\n",
      "Epoch 3599, Loss 2.927776\n",
      "    Params:  tensor([  5.3609, -17.2662])\n",
      "    Grad  :  tensor([-0.0012,  0.0066])\n",
      "Epoch 3600,Loss 2.927777\n",
      "Epoch 3600, Loss 2.927777\n",
      "    Params:  tensor([  5.3609, -17.2663])\n",
      "    Grad  :  tensor([-0.0012,  0.0066])\n",
      "Epoch 3601,Loss 2.927775\n",
      "Epoch 3601, Loss 2.927775\n",
      "    Params:  tensor([  5.3609, -17.2663])\n",
      "    Grad  :  tensor([-0.0012,  0.0065])\n",
      "Epoch 3602,Loss 2.927776\n",
      "Epoch 3602, Loss 2.927776\n",
      "    Params:  tensor([  5.3609, -17.2664])\n",
      "    Grad  :  tensor([-0.0012,  0.0065])\n",
      "Epoch 3603,Loss 2.927774\n",
      "Epoch 3603, Loss 2.927774\n",
      "    Params:  tensor([  5.3609, -17.2665])\n",
      "    Grad  :  tensor([-0.0012,  0.0065])\n",
      "Epoch 3604,Loss 2.927774\n",
      "Epoch 3604, Loss 2.927774\n",
      "    Params:  tensor([  5.3610, -17.2665])\n",
      "    Grad  :  tensor([-0.0012,  0.0065])\n",
      "Epoch 3605,Loss 2.927774\n",
      "Epoch 3605, Loss 2.927774\n",
      "    Params:  tensor([  5.3610, -17.2666])\n",
      "    Grad  :  tensor([-0.0012,  0.0065])\n",
      "Epoch 3606,Loss 2.927773\n",
      "Epoch 3606, Loss 2.927773\n",
      "    Params:  tensor([  5.3610, -17.2667])\n",
      "    Grad  :  tensor([-0.0012,  0.0065])\n",
      "Epoch 3607,Loss 2.927774\n",
      "Epoch 3607, Loss 2.927774\n",
      "    Params:  tensor([  5.3610, -17.2667])\n",
      "    Grad  :  tensor([-0.0012,  0.0065])\n",
      "Epoch 3608,Loss 2.927773\n",
      "Epoch 3608, Loss 2.927773\n",
      "    Params:  tensor([  5.3610, -17.2668])\n",
      "    Grad  :  tensor([-0.0012,  0.0065])\n",
      "Epoch 3609,Loss 2.927773\n",
      "Epoch 3609, Loss 2.927773\n",
      "    Params:  tensor([  5.3610, -17.2668])\n",
      "    Grad  :  tensor([-0.0012,  0.0065])\n",
      "Epoch 3610,Loss 2.927773\n",
      "Epoch 3610, Loss 2.927773\n",
      "    Params:  tensor([  5.3610, -17.2669])\n",
      "    Grad  :  tensor([-0.0012,  0.0064])\n",
      "Epoch 3611,Loss 2.927773\n",
      "Epoch 3611, Loss 2.927773\n",
      "    Params:  tensor([  5.3610, -17.2670])\n",
      "    Grad  :  tensor([-0.0012,  0.0064])\n",
      "Epoch 3612,Loss 2.927772\n",
      "Epoch 3612, Loss 2.927772\n",
      "    Params:  tensor([  5.3611, -17.2670])\n",
      "    Grad  :  tensor([-0.0012,  0.0064])\n",
      "Epoch 3613,Loss 2.927769\n",
      "Epoch 3613, Loss 2.927769\n",
      "    Params:  tensor([  5.3611, -17.2671])\n",
      "    Grad  :  tensor([-0.0011,  0.0064])\n",
      "Epoch 3614,Loss 2.927770\n",
      "Epoch 3614, Loss 2.927770\n",
      "    Params:  tensor([  5.3611, -17.2672])\n",
      "    Grad  :  tensor([-0.0012,  0.0064])\n",
      "Epoch 3615,Loss 2.927770\n",
      "Epoch 3615, Loss 2.927770\n",
      "    Params:  tensor([  5.3611, -17.2672])\n",
      "    Grad  :  tensor([-0.0011,  0.0064])\n",
      "Epoch 3616,Loss 2.927771\n",
      "Epoch 3616, Loss 2.927771\n",
      "    Params:  tensor([  5.3611, -17.2673])\n",
      "    Grad  :  tensor([-0.0011,  0.0064])\n",
      "Epoch 3617,Loss 2.927769\n",
      "Epoch 3617, Loss 2.927769\n",
      "    Params:  tensor([  5.3611, -17.2674])\n",
      "    Grad  :  tensor([-0.0011,  0.0064])\n",
      "Epoch 3618,Loss 2.927769\n",
      "Epoch 3618, Loss 2.927769\n",
      "    Params:  tensor([  5.3611, -17.2674])\n",
      "    Grad  :  tensor([-0.0011,  0.0064])\n",
      "Epoch 3619,Loss 2.927769\n",
      "Epoch 3619, Loss 2.927769\n",
      "    Params:  tensor([  5.3611, -17.2675])\n",
      "    Grad  :  tensor([-0.0011,  0.0063])\n",
      "Epoch 3620,Loss 2.927768\n",
      "Epoch 3620, Loss 2.927768\n",
      "    Params:  tensor([  5.3611, -17.2676])\n",
      "    Grad  :  tensor([-0.0011,  0.0063])\n",
      "Epoch 3621,Loss 2.927768\n",
      "Epoch 3621, Loss 2.927768\n",
      "    Params:  tensor([  5.3612, -17.2676])\n",
      "    Grad  :  tensor([-0.0011,  0.0063])\n",
      "Epoch 3622,Loss 2.927766\n",
      "Epoch 3622, Loss 2.927766\n",
      "    Params:  tensor([  5.3612, -17.2677])\n",
      "    Grad  :  tensor([-0.0011,  0.0063])\n",
      "Epoch 3623,Loss 2.927767\n",
      "Epoch 3623, Loss 2.927767\n",
      "    Params:  tensor([  5.3612, -17.2677])\n",
      "    Grad  :  tensor([-0.0011,  0.0063])\n",
      "Epoch 3624,Loss 2.927767\n",
      "Epoch 3624, Loss 2.927767\n",
      "    Params:  tensor([  5.3612, -17.2678])\n",
      "    Grad  :  tensor([-0.0011,  0.0063])\n",
      "Epoch 3625,Loss 2.927766\n",
      "Epoch 3625, Loss 2.927766\n",
      "    Params:  tensor([  5.3612, -17.2679])\n",
      "    Grad  :  tensor([-0.0011,  0.0063])\n",
      "Epoch 3626,Loss 2.927767\n",
      "Epoch 3626, Loss 2.927767\n",
      "    Params:  tensor([  5.3612, -17.2679])\n",
      "    Grad  :  tensor([-0.0011,  0.0063])\n",
      "Epoch 3627,Loss 2.927766\n",
      "Epoch 3627, Loss 2.927766\n",
      "    Params:  tensor([  5.3612, -17.2680])\n",
      "    Grad  :  tensor([-0.0011,  0.0063])\n",
      "Epoch 3628,Loss 2.927765\n",
      "Epoch 3628, Loss 2.927765\n",
      "    Params:  tensor([  5.3612, -17.2681])\n",
      "    Grad  :  tensor([-0.0011,  0.0063])\n",
      "Epoch 3629,Loss 2.927763\n",
      "Epoch 3629, Loss 2.927763\n",
      "    Params:  tensor([  5.3612, -17.2681])\n",
      "    Grad  :  tensor([-0.0011,  0.0062])\n",
      "Epoch 3630,Loss 2.927765\n",
      "Epoch 3630, Loss 2.927765\n",
      "    Params:  tensor([  5.3613, -17.2682])\n",
      "    Grad  :  tensor([-0.0011,  0.0062])\n",
      "Epoch 3631,Loss 2.927762\n",
      "Epoch 3631, Loss 2.927762\n",
      "    Params:  tensor([  5.3613, -17.2682])\n",
      "    Grad  :  tensor([-0.0011,  0.0062])\n",
      "Epoch 3632,Loss 2.927763\n",
      "Epoch 3632, Loss 2.927763\n",
      "    Params:  tensor([  5.3613, -17.2683])\n",
      "    Grad  :  tensor([-0.0011,  0.0062])\n",
      "Epoch 3633,Loss 2.927763\n",
      "Epoch 3633, Loss 2.927763\n",
      "    Params:  tensor([  5.3613, -17.2684])\n",
      "    Grad  :  tensor([-0.0011,  0.0062])\n",
      "Epoch 3634,Loss 2.927762\n",
      "Epoch 3634, Loss 2.927762\n",
      "    Params:  tensor([  5.3613, -17.2684])\n",
      "    Grad  :  tensor([-0.0011,  0.0062])\n",
      "Epoch 3635,Loss 2.927762\n",
      "Epoch 3635, Loss 2.927762\n",
      "    Params:  tensor([  5.3613, -17.2685])\n",
      "    Grad  :  tensor([-0.0011,  0.0062])\n",
      "Epoch 3636,Loss 2.927763\n",
      "Epoch 3636, Loss 2.927763\n",
      "    Params:  tensor([  5.3613, -17.2686])\n",
      "    Grad  :  tensor([-0.0011,  0.0062])\n",
      "Epoch 3637,Loss 2.927760\n",
      "Epoch 3637, Loss 2.927760\n",
      "    Params:  tensor([  5.3613, -17.2686])\n",
      "    Grad  :  tensor([-0.0011,  0.0062])\n",
      "Epoch 3638,Loss 2.927762\n",
      "Epoch 3638, Loss 2.927762\n",
      "    Params:  tensor([  5.3613, -17.2687])\n",
      "    Grad  :  tensor([-0.0011,  0.0061])\n",
      "Epoch 3639,Loss 2.927761\n",
      "Epoch 3639, Loss 2.927761\n",
      "    Params:  tensor([  5.3614, -17.2687])\n",
      "    Grad  :  tensor([-0.0011,  0.0061])\n",
      "Epoch 3640,Loss 2.927761\n",
      "Epoch 3640, Loss 2.927761\n",
      "    Params:  tensor([  5.3614, -17.2688])\n",
      "    Grad  :  tensor([-0.0011,  0.0061])\n",
      "Epoch 3641,Loss 2.927759\n",
      "Epoch 3641, Loss 2.927759\n",
      "    Params:  tensor([  5.3614, -17.2689])\n",
      "    Grad  :  tensor([-0.0011,  0.0061])\n",
      "Epoch 3642,Loss 2.927760\n",
      "Epoch 3642, Loss 2.927760\n",
      "    Params:  tensor([  5.3614, -17.2689])\n",
      "    Grad  :  tensor([-0.0011,  0.0061])\n",
      "Epoch 3643,Loss 2.927760\n",
      "Epoch 3643, Loss 2.927760\n",
      "    Params:  tensor([  5.3614, -17.2690])\n",
      "    Grad  :  tensor([-0.0011,  0.0061])\n",
      "Epoch 3644,Loss 2.927758\n",
      "Epoch 3644, Loss 2.927758\n",
      "    Params:  tensor([  5.3614, -17.2690])\n",
      "    Grad  :  tensor([-0.0011,  0.0061])\n",
      "Epoch 3645,Loss 2.927757\n",
      "Epoch 3645, Loss 2.927757\n",
      "    Params:  tensor([  5.3614, -17.2691])\n",
      "    Grad  :  tensor([-0.0011,  0.0061])\n",
      "Epoch 3646,Loss 2.927759\n",
      "Epoch 3646, Loss 2.927759\n",
      "    Params:  tensor([  5.3614, -17.2692])\n",
      "    Grad  :  tensor([-0.0011,  0.0061])\n",
      "Epoch 3647,Loss 2.927758\n",
      "Epoch 3647, Loss 2.927758\n",
      "    Params:  tensor([  5.3614, -17.2692])\n",
      "    Grad  :  tensor([-0.0011,  0.0061])\n",
      "Epoch 3648,Loss 2.927757\n",
      "Epoch 3648, Loss 2.927757\n",
      "    Params:  tensor([  5.3614, -17.2693])\n",
      "    Grad  :  tensor([-0.0011,  0.0060])\n",
      "Epoch 3649,Loss 2.927756\n",
      "Epoch 3649, Loss 2.927756\n",
      "    Params:  tensor([  5.3615, -17.2693])\n",
      "    Grad  :  tensor([-0.0011,  0.0060])\n",
      "Epoch 3650,Loss 2.927757\n",
      "Epoch 3650, Loss 2.927757\n",
      "    Params:  tensor([  5.3615, -17.2694])\n",
      "    Grad  :  tensor([-0.0011,  0.0060])\n",
      "Epoch 3651,Loss 2.927756\n",
      "Epoch 3651, Loss 2.927756\n",
      "    Params:  tensor([  5.3615, -17.2695])\n",
      "    Grad  :  tensor([-0.0011,  0.0060])\n",
      "Epoch 3652,Loss 2.927754\n",
      "Epoch 3652, Loss 2.927754\n",
      "    Params:  tensor([  5.3615, -17.2695])\n",
      "    Grad  :  tensor([-0.0011,  0.0060])\n",
      "Epoch 3653,Loss 2.927754\n",
      "Epoch 3653, Loss 2.927754\n",
      "    Params:  tensor([  5.3615, -17.2696])\n",
      "    Grad  :  tensor([-0.0011,  0.0060])\n",
      "Epoch 3654,Loss 2.927756\n",
      "Epoch 3654, Loss 2.927756\n",
      "    Params:  tensor([  5.3615, -17.2696])\n",
      "    Grad  :  tensor([-0.0010,  0.0060])\n",
      "Epoch 3655,Loss 2.927754\n",
      "Epoch 3655, Loss 2.927754\n",
      "    Params:  tensor([  5.3615, -17.2697])\n",
      "    Grad  :  tensor([-0.0011,  0.0060])\n",
      "Epoch 3656,Loss 2.927753\n",
      "Epoch 3656, Loss 2.927753\n",
      "    Params:  tensor([  5.3615, -17.2698])\n",
      "    Grad  :  tensor([-0.0010,  0.0060])\n",
      "Epoch 3657,Loss 2.927752\n",
      "Epoch 3657, Loss 2.927752\n",
      "    Params:  tensor([  5.3615, -17.2698])\n",
      "    Grad  :  tensor([-0.0010,  0.0060])\n",
      "Epoch 3658,Loss 2.927752\n",
      "Epoch 3658, Loss 2.927752\n",
      "    Params:  tensor([  5.3616, -17.2699])\n",
      "    Grad  :  tensor([-0.0010,  0.0059])\n",
      "Epoch 3659,Loss 2.927753\n",
      "Epoch 3659, Loss 2.927753\n",
      "    Params:  tensor([  5.3616, -17.2699])\n",
      "    Grad  :  tensor([-0.0010,  0.0059])\n",
      "Epoch 3660,Loss 2.927752\n",
      "Epoch 3660, Loss 2.927752\n",
      "    Params:  tensor([  5.3616, -17.2700])\n",
      "    Grad  :  tensor([-0.0010,  0.0059])\n",
      "Epoch 3661,Loss 2.927752\n",
      "Epoch 3661, Loss 2.927752\n",
      "    Params:  tensor([  5.3616, -17.2701])\n",
      "    Grad  :  tensor([-0.0010,  0.0059])\n",
      "Epoch 3662,Loss 2.927752\n",
      "Epoch 3662, Loss 2.927752\n",
      "    Params:  tensor([  5.3616, -17.2701])\n",
      "    Grad  :  tensor([-0.0010,  0.0059])\n",
      "Epoch 3663,Loss 2.927751\n",
      "Epoch 3663, Loss 2.927751\n",
      "    Params:  tensor([  5.3616, -17.2702])\n",
      "    Grad  :  tensor([-0.0010,  0.0059])\n",
      "Epoch 3664,Loss 2.927751\n",
      "Epoch 3664, Loss 2.927751\n",
      "    Params:  tensor([  5.3616, -17.2702])\n",
      "    Grad  :  tensor([-0.0010,  0.0059])\n",
      "Epoch 3665,Loss 2.927749\n",
      "Epoch 3665, Loss 2.927749\n",
      "    Params:  tensor([  5.3616, -17.2703])\n",
      "    Grad  :  tensor([-0.0010,  0.0059])\n",
      "Epoch 3666,Loss 2.927750\n",
      "Epoch 3666, Loss 2.927750\n",
      "    Params:  tensor([  5.3616, -17.2704])\n",
      "    Grad  :  tensor([-0.0010,  0.0059])\n",
      "Epoch 3667,Loss 2.927750\n",
      "Epoch 3667, Loss 2.927750\n",
      "    Params:  tensor([  5.3616, -17.2704])\n",
      "    Grad  :  tensor([-0.0010,  0.0059])\n",
      "Epoch 3668,Loss 2.927750\n",
      "Epoch 3668, Loss 2.927750\n",
      "    Params:  tensor([  5.3617, -17.2705])\n",
      "    Grad  :  tensor([-0.0010,  0.0058])\n",
      "Epoch 3669,Loss 2.927749\n",
      "Epoch 3669, Loss 2.927749\n",
      "    Params:  tensor([  5.3617, -17.2705])\n",
      "    Grad  :  tensor([-0.0010,  0.0058])\n",
      "Epoch 3670,Loss 2.927749\n",
      "Epoch 3670, Loss 2.927749\n",
      "    Params:  tensor([  5.3617, -17.2706])\n",
      "    Grad  :  tensor([-0.0010,  0.0058])\n",
      "Epoch 3671,Loss 2.927749\n",
      "Epoch 3671, Loss 2.927749\n",
      "    Params:  tensor([  5.3617, -17.2706])\n",
      "    Grad  :  tensor([-0.0010,  0.0058])\n",
      "Epoch 3672,Loss 2.927748\n",
      "Epoch 3672, Loss 2.927748\n",
      "    Params:  tensor([  5.3617, -17.2707])\n",
      "    Grad  :  tensor([-0.0010,  0.0058])\n",
      "Epoch 3673,Loss 2.927748\n",
      "Epoch 3673, Loss 2.927748\n",
      "    Params:  tensor([  5.3617, -17.2708])\n",
      "    Grad  :  tensor([-0.0010,  0.0058])\n",
      "Epoch 3674,Loss 2.927748\n",
      "Epoch 3674, Loss 2.927748\n",
      "    Params:  tensor([  5.3617, -17.2708])\n",
      "    Grad  :  tensor([-0.0010,  0.0058])\n",
      "Epoch 3675,Loss 2.927747\n",
      "Epoch 3675, Loss 2.927747\n",
      "    Params:  tensor([  5.3617, -17.2709])\n",
      "    Grad  :  tensor([-0.0010,  0.0058])\n",
      "Epoch 3676,Loss 2.927747\n",
      "Epoch 3676, Loss 2.927747\n",
      "    Params:  tensor([  5.3617, -17.2709])\n",
      "    Grad  :  tensor([-0.0010,  0.0058])\n",
      "Epoch 3677,Loss 2.927746\n",
      "Epoch 3677, Loss 2.927746\n",
      "    Params:  tensor([  5.3617, -17.2710])\n",
      "    Grad  :  tensor([-0.0010,  0.0058])\n",
      "Epoch 3678,Loss 2.927746\n",
      "Epoch 3678, Loss 2.927746\n",
      "    Params:  tensor([  5.3618, -17.2710])\n",
      "    Grad  :  tensor([-0.0010,  0.0057])\n",
      "Epoch 3679,Loss 2.927745\n",
      "Epoch 3679, Loss 2.927745\n",
      "    Params:  tensor([  5.3618, -17.2711])\n",
      "    Grad  :  tensor([-0.0010,  0.0057])\n",
      "Epoch 3680,Loss 2.927747\n",
      "Epoch 3680, Loss 2.927747\n",
      "    Params:  tensor([  5.3618, -17.2712])\n",
      "    Grad  :  tensor([-0.0010,  0.0057])\n",
      "Epoch 3681,Loss 2.927743\n",
      "Epoch 3681, Loss 2.927743\n",
      "    Params:  tensor([  5.3618, -17.2712])\n",
      "    Grad  :  tensor([-0.0010,  0.0057])\n",
      "Epoch 3682,Loss 2.927744\n",
      "Epoch 3682, Loss 2.927744\n",
      "    Params:  tensor([  5.3618, -17.2713])\n",
      "    Grad  :  tensor([-0.0010,  0.0057])\n",
      "Epoch 3683,Loss 2.927743\n",
      "Epoch 3683, Loss 2.927743\n",
      "    Params:  tensor([  5.3618, -17.2713])\n",
      "    Grad  :  tensor([-0.0010,  0.0057])\n",
      "Epoch 3684,Loss 2.927744\n",
      "Epoch 3684, Loss 2.927744\n",
      "    Params:  tensor([  5.3618, -17.2714])\n",
      "    Grad  :  tensor([-0.0010,  0.0057])\n",
      "Epoch 3685,Loss 2.927744\n",
      "Epoch 3685, Loss 2.927744\n",
      "    Params:  tensor([  5.3618, -17.2714])\n",
      "    Grad  :  tensor([-0.0010,  0.0057])\n",
      "Epoch 3686,Loss 2.927743\n",
      "Epoch 3686, Loss 2.927743\n",
      "    Params:  tensor([  5.3618, -17.2715])\n",
      "    Grad  :  tensor([-0.0010,  0.0057])\n",
      "Epoch 3687,Loss 2.927743\n",
      "Epoch 3687, Loss 2.927743\n",
      "    Params:  tensor([  5.3618, -17.2716])\n",
      "    Grad  :  tensor([-0.0010,  0.0057])\n",
      "Epoch 3688,Loss 2.927743\n",
      "Epoch 3688, Loss 2.927743\n",
      "    Params:  tensor([  5.3619, -17.2716])\n",
      "    Grad  :  tensor([-0.0010,  0.0056])\n",
      "Epoch 3689,Loss 2.927742\n",
      "Epoch 3689, Loss 2.927742\n",
      "    Params:  tensor([  5.3619, -17.2717])\n",
      "    Grad  :  tensor([-0.0010,  0.0056])\n",
      "Epoch 3690,Loss 2.927743\n",
      "Epoch 3690, Loss 2.927743\n",
      "    Params:  tensor([  5.3619, -17.2717])\n",
      "    Grad  :  tensor([-0.0010,  0.0056])\n",
      "Epoch 3691,Loss 2.927742\n",
      "Epoch 3691, Loss 2.927742\n",
      "    Params:  tensor([  5.3619, -17.2718])\n",
      "    Grad  :  tensor([-0.0010,  0.0056])\n",
      "Epoch 3692,Loss 2.927742\n",
      "Epoch 3692, Loss 2.927742\n",
      "    Params:  tensor([  5.3619, -17.2718])\n",
      "    Grad  :  tensor([-0.0010,  0.0056])\n",
      "Epoch 3693,Loss 2.927739\n",
      "Epoch 3693, Loss 2.927739\n",
      "    Params:  tensor([  5.3619, -17.2719])\n",
      "    Grad  :  tensor([-0.0010,  0.0056])\n",
      "Epoch 3694,Loss 2.927741\n",
      "Epoch 3694, Loss 2.927741\n",
      "    Params:  tensor([  5.3619, -17.2720])\n",
      "    Grad  :  tensor([-0.0010,  0.0056])\n",
      "Epoch 3695,Loss 2.927740\n",
      "Epoch 3695, Loss 2.927740\n",
      "    Params:  tensor([  5.3619, -17.2720])\n",
      "    Grad  :  tensor([-0.0010,  0.0056])\n",
      "Epoch 3696,Loss 2.927742\n",
      "Epoch 3696, Loss 2.927742\n",
      "    Params:  tensor([  5.3619, -17.2721])\n",
      "    Grad  :  tensor([-0.0010,  0.0056])\n",
      "Epoch 3697,Loss 2.927740\n",
      "Epoch 3697, Loss 2.927740\n",
      "    Params:  tensor([  5.3619, -17.2721])\n",
      "    Grad  :  tensor([-0.0010,  0.0056])\n",
      "Epoch 3698,Loss 2.927740\n",
      "Epoch 3698, Loss 2.927740\n",
      "    Params:  tensor([  5.3620, -17.2722])\n",
      "    Grad  :  tensor([-0.0010,  0.0055])\n",
      "Epoch 3699,Loss 2.927737\n",
      "Epoch 3699, Loss 2.927737\n",
      "    Params:  tensor([  5.3620, -17.2722])\n",
      "    Grad  :  tensor([-0.0010,  0.0055])\n",
      "Epoch 3700,Loss 2.927738\n",
      "Epoch 3700, Loss 2.927738\n",
      "    Params:  tensor([  5.3620, -17.2723])\n",
      "    Grad  :  tensor([-0.0010,  0.0055])\n",
      "Epoch 3701,Loss 2.927740\n",
      "Epoch 3701, Loss 2.927740\n",
      "    Params:  tensor([  5.3620, -17.2723])\n",
      "    Grad  :  tensor([-0.0010,  0.0055])\n",
      "Epoch 3702,Loss 2.927738\n",
      "Epoch 3702, Loss 2.927738\n",
      "    Params:  tensor([  5.3620, -17.2724])\n",
      "    Grad  :  tensor([-0.0010,  0.0055])\n",
      "Epoch 3703,Loss 2.927737\n",
      "Epoch 3703, Loss 2.927737\n",
      "    Params:  tensor([  5.3620, -17.2725])\n",
      "    Grad  :  tensor([-0.0010,  0.0055])\n",
      "Epoch 3704,Loss 2.927738\n",
      "Epoch 3704, Loss 2.927738\n",
      "    Params:  tensor([  5.3620, -17.2725])\n",
      "    Grad  :  tensor([-0.0010,  0.0055])\n",
      "Epoch 3705,Loss 2.927737\n",
      "Epoch 3705, Loss 2.927737\n",
      "    Params:  tensor([  5.3620, -17.2726])\n",
      "    Grad  :  tensor([-0.0010,  0.0055])\n",
      "Epoch 3706,Loss 2.927737\n",
      "Epoch 3706, Loss 2.927737\n",
      "    Params:  tensor([  5.3620, -17.2726])\n",
      "    Grad  :  tensor([-0.0010,  0.0055])\n",
      "Epoch 3707,Loss 2.927736\n",
      "Epoch 3707, Loss 2.927736\n",
      "    Params:  tensor([  5.3620, -17.2727])\n",
      "    Grad  :  tensor([-0.0010,  0.0055])\n",
      "Epoch 3708,Loss 2.927735\n",
      "Epoch 3708, Loss 2.927735\n",
      "    Params:  tensor([  5.3621, -17.2727])\n",
      "    Grad  :  tensor([-0.0010,  0.0055])\n",
      "Epoch 3709,Loss 2.927735\n",
      "Epoch 3709, Loss 2.927735\n",
      "    Params:  tensor([  5.3621, -17.2728])\n",
      "    Grad  :  tensor([-0.0010,  0.0054])\n",
      "Epoch 3710,Loss 2.927734\n",
      "Epoch 3710, Loss 2.927734\n",
      "    Params:  tensor([  5.3621, -17.2728])\n",
      "    Grad  :  tensor([-0.0010,  0.0054])\n",
      "Epoch 3711,Loss 2.927734\n",
      "Epoch 3711, Loss 2.927734\n",
      "    Params:  tensor([  5.3621, -17.2729])\n",
      "    Grad  :  tensor([-0.0009,  0.0054])\n",
      "Epoch 3712,Loss 2.927734\n",
      "Epoch 3712, Loss 2.927734\n",
      "    Params:  tensor([  5.3621, -17.2729])\n",
      "    Grad  :  tensor([-0.0009,  0.0054])\n",
      "Epoch 3713,Loss 2.927735\n",
      "Epoch 3713, Loss 2.927735\n",
      "    Params:  tensor([  5.3621, -17.2730])\n",
      "    Grad  :  tensor([-0.0009,  0.0054])\n",
      "Epoch 3714,Loss 2.927734\n",
      "Epoch 3714, Loss 2.927734\n",
      "    Params:  tensor([  5.3621, -17.2731])\n",
      "    Grad  :  tensor([-0.0010,  0.0054])\n",
      "Epoch 3715,Loss 2.927734\n",
      "Epoch 3715, Loss 2.927734\n",
      "    Params:  tensor([  5.3621, -17.2731])\n",
      "    Grad  :  tensor([-0.0010,  0.0054])\n",
      "Epoch 3716,Loss 2.927734\n",
      "Epoch 3716, Loss 2.927734\n",
      "    Params:  tensor([  5.3621, -17.2732])\n",
      "    Grad  :  tensor([-0.0009,  0.0054])\n",
      "Epoch 3717,Loss 2.927735\n",
      "Epoch 3717, Loss 2.927735\n",
      "    Params:  tensor([  5.3621, -17.2732])\n",
      "    Grad  :  tensor([-0.0009,  0.0054])\n",
      "Epoch 3718,Loss 2.927734\n",
      "Epoch 3718, Loss 2.927734\n",
      "    Params:  tensor([  5.3622, -17.2733])\n",
      "    Grad  :  tensor([-0.0009,  0.0054])\n",
      "Epoch 3719,Loss 2.927735\n",
      "Epoch 3719, Loss 2.927735\n",
      "    Params:  tensor([  5.3622, -17.2733])\n",
      "    Grad  :  tensor([-0.0009,  0.0054])\n",
      "Epoch 3720,Loss 2.927733\n",
      "Epoch 3720, Loss 2.927733\n",
      "    Params:  tensor([  5.3622, -17.2734])\n",
      "    Grad  :  tensor([-0.0009,  0.0053])\n",
      "Epoch 3721,Loss 2.927733\n",
      "Epoch 3721, Loss 2.927733\n",
      "    Params:  tensor([  5.3622, -17.2734])\n",
      "    Grad  :  tensor([-0.0009,  0.0053])\n",
      "Epoch 3722,Loss 2.927732\n",
      "Epoch 3722, Loss 2.927732\n",
      "    Params:  tensor([  5.3622, -17.2735])\n",
      "    Grad  :  tensor([-0.0009,  0.0053])\n",
      "Epoch 3723,Loss 2.927732\n",
      "Epoch 3723, Loss 2.927732\n",
      "    Params:  tensor([  5.3622, -17.2735])\n",
      "    Grad  :  tensor([-0.0009,  0.0053])\n",
      "Epoch 3724,Loss 2.927732\n",
      "Epoch 3724, Loss 2.927732\n",
      "    Params:  tensor([  5.3622, -17.2736])\n",
      "    Grad  :  tensor([-0.0009,  0.0053])\n",
      "Epoch 3725,Loss 2.927732\n",
      "Epoch 3725, Loss 2.927732\n",
      "    Params:  tensor([  5.3622, -17.2736])\n",
      "    Grad  :  tensor([-0.0009,  0.0053])\n",
      "Epoch 3726,Loss 2.927731\n",
      "Epoch 3726, Loss 2.927731\n",
      "    Params:  tensor([  5.3622, -17.2737])\n",
      "    Grad  :  tensor([-0.0009,  0.0053])\n",
      "Epoch 3727,Loss 2.927731\n",
      "Epoch 3727, Loss 2.927731\n",
      "    Params:  tensor([  5.3622, -17.2737])\n",
      "    Grad  :  tensor([-0.0009,  0.0053])\n",
      "Epoch 3728,Loss 2.927730\n",
      "Epoch 3728, Loss 2.927730\n",
      "    Params:  tensor([  5.3622, -17.2738])\n",
      "    Grad  :  tensor([-0.0009,  0.0053])\n",
      "Epoch 3729,Loss 2.927730\n",
      "Epoch 3729, Loss 2.927730\n",
      "    Params:  tensor([  5.3623, -17.2739])\n",
      "    Grad  :  tensor([-0.0010,  0.0053])\n",
      "Epoch 3730,Loss 2.927729\n",
      "Epoch 3730, Loss 2.927729\n",
      "    Params:  tensor([  5.3623, -17.2739])\n",
      "    Grad  :  tensor([-0.0009,  0.0053])\n",
      "Epoch 3731,Loss 2.927731\n",
      "Epoch 3731, Loss 2.927731\n",
      "    Params:  tensor([  5.3623, -17.2740])\n",
      "    Grad  :  tensor([-0.0009,  0.0052])\n",
      "Epoch 3732,Loss 2.927731\n",
      "Epoch 3732, Loss 2.927731\n",
      "    Params:  tensor([  5.3623, -17.2740])\n",
      "    Grad  :  tensor([-0.0009,  0.0052])\n",
      "Epoch 3733,Loss 2.927729\n",
      "Epoch 3733, Loss 2.927729\n",
      "    Params:  tensor([  5.3623, -17.2741])\n",
      "    Grad  :  tensor([-0.0009,  0.0052])\n",
      "Epoch 3734,Loss 2.927729\n",
      "Epoch 3734, Loss 2.927729\n",
      "    Params:  tensor([  5.3623, -17.2741])\n",
      "    Grad  :  tensor([-0.0009,  0.0052])\n",
      "Epoch 3735,Loss 2.927729\n",
      "Epoch 3735, Loss 2.927729\n",
      "    Params:  tensor([  5.3623, -17.2742])\n",
      "    Grad  :  tensor([-0.0009,  0.0052])\n",
      "Epoch 3736,Loss 2.927728\n",
      "Epoch 3736, Loss 2.927728\n",
      "    Params:  tensor([  5.3623, -17.2742])\n",
      "    Grad  :  tensor([-0.0009,  0.0052])\n",
      "Epoch 3737,Loss 2.927727\n",
      "Epoch 3737, Loss 2.927727\n",
      "    Params:  tensor([  5.3623, -17.2743])\n",
      "    Grad  :  tensor([-0.0009,  0.0052])\n",
      "Epoch 3738,Loss 2.927728\n",
      "Epoch 3738, Loss 2.927728\n",
      "    Params:  tensor([  5.3623, -17.2743])\n",
      "    Grad  :  tensor([-0.0009,  0.0052])\n",
      "Epoch 3739,Loss 2.927728\n",
      "Epoch 3739, Loss 2.927728\n",
      "    Params:  tensor([  5.3623, -17.2744])\n",
      "    Grad  :  tensor([-0.0009,  0.0052])\n",
      "Epoch 3740,Loss 2.927727\n",
      "Epoch 3740, Loss 2.927727\n",
      "    Params:  tensor([  5.3624, -17.2744])\n",
      "    Grad  :  tensor([-0.0009,  0.0052])\n",
      "Epoch 3741,Loss 2.927727\n",
      "Epoch 3741, Loss 2.927727\n",
      "    Params:  tensor([  5.3624, -17.2745])\n",
      "    Grad  :  tensor([-0.0009,  0.0052])\n",
      "Epoch 3742,Loss 2.927727\n",
      "Epoch 3742, Loss 2.927727\n",
      "    Params:  tensor([  5.3624, -17.2745])\n",
      "    Grad  :  tensor([-0.0009,  0.0051])\n",
      "Epoch 3743,Loss 2.927727\n",
      "Epoch 3743, Loss 2.927727\n",
      "    Params:  tensor([  5.3624, -17.2746])\n",
      "    Grad  :  tensor([-0.0009,  0.0051])\n",
      "Epoch 3744,Loss 2.927727\n",
      "Epoch 3744, Loss 2.927727\n",
      "    Params:  tensor([  5.3624, -17.2746])\n",
      "    Grad  :  tensor([-0.0009,  0.0051])\n",
      "Epoch 3745,Loss 2.927725\n",
      "Epoch 3745, Loss 2.927725\n",
      "    Params:  tensor([  5.3624, -17.2747])\n",
      "    Grad  :  tensor([-0.0009,  0.0051])\n",
      "Epoch 3746,Loss 2.927724\n",
      "Epoch 3746, Loss 2.927724\n",
      "    Params:  tensor([  5.3624, -17.2747])\n",
      "    Grad  :  tensor([-0.0009,  0.0051])\n",
      "Epoch 3747,Loss 2.927726\n",
      "Epoch 3747, Loss 2.927726\n",
      "    Params:  tensor([  5.3624, -17.2748])\n",
      "    Grad  :  tensor([-0.0009,  0.0051])\n",
      "Epoch 3748,Loss 2.927725\n",
      "Epoch 3748, Loss 2.927725\n",
      "    Params:  tensor([  5.3624, -17.2748])\n",
      "    Grad  :  tensor([-0.0009,  0.0051])\n",
      "Epoch 3749,Loss 2.927723\n",
      "Epoch 3749, Loss 2.927723\n",
      "    Params:  tensor([  5.3624, -17.2749])\n",
      "    Grad  :  tensor([-0.0009,  0.0051])\n",
      "Epoch 3750,Loss 2.927724\n",
      "Epoch 3750, Loss 2.927724\n",
      "    Params:  tensor([  5.3624, -17.2749])\n",
      "    Grad  :  tensor([-0.0009,  0.0051])\n",
      "Epoch 3751,Loss 2.927724\n",
      "Epoch 3751, Loss 2.927724\n",
      "    Params:  tensor([  5.3625, -17.2750])\n",
      "    Grad  :  tensor([-0.0009,  0.0051])\n",
      "Epoch 3752,Loss 2.927725\n",
      "Epoch 3752, Loss 2.927725\n",
      "    Params:  tensor([  5.3625, -17.2750])\n",
      "    Grad  :  tensor([-0.0009,  0.0051])\n",
      "Epoch 3753,Loss 2.927724\n",
      "Epoch 3753, Loss 2.927724\n",
      "    Params:  tensor([  5.3625, -17.2751])\n",
      "    Grad  :  tensor([-0.0009,  0.0050])\n",
      "Epoch 3754,Loss 2.927724\n",
      "Epoch 3754, Loss 2.927724\n",
      "    Params:  tensor([  5.3625, -17.2751])\n",
      "    Grad  :  tensor([-0.0009,  0.0050])\n",
      "Epoch 3755,Loss 2.927723\n",
      "Epoch 3755, Loss 2.927723\n",
      "    Params:  tensor([  5.3625, -17.2752])\n",
      "    Grad  :  tensor([-0.0009,  0.0050])\n",
      "Epoch 3756,Loss 2.927723\n",
      "Epoch 3756, Loss 2.927723\n",
      "    Params:  tensor([  5.3625, -17.2752])\n",
      "    Grad  :  tensor([-0.0009,  0.0050])\n",
      "Epoch 3757,Loss 2.927721\n",
      "Epoch 3757, Loss 2.927721\n",
      "    Params:  tensor([  5.3625, -17.2753])\n",
      "    Grad  :  tensor([-0.0009,  0.0050])\n",
      "Epoch 3758,Loss 2.927723\n",
      "Epoch 3758, Loss 2.927723\n",
      "    Params:  tensor([  5.3625, -17.2753])\n",
      "    Grad  :  tensor([-0.0009,  0.0050])\n",
      "Epoch 3759,Loss 2.927723\n",
      "Epoch 3759, Loss 2.927723\n",
      "    Params:  tensor([  5.3625, -17.2754])\n",
      "    Grad  :  tensor([-0.0009,  0.0050])\n",
      "Epoch 3760,Loss 2.927721\n",
      "Epoch 3760, Loss 2.927721\n",
      "    Params:  tensor([  5.3625, -17.2754])\n",
      "    Grad  :  tensor([-0.0009,  0.0050])\n",
      "Epoch 3761,Loss 2.927723\n",
      "Epoch 3761, Loss 2.927723\n",
      "    Params:  tensor([  5.3625, -17.2755])\n",
      "    Grad  :  tensor([-0.0009,  0.0050])\n",
      "Epoch 3762,Loss 2.927721\n",
      "Epoch 3762, Loss 2.927721\n",
      "    Params:  tensor([  5.3626, -17.2755])\n",
      "    Grad  :  tensor([-0.0009,  0.0050])\n",
      "Epoch 3763,Loss 2.927721\n",
      "Epoch 3763, Loss 2.927721\n",
      "    Params:  tensor([  5.3626, -17.2756])\n",
      "    Grad  :  tensor([-0.0009,  0.0050])\n",
      "Epoch 3764,Loss 2.927721\n",
      "Epoch 3764, Loss 2.927721\n",
      "    Params:  tensor([  5.3626, -17.2756])\n",
      "    Grad  :  tensor([-0.0009,  0.0050])\n",
      "Epoch 3765,Loss 2.927720\n",
      "Epoch 3765, Loss 2.927720\n",
      "    Params:  tensor([  5.3626, -17.2757])\n",
      "    Grad  :  tensor([-0.0009,  0.0050])\n",
      "Epoch 3766,Loss 2.927719\n",
      "Epoch 3766, Loss 2.927719\n",
      "    Params:  tensor([  5.3626, -17.2757])\n",
      "    Grad  :  tensor([-0.0009,  0.0049])\n",
      "Epoch 3767,Loss 2.927721\n",
      "Epoch 3767, Loss 2.927721\n",
      "    Params:  tensor([  5.3626, -17.2758])\n",
      "    Grad  :  tensor([-0.0009,  0.0049])\n",
      "Epoch 3768,Loss 2.927719\n",
      "Epoch 3768, Loss 2.927719\n",
      "    Params:  tensor([  5.3626, -17.2758])\n",
      "    Grad  :  tensor([-0.0009,  0.0049])\n",
      "Epoch 3769,Loss 2.927720\n",
      "Epoch 3769, Loss 2.927720\n",
      "    Params:  tensor([  5.3626, -17.2759])\n",
      "    Grad  :  tensor([-0.0009,  0.0049])\n",
      "Epoch 3770,Loss 2.927719\n",
      "Epoch 3770, Loss 2.927719\n",
      "    Params:  tensor([  5.3626, -17.2759])\n",
      "    Grad  :  tensor([-0.0009,  0.0049])\n",
      "Epoch 3771,Loss 2.927719\n",
      "Epoch 3771, Loss 2.927719\n",
      "    Params:  tensor([  5.3626, -17.2760])\n",
      "    Grad  :  tensor([-0.0009,  0.0049])\n",
      "Epoch 3772,Loss 2.927719\n",
      "Epoch 3772, Loss 2.927719\n",
      "    Params:  tensor([  5.3626, -17.2760])\n",
      "    Grad  :  tensor([-0.0009,  0.0049])\n",
      "Epoch 3773,Loss 2.927719\n",
      "Epoch 3773, Loss 2.927719\n",
      "    Params:  tensor([  5.3626, -17.2761])\n",
      "    Grad  :  tensor([-0.0009,  0.0049])\n",
      "Epoch 3774,Loss 2.927717\n",
      "Epoch 3774, Loss 2.927717\n",
      "    Params:  tensor([  5.3627, -17.2761])\n",
      "    Grad  :  tensor([-0.0009,  0.0049])\n",
      "Epoch 3775,Loss 2.927718\n",
      "Epoch 3775, Loss 2.927718\n",
      "    Params:  tensor([  5.3627, -17.2762])\n",
      "    Grad  :  tensor([-0.0009,  0.0049])\n",
      "Epoch 3776,Loss 2.927717\n",
      "Epoch 3776, Loss 2.927717\n",
      "    Params:  tensor([  5.3627, -17.2762])\n",
      "    Grad  :  tensor([-0.0009,  0.0049])\n",
      "Epoch 3777,Loss 2.927718\n",
      "Epoch 3777, Loss 2.927718\n",
      "    Params:  tensor([  5.3627, -17.2763])\n",
      "    Grad  :  tensor([-0.0008,  0.0049])\n",
      "Epoch 3778,Loss 2.927717\n",
      "Epoch 3778, Loss 2.927717\n",
      "    Params:  tensor([  5.3627, -17.2763])\n",
      "    Grad  :  tensor([-0.0008,  0.0048])\n",
      "Epoch 3779,Loss 2.927717\n",
      "Epoch 3779, Loss 2.927717\n",
      "    Params:  tensor([  5.3627, -17.2764])\n",
      "    Grad  :  tensor([-0.0008,  0.0048])\n",
      "Epoch 3780,Loss 2.927716\n",
      "Epoch 3780, Loss 2.927716\n",
      "    Params:  tensor([  5.3627, -17.2764])\n",
      "    Grad  :  tensor([-0.0008,  0.0048])\n",
      "Epoch 3781,Loss 2.927716\n",
      "Epoch 3781, Loss 2.927716\n",
      "    Params:  tensor([  5.3627, -17.2765])\n",
      "    Grad  :  tensor([-0.0008,  0.0048])\n",
      "Epoch 3782,Loss 2.927717\n",
      "Epoch 3782, Loss 2.927717\n",
      "    Params:  tensor([  5.3627, -17.2765])\n",
      "    Grad  :  tensor([-0.0008,  0.0048])\n",
      "Epoch 3783,Loss 2.927717\n",
      "Epoch 3783, Loss 2.927717\n",
      "    Params:  tensor([  5.3627, -17.2766])\n",
      "    Grad  :  tensor([-0.0008,  0.0048])\n",
      "Epoch 3784,Loss 2.927716\n",
      "Epoch 3784, Loss 2.927716\n",
      "    Params:  tensor([  5.3627, -17.2766])\n",
      "    Grad  :  tensor([-0.0009,  0.0048])\n",
      "Epoch 3785,Loss 2.927715\n",
      "Epoch 3785, Loss 2.927715\n",
      "    Params:  tensor([  5.3627, -17.2767])\n",
      "    Grad  :  tensor([-0.0008,  0.0048])\n",
      "Epoch 3786,Loss 2.927715\n",
      "Epoch 3786, Loss 2.927715\n",
      "    Params:  tensor([  5.3628, -17.2767])\n",
      "    Grad  :  tensor([-0.0008,  0.0048])\n",
      "Epoch 3787,Loss 2.927715\n",
      "Epoch 3787, Loss 2.927715\n",
      "    Params:  tensor([  5.3628, -17.2767])\n",
      "    Grad  :  tensor([-0.0008,  0.0048])\n",
      "Epoch 3788,Loss 2.927715\n",
      "Epoch 3788, Loss 2.927715\n",
      "    Params:  tensor([  5.3628, -17.2768])\n",
      "    Grad  :  tensor([-0.0008,  0.0048])\n",
      "Epoch 3789,Loss 2.927715\n",
      "Epoch 3789, Loss 2.927715\n",
      "    Params:  tensor([  5.3628, -17.2768])\n",
      "    Grad  :  tensor([-0.0008,  0.0048])\n",
      "Epoch 3790,Loss 2.927715\n",
      "Epoch 3790, Loss 2.927715\n",
      "    Params:  tensor([  5.3628, -17.2769])\n",
      "    Grad  :  tensor([-0.0008,  0.0047])\n",
      "Epoch 3791,Loss 2.927714\n",
      "Epoch 3791, Loss 2.927714\n",
      "    Params:  tensor([  5.3628, -17.2769])\n",
      "    Grad  :  tensor([-0.0008,  0.0047])\n",
      "Epoch 3792,Loss 2.927714\n",
      "Epoch 3792, Loss 2.927714\n",
      "    Params:  tensor([  5.3628, -17.2770])\n",
      "    Grad  :  tensor([-0.0008,  0.0047])\n",
      "Epoch 3793,Loss 2.927714\n",
      "Epoch 3793, Loss 2.927714\n",
      "    Params:  tensor([  5.3628, -17.2770])\n",
      "    Grad  :  tensor([-0.0008,  0.0047])\n",
      "Epoch 3794,Loss 2.927714\n",
      "Epoch 3794, Loss 2.927714\n",
      "    Params:  tensor([  5.3628, -17.2771])\n",
      "    Grad  :  tensor([-0.0008,  0.0047])\n",
      "Epoch 3795,Loss 2.927713\n",
      "Epoch 3795, Loss 2.927713\n",
      "    Params:  tensor([  5.3628, -17.2771])\n",
      "    Grad  :  tensor([-0.0008,  0.0047])\n",
      "Epoch 3796,Loss 2.927714\n",
      "Epoch 3796, Loss 2.927714\n",
      "    Params:  tensor([  5.3628, -17.2772])\n",
      "    Grad  :  tensor([-0.0008,  0.0047])\n",
      "Epoch 3797,Loss 2.927713\n",
      "Epoch 3797, Loss 2.927713\n",
      "    Params:  tensor([  5.3629, -17.2772])\n",
      "    Grad  :  tensor([-0.0008,  0.0047])\n",
      "Epoch 3798,Loss 2.927712\n",
      "Epoch 3798, Loss 2.927712\n",
      "    Params:  tensor([  5.3629, -17.2773])\n",
      "    Grad  :  tensor([-0.0008,  0.0047])\n",
      "Epoch 3799,Loss 2.927712\n",
      "Epoch 3799, Loss 2.927712\n",
      "    Params:  tensor([  5.3629, -17.2773])\n",
      "    Grad  :  tensor([-0.0008,  0.0047])\n",
      "Epoch 3800,Loss 2.927713\n",
      "Epoch 3800, Loss 2.927713\n",
      "    Params:  tensor([  5.3629, -17.2774])\n",
      "    Grad  :  tensor([-0.0008,  0.0047])\n",
      "Epoch 3801,Loss 2.927711\n",
      "Epoch 3801, Loss 2.927711\n",
      "    Params:  tensor([  5.3629, -17.2774])\n",
      "    Grad  :  tensor([-0.0008,  0.0047])\n",
      "Epoch 3802,Loss 2.927712\n",
      "Epoch 3802, Loss 2.927712\n",
      "    Params:  tensor([  5.3629, -17.2775])\n",
      "    Grad  :  tensor([-0.0008,  0.0047])\n",
      "Epoch 3803,Loss 2.927712\n",
      "Epoch 3803, Loss 2.927712\n",
      "    Params:  tensor([  5.3629, -17.2775])\n",
      "    Grad  :  tensor([-0.0008,  0.0046])\n",
      "Epoch 3804,Loss 2.927711\n",
      "Epoch 3804, Loss 2.927711\n",
      "    Params:  tensor([  5.3629, -17.2775])\n",
      "    Grad  :  tensor([-0.0008,  0.0046])\n",
      "Epoch 3805,Loss 2.927712\n",
      "Epoch 3805, Loss 2.927712\n",
      "    Params:  tensor([  5.3629, -17.2776])\n",
      "    Grad  :  tensor([-0.0008,  0.0046])\n",
      "Epoch 3806,Loss 2.927711\n",
      "Epoch 3806, Loss 2.927711\n",
      "    Params:  tensor([  5.3629, -17.2776])\n",
      "    Grad  :  tensor([-0.0008,  0.0046])\n",
      "Epoch 3807,Loss 2.927711\n",
      "Epoch 3807, Loss 2.927711\n",
      "    Params:  tensor([  5.3629, -17.2777])\n",
      "    Grad  :  tensor([-0.0008,  0.0046])\n",
      "Epoch 3808,Loss 2.927711\n",
      "Epoch 3808, Loss 2.927711\n",
      "    Params:  tensor([  5.3629, -17.2777])\n",
      "    Grad  :  tensor([-0.0008,  0.0046])\n",
      "Epoch 3809,Loss 2.927709\n",
      "Epoch 3809, Loss 2.927709\n",
      "    Params:  tensor([  5.3629, -17.2778])\n",
      "    Grad  :  tensor([-0.0008,  0.0046])\n",
      "Epoch 3810,Loss 2.927710\n",
      "Epoch 3810, Loss 2.927710\n",
      "    Params:  tensor([  5.3630, -17.2778])\n",
      "    Grad  :  tensor([-0.0008,  0.0046])\n",
      "Epoch 3811,Loss 2.927710\n",
      "Epoch 3811, Loss 2.927710\n",
      "    Params:  tensor([  5.3630, -17.2779])\n",
      "    Grad  :  tensor([-0.0008,  0.0046])\n",
      "Epoch 3812,Loss 2.927708\n",
      "Epoch 3812, Loss 2.927708\n",
      "    Params:  tensor([  5.3630, -17.2779])\n",
      "    Grad  :  tensor([-0.0008,  0.0046])\n",
      "Epoch 3813,Loss 2.927708\n",
      "Epoch 3813, Loss 2.927708\n",
      "    Params:  tensor([  5.3630, -17.2780])\n",
      "    Grad  :  tensor([-0.0008,  0.0046])\n",
      "Epoch 3814,Loss 2.927709\n",
      "Epoch 3814, Loss 2.927709\n",
      "    Params:  tensor([  5.3630, -17.2780])\n",
      "    Grad  :  tensor([-0.0008,  0.0046])\n",
      "Epoch 3815,Loss 2.927709\n",
      "Epoch 3815, Loss 2.927709\n",
      "    Params:  tensor([  5.3630, -17.2781])\n",
      "    Grad  :  tensor([-0.0008,  0.0045])\n",
      "Epoch 3816,Loss 2.927710\n",
      "Epoch 3816, Loss 2.927710\n",
      "    Params:  tensor([  5.3630, -17.2781])\n",
      "    Grad  :  tensor([-0.0008,  0.0045])\n",
      "Epoch 3817,Loss 2.927708\n",
      "Epoch 3817, Loss 2.927708\n",
      "    Params:  tensor([  5.3630, -17.2781])\n",
      "    Grad  :  tensor([-0.0008,  0.0045])\n",
      "Epoch 3818,Loss 2.927708\n",
      "Epoch 3818, Loss 2.927708\n",
      "    Params:  tensor([  5.3630, -17.2782])\n",
      "    Grad  :  tensor([-0.0008,  0.0045])\n",
      "Epoch 3819,Loss 2.927706\n",
      "Epoch 3819, Loss 2.927706\n",
      "    Params:  tensor([  5.3630, -17.2782])\n",
      "    Grad  :  tensor([-0.0008,  0.0045])\n",
      "Epoch 3820,Loss 2.927707\n",
      "Epoch 3820, Loss 2.927707\n",
      "    Params:  tensor([  5.3630, -17.2783])\n",
      "    Grad  :  tensor([-0.0008,  0.0045])\n",
      "Epoch 3821,Loss 2.927708\n",
      "Epoch 3821, Loss 2.927708\n",
      "    Params:  tensor([  5.3630, -17.2783])\n",
      "    Grad  :  tensor([-0.0008,  0.0045])\n",
      "Epoch 3822,Loss 2.927707\n",
      "Epoch 3822, Loss 2.927707\n",
      "    Params:  tensor([  5.3631, -17.2784])\n",
      "    Grad  :  tensor([-0.0008,  0.0045])\n",
      "Epoch 3823,Loss 2.927707\n",
      "Epoch 3823, Loss 2.927707\n",
      "    Params:  tensor([  5.3631, -17.2784])\n",
      "    Grad  :  tensor([-0.0008,  0.0045])\n",
      "Epoch 3824,Loss 2.927707\n",
      "Epoch 3824, Loss 2.927707\n",
      "    Params:  tensor([  5.3631, -17.2785])\n",
      "    Grad  :  tensor([-0.0008,  0.0045])\n",
      "Epoch 3825,Loss 2.927708\n",
      "Epoch 3825, Loss 2.927708\n",
      "    Params:  tensor([  5.3631, -17.2785])\n",
      "    Grad  :  tensor([-0.0008,  0.0045])\n",
      "Epoch 3826,Loss 2.927707\n",
      "Epoch 3826, Loss 2.927707\n",
      "    Params:  tensor([  5.3631, -17.2786])\n",
      "    Grad  :  tensor([-0.0008,  0.0045])\n",
      "Epoch 3827,Loss 2.927706\n",
      "Epoch 3827, Loss 2.927706\n",
      "    Params:  tensor([  5.3631, -17.2786])\n",
      "    Grad  :  tensor([-0.0008,  0.0045])\n",
      "Epoch 3828,Loss 2.927707\n",
      "Epoch 3828, Loss 2.927707\n",
      "    Params:  tensor([  5.3631, -17.2786])\n",
      "    Grad  :  tensor([-0.0008,  0.0044])\n",
      "Epoch 3829,Loss 2.927705\n",
      "Epoch 3829, Loss 2.927705\n",
      "    Params:  tensor([  5.3631, -17.2787])\n",
      "    Grad  :  tensor([-0.0008,  0.0044])\n",
      "Epoch 3830,Loss 2.927706\n",
      "Epoch 3830, Loss 2.927706\n",
      "    Params:  tensor([  5.3631, -17.2787])\n",
      "    Grad  :  tensor([-0.0008,  0.0044])\n",
      "Epoch 3831,Loss 2.927706\n",
      "Epoch 3831, Loss 2.927706\n",
      "    Params:  tensor([  5.3631, -17.2788])\n",
      "    Grad  :  tensor([-0.0008,  0.0044])\n",
      "Epoch 3832,Loss 2.927705\n",
      "Epoch 3832, Loss 2.927705\n",
      "    Params:  tensor([  5.3631, -17.2788])\n",
      "    Grad  :  tensor([-0.0008,  0.0044])\n",
      "Epoch 3833,Loss 2.927705\n",
      "Epoch 3833, Loss 2.927705\n",
      "    Params:  tensor([  5.3631, -17.2789])\n",
      "    Grad  :  tensor([-0.0008,  0.0044])\n",
      "Epoch 3834,Loss 2.927705\n",
      "Epoch 3834, Loss 2.927705\n",
      "    Params:  tensor([  5.3631, -17.2789])\n",
      "    Grad  :  tensor([-0.0008,  0.0044])\n",
      "Epoch 3835,Loss 2.927705\n",
      "Epoch 3835, Loss 2.927705\n",
      "    Params:  tensor([  5.3632, -17.2789])\n",
      "    Grad  :  tensor([-0.0008,  0.0044])\n",
      "Epoch 3836,Loss 2.927705\n",
      "Epoch 3836, Loss 2.927705\n",
      "    Params:  tensor([  5.3632, -17.2790])\n",
      "    Grad  :  tensor([-0.0008,  0.0044])\n",
      "Epoch 3837,Loss 2.927705\n",
      "Epoch 3837, Loss 2.927705\n",
      "    Params:  tensor([  5.3632, -17.2790])\n",
      "    Grad  :  tensor([-0.0008,  0.0044])\n",
      "Epoch 3838,Loss 2.927704\n",
      "Epoch 3838, Loss 2.927704\n",
      "    Params:  tensor([  5.3632, -17.2791])\n",
      "    Grad  :  tensor([-0.0008,  0.0044])\n",
      "Epoch 3839,Loss 2.927704\n",
      "Epoch 3839, Loss 2.927704\n",
      "    Params:  tensor([  5.3632, -17.2791])\n",
      "    Grad  :  tensor([-0.0008,  0.0044])\n",
      "Epoch 3840,Loss 2.927704\n",
      "Epoch 3840, Loss 2.927704\n",
      "    Params:  tensor([  5.3632, -17.2792])\n",
      "    Grad  :  tensor([-0.0008,  0.0044])\n",
      "Epoch 3841,Loss 2.927703\n",
      "Epoch 3841, Loss 2.927703\n",
      "    Params:  tensor([  5.3632, -17.2792])\n",
      "    Grad  :  tensor([-0.0008,  0.0044])\n",
      "Epoch 3842,Loss 2.927702\n",
      "Epoch 3842, Loss 2.927702\n",
      "    Params:  tensor([  5.3632, -17.2793])\n",
      "    Grad  :  tensor([-0.0008,  0.0043])\n",
      "Epoch 3843,Loss 2.927703\n",
      "Epoch 3843, Loss 2.927703\n",
      "    Params:  tensor([  5.3632, -17.2793])\n",
      "    Grad  :  tensor([-0.0008,  0.0043])\n",
      "Epoch 3844,Loss 2.927703\n",
      "Epoch 3844, Loss 2.927703\n",
      "    Params:  tensor([  5.3632, -17.2793])\n",
      "    Grad  :  tensor([-0.0008,  0.0043])\n",
      "Epoch 3845,Loss 2.927704\n",
      "Epoch 3845, Loss 2.927704\n",
      "    Params:  tensor([  5.3632, -17.2794])\n",
      "    Grad  :  tensor([-0.0008,  0.0043])\n",
      "Epoch 3846,Loss 2.927702\n",
      "Epoch 3846, Loss 2.927702\n",
      "    Params:  tensor([  5.3632, -17.2794])\n",
      "    Grad  :  tensor([-0.0008,  0.0043])\n",
      "Epoch 3847,Loss 2.927701\n",
      "Epoch 3847, Loss 2.927701\n",
      "    Params:  tensor([  5.3632, -17.2795])\n",
      "    Grad  :  tensor([-0.0008,  0.0043])\n",
      "Epoch 3848,Loss 2.927703\n",
      "Epoch 3848, Loss 2.927703\n",
      "    Params:  tensor([  5.3633, -17.2795])\n",
      "    Grad  :  tensor([-0.0008,  0.0043])\n",
      "Epoch 3849,Loss 2.927702\n",
      "Epoch 3849, Loss 2.927702\n",
      "    Params:  tensor([  5.3633, -17.2796])\n",
      "    Grad  :  tensor([-0.0008,  0.0043])\n",
      "Epoch 3850,Loss 2.927701\n",
      "Epoch 3850, Loss 2.927701\n",
      "    Params:  tensor([  5.3633, -17.2796])\n",
      "    Grad  :  tensor([-0.0007,  0.0043])\n",
      "Epoch 3851,Loss 2.927701\n",
      "Epoch 3851, Loss 2.927701\n",
      "    Params:  tensor([  5.3633, -17.2796])\n",
      "    Grad  :  tensor([-0.0007,  0.0043])\n",
      "Epoch 3852,Loss 2.927703\n",
      "Epoch 3852, Loss 2.927703\n",
      "    Params:  tensor([  5.3633, -17.2797])\n",
      "    Grad  :  tensor([-0.0007,  0.0043])\n",
      "Epoch 3853,Loss 2.927700\n",
      "Epoch 3853, Loss 2.927700\n",
      "    Params:  tensor([  5.3633, -17.2797])\n",
      "    Grad  :  tensor([-0.0007,  0.0043])\n",
      "Epoch 3854,Loss 2.927701\n",
      "Epoch 3854, Loss 2.927701\n",
      "    Params:  tensor([  5.3633, -17.2798])\n",
      "    Grad  :  tensor([-0.0007,  0.0043])\n",
      "Epoch 3855,Loss 2.927701\n",
      "Epoch 3855, Loss 2.927701\n",
      "    Params:  tensor([  5.3633, -17.2798])\n",
      "    Grad  :  tensor([-0.0007,  0.0043])\n",
      "Epoch 3856,Loss 2.927700\n",
      "Epoch 3856, Loss 2.927700\n",
      "    Params:  tensor([  5.3633, -17.2799])\n",
      "    Grad  :  tensor([-0.0007,  0.0042])\n",
      "Epoch 3857,Loss 2.927700\n",
      "Epoch 3857, Loss 2.927700\n",
      "    Params:  tensor([  5.3633, -17.2799])\n",
      "    Grad  :  tensor([-0.0007,  0.0042])\n",
      "Epoch 3858,Loss 2.927700\n",
      "Epoch 3858, Loss 2.927700\n",
      "    Params:  tensor([  5.3633, -17.2799])\n",
      "    Grad  :  tensor([-0.0007,  0.0042])\n",
      "Epoch 3859,Loss 2.927701\n",
      "Epoch 3859, Loss 2.927701\n",
      "    Params:  tensor([  5.3633, -17.2800])\n",
      "    Grad  :  tensor([-0.0007,  0.0042])\n",
      "Epoch 3860,Loss 2.927699\n",
      "Epoch 3860, Loss 2.927699\n",
      "    Params:  tensor([  5.3633, -17.2800])\n",
      "    Grad  :  tensor([-0.0008,  0.0042])\n",
      "Epoch 3861,Loss 2.927699\n",
      "Epoch 3861, Loss 2.927699\n",
      "    Params:  tensor([  5.3634, -17.2801])\n",
      "    Grad  :  tensor([-0.0007,  0.0042])\n",
      "Epoch 3862,Loss 2.927700\n",
      "Epoch 3862, Loss 2.927700\n",
      "    Params:  tensor([  5.3634, -17.2801])\n",
      "    Grad  :  tensor([-0.0007,  0.0042])\n",
      "Epoch 3863,Loss 2.927699\n",
      "Epoch 3863, Loss 2.927699\n",
      "    Params:  tensor([  5.3634, -17.2801])\n",
      "    Grad  :  tensor([-0.0007,  0.0042])\n",
      "Epoch 3864,Loss 2.927698\n",
      "Epoch 3864, Loss 2.927698\n",
      "    Params:  tensor([  5.3634, -17.2802])\n",
      "    Grad  :  tensor([-0.0007,  0.0042])\n",
      "Epoch 3865,Loss 2.927699\n",
      "Epoch 3865, Loss 2.927699\n",
      "    Params:  tensor([  5.3634, -17.2802])\n",
      "    Grad  :  tensor([-0.0007,  0.0042])\n",
      "Epoch 3866,Loss 2.927697\n",
      "Epoch 3866, Loss 2.927697\n",
      "    Params:  tensor([  5.3634, -17.2803])\n",
      "    Grad  :  tensor([-0.0007,  0.0042])\n",
      "Epoch 3867,Loss 2.927700\n",
      "Epoch 3867, Loss 2.927700\n",
      "    Params:  tensor([  5.3634, -17.2803])\n",
      "    Grad  :  tensor([-0.0007,  0.0042])\n",
      "Epoch 3868,Loss 2.927699\n",
      "Epoch 3868, Loss 2.927699\n",
      "    Params:  tensor([  5.3634, -17.2804])\n",
      "    Grad  :  tensor([-0.0007,  0.0042])\n",
      "Epoch 3869,Loss 2.927698\n",
      "Epoch 3869, Loss 2.927698\n",
      "    Params:  tensor([  5.3634, -17.2804])\n",
      "    Grad  :  tensor([-0.0007,  0.0042])\n",
      "Epoch 3870,Loss 2.927697\n",
      "Epoch 3870, Loss 2.927697\n",
      "    Params:  tensor([  5.3634, -17.2804])\n",
      "    Grad  :  tensor([-0.0007,  0.0041])\n",
      "Epoch 3871,Loss 2.927698\n",
      "Epoch 3871, Loss 2.927698\n",
      "    Params:  tensor([  5.3634, -17.2805])\n",
      "    Grad  :  tensor([-0.0007,  0.0041])\n",
      "Epoch 3872,Loss 2.927696\n",
      "Epoch 3872, Loss 2.927696\n",
      "    Params:  tensor([  5.3634, -17.2805])\n",
      "    Grad  :  tensor([-0.0007,  0.0041])\n",
      "Epoch 3873,Loss 2.927699\n",
      "Epoch 3873, Loss 2.927699\n",
      "    Params:  tensor([  5.3634, -17.2806])\n",
      "    Grad  :  tensor([-0.0007,  0.0041])\n",
      "Epoch 3874,Loss 2.927698\n",
      "Epoch 3874, Loss 2.927698\n",
      "    Params:  tensor([  5.3634, -17.2806])\n",
      "    Grad  :  tensor([-0.0007,  0.0041])\n",
      "Epoch 3875,Loss 2.927696\n",
      "Epoch 3875, Loss 2.927696\n",
      "    Params:  tensor([  5.3635, -17.2806])\n",
      "    Grad  :  tensor([-0.0007,  0.0041])\n",
      "Epoch 3876,Loss 2.927698\n",
      "Epoch 3876, Loss 2.927698\n",
      "    Params:  tensor([  5.3635, -17.2807])\n",
      "    Grad  :  tensor([-0.0007,  0.0041])\n",
      "Epoch 3877,Loss 2.927697\n",
      "Epoch 3877, Loss 2.927697\n",
      "    Params:  tensor([  5.3635, -17.2807])\n",
      "    Grad  :  tensor([-0.0007,  0.0041])\n",
      "Epoch 3878,Loss 2.927696\n",
      "Epoch 3878, Loss 2.927696\n",
      "    Params:  tensor([  5.3635, -17.2808])\n",
      "    Grad  :  tensor([-0.0007,  0.0041])\n",
      "Epoch 3879,Loss 2.927697\n",
      "Epoch 3879, Loss 2.927697\n",
      "    Params:  tensor([  5.3635, -17.2808])\n",
      "    Grad  :  tensor([-0.0007,  0.0041])\n",
      "Epoch 3880,Loss 2.927696\n",
      "Epoch 3880, Loss 2.927696\n",
      "    Params:  tensor([  5.3635, -17.2808])\n",
      "    Grad  :  tensor([-0.0007,  0.0041])\n",
      "Epoch 3881,Loss 2.927696\n",
      "Epoch 3881, Loss 2.927696\n",
      "    Params:  tensor([  5.3635, -17.2809])\n",
      "    Grad  :  tensor([-0.0007,  0.0041])\n",
      "Epoch 3882,Loss 2.927696\n",
      "Epoch 3882, Loss 2.927696\n",
      "    Params:  tensor([  5.3635, -17.2809])\n",
      "    Grad  :  tensor([-0.0007,  0.0041])\n",
      "Epoch 3883,Loss 2.927696\n",
      "Epoch 3883, Loss 2.927696\n",
      "    Params:  tensor([  5.3635, -17.2810])\n",
      "    Grad  :  tensor([-0.0007,  0.0041])\n",
      "Epoch 3884,Loss 2.927696\n",
      "Epoch 3884, Loss 2.927696\n",
      "    Params:  tensor([  5.3635, -17.2810])\n",
      "    Grad  :  tensor([-0.0007,  0.0040])\n",
      "Epoch 3885,Loss 2.927695\n",
      "Epoch 3885, Loss 2.927695\n",
      "    Params:  tensor([  5.3635, -17.2810])\n",
      "    Grad  :  tensor([-0.0007,  0.0040])\n",
      "Epoch 3886,Loss 2.927696\n",
      "Epoch 3886, Loss 2.927696\n",
      "    Params:  tensor([  5.3635, -17.2811])\n",
      "    Grad  :  tensor([-0.0007,  0.0040])\n",
      "Epoch 3887,Loss 2.927696\n",
      "Epoch 3887, Loss 2.927696\n",
      "    Params:  tensor([  5.3635, -17.2811])\n",
      "    Grad  :  tensor([-0.0007,  0.0040])\n",
      "Epoch 3888,Loss 2.927695\n",
      "Epoch 3888, Loss 2.927695\n",
      "    Params:  tensor([  5.3635, -17.2812])\n",
      "    Grad  :  tensor([-0.0007,  0.0040])\n",
      "Epoch 3889,Loss 2.927695\n",
      "Epoch 3889, Loss 2.927695\n",
      "    Params:  tensor([  5.3636, -17.2812])\n",
      "    Grad  :  tensor([-0.0007,  0.0040])\n",
      "Epoch 3890,Loss 2.927694\n",
      "Epoch 3890, Loss 2.927694\n",
      "    Params:  tensor([  5.3636, -17.2812])\n",
      "    Grad  :  tensor([-0.0007,  0.0040])\n",
      "Epoch 3891,Loss 2.927693\n",
      "Epoch 3891, Loss 2.927693\n",
      "    Params:  tensor([  5.3636, -17.2813])\n",
      "    Grad  :  tensor([-0.0007,  0.0040])\n",
      "Epoch 3892,Loss 2.927693\n",
      "Epoch 3892, Loss 2.927693\n",
      "    Params:  tensor([  5.3636, -17.2813])\n",
      "    Grad  :  tensor([-0.0007,  0.0040])\n",
      "Epoch 3893,Loss 2.927695\n",
      "Epoch 3893, Loss 2.927695\n",
      "    Params:  tensor([  5.3636, -17.2814])\n",
      "    Grad  :  tensor([-0.0007,  0.0040])\n",
      "Epoch 3894,Loss 2.927695\n",
      "Epoch 3894, Loss 2.927695\n",
      "    Params:  tensor([  5.3636, -17.2814])\n",
      "    Grad  :  tensor([-0.0007,  0.0040])\n",
      "Epoch 3895,Loss 2.927694\n",
      "Epoch 3895, Loss 2.927694\n",
      "    Params:  tensor([  5.3636, -17.2815])\n",
      "    Grad  :  tensor([-0.0007,  0.0040])\n",
      "Epoch 3896,Loss 2.927696\n",
      "Epoch 3896, Loss 2.927696\n",
      "    Params:  tensor([  5.3636, -17.2815])\n",
      "    Grad  :  tensor([-0.0007,  0.0040])\n",
      "Epoch 3897,Loss 2.927693\n",
      "Epoch 3897, Loss 2.927693\n",
      "    Params:  tensor([  5.3636, -17.2815])\n",
      "    Grad  :  tensor([-0.0007,  0.0040])\n",
      "Epoch 3898,Loss 2.927693\n",
      "Epoch 3898, Loss 2.927693\n",
      "    Params:  tensor([  5.3636, -17.2816])\n",
      "    Grad  :  tensor([-0.0007,  0.0039])\n",
      "Epoch 3899,Loss 2.927694\n",
      "Epoch 3899, Loss 2.927694\n",
      "    Params:  tensor([  5.3636, -17.2816])\n",
      "    Grad  :  tensor([-0.0007,  0.0039])\n",
      "Epoch 3900,Loss 2.927693\n",
      "Epoch 3900, Loss 2.927693\n",
      "    Params:  tensor([  5.3636, -17.2817])\n",
      "    Grad  :  tensor([-0.0007,  0.0039])\n",
      "Epoch 3901,Loss 2.927692\n",
      "Epoch 3901, Loss 2.927692\n",
      "    Params:  tensor([  5.3636, -17.2817])\n",
      "    Grad  :  tensor([-0.0007,  0.0039])\n",
      "Epoch 3902,Loss 2.927694\n",
      "Epoch 3902, Loss 2.927694\n",
      "    Params:  tensor([  5.3636, -17.2817])\n",
      "    Grad  :  tensor([-0.0007,  0.0039])\n",
      "Epoch 3903,Loss 2.927692\n",
      "Epoch 3903, Loss 2.927692\n",
      "    Params:  tensor([  5.3637, -17.2818])\n",
      "    Grad  :  tensor([-0.0007,  0.0039])\n",
      "Epoch 3904,Loss 2.927693\n",
      "Epoch 3904, Loss 2.927693\n",
      "    Params:  tensor([  5.3637, -17.2818])\n",
      "    Grad  :  tensor([-0.0007,  0.0039])\n",
      "Epoch 3905,Loss 2.927691\n",
      "Epoch 3905, Loss 2.927691\n",
      "    Params:  tensor([  5.3637, -17.2818])\n",
      "    Grad  :  tensor([-0.0007,  0.0039])\n",
      "Epoch 3906,Loss 2.927692\n",
      "Epoch 3906, Loss 2.927692\n",
      "    Params:  tensor([  5.3637, -17.2819])\n",
      "    Grad  :  tensor([-0.0007,  0.0039])\n",
      "Epoch 3907,Loss 2.927692\n",
      "Epoch 3907, Loss 2.927692\n",
      "    Params:  tensor([  5.3637, -17.2819])\n",
      "    Grad  :  tensor([-0.0007,  0.0039])\n",
      "Epoch 3908,Loss 2.927692\n",
      "Epoch 3908, Loss 2.927692\n",
      "    Params:  tensor([  5.3637, -17.2820])\n",
      "    Grad  :  tensor([-0.0007,  0.0039])\n",
      "Epoch 3909,Loss 2.927691\n",
      "Epoch 3909, Loss 2.927691\n",
      "    Params:  tensor([  5.3637, -17.2820])\n",
      "    Grad  :  tensor([-0.0007,  0.0039])\n",
      "Epoch 3910,Loss 2.927692\n",
      "Epoch 3910, Loss 2.927692\n",
      "    Params:  tensor([  5.3637, -17.2820])\n",
      "    Grad  :  tensor([-0.0007,  0.0039])\n",
      "Epoch 3911,Loss 2.927690\n",
      "Epoch 3911, Loss 2.927690\n",
      "    Params:  tensor([  5.3637, -17.2821])\n",
      "    Grad  :  tensor([-0.0007,  0.0039])\n",
      "Epoch 3912,Loss 2.927691\n",
      "Epoch 3912, Loss 2.927691\n",
      "    Params:  tensor([  5.3637, -17.2821])\n",
      "    Grad  :  tensor([-0.0007,  0.0039])\n",
      "Epoch 3913,Loss 2.927691\n",
      "Epoch 3913, Loss 2.927691\n",
      "    Params:  tensor([  5.3637, -17.2822])\n",
      "    Grad  :  tensor([-0.0007,  0.0039])\n",
      "Epoch 3914,Loss 2.927691\n",
      "Epoch 3914, Loss 2.927691\n",
      "    Params:  tensor([  5.3637, -17.2822])\n",
      "    Grad  :  tensor([-0.0007,  0.0038])\n",
      "Epoch 3915,Loss 2.927690\n",
      "Epoch 3915, Loss 2.927690\n",
      "    Params:  tensor([  5.3637, -17.2822])\n",
      "    Grad  :  tensor([-0.0007,  0.0038])\n",
      "Epoch 3916,Loss 2.927691\n",
      "Epoch 3916, Loss 2.927691\n",
      "    Params:  tensor([  5.3637, -17.2823])\n",
      "    Grad  :  tensor([-0.0007,  0.0038])\n",
      "Epoch 3917,Loss 2.927691\n",
      "Epoch 3917, Loss 2.927691\n",
      "    Params:  tensor([  5.3637, -17.2823])\n",
      "    Grad  :  tensor([-0.0007,  0.0038])\n",
      "Epoch 3918,Loss 2.927689\n",
      "Epoch 3918, Loss 2.927689\n",
      "    Params:  tensor([  5.3638, -17.2823])\n",
      "    Grad  :  tensor([-0.0007,  0.0038])\n",
      "Epoch 3919,Loss 2.927690\n",
      "Epoch 3919, Loss 2.927690\n",
      "    Params:  tensor([  5.3638, -17.2824])\n",
      "    Grad  :  tensor([-0.0007,  0.0038])\n",
      "Epoch 3920,Loss 2.927690\n",
      "Epoch 3920, Loss 2.927690\n",
      "    Params:  tensor([  5.3638, -17.2824])\n",
      "    Grad  :  tensor([-0.0007,  0.0038])\n",
      "Epoch 3921,Loss 2.927690\n",
      "Epoch 3921, Loss 2.927690\n",
      "    Params:  tensor([  5.3638, -17.2825])\n",
      "    Grad  :  tensor([-0.0007,  0.0038])\n",
      "Epoch 3922,Loss 2.927690\n",
      "Epoch 3922, Loss 2.927690\n",
      "    Params:  tensor([  5.3638, -17.2825])\n",
      "    Grad  :  tensor([-0.0007,  0.0038])\n",
      "Epoch 3923,Loss 2.927689\n",
      "Epoch 3923, Loss 2.927689\n",
      "    Params:  tensor([  5.3638, -17.2825])\n",
      "    Grad  :  tensor([-0.0007,  0.0038])\n",
      "Epoch 3924,Loss 2.927689\n",
      "Epoch 3924, Loss 2.927689\n",
      "    Params:  tensor([  5.3638, -17.2826])\n",
      "    Grad  :  tensor([-0.0007,  0.0038])\n",
      "Epoch 3925,Loss 2.927689\n",
      "Epoch 3925, Loss 2.927689\n",
      "    Params:  tensor([  5.3638, -17.2826])\n",
      "    Grad  :  tensor([-0.0007,  0.0038])\n",
      "Epoch 3926,Loss 2.927688\n",
      "Epoch 3926, Loss 2.927688\n",
      "    Params:  tensor([  5.3638, -17.2826])\n",
      "    Grad  :  tensor([-0.0007,  0.0038])\n",
      "Epoch 3927,Loss 2.927689\n",
      "Epoch 3927, Loss 2.927689\n",
      "    Params:  tensor([  5.3638, -17.2827])\n",
      "    Grad  :  tensor([-0.0007,  0.0038])\n",
      "Epoch 3928,Loss 2.927689\n",
      "Epoch 3928, Loss 2.927689\n",
      "    Params:  tensor([  5.3638, -17.2827])\n",
      "    Grad  :  tensor([-0.0007,  0.0038])\n",
      "Epoch 3929,Loss 2.927688\n",
      "Epoch 3929, Loss 2.927688\n",
      "    Params:  tensor([  5.3638, -17.2828])\n",
      "    Grad  :  tensor([-0.0007,  0.0037])\n",
      "Epoch 3930,Loss 2.927688\n",
      "Epoch 3930, Loss 2.927688\n",
      "    Params:  tensor([  5.3638, -17.2828])\n",
      "    Grad  :  tensor([-0.0007,  0.0037])\n",
      "Epoch 3931,Loss 2.927688\n",
      "Epoch 3931, Loss 2.927688\n",
      "    Params:  tensor([  5.3638, -17.2828])\n",
      "    Grad  :  tensor([-0.0007,  0.0037])\n",
      "Epoch 3932,Loss 2.927688\n",
      "Epoch 3932, Loss 2.927688\n",
      "    Params:  tensor([  5.3638, -17.2829])\n",
      "    Grad  :  tensor([-0.0007,  0.0037])\n",
      "Epoch 3933,Loss 2.927687\n",
      "Epoch 3933, Loss 2.927687\n",
      "    Params:  tensor([  5.3639, -17.2829])\n",
      "    Grad  :  tensor([-0.0007,  0.0037])\n",
      "Epoch 3934,Loss 2.927689\n",
      "Epoch 3934, Loss 2.927689\n",
      "    Params:  tensor([  5.3639, -17.2829])\n",
      "    Grad  :  tensor([-0.0006,  0.0037])\n",
      "Epoch 3935,Loss 2.927688\n",
      "Epoch 3935, Loss 2.927688\n",
      "    Params:  tensor([  5.3639, -17.2830])\n",
      "    Grad  :  tensor([-0.0006,  0.0037])\n",
      "Epoch 3936,Loss 2.927687\n",
      "Epoch 3936, Loss 2.927687\n",
      "    Params:  tensor([  5.3639, -17.2830])\n",
      "    Grad  :  tensor([-0.0006,  0.0037])\n",
      "Epoch 3937,Loss 2.927687\n",
      "Epoch 3937, Loss 2.927687\n",
      "    Params:  tensor([  5.3639, -17.2831])\n",
      "    Grad  :  tensor([-0.0006,  0.0037])\n",
      "Epoch 3938,Loss 2.927687\n",
      "Epoch 3938, Loss 2.927687\n",
      "    Params:  tensor([  5.3639, -17.2831])\n",
      "    Grad  :  tensor([-0.0006,  0.0037])\n",
      "Epoch 3939,Loss 2.927686\n",
      "Epoch 3939, Loss 2.927686\n",
      "    Params:  tensor([  5.3639, -17.2831])\n",
      "    Grad  :  tensor([-0.0006,  0.0037])\n",
      "Epoch 3940,Loss 2.927686\n",
      "Epoch 3940, Loss 2.927686\n",
      "    Params:  tensor([  5.3639, -17.2832])\n",
      "    Grad  :  tensor([-0.0007,  0.0037])\n",
      "Epoch 3941,Loss 2.927687\n",
      "Epoch 3941, Loss 2.927687\n",
      "    Params:  tensor([  5.3639, -17.2832])\n",
      "    Grad  :  tensor([-0.0006,  0.0037])\n",
      "Epoch 3942,Loss 2.927686\n",
      "Epoch 3942, Loss 2.927686\n",
      "    Params:  tensor([  5.3639, -17.2832])\n",
      "    Grad  :  tensor([-0.0006,  0.0037])\n",
      "Epoch 3943,Loss 2.927686\n",
      "Epoch 3943, Loss 2.927686\n",
      "    Params:  tensor([  5.3639, -17.2833])\n",
      "    Grad  :  tensor([-0.0006,  0.0037])\n",
      "Epoch 3944,Loss 2.927686\n",
      "Epoch 3944, Loss 2.927686\n",
      "    Params:  tensor([  5.3639, -17.2833])\n",
      "    Grad  :  tensor([-0.0006,  0.0037])\n",
      "Epoch 3945,Loss 2.927686\n",
      "Epoch 3945, Loss 2.927686\n",
      "    Params:  tensor([  5.3639, -17.2833])\n",
      "    Grad  :  tensor([-0.0007,  0.0036])\n",
      "Epoch 3946,Loss 2.927685\n",
      "Epoch 3946, Loss 2.927685\n",
      "    Params:  tensor([  5.3639, -17.2834])\n",
      "    Grad  :  tensor([-0.0006,  0.0036])\n",
      "Epoch 3947,Loss 2.927685\n",
      "Epoch 3947, Loss 2.927685\n",
      "    Params:  tensor([  5.3639, -17.2834])\n",
      "    Grad  :  tensor([-0.0006,  0.0036])\n",
      "Epoch 3948,Loss 2.927686\n",
      "Epoch 3948, Loss 2.927686\n",
      "    Params:  tensor([  5.3640, -17.2835])\n",
      "    Grad  :  tensor([-0.0006,  0.0036])\n",
      "Epoch 3949,Loss 2.927685\n",
      "Epoch 3949, Loss 2.927685\n",
      "    Params:  tensor([  5.3640, -17.2835])\n",
      "    Grad  :  tensor([-0.0006,  0.0036])\n",
      "Epoch 3950,Loss 2.927686\n",
      "Epoch 3950, Loss 2.927686\n",
      "    Params:  tensor([  5.3640, -17.2835])\n",
      "    Grad  :  tensor([-0.0007,  0.0036])\n",
      "Epoch 3951,Loss 2.927686\n",
      "Epoch 3951, Loss 2.927686\n",
      "    Params:  tensor([  5.3640, -17.2836])\n",
      "    Grad  :  tensor([-0.0006,  0.0036])\n",
      "Epoch 3952,Loss 2.927687\n",
      "Epoch 3952, Loss 2.927687\n",
      "    Params:  tensor([  5.3640, -17.2836])\n",
      "    Grad  :  tensor([-0.0006,  0.0036])\n",
      "Epoch 3953,Loss 2.927685\n",
      "Epoch 3953, Loss 2.927685\n",
      "    Params:  tensor([  5.3640, -17.2836])\n",
      "    Grad  :  tensor([-0.0006,  0.0036])\n",
      "Epoch 3954,Loss 2.927686\n",
      "Epoch 3954, Loss 2.927686\n",
      "    Params:  tensor([  5.3640, -17.2837])\n",
      "    Grad  :  tensor([-0.0006,  0.0036])\n",
      "Epoch 3955,Loss 2.927686\n",
      "Epoch 3955, Loss 2.927686\n",
      "    Params:  tensor([  5.3640, -17.2837])\n",
      "    Grad  :  tensor([-0.0006,  0.0036])\n",
      "Epoch 3956,Loss 2.927685\n",
      "Epoch 3956, Loss 2.927685\n",
      "    Params:  tensor([  5.3640, -17.2837])\n",
      "    Grad  :  tensor([-0.0006,  0.0036])\n",
      "Epoch 3957,Loss 2.927683\n",
      "Epoch 3957, Loss 2.927683\n",
      "    Params:  tensor([  5.3640, -17.2838])\n",
      "    Grad  :  tensor([-0.0006,  0.0036])\n",
      "Epoch 3958,Loss 2.927684\n",
      "Epoch 3958, Loss 2.927684\n",
      "    Params:  tensor([  5.3640, -17.2838])\n",
      "    Grad  :  tensor([-0.0007,  0.0036])\n",
      "Epoch 3959,Loss 2.927685\n",
      "Epoch 3959, Loss 2.927685\n",
      "    Params:  tensor([  5.3640, -17.2839])\n",
      "    Grad  :  tensor([-0.0006,  0.0036])\n",
      "Epoch 3960,Loss 2.927684\n",
      "Epoch 3960, Loss 2.927684\n",
      "    Params:  tensor([  5.3640, -17.2839])\n",
      "    Grad  :  tensor([-0.0007,  0.0036])\n",
      "Epoch 3961,Loss 2.927684\n",
      "Epoch 3961, Loss 2.927684\n",
      "    Params:  tensor([  5.3640, -17.2839])\n",
      "    Grad  :  tensor([-0.0006,  0.0035])\n",
      "Epoch 3962,Loss 2.927684\n",
      "Epoch 3962, Loss 2.927684\n",
      "    Params:  tensor([  5.3640, -17.2840])\n",
      "    Grad  :  tensor([-0.0006,  0.0035])\n",
      "Epoch 3963,Loss 2.927685\n",
      "Epoch 3963, Loss 2.927685\n",
      "    Params:  tensor([  5.3640, -17.2840])\n",
      "    Grad  :  tensor([-0.0007,  0.0035])\n",
      "Epoch 3964,Loss 2.927683\n",
      "Epoch 3964, Loss 2.927683\n",
      "    Params:  tensor([  5.3641, -17.2840])\n",
      "    Grad  :  tensor([-0.0006,  0.0035])\n",
      "Epoch 3965,Loss 2.927685\n",
      "Epoch 3965, Loss 2.927685\n",
      "    Params:  tensor([  5.3641, -17.2841])\n",
      "    Grad  :  tensor([-0.0006,  0.0035])\n",
      "Epoch 3966,Loss 2.927685\n",
      "Epoch 3966, Loss 2.927685\n",
      "    Params:  tensor([  5.3641, -17.2841])\n",
      "    Grad  :  tensor([-0.0006,  0.0035])\n",
      "Epoch 3967,Loss 2.927684\n",
      "Epoch 3967, Loss 2.927684\n",
      "    Params:  tensor([  5.3641, -17.2841])\n",
      "    Grad  :  tensor([-0.0006,  0.0035])\n",
      "Epoch 3968,Loss 2.927683\n",
      "Epoch 3968, Loss 2.927683\n",
      "    Params:  tensor([  5.3641, -17.2842])\n",
      "    Grad  :  tensor([-0.0006,  0.0035])\n",
      "Epoch 3969,Loss 2.927683\n",
      "Epoch 3969, Loss 2.927683\n",
      "    Params:  tensor([  5.3641, -17.2842])\n",
      "    Grad  :  tensor([-0.0006,  0.0035])\n",
      "Epoch 3970,Loss 2.927682\n",
      "Epoch 3970, Loss 2.927682\n",
      "    Params:  tensor([  5.3641, -17.2842])\n",
      "    Grad  :  tensor([-0.0006,  0.0035])\n",
      "Epoch 3971,Loss 2.927683\n",
      "Epoch 3971, Loss 2.927683\n",
      "    Params:  tensor([  5.3641, -17.2843])\n",
      "    Grad  :  tensor([-0.0006,  0.0035])\n",
      "Epoch 3972,Loss 2.927684\n",
      "Epoch 3972, Loss 2.927684\n",
      "    Params:  tensor([  5.3641, -17.2843])\n",
      "    Grad  :  tensor([-0.0006,  0.0035])\n",
      "Epoch 3973,Loss 2.927682\n",
      "Epoch 3973, Loss 2.927682\n",
      "    Params:  tensor([  5.3641, -17.2843])\n",
      "    Grad  :  tensor([-0.0006,  0.0035])\n",
      "Epoch 3974,Loss 2.927683\n",
      "Epoch 3974, Loss 2.927683\n",
      "    Params:  tensor([  5.3641, -17.2844])\n",
      "    Grad  :  tensor([-0.0006,  0.0035])\n",
      "Epoch 3975,Loss 2.927683\n",
      "Epoch 3975, Loss 2.927683\n",
      "    Params:  tensor([  5.3641, -17.2844])\n",
      "    Grad  :  tensor([-0.0006,  0.0035])\n",
      "Epoch 3976,Loss 2.927683\n",
      "Epoch 3976, Loss 2.927683\n",
      "    Params:  tensor([  5.3641, -17.2844])\n",
      "    Grad  :  tensor([-0.0006,  0.0035])\n",
      "Epoch 3977,Loss 2.927682\n",
      "Epoch 3977, Loss 2.927682\n",
      "    Params:  tensor([  5.3641, -17.2845])\n",
      "    Grad  :  tensor([-0.0006,  0.0035])\n",
      "Epoch 3978,Loss 2.927682\n",
      "Epoch 3978, Loss 2.927682\n",
      "    Params:  tensor([  5.3641, -17.2845])\n",
      "    Grad  :  tensor([-0.0006,  0.0035])\n",
      "Epoch 3979,Loss 2.927682\n",
      "Epoch 3979, Loss 2.927682\n",
      "    Params:  tensor([  5.3641, -17.2845])\n",
      "    Grad  :  tensor([-0.0006,  0.0034])\n",
      "Epoch 3980,Loss 2.927681\n",
      "Epoch 3980, Loss 2.927681\n",
      "    Params:  tensor([  5.3642, -17.2846])\n",
      "    Grad  :  tensor([-0.0006,  0.0034])\n",
      "Epoch 3981,Loss 2.927682\n",
      "Epoch 3981, Loss 2.927682\n",
      "    Params:  tensor([  5.3642, -17.2846])\n",
      "    Grad  :  tensor([-0.0006,  0.0034])\n",
      "Epoch 3982,Loss 2.927682\n",
      "Epoch 3982, Loss 2.927682\n",
      "    Params:  tensor([  5.3642, -17.2847])\n",
      "    Grad  :  tensor([-0.0006,  0.0034])\n",
      "Epoch 3983,Loss 2.927682\n",
      "Epoch 3983, Loss 2.927682\n",
      "    Params:  tensor([  5.3642, -17.2847])\n",
      "    Grad  :  tensor([-0.0006,  0.0034])\n",
      "Epoch 3984,Loss 2.927682\n",
      "Epoch 3984, Loss 2.927682\n",
      "    Params:  tensor([  5.3642, -17.2847])\n",
      "    Grad  :  tensor([-0.0006,  0.0034])\n",
      "Epoch 3985,Loss 2.927682\n",
      "Epoch 3985, Loss 2.927682\n",
      "    Params:  tensor([  5.3642, -17.2848])\n",
      "    Grad  :  tensor([-0.0006,  0.0034])\n",
      "Epoch 3986,Loss 2.927682\n",
      "Epoch 3986, Loss 2.927682\n",
      "    Params:  tensor([  5.3642, -17.2848])\n",
      "    Grad  :  tensor([-0.0006,  0.0034])\n",
      "Epoch 3987,Loss 2.927680\n",
      "Epoch 3987, Loss 2.927680\n",
      "    Params:  tensor([  5.3642, -17.2848])\n",
      "    Grad  :  tensor([-0.0006,  0.0034])\n",
      "Epoch 3988,Loss 2.927682\n",
      "Epoch 3988, Loss 2.927682\n",
      "    Params:  tensor([  5.3642, -17.2849])\n",
      "    Grad  :  tensor([-0.0006,  0.0034])\n",
      "Epoch 3989,Loss 2.927681\n",
      "Epoch 3989, Loss 2.927681\n",
      "    Params:  tensor([  5.3642, -17.2849])\n",
      "    Grad  :  tensor([-0.0006,  0.0034])\n",
      "Epoch 3990,Loss 2.927681\n",
      "Epoch 3990, Loss 2.927681\n",
      "    Params:  tensor([  5.3642, -17.2849])\n",
      "    Grad  :  tensor([-0.0006,  0.0034])\n",
      "Epoch 3991,Loss 2.927680\n",
      "Epoch 3991, Loss 2.927680\n",
      "    Params:  tensor([  5.3642, -17.2850])\n",
      "    Grad  :  tensor([-0.0006,  0.0034])\n",
      "Epoch 3992,Loss 2.927681\n",
      "Epoch 3992, Loss 2.927681\n",
      "    Params:  tensor([  5.3642, -17.2850])\n",
      "    Grad  :  tensor([-0.0006,  0.0034])\n",
      "Epoch 3993,Loss 2.927680\n",
      "Epoch 3993, Loss 2.927680\n",
      "    Params:  tensor([  5.3642, -17.2850])\n",
      "    Grad  :  tensor([-0.0006,  0.0034])\n",
      "Epoch 3994,Loss 2.927680\n",
      "Epoch 3994, Loss 2.927680\n",
      "    Params:  tensor([  5.3642, -17.2851])\n",
      "    Grad  :  tensor([-0.0006,  0.0034])\n",
      "Epoch 3995,Loss 2.927681\n",
      "Epoch 3995, Loss 2.927681\n",
      "    Params:  tensor([  5.3642, -17.2851])\n",
      "    Grad  :  tensor([-0.0006,  0.0033])\n",
      "Epoch 3996,Loss 2.927681\n",
      "Epoch 3996, Loss 2.927681\n",
      "    Params:  tensor([  5.3642, -17.2851])\n",
      "    Grad  :  tensor([-0.0006,  0.0033])\n",
      "Epoch 3997,Loss 2.927679\n",
      "Epoch 3997, Loss 2.927679\n",
      "    Params:  tensor([  5.3643, -17.2852])\n",
      "    Grad  :  tensor([-0.0006,  0.0033])\n",
      "Epoch 3998,Loss 2.927680\n",
      "Epoch 3998, Loss 2.927680\n",
      "    Params:  tensor([  5.3643, -17.2852])\n",
      "    Grad  :  tensor([-0.0006,  0.0033])\n",
      "Epoch 3999,Loss 2.927679\n",
      "Epoch 3999, Loss 2.927679\n",
      "    Params:  tensor([  5.3643, -17.2852])\n",
      "    Grad  :  tensor([-0.0006,  0.0033])\n",
      "Epoch 4000,Loss 2.927680\n",
      "Epoch 4000, Loss 2.927680\n",
      "    Params:  tensor([  5.3643, -17.2853])\n",
      "    Grad  :  tensor([-0.0006,  0.0033])\n",
      "Epoch 4001,Loss 2.927680\n",
      "Epoch 4001, Loss 2.927680\n",
      "    Params:  tensor([  5.3643, -17.2853])\n",
      "    Grad  :  tensor([-0.0006,  0.0033])\n",
      "Epoch 4002,Loss 2.927681\n",
      "Epoch 4002, Loss 2.927681\n",
      "    Params:  tensor([  5.3643, -17.2853])\n",
      "    Grad  :  tensor([-0.0006,  0.0033])\n",
      "Epoch 4003,Loss 2.927679\n",
      "Epoch 4003, Loss 2.927679\n",
      "    Params:  tensor([  5.3643, -17.2854])\n",
      "    Grad  :  tensor([-0.0006,  0.0033])\n",
      "Epoch 4004,Loss 2.927679\n",
      "Epoch 4004, Loss 2.927679\n",
      "    Params:  tensor([  5.3643, -17.2854])\n",
      "    Grad  :  tensor([-0.0006,  0.0033])\n",
      "Epoch 4005,Loss 2.927680\n",
      "Epoch 4005, Loss 2.927680\n",
      "    Params:  tensor([  5.3643, -17.2854])\n",
      "    Grad  :  tensor([-0.0006,  0.0033])\n",
      "Epoch 4006,Loss 2.927680\n",
      "Epoch 4006, Loss 2.927680\n",
      "    Params:  tensor([  5.3643, -17.2855])\n",
      "    Grad  :  tensor([-0.0006,  0.0033])\n",
      "Epoch 4007,Loss 2.927677\n",
      "Epoch 4007, Loss 2.927677\n",
      "    Params:  tensor([  5.3643, -17.2855])\n",
      "    Grad  :  tensor([-0.0006,  0.0033])\n",
      "Epoch 4008,Loss 2.927678\n",
      "Epoch 4008, Loss 2.927678\n",
      "    Params:  tensor([  5.3643, -17.2855])\n",
      "    Grad  :  tensor([-0.0006,  0.0033])\n",
      "Epoch 4009,Loss 2.927679\n",
      "Epoch 4009, Loss 2.927679\n",
      "    Params:  tensor([  5.3643, -17.2856])\n",
      "    Grad  :  tensor([-0.0006,  0.0033])\n",
      "Epoch 4010,Loss 2.927678\n",
      "Epoch 4010, Loss 2.927678\n",
      "    Params:  tensor([  5.3643, -17.2856])\n",
      "    Grad  :  tensor([-0.0006,  0.0033])\n",
      "Epoch 4011,Loss 2.927679\n",
      "Epoch 4011, Loss 2.927679\n",
      "    Params:  tensor([  5.3643, -17.2856])\n",
      "    Grad  :  tensor([-0.0006,  0.0033])\n",
      "Epoch 4012,Loss 2.927679\n",
      "Epoch 4012, Loss 2.927679\n",
      "    Params:  tensor([  5.3643, -17.2857])\n",
      "    Grad  :  tensor([-0.0006,  0.0033])\n",
      "Epoch 4013,Loss 2.927679\n",
      "Epoch 4013, Loss 2.927679\n",
      "    Params:  tensor([  5.3643, -17.2857])\n",
      "    Grad  :  tensor([-0.0006,  0.0032])\n",
      "Epoch 4014,Loss 2.927677\n",
      "Epoch 4014, Loss 2.927677\n",
      "    Params:  tensor([  5.3644, -17.2857])\n",
      "    Grad  :  tensor([-0.0006,  0.0032])\n",
      "Epoch 4015,Loss 2.927677\n",
      "Epoch 4015, Loss 2.927677\n",
      "    Params:  tensor([  5.3644, -17.2857])\n",
      "    Grad  :  tensor([-0.0006,  0.0032])\n",
      "Epoch 4016,Loss 2.927677\n",
      "Epoch 4016, Loss 2.927677\n",
      "    Params:  tensor([  5.3644, -17.2858])\n",
      "    Grad  :  tensor([-0.0006,  0.0032])\n",
      "Epoch 4017,Loss 2.927679\n",
      "Epoch 4017, Loss 2.927679\n",
      "    Params:  tensor([  5.3644, -17.2858])\n",
      "    Grad  :  tensor([-0.0006,  0.0032])\n",
      "Epoch 4018,Loss 2.927677\n",
      "Epoch 4018, Loss 2.927677\n",
      "    Params:  tensor([  5.3644, -17.2858])\n",
      "    Grad  :  tensor([-0.0006,  0.0032])\n",
      "Epoch 4019,Loss 2.927678\n",
      "Epoch 4019, Loss 2.927678\n",
      "    Params:  tensor([  5.3644, -17.2859])\n",
      "    Grad  :  tensor([-0.0006,  0.0032])\n",
      "Epoch 4020,Loss 2.927678\n",
      "Epoch 4020, Loss 2.927678\n",
      "    Params:  tensor([  5.3644, -17.2859])\n",
      "    Grad  :  tensor([-0.0006,  0.0032])\n",
      "Epoch 4021,Loss 2.927677\n",
      "Epoch 4021, Loss 2.927677\n",
      "    Params:  tensor([  5.3644, -17.2859])\n",
      "    Grad  :  tensor([-0.0006,  0.0032])\n",
      "Epoch 4022,Loss 2.927677\n",
      "Epoch 4022, Loss 2.927677\n",
      "    Params:  tensor([  5.3644, -17.2860])\n",
      "    Grad  :  tensor([-0.0006,  0.0032])\n",
      "Epoch 4023,Loss 2.927678\n",
      "Epoch 4023, Loss 2.927678\n",
      "    Params:  tensor([  5.3644, -17.2860])\n",
      "    Grad  :  tensor([-0.0006,  0.0032])\n",
      "Epoch 4024,Loss 2.927677\n",
      "Epoch 4024, Loss 2.927677\n",
      "    Params:  tensor([  5.3644, -17.2860])\n",
      "    Grad  :  tensor([-0.0006,  0.0032])\n",
      "Epoch 4025,Loss 2.927677\n",
      "Epoch 4025, Loss 2.927677\n",
      "    Params:  tensor([  5.3644, -17.2861])\n",
      "    Grad  :  tensor([-0.0006,  0.0032])\n",
      "Epoch 4026,Loss 2.927676\n",
      "Epoch 4026, Loss 2.927676\n",
      "    Params:  tensor([  5.3644, -17.2861])\n",
      "    Grad  :  tensor([-0.0006,  0.0032])\n",
      "Epoch 4027,Loss 2.927676\n",
      "Epoch 4027, Loss 2.927676\n",
      "    Params:  tensor([  5.3644, -17.2861])\n",
      "    Grad  :  tensor([-0.0006,  0.0032])\n",
      "Epoch 4028,Loss 2.927675\n",
      "Epoch 4028, Loss 2.927675\n",
      "    Params:  tensor([  5.3644, -17.2862])\n",
      "    Grad  :  tensor([-0.0006,  0.0032])\n",
      "Epoch 4029,Loss 2.927677\n",
      "Epoch 4029, Loss 2.927677\n",
      "    Params:  tensor([  5.3644, -17.2862])\n",
      "    Grad  :  tensor([-0.0006,  0.0032])\n",
      "Epoch 4030,Loss 2.927674\n",
      "Epoch 4030, Loss 2.927674\n",
      "    Params:  tensor([  5.3644, -17.2862])\n",
      "    Grad  :  tensor([-0.0006,  0.0032])\n",
      "Epoch 4031,Loss 2.927676\n",
      "Epoch 4031, Loss 2.927676\n",
      "    Params:  tensor([  5.3644, -17.2863])\n",
      "    Grad  :  tensor([-0.0006,  0.0031])\n",
      "Epoch 4032,Loss 2.927675\n",
      "Epoch 4032, Loss 2.927675\n",
      "    Params:  tensor([  5.3645, -17.2863])\n",
      "    Grad  :  tensor([-0.0006,  0.0031])\n",
      "Epoch 4033,Loss 2.927675\n",
      "Epoch 4033, Loss 2.927675\n",
      "    Params:  tensor([  5.3645, -17.2863])\n",
      "    Grad  :  tensor([-0.0006,  0.0031])\n",
      "Epoch 4034,Loss 2.927675\n",
      "Epoch 4034, Loss 2.927675\n",
      "    Params:  tensor([  5.3645, -17.2864])\n",
      "    Grad  :  tensor([-0.0005,  0.0031])\n",
      "Epoch 4035,Loss 2.927675\n",
      "Epoch 4035, Loss 2.927675\n",
      "    Params:  tensor([  5.3645, -17.2864])\n",
      "    Grad  :  tensor([-0.0005,  0.0031])\n",
      "Epoch 4036,Loss 2.927674\n",
      "Epoch 4036, Loss 2.927674\n",
      "    Params:  tensor([  5.3645, -17.2864])\n",
      "    Grad  :  tensor([-0.0005,  0.0031])\n",
      "Epoch 4037,Loss 2.927674\n",
      "Epoch 4037, Loss 2.927674\n",
      "    Params:  tensor([  5.3645, -17.2865])\n",
      "    Grad  :  tensor([-0.0006,  0.0031])\n",
      "Epoch 4038,Loss 2.927677\n",
      "Epoch 4038, Loss 2.927677\n",
      "    Params:  tensor([  5.3645, -17.2865])\n",
      "    Grad  :  tensor([-0.0005,  0.0031])\n",
      "Epoch 4039,Loss 2.927674\n",
      "Epoch 4039, Loss 2.927674\n",
      "    Params:  tensor([  5.3645, -17.2865])\n",
      "    Grad  :  tensor([-0.0005,  0.0031])\n",
      "Epoch 4040,Loss 2.927676\n",
      "Epoch 4040, Loss 2.927676\n",
      "    Params:  tensor([  5.3645, -17.2865])\n",
      "    Grad  :  tensor([-0.0005,  0.0031])\n",
      "Epoch 4041,Loss 2.927675\n",
      "Epoch 4041, Loss 2.927675\n",
      "    Params:  tensor([  5.3645, -17.2866])\n",
      "    Grad  :  tensor([-0.0006,  0.0031])\n",
      "Epoch 4042,Loss 2.927675\n",
      "Epoch 4042, Loss 2.927675\n",
      "    Params:  tensor([  5.3645, -17.2866])\n",
      "    Grad  :  tensor([-0.0005,  0.0031])\n",
      "Epoch 4043,Loss 2.927675\n",
      "Epoch 4043, Loss 2.927675\n",
      "    Params:  tensor([  5.3645, -17.2866])\n",
      "    Grad  :  tensor([-0.0005,  0.0031])\n",
      "Epoch 4044,Loss 2.927674\n",
      "Epoch 4044, Loss 2.927674\n",
      "    Params:  tensor([  5.3645, -17.2867])\n",
      "    Grad  :  tensor([-0.0005,  0.0031])\n",
      "Epoch 4045,Loss 2.927674\n",
      "Epoch 4045, Loss 2.927674\n",
      "    Params:  tensor([  5.3645, -17.2867])\n",
      "    Grad  :  tensor([-0.0006,  0.0031])\n",
      "Epoch 4046,Loss 2.927675\n",
      "Epoch 4046, Loss 2.927675\n",
      "    Params:  tensor([  5.3645, -17.2867])\n",
      "    Grad  :  tensor([-0.0005,  0.0031])\n",
      "Epoch 4047,Loss 2.927674\n",
      "Epoch 4047, Loss 2.927674\n",
      "    Params:  tensor([  5.3645, -17.2868])\n",
      "    Grad  :  tensor([-0.0005,  0.0031])\n",
      "Epoch 4048,Loss 2.927674\n",
      "Epoch 4048, Loss 2.927674\n",
      "    Params:  tensor([  5.3645, -17.2868])\n",
      "    Grad  :  tensor([-0.0006,  0.0031])\n",
      "Epoch 4049,Loss 2.927675\n",
      "Epoch 4049, Loss 2.927675\n",
      "    Params:  tensor([  5.3645, -17.2868])\n",
      "    Grad  :  tensor([-0.0005,  0.0031])\n",
      "Epoch 4050,Loss 2.927672\n",
      "Epoch 4050, Loss 2.927672\n",
      "    Params:  tensor([  5.3646, -17.2868])\n",
      "    Grad  :  tensor([-0.0005,  0.0031])\n",
      "Epoch 4051,Loss 2.927675\n",
      "Epoch 4051, Loss 2.927675\n",
      "    Params:  tensor([  5.3646, -17.2869])\n",
      "    Grad  :  tensor([-0.0005,  0.0030])\n",
      "Epoch 4052,Loss 2.927675\n",
      "Epoch 4052, Loss 2.927675\n",
      "    Params:  tensor([  5.3646, -17.2869])\n",
      "    Grad  :  tensor([-0.0006,  0.0030])\n",
      "Epoch 4053,Loss 2.927673\n",
      "Epoch 4053, Loss 2.927673\n",
      "    Params:  tensor([  5.3646, -17.2869])\n",
      "    Grad  :  tensor([-0.0005,  0.0030])\n",
      "Epoch 4054,Loss 2.927673\n",
      "Epoch 4054, Loss 2.927673\n",
      "    Params:  tensor([  5.3646, -17.2870])\n",
      "    Grad  :  tensor([-0.0005,  0.0030])\n",
      "Epoch 4055,Loss 2.927674\n",
      "Epoch 4055, Loss 2.927674\n",
      "    Params:  tensor([  5.3646, -17.2870])\n",
      "    Grad  :  tensor([-0.0005,  0.0030])\n",
      "Epoch 4056,Loss 2.927673\n",
      "Epoch 4056, Loss 2.927673\n",
      "    Params:  tensor([  5.3646, -17.2870])\n",
      "    Grad  :  tensor([-0.0006,  0.0030])\n",
      "Epoch 4057,Loss 2.927674\n",
      "Epoch 4057, Loss 2.927674\n",
      "    Params:  tensor([  5.3646, -17.2871])\n",
      "    Grad  :  tensor([-0.0005,  0.0030])\n",
      "Epoch 4058,Loss 2.927672\n",
      "Epoch 4058, Loss 2.927672\n",
      "    Params:  tensor([  5.3646, -17.2871])\n",
      "    Grad  :  tensor([-0.0005,  0.0030])\n",
      "Epoch 4059,Loss 2.927674\n",
      "Epoch 4059, Loss 2.927674\n",
      "    Params:  tensor([  5.3646, -17.2871])\n",
      "    Grad  :  tensor([-0.0006,  0.0030])\n",
      "Epoch 4060,Loss 2.927675\n",
      "Epoch 4060, Loss 2.927675\n",
      "    Params:  tensor([  5.3646, -17.2872])\n",
      "    Grad  :  tensor([-0.0005,  0.0030])\n",
      "Epoch 4061,Loss 2.927672\n",
      "Epoch 4061, Loss 2.927672\n",
      "    Params:  tensor([  5.3646, -17.2872])\n",
      "    Grad  :  tensor([-0.0005,  0.0030])\n",
      "Epoch 4062,Loss 2.927673\n",
      "Epoch 4062, Loss 2.927673\n",
      "    Params:  tensor([  5.3646, -17.2872])\n",
      "    Grad  :  tensor([-0.0005,  0.0030])\n",
      "Epoch 4063,Loss 2.927675\n",
      "Epoch 4063, Loss 2.927675\n",
      "    Params:  tensor([  5.3646, -17.2872])\n",
      "    Grad  :  tensor([-0.0006,  0.0030])\n",
      "Epoch 4064,Loss 2.927673\n",
      "Epoch 4064, Loss 2.927673\n",
      "    Params:  tensor([  5.3646, -17.2873])\n",
      "    Grad  :  tensor([-0.0005,  0.0030])\n",
      "Epoch 4065,Loss 2.927674\n",
      "Epoch 4065, Loss 2.927674\n",
      "    Params:  tensor([  5.3646, -17.2873])\n",
      "    Grad  :  tensor([-0.0005,  0.0030])\n",
      "Epoch 4066,Loss 2.927672\n",
      "Epoch 4066, Loss 2.927672\n",
      "    Params:  tensor([  5.3646, -17.2873])\n",
      "    Grad  :  tensor([-0.0005,  0.0030])\n",
      "Epoch 4067,Loss 2.927673\n",
      "Epoch 4067, Loss 2.927673\n",
      "    Params:  tensor([  5.3646, -17.2874])\n",
      "    Grad  :  tensor([-0.0005,  0.0030])\n",
      "Epoch 4068,Loss 2.927673\n",
      "Epoch 4068, Loss 2.927673\n",
      "    Params:  tensor([  5.3646, -17.2874])\n",
      "    Grad  :  tensor([-0.0005,  0.0030])\n",
      "Epoch 4069,Loss 2.927672\n",
      "Epoch 4069, Loss 2.927672\n",
      "    Params:  tensor([  5.3647, -17.2874])\n",
      "    Grad  :  tensor([-0.0005,  0.0030])\n",
      "Epoch 4070,Loss 2.927672\n",
      "Epoch 4070, Loss 2.927672\n",
      "    Params:  tensor([  5.3647, -17.2875])\n",
      "    Grad  :  tensor([-0.0005,  0.0030])\n",
      "Epoch 4071,Loss 2.927673\n",
      "Epoch 4071, Loss 2.927673\n",
      "    Params:  tensor([  5.3647, -17.2875])\n",
      "    Grad  :  tensor([-0.0005,  0.0029])\n",
      "Epoch 4072,Loss 2.927673\n",
      "Epoch 4072, Loss 2.927673\n",
      "    Params:  tensor([  5.3647, -17.2875])\n",
      "    Grad  :  tensor([-0.0005,  0.0029])\n",
      "Epoch 4073,Loss 2.927671\n",
      "Epoch 4073, Loss 2.927671\n",
      "    Params:  tensor([  5.3647, -17.2875])\n",
      "    Grad  :  tensor([-0.0005,  0.0029])\n",
      "Epoch 4074,Loss 2.927673\n",
      "Epoch 4074, Loss 2.927673\n",
      "    Params:  tensor([  5.3647, -17.2876])\n",
      "    Grad  :  tensor([-0.0005,  0.0029])\n",
      "Epoch 4075,Loss 2.927672\n",
      "Epoch 4075, Loss 2.927672\n",
      "    Params:  tensor([  5.3647, -17.2876])\n",
      "    Grad  :  tensor([-0.0005,  0.0029])\n",
      "Epoch 4076,Loss 2.927672\n",
      "Epoch 4076, Loss 2.927672\n",
      "    Params:  tensor([  5.3647, -17.2876])\n",
      "    Grad  :  tensor([-0.0005,  0.0029])\n",
      "Epoch 4077,Loss 2.927672\n",
      "Epoch 4077, Loss 2.927672\n",
      "    Params:  tensor([  5.3647, -17.2877])\n",
      "    Grad  :  tensor([-0.0005,  0.0029])\n",
      "Epoch 4078,Loss 2.927670\n",
      "Epoch 4078, Loss 2.927670\n",
      "    Params:  tensor([  5.3647, -17.2877])\n",
      "    Grad  :  tensor([-0.0005,  0.0029])\n",
      "Epoch 4079,Loss 2.927672\n",
      "Epoch 4079, Loss 2.927672\n",
      "    Params:  tensor([  5.3647, -17.2877])\n",
      "    Grad  :  tensor([-0.0005,  0.0029])\n",
      "Epoch 4080,Loss 2.927672\n",
      "Epoch 4080, Loss 2.927672\n",
      "    Params:  tensor([  5.3647, -17.2877])\n",
      "    Grad  :  tensor([-0.0005,  0.0029])\n",
      "Epoch 4081,Loss 2.927671\n",
      "Epoch 4081, Loss 2.927671\n",
      "    Params:  tensor([  5.3647, -17.2878])\n",
      "    Grad  :  tensor([-0.0005,  0.0029])\n",
      "Epoch 4082,Loss 2.927670\n",
      "Epoch 4082, Loss 2.927670\n",
      "    Params:  tensor([  5.3647, -17.2878])\n",
      "    Grad  :  tensor([-0.0005,  0.0029])\n",
      "Epoch 4083,Loss 2.927673\n",
      "Epoch 4083, Loss 2.927673\n",
      "    Params:  tensor([  5.3647, -17.2878])\n",
      "    Grad  :  tensor([-0.0005,  0.0029])\n",
      "Epoch 4084,Loss 2.927672\n",
      "Epoch 4084, Loss 2.927672\n",
      "    Params:  tensor([  5.3647, -17.2879])\n",
      "    Grad  :  tensor([-0.0005,  0.0029])\n",
      "Epoch 4085,Loss 2.927670\n",
      "Epoch 4085, Loss 2.927670\n",
      "    Params:  tensor([  5.3647, -17.2879])\n",
      "    Grad  :  tensor([-0.0005,  0.0029])\n",
      "Epoch 4086,Loss 2.927670\n",
      "Epoch 4086, Loss 2.927670\n",
      "    Params:  tensor([  5.3647, -17.2879])\n",
      "    Grad  :  tensor([-0.0005,  0.0029])\n",
      "Epoch 4087,Loss 2.927670\n",
      "Epoch 4087, Loss 2.927670\n",
      "    Params:  tensor([  5.3647, -17.2879])\n",
      "    Grad  :  tensor([-0.0005,  0.0029])\n",
      "Epoch 4088,Loss 2.927672\n",
      "Epoch 4088, Loss 2.927672\n",
      "    Params:  tensor([  5.3647, -17.2880])\n",
      "    Grad  :  tensor([-0.0005,  0.0029])\n",
      "Epoch 4089,Loss 2.927670\n",
      "Epoch 4089, Loss 2.927670\n",
      "    Params:  tensor([  5.3648, -17.2880])\n",
      "    Grad  :  tensor([-0.0005,  0.0029])\n",
      "Epoch 4090,Loss 2.927670\n",
      "Epoch 4090, Loss 2.927670\n",
      "    Params:  tensor([  5.3648, -17.2880])\n",
      "    Grad  :  tensor([-0.0005,  0.0029])\n",
      "Epoch 4091,Loss 2.927670\n",
      "Epoch 4091, Loss 2.927670\n",
      "    Params:  tensor([  5.3648, -17.2881])\n",
      "    Grad  :  tensor([-0.0005,  0.0028])\n",
      "Epoch 4092,Loss 2.927670\n",
      "Epoch 4092, Loss 2.927670\n",
      "    Params:  tensor([  5.3648, -17.2881])\n",
      "    Grad  :  tensor([-0.0005,  0.0028])\n",
      "Epoch 4093,Loss 2.927670\n",
      "Epoch 4093, Loss 2.927670\n",
      "    Params:  tensor([  5.3648, -17.2881])\n",
      "    Grad  :  tensor([-0.0005,  0.0028])\n",
      "Epoch 4094,Loss 2.927670\n",
      "Epoch 4094, Loss 2.927670\n",
      "    Params:  tensor([  5.3648, -17.2881])\n",
      "    Grad  :  tensor([-0.0005,  0.0028])\n",
      "Epoch 4095,Loss 2.927669\n",
      "Epoch 4095, Loss 2.927669\n",
      "    Params:  tensor([  5.3648, -17.2882])\n",
      "    Grad  :  tensor([-0.0005,  0.0028])\n",
      "Epoch 4096,Loss 2.927670\n",
      "Epoch 4096, Loss 2.927670\n",
      "    Params:  tensor([  5.3648, -17.2882])\n",
      "    Grad  :  tensor([-0.0005,  0.0028])\n",
      "Epoch 4097,Loss 2.927670\n",
      "Epoch 4097, Loss 2.927670\n",
      "    Params:  tensor([  5.3648, -17.2882])\n",
      "    Grad  :  tensor([-0.0005,  0.0028])\n",
      "Epoch 4098,Loss 2.927671\n",
      "Epoch 4098, Loss 2.927671\n",
      "    Params:  tensor([  5.3648, -17.2883])\n",
      "    Grad  :  tensor([-0.0005,  0.0028])\n",
      "Epoch 4099,Loss 2.927670\n",
      "Epoch 4099, Loss 2.927670\n",
      "    Params:  tensor([  5.3648, -17.2883])\n",
      "    Grad  :  tensor([-0.0005,  0.0028])\n",
      "Epoch 4100,Loss 2.927671\n",
      "Epoch 4100, Loss 2.927671\n",
      "    Params:  tensor([  5.3648, -17.2883])\n",
      "    Grad  :  tensor([-0.0005,  0.0028])\n",
      "Epoch 4101,Loss 2.927670\n",
      "Epoch 4101, Loss 2.927670\n",
      "    Params:  tensor([  5.3648, -17.2883])\n",
      "    Grad  :  tensor([-0.0005,  0.0028])\n",
      "Epoch 4102,Loss 2.927670\n",
      "Epoch 4102, Loss 2.927670\n",
      "    Params:  tensor([  5.3648, -17.2884])\n",
      "    Grad  :  tensor([-0.0005,  0.0028])\n",
      "Epoch 4103,Loss 2.927671\n",
      "Epoch 4103, Loss 2.927671\n",
      "    Params:  tensor([  5.3648, -17.2884])\n",
      "    Grad  :  tensor([-0.0005,  0.0028])\n",
      "Epoch 4104,Loss 2.927669\n",
      "Epoch 4104, Loss 2.927669\n",
      "    Params:  tensor([  5.3648, -17.2884])\n",
      "    Grad  :  tensor([-0.0005,  0.0028])\n",
      "Epoch 4105,Loss 2.927670\n",
      "Epoch 4105, Loss 2.927670\n",
      "    Params:  tensor([  5.3648, -17.2885])\n",
      "    Grad  :  tensor([-0.0005,  0.0028])\n",
      "Epoch 4106,Loss 2.927670\n",
      "Epoch 4106, Loss 2.927670\n",
      "    Params:  tensor([  5.3648, -17.2885])\n",
      "    Grad  :  tensor([-0.0005,  0.0028])\n",
      "Epoch 4107,Loss 2.927670\n",
      "Epoch 4107, Loss 2.927670\n",
      "    Params:  tensor([  5.3648, -17.2885])\n",
      "    Grad  :  tensor([-0.0005,  0.0028])\n",
      "Epoch 4108,Loss 2.927670\n",
      "Epoch 4108, Loss 2.927670\n",
      "    Params:  tensor([  5.3648, -17.2885])\n",
      "    Grad  :  tensor([-0.0005,  0.0028])\n",
      "Epoch 4109,Loss 2.927668\n",
      "Epoch 4109, Loss 2.927668\n",
      "    Params:  tensor([  5.3649, -17.2886])\n",
      "    Grad  :  tensor([-0.0005,  0.0028])\n",
      "Epoch 4110,Loss 2.927669\n",
      "Epoch 4110, Loss 2.927669\n",
      "    Params:  tensor([  5.3649, -17.2886])\n",
      "    Grad  :  tensor([-0.0005,  0.0028])\n",
      "Epoch 4111,Loss 2.927669\n",
      "Epoch 4111, Loss 2.927669\n",
      "    Params:  tensor([  5.3649, -17.2886])\n",
      "    Grad  :  tensor([-0.0005,  0.0028])\n",
      "Epoch 4112,Loss 2.927670\n",
      "Epoch 4112, Loss 2.927670\n",
      "    Params:  tensor([  5.3649, -17.2886])\n",
      "    Grad  :  tensor([-0.0005,  0.0027])\n",
      "Epoch 4113,Loss 2.927670\n",
      "Epoch 4113, Loss 2.927670\n",
      "    Params:  tensor([  5.3649, -17.2887])\n",
      "    Grad  :  tensor([-0.0005,  0.0027])\n",
      "Epoch 4114,Loss 2.927670\n",
      "Epoch 4114, Loss 2.927670\n",
      "    Params:  tensor([  5.3649, -17.2887])\n",
      "    Grad  :  tensor([-0.0005,  0.0027])\n",
      "Epoch 4115,Loss 2.927670\n",
      "Epoch 4115, Loss 2.927670\n",
      "    Params:  tensor([  5.3649, -17.2887])\n",
      "    Grad  :  tensor([-0.0005,  0.0027])\n",
      "Epoch 4116,Loss 2.927669\n",
      "Epoch 4116, Loss 2.927669\n",
      "    Params:  tensor([  5.3649, -17.2887])\n",
      "    Grad  :  tensor([-0.0005,  0.0027])\n",
      "Epoch 4117,Loss 2.927669\n",
      "Epoch 4117, Loss 2.927669\n",
      "    Params:  tensor([  5.3649, -17.2888])\n",
      "    Grad  :  tensor([-0.0004,  0.0027])\n",
      "Epoch 4118,Loss 2.927670\n",
      "Epoch 4118, Loss 2.927670\n",
      "    Params:  tensor([  5.3649, -17.2888])\n",
      "    Grad  :  tensor([-0.0005,  0.0027])\n",
      "Epoch 4119,Loss 2.927669\n",
      "Epoch 4119, Loss 2.927669\n",
      "    Params:  tensor([  5.3649, -17.2888])\n",
      "    Grad  :  tensor([-0.0005,  0.0027])\n",
      "Epoch 4120,Loss 2.927670\n",
      "Epoch 4120, Loss 2.927670\n",
      "    Params:  tensor([  5.3649, -17.2889])\n",
      "    Grad  :  tensor([-0.0005,  0.0027])\n",
      "Epoch 4121,Loss 2.927668\n",
      "Epoch 4121, Loss 2.927668\n",
      "    Params:  tensor([  5.3649, -17.2889])\n",
      "    Grad  :  tensor([-0.0005,  0.0027])\n",
      "Epoch 4122,Loss 2.927668\n",
      "Epoch 4122, Loss 2.927668\n",
      "    Params:  tensor([  5.3649, -17.2889])\n",
      "    Grad  :  tensor([-0.0005,  0.0027])\n",
      "Epoch 4123,Loss 2.927669\n",
      "Epoch 4123, Loss 2.927669\n",
      "    Params:  tensor([  5.3649, -17.2889])\n",
      "    Grad  :  tensor([-0.0005,  0.0027])\n",
      "Epoch 4124,Loss 2.927668\n",
      "Epoch 4124, Loss 2.927668\n",
      "    Params:  tensor([  5.3649, -17.2890])\n",
      "    Grad  :  tensor([-0.0005,  0.0027])\n",
      "Epoch 4125,Loss 2.927670\n",
      "Epoch 4125, Loss 2.927670\n",
      "    Params:  tensor([  5.3649, -17.2890])\n",
      "    Grad  :  tensor([-0.0005,  0.0027])\n",
      "Epoch 4126,Loss 2.927666\n",
      "Epoch 4126, Loss 2.927666\n",
      "    Params:  tensor([  5.3649, -17.2890])\n",
      "    Grad  :  tensor([-0.0005,  0.0027])\n",
      "Epoch 4127,Loss 2.927669\n",
      "Epoch 4127, Loss 2.927669\n",
      "    Params:  tensor([  5.3649, -17.2890])\n",
      "    Grad  :  tensor([-0.0005,  0.0027])\n",
      "Epoch 4128,Loss 2.927668\n",
      "Epoch 4128, Loss 2.927668\n",
      "    Params:  tensor([  5.3649, -17.2891])\n",
      "    Grad  :  tensor([-0.0005,  0.0027])\n",
      "Epoch 4129,Loss 2.927669\n",
      "Epoch 4129, Loss 2.927669\n",
      "    Params:  tensor([  5.3649, -17.2891])\n",
      "    Grad  :  tensor([-0.0005,  0.0027])\n",
      "Epoch 4130,Loss 2.927667\n",
      "Epoch 4130, Loss 2.927667\n",
      "    Params:  tensor([  5.3650, -17.2891])\n",
      "    Grad  :  tensor([-0.0005,  0.0027])\n",
      "Epoch 4131,Loss 2.927667\n",
      "Epoch 4131, Loss 2.927667\n",
      "    Params:  tensor([  5.3650, -17.2892])\n",
      "    Grad  :  tensor([-0.0004,  0.0027])\n",
      "Epoch 4132,Loss 2.927668\n",
      "Epoch 4132, Loss 2.927668\n",
      "    Params:  tensor([  5.3650, -17.2892])\n",
      "    Grad  :  tensor([-0.0005,  0.0027])\n",
      "Epoch 4133,Loss 2.927667\n",
      "Epoch 4133, Loss 2.927667\n",
      "    Params:  tensor([  5.3650, -17.2892])\n",
      "    Grad  :  tensor([-0.0005,  0.0027])\n",
      "Epoch 4134,Loss 2.927667\n",
      "Epoch 4134, Loss 2.927667\n",
      "    Params:  tensor([  5.3650, -17.2892])\n",
      "    Grad  :  tensor([-0.0005,  0.0026])\n",
      "Epoch 4135,Loss 2.927666\n",
      "Epoch 4135, Loss 2.927666\n",
      "    Params:  tensor([  5.3650, -17.2893])\n",
      "    Grad  :  tensor([-0.0005,  0.0026])\n",
      "Epoch 4136,Loss 2.927666\n",
      "Epoch 4136, Loss 2.927666\n",
      "    Params:  tensor([  5.3650, -17.2893])\n",
      "    Grad  :  tensor([-0.0005,  0.0026])\n",
      "Epoch 4137,Loss 2.927669\n",
      "Epoch 4137, Loss 2.927669\n",
      "    Params:  tensor([  5.3650, -17.2893])\n",
      "    Grad  :  tensor([-0.0005,  0.0026])\n",
      "Epoch 4138,Loss 2.927666\n",
      "Epoch 4138, Loss 2.927666\n",
      "    Params:  tensor([  5.3650, -17.2893])\n",
      "    Grad  :  tensor([-0.0004,  0.0026])\n",
      "Epoch 4139,Loss 2.927668\n",
      "Epoch 4139, Loss 2.927668\n",
      "    Params:  tensor([  5.3650, -17.2894])\n",
      "    Grad  :  tensor([-0.0005,  0.0026])\n",
      "Epoch 4140,Loss 2.927666\n",
      "Epoch 4140, Loss 2.927666\n",
      "    Params:  tensor([  5.3650, -17.2894])\n",
      "    Grad  :  tensor([-0.0005,  0.0026])\n",
      "Epoch 4141,Loss 2.927667\n",
      "Epoch 4141, Loss 2.927667\n",
      "    Params:  tensor([  5.3650, -17.2894])\n",
      "    Grad  :  tensor([-0.0005,  0.0026])\n",
      "Epoch 4142,Loss 2.927667\n",
      "Epoch 4142, Loss 2.927667\n",
      "    Params:  tensor([  5.3650, -17.2894])\n",
      "    Grad  :  tensor([-0.0005,  0.0026])\n",
      "Epoch 4143,Loss 2.927666\n",
      "Epoch 4143, Loss 2.927666\n",
      "    Params:  tensor([  5.3650, -17.2895])\n",
      "    Grad  :  tensor([-0.0005,  0.0026])\n",
      "Epoch 4144,Loss 2.927667\n",
      "Epoch 4144, Loss 2.927667\n",
      "    Params:  tensor([  5.3650, -17.2895])\n",
      "    Grad  :  tensor([-0.0005,  0.0026])\n",
      "Epoch 4145,Loss 2.927666\n",
      "Epoch 4145, Loss 2.927666\n",
      "    Params:  tensor([  5.3650, -17.2895])\n",
      "    Grad  :  tensor([-0.0005,  0.0026])\n",
      "Epoch 4146,Loss 2.927667\n",
      "Epoch 4146, Loss 2.927667\n",
      "    Params:  tensor([  5.3650, -17.2896])\n",
      "    Grad  :  tensor([-0.0005,  0.0026])\n",
      "Epoch 4147,Loss 2.927667\n",
      "Epoch 4147, Loss 2.927667\n",
      "    Params:  tensor([  5.3650, -17.2896])\n",
      "    Grad  :  tensor([-0.0005,  0.0026])\n",
      "Epoch 4148,Loss 2.927667\n",
      "Epoch 4148, Loss 2.927667\n",
      "    Params:  tensor([  5.3650, -17.2896])\n",
      "    Grad  :  tensor([-0.0005,  0.0026])\n",
      "Epoch 4149,Loss 2.927667\n",
      "Epoch 4149, Loss 2.927667\n",
      "    Params:  tensor([  5.3650, -17.2896])\n",
      "    Grad  :  tensor([-0.0005,  0.0026])\n",
      "Epoch 4150,Loss 2.927665\n",
      "Epoch 4150, Loss 2.927665\n",
      "    Params:  tensor([  5.3650, -17.2897])\n",
      "    Grad  :  tensor([-0.0005,  0.0026])\n",
      "Epoch 4151,Loss 2.927666\n",
      "Epoch 4151, Loss 2.927666\n",
      "    Params:  tensor([  5.3651, -17.2897])\n",
      "    Grad  :  tensor([-0.0004,  0.0026])\n",
      "Epoch 4152,Loss 2.927666\n",
      "Epoch 4152, Loss 2.927666\n",
      "    Params:  tensor([  5.3651, -17.2897])\n",
      "    Grad  :  tensor([-0.0004,  0.0026])\n",
      "Epoch 4153,Loss 2.927666\n",
      "Epoch 4153, Loss 2.927666\n",
      "    Params:  tensor([  5.3651, -17.2897])\n",
      "    Grad  :  tensor([-0.0005,  0.0026])\n",
      "Epoch 4154,Loss 2.927666\n",
      "Epoch 4154, Loss 2.927666\n",
      "    Params:  tensor([  5.3651, -17.2898])\n",
      "    Grad  :  tensor([-0.0005,  0.0026])\n",
      "Epoch 4155,Loss 2.927666\n",
      "Epoch 4155, Loss 2.927666\n",
      "    Params:  tensor([  5.3651, -17.2898])\n",
      "    Grad  :  tensor([-0.0004,  0.0026])\n",
      "Epoch 4156,Loss 2.927666\n",
      "Epoch 4156, Loss 2.927666\n",
      "    Params:  tensor([  5.3651, -17.2898])\n",
      "    Grad  :  tensor([-0.0004,  0.0026])\n",
      "Epoch 4157,Loss 2.927666\n",
      "Epoch 4157, Loss 2.927666\n",
      "    Params:  tensor([  5.3651, -17.2898])\n",
      "    Grad  :  tensor([-0.0004,  0.0025])\n",
      "Epoch 4158,Loss 2.927665\n",
      "Epoch 4158, Loss 2.927665\n",
      "    Params:  tensor([  5.3651, -17.2899])\n",
      "    Grad  :  tensor([-0.0004,  0.0025])\n",
      "Epoch 4159,Loss 2.927666\n",
      "Epoch 4159, Loss 2.927666\n",
      "    Params:  tensor([  5.3651, -17.2899])\n",
      "    Grad  :  tensor([-0.0004,  0.0025])\n",
      "Epoch 4160,Loss 2.927665\n",
      "Epoch 4160, Loss 2.927665\n",
      "    Params:  tensor([  5.3651, -17.2899])\n",
      "    Grad  :  tensor([-0.0004,  0.0025])\n",
      "Epoch 4161,Loss 2.927664\n",
      "Epoch 4161, Loss 2.927664\n",
      "    Params:  tensor([  5.3651, -17.2899])\n",
      "    Grad  :  tensor([-0.0005,  0.0025])\n",
      "Epoch 4162,Loss 2.927666\n",
      "Epoch 4162, Loss 2.927666\n",
      "    Params:  tensor([  5.3651, -17.2900])\n",
      "    Grad  :  tensor([-0.0004,  0.0025])\n",
      "Epoch 4163,Loss 2.927665\n",
      "Epoch 4163, Loss 2.927665\n",
      "    Params:  tensor([  5.3651, -17.2900])\n",
      "    Grad  :  tensor([-0.0004,  0.0025])\n",
      "Epoch 4164,Loss 2.927666\n",
      "Epoch 4164, Loss 2.927666\n",
      "    Params:  tensor([  5.3651, -17.2900])\n",
      "    Grad  :  tensor([-0.0004,  0.0025])\n",
      "Epoch 4165,Loss 2.927664\n",
      "Epoch 4165, Loss 2.927664\n",
      "    Params:  tensor([  5.3651, -17.2900])\n",
      "    Grad  :  tensor([-0.0004,  0.0025])\n",
      "Epoch 4166,Loss 2.927665\n",
      "Epoch 4166, Loss 2.927665\n",
      "    Params:  tensor([  5.3651, -17.2901])\n",
      "    Grad  :  tensor([-0.0005,  0.0025])\n",
      "Epoch 4167,Loss 2.927665\n",
      "Epoch 4167, Loss 2.927665\n",
      "    Params:  tensor([  5.3651, -17.2901])\n",
      "    Grad  :  tensor([-0.0005,  0.0025])\n",
      "Epoch 4168,Loss 2.927665\n",
      "Epoch 4168, Loss 2.927665\n",
      "    Params:  tensor([  5.3651, -17.2901])\n",
      "    Grad  :  tensor([-0.0005,  0.0025])\n",
      "Epoch 4169,Loss 2.927666\n",
      "Epoch 4169, Loss 2.927666\n",
      "    Params:  tensor([  5.3651, -17.2901])\n",
      "    Grad  :  tensor([-0.0004,  0.0025])\n",
      "Epoch 4170,Loss 2.927664\n",
      "Epoch 4170, Loss 2.927664\n",
      "    Params:  tensor([  5.3651, -17.2902])\n",
      "    Grad  :  tensor([-0.0004,  0.0025])\n",
      "Epoch 4171,Loss 2.927665\n",
      "Epoch 4171, Loss 2.927665\n",
      "    Params:  tensor([  5.3651, -17.2902])\n",
      "    Grad  :  tensor([-0.0004,  0.0025])\n",
      "Epoch 4172,Loss 2.927666\n",
      "Epoch 4172, Loss 2.927666\n",
      "    Params:  tensor([  5.3651, -17.2902])\n",
      "    Grad  :  tensor([-0.0004,  0.0025])\n",
      "Epoch 4173,Loss 2.927663\n",
      "Epoch 4173, Loss 2.927663\n",
      "    Params:  tensor([  5.3651, -17.2902])\n",
      "    Grad  :  tensor([-0.0005,  0.0025])\n",
      "Epoch 4174,Loss 2.927664\n",
      "Epoch 4174, Loss 2.927664\n",
      "    Params:  tensor([  5.3652, -17.2903])\n",
      "    Grad  :  tensor([-0.0004,  0.0025])\n",
      "Epoch 4175,Loss 2.927664\n",
      "Epoch 4175, Loss 2.927664\n",
      "    Params:  tensor([  5.3652, -17.2903])\n",
      "    Grad  :  tensor([-0.0004,  0.0025])\n",
      "Epoch 4176,Loss 2.927665\n",
      "Epoch 4176, Loss 2.927665\n",
      "    Params:  tensor([  5.3652, -17.2903])\n",
      "    Grad  :  tensor([-0.0004,  0.0025])\n",
      "Epoch 4177,Loss 2.927663\n",
      "Epoch 4177, Loss 2.927663\n",
      "    Params:  tensor([  5.3652, -17.2903])\n",
      "    Grad  :  tensor([-0.0004,  0.0025])\n",
      "Epoch 4178,Loss 2.927664\n",
      "Epoch 4178, Loss 2.927664\n",
      "    Params:  tensor([  5.3652, -17.2903])\n",
      "    Grad  :  tensor([-0.0005,  0.0025])\n",
      "Epoch 4179,Loss 2.927664\n",
      "Epoch 4179, Loss 2.927664\n",
      "    Params:  tensor([  5.3652, -17.2904])\n",
      "    Grad  :  tensor([-0.0004,  0.0024])\n",
      "Epoch 4180,Loss 2.927663\n",
      "Epoch 4180, Loss 2.927663\n",
      "    Params:  tensor([  5.3652, -17.2904])\n",
      "    Grad  :  tensor([-0.0005,  0.0024])\n",
      "Epoch 4181,Loss 2.927664\n",
      "Epoch 4181, Loss 2.927664\n",
      "    Params:  tensor([  5.3652, -17.2904])\n",
      "    Grad  :  tensor([-0.0004,  0.0024])\n",
      "Epoch 4182,Loss 2.927664\n",
      "Epoch 4182, Loss 2.927664\n",
      "    Params:  tensor([  5.3652, -17.2904])\n",
      "    Grad  :  tensor([-0.0004,  0.0024])\n",
      "Epoch 4183,Loss 2.927663\n",
      "Epoch 4183, Loss 2.927663\n",
      "    Params:  tensor([  5.3652, -17.2905])\n",
      "    Grad  :  tensor([-0.0004,  0.0024])\n",
      "Epoch 4184,Loss 2.927664\n",
      "Epoch 4184, Loss 2.927664\n",
      "    Params:  tensor([  5.3652, -17.2905])\n",
      "    Grad  :  tensor([-0.0004,  0.0024])\n",
      "Epoch 4185,Loss 2.927664\n",
      "Epoch 4185, Loss 2.927664\n",
      "    Params:  tensor([  5.3652, -17.2905])\n",
      "    Grad  :  tensor([-0.0004,  0.0024])\n",
      "Epoch 4186,Loss 2.927662\n",
      "Epoch 4186, Loss 2.927662\n",
      "    Params:  tensor([  5.3652, -17.2905])\n",
      "    Grad  :  tensor([-0.0005,  0.0024])\n",
      "Epoch 4187,Loss 2.927665\n",
      "Epoch 4187, Loss 2.927665\n",
      "    Params:  tensor([  5.3652, -17.2906])\n",
      "    Grad  :  tensor([-0.0004,  0.0024])\n",
      "Epoch 4188,Loss 2.927663\n",
      "Epoch 4188, Loss 2.927663\n",
      "    Params:  tensor([  5.3652, -17.2906])\n",
      "    Grad  :  tensor([-0.0004,  0.0024])\n",
      "Epoch 4189,Loss 2.927662\n",
      "Epoch 4189, Loss 2.927662\n",
      "    Params:  tensor([  5.3652, -17.2906])\n",
      "    Grad  :  tensor([-0.0004,  0.0024])\n",
      "Epoch 4190,Loss 2.927663\n",
      "Epoch 4190, Loss 2.927663\n",
      "    Params:  tensor([  5.3652, -17.2906])\n",
      "    Grad  :  tensor([-0.0004,  0.0024])\n",
      "Epoch 4191,Loss 2.927664\n",
      "Epoch 4191, Loss 2.927664\n",
      "    Params:  tensor([  5.3652, -17.2907])\n",
      "    Grad  :  tensor([-0.0004,  0.0024])\n",
      "Epoch 4192,Loss 2.927664\n",
      "Epoch 4192, Loss 2.927664\n",
      "    Params:  tensor([  5.3652, -17.2907])\n",
      "    Grad  :  tensor([-0.0005,  0.0024])\n",
      "Epoch 4193,Loss 2.927662\n",
      "Epoch 4193, Loss 2.927662\n",
      "    Params:  tensor([  5.3652, -17.2907])\n",
      "    Grad  :  tensor([-0.0004,  0.0024])\n",
      "Epoch 4194,Loss 2.927663\n",
      "Epoch 4194, Loss 2.927663\n",
      "    Params:  tensor([  5.3652, -17.2907])\n",
      "    Grad  :  tensor([-0.0004,  0.0024])\n",
      "Epoch 4195,Loss 2.927663\n",
      "Epoch 4195, Loss 2.927663\n",
      "    Params:  tensor([  5.3652, -17.2908])\n",
      "    Grad  :  tensor([-0.0004,  0.0024])\n",
      "Epoch 4196,Loss 2.927665\n",
      "Epoch 4196, Loss 2.927665\n",
      "    Params:  tensor([  5.3652, -17.2908])\n",
      "    Grad  :  tensor([-0.0004,  0.0024])\n",
      "Epoch 4197,Loss 2.927664\n",
      "Epoch 4197, Loss 2.927664\n",
      "    Params:  tensor([  5.3653, -17.2908])\n",
      "    Grad  :  tensor([-0.0004,  0.0024])\n",
      "Epoch 4198,Loss 2.927663\n",
      "Epoch 4198, Loss 2.927663\n",
      "    Params:  tensor([  5.3653, -17.2908])\n",
      "    Grad  :  tensor([-0.0004,  0.0024])\n",
      "Epoch 4199,Loss 2.927662\n",
      "Epoch 4199, Loss 2.927662\n",
      "    Params:  tensor([  5.3653, -17.2909])\n",
      "    Grad  :  tensor([-0.0004,  0.0024])\n",
      "Epoch 4200,Loss 2.927664\n",
      "Epoch 4200, Loss 2.927664\n",
      "    Params:  tensor([  5.3653, -17.2909])\n",
      "    Grad  :  tensor([-0.0004,  0.0024])\n",
      "Epoch 4201,Loss 2.927663\n",
      "Epoch 4201, Loss 2.927663\n",
      "    Params:  tensor([  5.3653, -17.2909])\n",
      "    Grad  :  tensor([-0.0004,  0.0024])\n",
      "Epoch 4202,Loss 2.927661\n",
      "Epoch 4202, Loss 2.927661\n",
      "    Params:  tensor([  5.3653, -17.2909])\n",
      "    Grad  :  tensor([-0.0004,  0.0024])\n",
      "Epoch 4203,Loss 2.927662\n",
      "Epoch 4203, Loss 2.927662\n",
      "    Params:  tensor([  5.3653, -17.2910])\n",
      "    Grad  :  tensor([-0.0004,  0.0024])\n",
      "Epoch 4204,Loss 2.927662\n",
      "Epoch 4204, Loss 2.927662\n",
      "    Params:  tensor([  5.3653, -17.2910])\n",
      "    Grad  :  tensor([-0.0004,  0.0024])\n",
      "Epoch 4205,Loss 2.927663\n",
      "Epoch 4205, Loss 2.927663\n",
      "    Params:  tensor([  5.3653, -17.2910])\n",
      "    Grad  :  tensor([-0.0004,  0.0023])\n",
      "Epoch 4206,Loss 2.927663\n",
      "Epoch 4206, Loss 2.927663\n",
      "    Params:  tensor([  5.3653, -17.2910])\n",
      "    Grad  :  tensor([-0.0004,  0.0023])\n",
      "Epoch 4207,Loss 2.927662\n",
      "Epoch 4207, Loss 2.927662\n",
      "    Params:  tensor([  5.3653, -17.2910])\n",
      "    Grad  :  tensor([-0.0004,  0.0023])\n",
      "Epoch 4208,Loss 2.927662\n",
      "Epoch 4208, Loss 2.927662\n",
      "    Params:  tensor([  5.3653, -17.2911])\n",
      "    Grad  :  tensor([-0.0004,  0.0023])\n",
      "Epoch 4209,Loss 2.927663\n",
      "Epoch 4209, Loss 2.927663\n",
      "    Params:  tensor([  5.3653, -17.2911])\n",
      "    Grad  :  tensor([-0.0004,  0.0023])\n",
      "Epoch 4210,Loss 2.927664\n",
      "Epoch 4210, Loss 2.927664\n",
      "    Params:  tensor([  5.3653, -17.2911])\n",
      "    Grad  :  tensor([-0.0004,  0.0023])\n",
      "Epoch 4211,Loss 2.927662\n",
      "Epoch 4211, Loss 2.927662\n",
      "    Params:  tensor([  5.3653, -17.2911])\n",
      "    Grad  :  tensor([-0.0004,  0.0023])\n",
      "Epoch 4212,Loss 2.927660\n",
      "Epoch 4212, Loss 2.927660\n",
      "    Params:  tensor([  5.3653, -17.2912])\n",
      "    Grad  :  tensor([-0.0004,  0.0023])\n",
      "Epoch 4213,Loss 2.927662\n",
      "Epoch 4213, Loss 2.927662\n",
      "    Params:  tensor([  5.3653, -17.2912])\n",
      "    Grad  :  tensor([-0.0004,  0.0023])\n",
      "Epoch 4214,Loss 2.927662\n",
      "Epoch 4214, Loss 2.927662\n",
      "    Params:  tensor([  5.3653, -17.2912])\n",
      "    Grad  :  tensor([-0.0004,  0.0023])\n",
      "Epoch 4215,Loss 2.927662\n",
      "Epoch 4215, Loss 2.927662\n",
      "    Params:  tensor([  5.3653, -17.2912])\n",
      "    Grad  :  tensor([-0.0004,  0.0023])\n",
      "Epoch 4216,Loss 2.927661\n",
      "Epoch 4216, Loss 2.927661\n",
      "    Params:  tensor([  5.3653, -17.2913])\n",
      "    Grad  :  tensor([-0.0004,  0.0023])\n",
      "Epoch 4217,Loss 2.927660\n",
      "Epoch 4217, Loss 2.927660\n",
      "    Params:  tensor([  5.3653, -17.2913])\n",
      "    Grad  :  tensor([-0.0004,  0.0023])\n",
      "Epoch 4218,Loss 2.927662\n",
      "Epoch 4218, Loss 2.927662\n",
      "    Params:  tensor([  5.3653, -17.2913])\n",
      "    Grad  :  tensor([-0.0004,  0.0023])\n",
      "Epoch 4219,Loss 2.927662\n",
      "Epoch 4219, Loss 2.927662\n",
      "    Params:  tensor([  5.3653, -17.2913])\n",
      "    Grad  :  tensor([-0.0004,  0.0023])\n",
      "Epoch 4220,Loss 2.927663\n",
      "Epoch 4220, Loss 2.927663\n",
      "    Params:  tensor([  5.3653, -17.2913])\n",
      "    Grad  :  tensor([-0.0004,  0.0023])\n",
      "Epoch 4221,Loss 2.927662\n",
      "Epoch 4221, Loss 2.927662\n",
      "    Params:  tensor([  5.3653, -17.2914])\n",
      "    Grad  :  tensor([-0.0004,  0.0023])\n",
      "Epoch 4222,Loss 2.927662\n",
      "Epoch 4222, Loss 2.927662\n",
      "    Params:  tensor([  5.3654, -17.2914])\n",
      "    Grad  :  tensor([-0.0004,  0.0023])\n",
      "Epoch 4223,Loss 2.927662\n",
      "Epoch 4223, Loss 2.927662\n",
      "    Params:  tensor([  5.3654, -17.2914])\n",
      "    Grad  :  tensor([-0.0004,  0.0023])\n",
      "Epoch 4224,Loss 2.927663\n",
      "Epoch 4224, Loss 2.927663\n",
      "    Params:  tensor([  5.3654, -17.2914])\n",
      "    Grad  :  tensor([-0.0004,  0.0023])\n",
      "Epoch 4225,Loss 2.927660\n",
      "Epoch 4225, Loss 2.927660\n",
      "    Params:  tensor([  5.3654, -17.2915])\n",
      "    Grad  :  tensor([-0.0004,  0.0023])\n",
      "Epoch 4226,Loss 2.927662\n",
      "Epoch 4226, Loss 2.927662\n",
      "    Params:  tensor([  5.3654, -17.2915])\n",
      "    Grad  :  tensor([-0.0004,  0.0023])\n",
      "Epoch 4227,Loss 2.927660\n",
      "Epoch 4227, Loss 2.927660\n",
      "    Params:  tensor([  5.3654, -17.2915])\n",
      "    Grad  :  tensor([-0.0004,  0.0023])\n",
      "Epoch 4228,Loss 2.927661\n",
      "Epoch 4228, Loss 2.927661\n",
      "    Params:  tensor([  5.3654, -17.2915])\n",
      "    Grad  :  tensor([-0.0004,  0.0023])\n",
      "Epoch 4229,Loss 2.927661\n",
      "Epoch 4229, Loss 2.927661\n",
      "    Params:  tensor([  5.3654, -17.2915])\n",
      "    Grad  :  tensor([-0.0004,  0.0023])\n",
      "Epoch 4230,Loss 2.927660\n",
      "Epoch 4230, Loss 2.927660\n",
      "    Params:  tensor([  5.3654, -17.2916])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4231,Loss 2.927662\n",
      "Epoch 4231, Loss 2.927662\n",
      "    Params:  tensor([  5.3654, -17.2916])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4232,Loss 2.927662\n",
      "Epoch 4232, Loss 2.927662\n",
      "    Params:  tensor([  5.3654, -17.2916])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4233,Loss 2.927660\n",
      "Epoch 4233, Loss 2.927660\n",
      "    Params:  tensor([  5.3654, -17.2916])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4234,Loss 2.927662\n",
      "Epoch 4234, Loss 2.927662\n",
      "    Params:  tensor([  5.3654, -17.2917])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4235,Loss 2.927661\n",
      "Epoch 4235, Loss 2.927661\n",
      "    Params:  tensor([  5.3654, -17.2917])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4236,Loss 2.927662\n",
      "Epoch 4236, Loss 2.927662\n",
      "    Params:  tensor([  5.3654, -17.2917])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4237,Loss 2.927661\n",
      "Epoch 4237, Loss 2.927661\n",
      "    Params:  tensor([  5.3654, -17.2917])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4238,Loss 2.927660\n",
      "Epoch 4238, Loss 2.927660\n",
      "    Params:  tensor([  5.3654, -17.2918])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4239,Loss 2.927661\n",
      "Epoch 4239, Loss 2.927661\n",
      "    Params:  tensor([  5.3654, -17.2918])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4240,Loss 2.927660\n",
      "Epoch 4240, Loss 2.927660\n",
      "    Params:  tensor([  5.3654, -17.2918])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4241,Loss 2.927662\n",
      "Epoch 4241, Loss 2.927662\n",
      "    Params:  tensor([  5.3654, -17.2918])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4242,Loss 2.927660\n",
      "Epoch 4242, Loss 2.927660\n",
      "    Params:  tensor([  5.3654, -17.2918])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4243,Loss 2.927659\n",
      "Epoch 4243, Loss 2.927659\n",
      "    Params:  tensor([  5.3654, -17.2919])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4244,Loss 2.927661\n",
      "Epoch 4244, Loss 2.927661\n",
      "    Params:  tensor([  5.3654, -17.2919])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4245,Loss 2.927661\n",
      "Epoch 4245, Loss 2.927661\n",
      "    Params:  tensor([  5.3654, -17.2919])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4246,Loss 2.927662\n",
      "Epoch 4246, Loss 2.927662\n",
      "    Params:  tensor([  5.3654, -17.2919])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4247,Loss 2.927660\n",
      "Epoch 4247, Loss 2.927660\n",
      "    Params:  tensor([  5.3655, -17.2920])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4248,Loss 2.927659\n",
      "Epoch 4248, Loss 2.927659\n",
      "    Params:  tensor([  5.3655, -17.2920])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4249,Loss 2.927660\n",
      "Epoch 4249, Loss 2.927660\n",
      "    Params:  tensor([  5.3655, -17.2920])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4250,Loss 2.927660\n",
      "Epoch 4250, Loss 2.927660\n",
      "    Params:  tensor([  5.3655, -17.2920])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4251,Loss 2.927662\n",
      "Epoch 4251, Loss 2.927662\n",
      "    Params:  tensor([  5.3655, -17.2920])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4252,Loss 2.927660\n",
      "Epoch 4252, Loss 2.927660\n",
      "    Params:  tensor([  5.3655, -17.2921])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4253,Loss 2.927660\n",
      "Epoch 4253, Loss 2.927660\n",
      "    Params:  tensor([  5.3655, -17.2921])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4254,Loss 2.927660\n",
      "Epoch 4254, Loss 2.927660\n",
      "    Params:  tensor([  5.3655, -17.2921])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4255,Loss 2.927660\n",
      "Epoch 4255, Loss 2.927660\n",
      "    Params:  tensor([  5.3655, -17.2921])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4256,Loss 2.927660\n",
      "Epoch 4256, Loss 2.927660\n",
      "    Params:  tensor([  5.3655, -17.2921])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4257,Loss 2.927661\n",
      "Epoch 4257, Loss 2.927661\n",
      "    Params:  tensor([  5.3655, -17.2922])\n",
      "    Grad  :  tensor([-0.0004,  0.0022])\n",
      "Epoch 4258,Loss 2.927659\n",
      "Epoch 4258, Loss 2.927659\n",
      "    Params:  tensor([  5.3655, -17.2922])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4259,Loss 2.927660\n",
      "Epoch 4259, Loss 2.927660\n",
      "    Params:  tensor([  5.3655, -17.2922])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4260,Loss 2.927659\n",
      "Epoch 4260, Loss 2.927659\n",
      "    Params:  tensor([  5.3655, -17.2922])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4261,Loss 2.927659\n",
      "Epoch 4261, Loss 2.927659\n",
      "    Params:  tensor([  5.3655, -17.2922])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4262,Loss 2.927662\n",
      "Epoch 4262, Loss 2.927662\n",
      "    Params:  tensor([  5.3655, -17.2923])\n",
      "    Grad  :  tensor([-0.0003,  0.0021])\n",
      "Epoch 4263,Loss 2.927658\n",
      "Epoch 4263, Loss 2.927658\n",
      "    Params:  tensor([  5.3655, -17.2923])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4264,Loss 2.927659\n",
      "Epoch 4264, Loss 2.927659\n",
      "    Params:  tensor([  5.3655, -17.2923])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4265,Loss 2.927660\n",
      "Epoch 4265, Loss 2.927660\n",
      "    Params:  tensor([  5.3655, -17.2923])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4266,Loss 2.927659\n",
      "Epoch 4266, Loss 2.927659\n",
      "    Params:  tensor([  5.3655, -17.2924])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4267,Loss 2.927660\n",
      "Epoch 4267, Loss 2.927660\n",
      "    Params:  tensor([  5.3655, -17.2924])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4268,Loss 2.927660\n",
      "Epoch 4268, Loss 2.927660\n",
      "    Params:  tensor([  5.3655, -17.2924])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4269,Loss 2.927659\n",
      "Epoch 4269, Loss 2.927659\n",
      "    Params:  tensor([  5.3655, -17.2924])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4270,Loss 2.927660\n",
      "Epoch 4270, Loss 2.927660\n",
      "    Params:  tensor([  5.3655, -17.2924])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4271,Loss 2.927660\n",
      "Epoch 4271, Loss 2.927660\n",
      "    Params:  tensor([  5.3655, -17.2925])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4272,Loss 2.927660\n",
      "Epoch 4272, Loss 2.927660\n",
      "    Params:  tensor([  5.3655, -17.2925])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4273,Loss 2.927660\n",
      "Epoch 4273, Loss 2.927660\n",
      "    Params:  tensor([  5.3655, -17.2925])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4274,Loss 2.927658\n",
      "Epoch 4274, Loss 2.927658\n",
      "    Params:  tensor([  5.3656, -17.2925])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4275,Loss 2.927659\n",
      "Epoch 4275, Loss 2.927659\n",
      "    Params:  tensor([  5.3656, -17.2925])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4276,Loss 2.927660\n",
      "Epoch 4276, Loss 2.927660\n",
      "    Params:  tensor([  5.3656, -17.2926])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4277,Loss 2.927659\n",
      "Epoch 4277, Loss 2.927659\n",
      "    Params:  tensor([  5.3656, -17.2926])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4278,Loss 2.927659\n",
      "Epoch 4278, Loss 2.927659\n",
      "    Params:  tensor([  5.3656, -17.2926])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4279,Loss 2.927658\n",
      "Epoch 4279, Loss 2.927658\n",
      "    Params:  tensor([  5.3656, -17.2926])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4280,Loss 2.927658\n",
      "Epoch 4280, Loss 2.927658\n",
      "    Params:  tensor([  5.3656, -17.2926])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4281,Loss 2.927659\n",
      "Epoch 4281, Loss 2.927659\n",
      "    Params:  tensor([  5.3656, -17.2927])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4282,Loss 2.927659\n",
      "Epoch 4282, Loss 2.927659\n",
      "    Params:  tensor([  5.3656, -17.2927])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4283,Loss 2.927660\n",
      "Epoch 4283, Loss 2.927660\n",
      "    Params:  tensor([  5.3656, -17.2927])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4284,Loss 2.927660\n",
      "Epoch 4284, Loss 2.927660\n",
      "    Params:  tensor([  5.3656, -17.2927])\n",
      "    Grad  :  tensor([-0.0004,  0.0021])\n",
      "Epoch 4285,Loss 2.927658\n",
      "Epoch 4285, Loss 2.927658\n",
      "    Params:  tensor([  5.3656, -17.2927])\n",
      "    Grad  :  tensor([-0.0004,  0.0020])\n",
      "Epoch 4286,Loss 2.927659\n",
      "Epoch 4286, Loss 2.927659\n",
      "    Params:  tensor([  5.3656, -17.2928])\n",
      "    Grad  :  tensor([-0.0004,  0.0020])\n",
      "Epoch 4287,Loss 2.927658\n",
      "Epoch 4287, Loss 2.927658\n",
      "    Params:  tensor([  5.3656, -17.2928])\n",
      "    Grad  :  tensor([-0.0004,  0.0020])\n",
      "Epoch 4288,Loss 2.927659\n",
      "Epoch 4288, Loss 2.927659\n",
      "    Params:  tensor([  5.3656, -17.2928])\n",
      "    Grad  :  tensor([-0.0004,  0.0020])\n",
      "Epoch 4289,Loss 2.927658\n",
      "Epoch 4289, Loss 2.927658\n",
      "    Params:  tensor([  5.3656, -17.2928])\n",
      "    Grad  :  tensor([-0.0004,  0.0020])\n",
      "Epoch 4290,Loss 2.927657\n",
      "Epoch 4290, Loss 2.927657\n",
      "    Params:  tensor([  5.3656, -17.2929])\n",
      "    Grad  :  tensor([-0.0004,  0.0020])\n",
      "Epoch 4291,Loss 2.927659\n",
      "Epoch 4291, Loss 2.927659\n",
      "    Params:  tensor([  5.3656, -17.2929])\n",
      "    Grad  :  tensor([-0.0004,  0.0020])\n",
      "Epoch 4292,Loss 2.927659\n",
      "Epoch 4292, Loss 2.927659\n",
      "    Params:  tensor([  5.3656, -17.2929])\n",
      "    Grad  :  tensor([-0.0004,  0.0020])\n",
      "Epoch 4293,Loss 2.927659\n",
      "Epoch 4293, Loss 2.927659\n",
      "    Params:  tensor([  5.3656, -17.2929])\n",
      "    Grad  :  tensor([-0.0004,  0.0020])\n",
      "Epoch 4294,Loss 2.927659\n",
      "Epoch 4294, Loss 2.927659\n",
      "    Params:  tensor([  5.3656, -17.2929])\n",
      "    Grad  :  tensor([-0.0003,  0.0020])\n",
      "Epoch 4295,Loss 2.927659\n",
      "Epoch 4295, Loss 2.927659\n",
      "    Params:  tensor([  5.3656, -17.2930])\n",
      "    Grad  :  tensor([-0.0004,  0.0020])\n",
      "Epoch 4296,Loss 2.927657\n",
      "Epoch 4296, Loss 2.927657\n",
      "    Params:  tensor([  5.3656, -17.2930])\n",
      "    Grad  :  tensor([-0.0004,  0.0020])\n",
      "Epoch 4297,Loss 2.927657\n",
      "Epoch 4297, Loss 2.927657\n",
      "    Params:  tensor([  5.3656, -17.2930])\n",
      "    Grad  :  tensor([-0.0004,  0.0020])\n",
      "Epoch 4298,Loss 2.927657\n",
      "Epoch 4298, Loss 2.927657\n",
      "    Params:  tensor([  5.3656, -17.2930])\n",
      "    Grad  :  tensor([-0.0004,  0.0020])\n",
      "Epoch 4299,Loss 2.927658\n",
      "Epoch 4299, Loss 2.927658\n",
      "    Params:  tensor([  5.3656, -17.2930])\n",
      "    Grad  :  tensor([-0.0004,  0.0020])\n",
      "Epoch 4300,Loss 2.927659\n",
      "Epoch 4300, Loss 2.927659\n",
      "    Params:  tensor([  5.3656, -17.2931])\n",
      "    Grad  :  tensor([-0.0004,  0.0020])\n",
      "Epoch 4301,Loss 2.927660\n",
      "Epoch 4301, Loss 2.927660\n",
      "    Params:  tensor([  5.3657, -17.2931])\n",
      "    Grad  :  tensor([-0.0004,  0.0020])\n",
      "Epoch 4302,Loss 2.927657\n",
      "Epoch 4302, Loss 2.927657\n",
      "    Params:  tensor([  5.3657, -17.2931])\n",
      "    Grad  :  tensor([-0.0003,  0.0020])\n",
      "Epoch 4303,Loss 2.927658\n",
      "Epoch 4303, Loss 2.927658\n",
      "    Params:  tensor([  5.3657, -17.2931])\n",
      "    Grad  :  tensor([-0.0003,  0.0020])\n",
      "Epoch 4304,Loss 2.927658\n",
      "Epoch 4304, Loss 2.927658\n",
      "    Params:  tensor([  5.3657, -17.2931])\n",
      "    Grad  :  tensor([-0.0003,  0.0020])\n",
      "Epoch 4305,Loss 2.927658\n",
      "Epoch 4305, Loss 2.927658\n",
      "    Params:  tensor([  5.3657, -17.2932])\n",
      "    Grad  :  tensor([-0.0003,  0.0020])\n",
      "Epoch 4306,Loss 2.927658\n",
      "Epoch 4306, Loss 2.927658\n",
      "    Params:  tensor([  5.3657, -17.2932])\n",
      "    Grad  :  tensor([-0.0003,  0.0020])\n",
      "Epoch 4307,Loss 2.927657\n",
      "Epoch 4307, Loss 2.927657\n",
      "    Params:  tensor([  5.3657, -17.2932])\n",
      "    Grad  :  tensor([-0.0003,  0.0020])\n",
      "Epoch 4308,Loss 2.927657\n",
      "Epoch 4308, Loss 2.927657\n",
      "    Params:  tensor([  5.3657, -17.2932])\n",
      "    Grad  :  tensor([-0.0003,  0.0020])\n",
      "Epoch 4309,Loss 2.927658\n",
      "Epoch 4309, Loss 2.927658\n",
      "    Params:  tensor([  5.3657, -17.2932])\n",
      "    Grad  :  tensor([-0.0003,  0.0020])\n",
      "Epoch 4310,Loss 2.927657\n",
      "Epoch 4310, Loss 2.927657\n",
      "    Params:  tensor([  5.3657, -17.2932])\n",
      "    Grad  :  tensor([-0.0003,  0.0020])\n",
      "Epoch 4311,Loss 2.927660\n",
      "Epoch 4311, Loss 2.927660\n",
      "    Params:  tensor([  5.3657, -17.2933])\n",
      "    Grad  :  tensor([-0.0003,  0.0020])\n",
      "Epoch 4312,Loss 2.927659\n",
      "Epoch 4312, Loss 2.927659\n",
      "    Params:  tensor([  5.3657, -17.2933])\n",
      "    Grad  :  tensor([-0.0003,  0.0020])\n",
      "Epoch 4313,Loss 2.927658\n",
      "Epoch 4313, Loss 2.927658\n",
      "    Params:  tensor([  5.3657, -17.2933])\n",
      "    Grad  :  tensor([-0.0003,  0.0020])\n",
      "Epoch 4314,Loss 2.927656\n",
      "Epoch 4314, Loss 2.927656\n",
      "    Params:  tensor([  5.3657, -17.2933])\n",
      "    Grad  :  tensor([-0.0003,  0.0019])\n",
      "Epoch 4315,Loss 2.927658\n",
      "Epoch 4315, Loss 2.927658\n",
      "    Params:  tensor([  5.3657, -17.2933])\n",
      "    Grad  :  tensor([-0.0003,  0.0019])\n",
      "Epoch 4316,Loss 2.927657\n",
      "Epoch 4316, Loss 2.927657\n",
      "    Params:  tensor([  5.3657, -17.2934])\n",
      "    Grad  :  tensor([-0.0003,  0.0019])\n",
      "Epoch 4317,Loss 2.927657\n",
      "Epoch 4317, Loss 2.927657\n",
      "    Params:  tensor([  5.3657, -17.2934])\n",
      "    Grad  :  tensor([-0.0003,  0.0019])\n",
      "Epoch 4318,Loss 2.927658\n",
      "Epoch 4318, Loss 2.927658\n",
      "    Params:  tensor([  5.3657, -17.2934])\n",
      "    Grad  :  tensor([-0.0003,  0.0019])\n",
      "Epoch 4319,Loss 2.927658\n",
      "Epoch 4319, Loss 2.927658\n",
      "    Params:  tensor([  5.3657, -17.2934])\n",
      "    Grad  :  tensor([-0.0003,  0.0019])\n",
      "Epoch 4320,Loss 2.927657\n",
      "Epoch 4320, Loss 2.927657\n",
      "    Params:  tensor([  5.3657, -17.2934])\n",
      "    Grad  :  tensor([-0.0004,  0.0019])\n",
      "Epoch 4321,Loss 2.927656\n",
      "Epoch 4321, Loss 2.927656\n",
      "    Params:  tensor([  5.3657, -17.2935])\n",
      "    Grad  :  tensor([-0.0004,  0.0019])\n",
      "Epoch 4322,Loss 2.927657\n",
      "Epoch 4322, Loss 2.927657\n",
      "    Params:  tensor([  5.3657, -17.2935])\n",
      "    Grad  :  tensor([-0.0003,  0.0019])\n",
      "Epoch 4323,Loss 2.927657\n",
      "Epoch 4323, Loss 2.927657\n",
      "    Params:  tensor([  5.3657, -17.2935])\n",
      "    Grad  :  tensor([-0.0004,  0.0019])\n",
      "Epoch 4324,Loss 2.927658\n",
      "Epoch 4324, Loss 2.927658\n",
      "    Params:  tensor([  5.3657, -17.2935])\n",
      "    Grad  :  tensor([-0.0004,  0.0019])\n",
      "Epoch 4325,Loss 2.927658\n",
      "Epoch 4325, Loss 2.927658\n",
      "    Params:  tensor([  5.3657, -17.2935])\n",
      "    Grad  :  tensor([-0.0004,  0.0019])\n",
      "Epoch 4326,Loss 2.927657\n",
      "Epoch 4326, Loss 2.927657\n",
      "    Params:  tensor([  5.3657, -17.2936])\n",
      "    Grad  :  tensor([-0.0003,  0.0019])\n",
      "Epoch 4327,Loss 2.927657\n",
      "Epoch 4327, Loss 2.927657\n",
      "    Params:  tensor([  5.3657, -17.2936])\n",
      "    Grad  :  tensor([-0.0003,  0.0019])\n",
      "Epoch 4328,Loss 2.927657\n",
      "Epoch 4328, Loss 2.927657\n",
      "    Params:  tensor([  5.3657, -17.2936])\n",
      "    Grad  :  tensor([-0.0003,  0.0019])\n",
      "Epoch 4329,Loss 2.927656\n",
      "Epoch 4329, Loss 2.927656\n",
      "    Params:  tensor([  5.3657, -17.2936])\n",
      "    Grad  :  tensor([-0.0003,  0.0019])\n",
      "Epoch 4330,Loss 2.927657\n",
      "Epoch 4330, Loss 2.927657\n",
      "    Params:  tensor([  5.3657, -17.2936])\n",
      "    Grad  :  tensor([-0.0003,  0.0019])\n",
      "Epoch 4331,Loss 2.927656\n",
      "Epoch 4331, Loss 2.927656\n",
      "    Params:  tensor([  5.3658, -17.2936])\n",
      "    Grad  :  tensor([-0.0003,  0.0019])\n",
      "Epoch 4332,Loss 2.927656\n",
      "Epoch 4332, Loss 2.927656\n",
      "    Params:  tensor([  5.3658, -17.2937])\n",
      "    Grad  :  tensor([-0.0003,  0.0019])\n",
      "Epoch 4333,Loss 2.927656\n",
      "Epoch 4333, Loss 2.927656\n",
      "    Params:  tensor([  5.3658, -17.2937])\n",
      "    Grad  :  tensor([-0.0003,  0.0019])\n",
      "Epoch 4334,Loss 2.927656\n",
      "Epoch 4334, Loss 2.927656\n",
      "    Params:  tensor([  5.3658, -17.2937])\n",
      "    Grad  :  tensor([-0.0003,  0.0019])\n",
      "Epoch 4335,Loss 2.927656\n",
      "Epoch 4335, Loss 2.927656\n",
      "    Params:  tensor([  5.3658, -17.2937])\n",
      "    Grad  :  tensor([-0.0003,  0.0019])\n",
      "Epoch 4336,Loss 2.927657\n",
      "Epoch 4336, Loss 2.927657\n",
      "    Params:  tensor([  5.3658, -17.2937])\n",
      "    Grad  :  tensor([-0.0003,  0.0019])\n",
      "Epoch 4337,Loss 2.927656\n",
      "Epoch 4337, Loss 2.927656\n",
      "    Params:  tensor([  5.3658, -17.2938])\n",
      "    Grad  :  tensor([-0.0003,  0.0019])\n",
      "Epoch 4338,Loss 2.927656\n",
      "Epoch 4338, Loss 2.927656\n",
      "    Params:  tensor([  5.3658, -17.2938])\n",
      "    Grad  :  tensor([-0.0003,  0.0019])\n",
      "Epoch 4339,Loss 2.927656\n",
      "Epoch 4339, Loss 2.927656\n",
      "    Params:  tensor([  5.3658, -17.2938])\n",
      "    Grad  :  tensor([-0.0003,  0.0019])\n",
      "Epoch 4340,Loss 2.927657\n",
      "Epoch 4340, Loss 2.927657\n",
      "    Params:  tensor([  5.3658, -17.2938])\n",
      "    Grad  :  tensor([-0.0003,  0.0019])\n",
      "Epoch 4341,Loss 2.927656\n",
      "Epoch 4341, Loss 2.927656\n",
      "    Params:  tensor([  5.3658, -17.2938])\n",
      "    Grad  :  tensor([-0.0003,  0.0019])\n",
      "Epoch 4342,Loss 2.927657\n",
      "Epoch 4342, Loss 2.927657\n",
      "    Params:  tensor([  5.3658, -17.2939])\n",
      "    Grad  :  tensor([-0.0004,  0.0019])\n",
      "Epoch 4343,Loss 2.927656\n",
      "Epoch 4343, Loss 2.927656\n",
      "    Params:  tensor([  5.3658, -17.2939])\n",
      "    Grad  :  tensor([-0.0004,  0.0019])\n",
      "Epoch 4344,Loss 2.927656\n",
      "Epoch 4344, Loss 2.927656\n",
      "    Params:  tensor([  5.3658, -17.2939])\n",
      "    Grad  :  tensor([-0.0004,  0.0018])\n",
      "Epoch 4345,Loss 2.927657\n",
      "Epoch 4345, Loss 2.927657\n",
      "    Params:  tensor([  5.3658, -17.2939])\n",
      "    Grad  :  tensor([-0.0004,  0.0018])\n",
      "Epoch 4346,Loss 2.927656\n",
      "Epoch 4346, Loss 2.927656\n",
      "    Params:  tensor([  5.3658, -17.2939])\n",
      "    Grad  :  tensor([-0.0004,  0.0018])\n",
      "Epoch 4347,Loss 2.927656\n",
      "Epoch 4347, Loss 2.927656\n",
      "    Params:  tensor([  5.3658, -17.2940])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4348,Loss 2.927657\n",
      "Epoch 4348, Loss 2.927657\n",
      "    Params:  tensor([  5.3658, -17.2940])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4349,Loss 2.927657\n",
      "Epoch 4349, Loss 2.927657\n",
      "    Params:  tensor([  5.3658, -17.2940])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4350,Loss 2.927656\n",
      "Epoch 4350, Loss 2.927656\n",
      "    Params:  tensor([  5.3658, -17.2940])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4351,Loss 2.927657\n",
      "Epoch 4351, Loss 2.927657\n",
      "    Params:  tensor([  5.3658, -17.2940])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4352,Loss 2.927657\n",
      "Epoch 4352, Loss 2.927657\n",
      "    Params:  tensor([  5.3658, -17.2941])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4353,Loss 2.927657\n",
      "Epoch 4353, Loss 2.927657\n",
      "    Params:  tensor([  5.3658, -17.2941])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4354,Loss 2.927655\n",
      "Epoch 4354, Loss 2.927655\n",
      "    Params:  tensor([  5.3658, -17.2941])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4355,Loss 2.927656\n",
      "Epoch 4355, Loss 2.927656\n",
      "    Params:  tensor([  5.3658, -17.2941])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4356,Loss 2.927656\n",
      "Epoch 4356, Loss 2.927656\n",
      "    Params:  tensor([  5.3658, -17.2941])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4357,Loss 2.927656\n",
      "Epoch 4357, Loss 2.927656\n",
      "    Params:  tensor([  5.3658, -17.2941])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4358,Loss 2.927657\n",
      "Epoch 4358, Loss 2.927657\n",
      "    Params:  tensor([  5.3658, -17.2942])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4359,Loss 2.927656\n",
      "Epoch 4359, Loss 2.927656\n",
      "    Params:  tensor([  5.3658, -17.2942])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4360,Loss 2.927656\n",
      "Epoch 4360, Loss 2.927656\n",
      "    Params:  tensor([  5.3658, -17.2942])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4361,Loss 2.927656\n",
      "Epoch 4361, Loss 2.927656\n",
      "    Params:  tensor([  5.3659, -17.2942])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4362,Loss 2.927655\n",
      "Epoch 4362, Loss 2.927655\n",
      "    Params:  tensor([  5.3659, -17.2942])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4363,Loss 2.927657\n",
      "Epoch 4363, Loss 2.927657\n",
      "    Params:  tensor([  5.3659, -17.2942])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4364,Loss 2.927655\n",
      "Epoch 4364, Loss 2.927655\n",
      "    Params:  tensor([  5.3659, -17.2943])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4365,Loss 2.927656\n",
      "Epoch 4365, Loss 2.927656\n",
      "    Params:  tensor([  5.3659, -17.2943])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4366,Loss 2.927656\n",
      "Epoch 4366, Loss 2.927656\n",
      "    Params:  tensor([  5.3659, -17.2943])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4367,Loss 2.927656\n",
      "Epoch 4367, Loss 2.927656\n",
      "    Params:  tensor([  5.3659, -17.2943])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4368,Loss 2.927654\n",
      "Epoch 4368, Loss 2.927654\n",
      "    Params:  tensor([  5.3659, -17.2943])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4369,Loss 2.927655\n",
      "Epoch 4369, Loss 2.927655\n",
      "    Params:  tensor([  5.3659, -17.2943])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4370,Loss 2.927656\n",
      "Epoch 4370, Loss 2.927656\n",
      "    Params:  tensor([  5.3659, -17.2944])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4371,Loss 2.927655\n",
      "Epoch 4371, Loss 2.927655\n",
      "    Params:  tensor([  5.3659, -17.2944])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4372,Loss 2.927657\n",
      "Epoch 4372, Loss 2.927657\n",
      "    Params:  tensor([  5.3659, -17.2944])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4373,Loss 2.927655\n",
      "Epoch 4373, Loss 2.927655\n",
      "    Params:  tensor([  5.3659, -17.2944])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4374,Loss 2.927657\n",
      "Epoch 4374, Loss 2.927657\n",
      "    Params:  tensor([  5.3659, -17.2944])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4375,Loss 2.927656\n",
      "Epoch 4375, Loss 2.927656\n",
      "    Params:  tensor([  5.3659, -17.2945])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4376,Loss 2.927655\n",
      "Epoch 4376, Loss 2.927655\n",
      "    Params:  tensor([  5.3659, -17.2945])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4377,Loss 2.927654\n",
      "Epoch 4377, Loss 2.927654\n",
      "    Params:  tensor([  5.3659, -17.2945])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4378,Loss 2.927655\n",
      "Epoch 4378, Loss 2.927655\n",
      "    Params:  tensor([  5.3659, -17.2945])\n",
      "    Grad  :  tensor([-0.0003,  0.0018])\n",
      "Epoch 4379,Loss 2.927655\n",
      "Epoch 4379, Loss 2.927655\n",
      "    Params:  tensor([  5.3659, -17.2945])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4380,Loss 2.927654\n",
      "Epoch 4380, Loss 2.927654\n",
      "    Params:  tensor([  5.3659, -17.2945])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4381,Loss 2.927656\n",
      "Epoch 4381, Loss 2.927656\n",
      "    Params:  tensor([  5.3659, -17.2946])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4382,Loss 2.927655\n",
      "Epoch 4382, Loss 2.927655\n",
      "    Params:  tensor([  5.3659, -17.2946])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4383,Loss 2.927655\n",
      "Epoch 4383, Loss 2.927655\n",
      "    Params:  tensor([  5.3659, -17.2946])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4384,Loss 2.927655\n",
      "Epoch 4384, Loss 2.927655\n",
      "    Params:  tensor([  5.3659, -17.2946])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4385,Loss 2.927656\n",
      "Epoch 4385, Loss 2.927656\n",
      "    Params:  tensor([  5.3659, -17.2946])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4386,Loss 2.927655\n",
      "Epoch 4386, Loss 2.927655\n",
      "    Params:  tensor([  5.3659, -17.2946])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4387,Loss 2.927655\n",
      "Epoch 4387, Loss 2.927655\n",
      "    Params:  tensor([  5.3659, -17.2947])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4388,Loss 2.927653\n",
      "Epoch 4388, Loss 2.927653\n",
      "    Params:  tensor([  5.3659, -17.2947])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4389,Loss 2.927654\n",
      "Epoch 4389, Loss 2.927654\n",
      "    Params:  tensor([  5.3659, -17.2947])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4390,Loss 2.927654\n",
      "Epoch 4390, Loss 2.927654\n",
      "    Params:  tensor([  5.3659, -17.2947])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4391,Loss 2.927655\n",
      "Epoch 4391, Loss 2.927655\n",
      "    Params:  tensor([  5.3659, -17.2947])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4392,Loss 2.927656\n",
      "Epoch 4392, Loss 2.927656\n",
      "    Params:  tensor([  5.3659, -17.2947])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4393,Loss 2.927655\n",
      "Epoch 4393, Loss 2.927655\n",
      "    Params:  tensor([  5.3659, -17.2948])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4394,Loss 2.927656\n",
      "Epoch 4394, Loss 2.927656\n",
      "    Params:  tensor([  5.3660, -17.2948])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4395,Loss 2.927655\n",
      "Epoch 4395, Loss 2.927655\n",
      "    Params:  tensor([  5.3660, -17.2948])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4396,Loss 2.927655\n",
      "Epoch 4396, Loss 2.927655\n",
      "    Params:  tensor([  5.3660, -17.2948])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4397,Loss 2.927655\n",
      "Epoch 4397, Loss 2.927655\n",
      "    Params:  tensor([  5.3660, -17.2948])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4398,Loss 2.927655\n",
      "Epoch 4398, Loss 2.927655\n",
      "    Params:  tensor([  5.3660, -17.2948])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4399,Loss 2.927656\n",
      "Epoch 4399, Loss 2.927656\n",
      "    Params:  tensor([  5.3660, -17.2949])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4400,Loss 2.927654\n",
      "Epoch 4400, Loss 2.927654\n",
      "    Params:  tensor([  5.3660, -17.2949])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4401,Loss 2.927655\n",
      "Epoch 4401, Loss 2.927655\n",
      "    Params:  tensor([  5.3660, -17.2949])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4402,Loss 2.927654\n",
      "Epoch 4402, Loss 2.927654\n",
      "    Params:  tensor([  5.3660, -17.2949])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4403,Loss 2.927655\n",
      "Epoch 4403, Loss 2.927655\n",
      "    Params:  tensor([  5.3660, -17.2949])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4404,Loss 2.927655\n",
      "Epoch 4404, Loss 2.927655\n",
      "    Params:  tensor([  5.3660, -17.2949])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4405,Loss 2.927656\n",
      "Epoch 4405, Loss 2.927656\n",
      "    Params:  tensor([  5.3660, -17.2950])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4406,Loss 2.927655\n",
      "Epoch 4406, Loss 2.927655\n",
      "    Params:  tensor([  5.3660, -17.2950])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4407,Loss 2.927655\n",
      "Epoch 4407, Loss 2.927655\n",
      "    Params:  tensor([  5.3660, -17.2950])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4408,Loss 2.927654\n",
      "Epoch 4408, Loss 2.927654\n",
      "    Params:  tensor([  5.3660, -17.2950])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4409,Loss 2.927653\n",
      "Epoch 4409, Loss 2.927653\n",
      "    Params:  tensor([  5.3660, -17.2950])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4410,Loss 2.927655\n",
      "Epoch 4410, Loss 2.927655\n",
      "    Params:  tensor([  5.3660, -17.2951])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4411,Loss 2.927655\n",
      "Epoch 4411, Loss 2.927655\n",
      "    Params:  tensor([  5.3660, -17.2951])\n",
      "    Grad  :  tensor([-0.0003,  0.0017])\n",
      "Epoch 4412,Loss 2.927654\n",
      "Epoch 4412, Loss 2.927654\n",
      "    Params:  tensor([  5.3660, -17.2951])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4413,Loss 2.927654\n",
      "Epoch 4413, Loss 2.927654\n",
      "    Params:  tensor([  5.3660, -17.2951])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4414,Loss 2.927655\n",
      "Epoch 4414, Loss 2.927655\n",
      "    Params:  tensor([  5.3660, -17.2951])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4415,Loss 2.927653\n",
      "Epoch 4415, Loss 2.927653\n",
      "    Params:  tensor([  5.3660, -17.2951])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4416,Loss 2.927654\n",
      "Epoch 4416, Loss 2.927654\n",
      "    Params:  tensor([  5.3660, -17.2952])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4417,Loss 2.927654\n",
      "Epoch 4417, Loss 2.927654\n",
      "    Params:  tensor([  5.3660, -17.2952])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4418,Loss 2.927654\n",
      "Epoch 4418, Loss 2.927654\n",
      "    Params:  tensor([  5.3660, -17.2952])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4419,Loss 2.927654\n",
      "Epoch 4419, Loss 2.927654\n",
      "    Params:  tensor([  5.3660, -17.2952])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4420,Loss 2.927654\n",
      "Epoch 4420, Loss 2.927654\n",
      "    Params:  tensor([  5.3660, -17.2952])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4421,Loss 2.927654\n",
      "Epoch 4421, Loss 2.927654\n",
      "    Params:  tensor([  5.3660, -17.2952])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4422,Loss 2.927653\n",
      "Epoch 4422, Loss 2.927653\n",
      "    Params:  tensor([  5.3660, -17.2953])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4423,Loss 2.927655\n",
      "Epoch 4423, Loss 2.927655\n",
      "    Params:  tensor([  5.3660, -17.2953])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4424,Loss 2.927653\n",
      "Epoch 4424, Loss 2.927653\n",
      "    Params:  tensor([  5.3660, -17.2953])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4425,Loss 2.927654\n",
      "Epoch 4425, Loss 2.927654\n",
      "    Params:  tensor([  5.3660, -17.2953])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4426,Loss 2.927655\n",
      "Epoch 4426, Loss 2.927655\n",
      "    Params:  tensor([  5.3660, -17.2953])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4427,Loss 2.927654\n",
      "Epoch 4427, Loss 2.927654\n",
      "    Params:  tensor([  5.3660, -17.2953])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4428,Loss 2.927654\n",
      "Epoch 4428, Loss 2.927654\n",
      "    Params:  tensor([  5.3661, -17.2953])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4429,Loss 2.927653\n",
      "Epoch 4429, Loss 2.927653\n",
      "    Params:  tensor([  5.3661, -17.2954])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4430,Loss 2.927654\n",
      "Epoch 4430, Loss 2.927654\n",
      "    Params:  tensor([  5.3661, -17.2954])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4431,Loss 2.927653\n",
      "Epoch 4431, Loss 2.927653\n",
      "    Params:  tensor([  5.3661, -17.2954])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4432,Loss 2.927654\n",
      "Epoch 4432, Loss 2.927654\n",
      "    Params:  tensor([  5.3661, -17.2954])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4433,Loss 2.927655\n",
      "Epoch 4433, Loss 2.927655\n",
      "    Params:  tensor([  5.3661, -17.2954])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4434,Loss 2.927654\n",
      "Epoch 4434, Loss 2.927654\n",
      "    Params:  tensor([  5.3661, -17.2954])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4435,Loss 2.927655\n",
      "Epoch 4435, Loss 2.927655\n",
      "    Params:  tensor([  5.3661, -17.2955])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4436,Loss 2.927652\n",
      "Epoch 4436, Loss 2.927652\n",
      "    Params:  tensor([  5.3661, -17.2955])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4437,Loss 2.927653\n",
      "Epoch 4437, Loss 2.927653\n",
      "    Params:  tensor([  5.3661, -17.2955])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4438,Loss 2.927654\n",
      "Epoch 4438, Loss 2.927654\n",
      "    Params:  tensor([  5.3661, -17.2955])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4439,Loss 2.927654\n",
      "Epoch 4439, Loss 2.927654\n",
      "    Params:  tensor([  5.3661, -17.2955])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4440,Loss 2.927654\n",
      "Epoch 4440, Loss 2.927654\n",
      "    Params:  tensor([  5.3661, -17.2955])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4441,Loss 2.927654\n",
      "Epoch 4441, Loss 2.927654\n",
      "    Params:  tensor([  5.3661, -17.2955])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4442,Loss 2.927653\n",
      "Epoch 4442, Loss 2.927653\n",
      "    Params:  tensor([  5.3661, -17.2956])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4443,Loss 2.927653\n",
      "Epoch 4443, Loss 2.927653\n",
      "    Params:  tensor([  5.3661, -17.2956])\n",
      "    Grad  :  tensor([-0.0002,  0.0016])\n",
      "Epoch 4444,Loss 2.927653\n",
      "Epoch 4444, Loss 2.927653\n",
      "    Params:  tensor([  5.3661, -17.2956])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4445,Loss 2.927653\n",
      "Epoch 4445, Loss 2.927653\n",
      "    Params:  tensor([  5.3661, -17.2956])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4446,Loss 2.927653\n",
      "Epoch 4446, Loss 2.927653\n",
      "    Params:  tensor([  5.3661, -17.2956])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4447,Loss 2.927652\n",
      "Epoch 4447, Loss 2.927652\n",
      "    Params:  tensor([  5.3661, -17.2956])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4448,Loss 2.927654\n",
      "Epoch 4448, Loss 2.927654\n",
      "    Params:  tensor([  5.3661, -17.2957])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4449,Loss 2.927654\n",
      "Epoch 4449, Loss 2.927654\n",
      "    Params:  tensor([  5.3661, -17.2957])\n",
      "    Grad  :  tensor([-0.0003,  0.0016])\n",
      "Epoch 4450,Loss 2.927654\n",
      "Epoch 4450, Loss 2.927654\n",
      "    Params:  tensor([  5.3661, -17.2957])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4451,Loss 2.927653\n",
      "Epoch 4451, Loss 2.927653\n",
      "    Params:  tensor([  5.3661, -17.2957])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4452,Loss 2.927651\n",
      "Epoch 4452, Loss 2.927651\n",
      "    Params:  tensor([  5.3661, -17.2957])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4453,Loss 2.927653\n",
      "Epoch 4453, Loss 2.927653\n",
      "    Params:  tensor([  5.3661, -17.2957])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4454,Loss 2.927654\n",
      "Epoch 4454, Loss 2.927654\n",
      "    Params:  tensor([  5.3661, -17.2957])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4455,Loss 2.927653\n",
      "Epoch 4455, Loss 2.927653\n",
      "    Params:  tensor([  5.3661, -17.2958])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4456,Loss 2.927655\n",
      "Epoch 4456, Loss 2.927655\n",
      "    Params:  tensor([  5.3661, -17.2958])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4457,Loss 2.927654\n",
      "Epoch 4457, Loss 2.927654\n",
      "    Params:  tensor([  5.3661, -17.2958])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4458,Loss 2.927652\n",
      "Epoch 4458, Loss 2.927652\n",
      "    Params:  tensor([  5.3661, -17.2958])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4459,Loss 2.927653\n",
      "Epoch 4459, Loss 2.927653\n",
      "    Params:  tensor([  5.3661, -17.2958])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4460,Loss 2.927653\n",
      "Epoch 4460, Loss 2.927653\n",
      "    Params:  tensor([  5.3661, -17.2958])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4461,Loss 2.927654\n",
      "Epoch 4461, Loss 2.927654\n",
      "    Params:  tensor([  5.3661, -17.2959])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4462,Loss 2.927653\n",
      "Epoch 4462, Loss 2.927653\n",
      "    Params:  tensor([  5.3661, -17.2959])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4463,Loss 2.927652\n",
      "Epoch 4463, Loss 2.927652\n",
      "    Params:  tensor([  5.3661, -17.2959])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4464,Loss 2.927653\n",
      "Epoch 4464, Loss 2.927653\n",
      "    Params:  tensor([  5.3661, -17.2959])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4465,Loss 2.927654\n",
      "Epoch 4465, Loss 2.927654\n",
      "    Params:  tensor([  5.3662, -17.2959])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4466,Loss 2.927654\n",
      "Epoch 4466, Loss 2.927654\n",
      "    Params:  tensor([  5.3662, -17.2959])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4467,Loss 2.927654\n",
      "Epoch 4467, Loss 2.927654\n",
      "    Params:  tensor([  5.3662, -17.2959])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4468,Loss 2.927652\n",
      "Epoch 4468, Loss 2.927652\n",
      "    Params:  tensor([  5.3662, -17.2960])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4469,Loss 2.927653\n",
      "Epoch 4469, Loss 2.927653\n",
      "    Params:  tensor([  5.3662, -17.2960])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4470,Loss 2.927653\n",
      "Epoch 4470, Loss 2.927653\n",
      "    Params:  tensor([  5.3662, -17.2960])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4471,Loss 2.927653\n",
      "Epoch 4471, Loss 2.927653\n",
      "    Params:  tensor([  5.3662, -17.2960])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4472,Loss 2.927653\n",
      "Epoch 4472, Loss 2.927653\n",
      "    Params:  tensor([  5.3662, -17.2960])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4473,Loss 2.927652\n",
      "Epoch 4473, Loss 2.927652\n",
      "    Params:  tensor([  5.3662, -17.2960])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4474,Loss 2.927652\n",
      "Epoch 4474, Loss 2.927652\n",
      "    Params:  tensor([  5.3662, -17.2960])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4475,Loss 2.927652\n",
      "Epoch 4475, Loss 2.927652\n",
      "    Params:  tensor([  5.3662, -17.2961])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4476,Loss 2.927653\n",
      "Epoch 4476, Loss 2.927653\n",
      "    Params:  tensor([  5.3662, -17.2961])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4477,Loss 2.927653\n",
      "Epoch 4477, Loss 2.927653\n",
      "    Params:  tensor([  5.3662, -17.2961])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4478,Loss 2.927652\n",
      "Epoch 4478, Loss 2.927652\n",
      "    Params:  tensor([  5.3662, -17.2961])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4479,Loss 2.927653\n",
      "Epoch 4479, Loss 2.927653\n",
      "    Params:  tensor([  5.3662, -17.2961])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4480,Loss 2.927653\n",
      "Epoch 4480, Loss 2.927653\n",
      "    Params:  tensor([  5.3662, -17.2961])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4481,Loss 2.927653\n",
      "Epoch 4481, Loss 2.927653\n",
      "    Params:  tensor([  5.3662, -17.2962])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4482,Loss 2.927653\n",
      "Epoch 4482, Loss 2.927653\n",
      "    Params:  tensor([  5.3662, -17.2962])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4483,Loss 2.927654\n",
      "Epoch 4483, Loss 2.927654\n",
      "    Params:  tensor([  5.3662, -17.2962])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4484,Loss 2.927653\n",
      "Epoch 4484, Loss 2.927653\n",
      "    Params:  tensor([  5.3662, -17.2962])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4485,Loss 2.927652\n",
      "Epoch 4485, Loss 2.927652\n",
      "    Params:  tensor([  5.3662, -17.2962])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4486,Loss 2.927653\n",
      "Epoch 4486, Loss 2.927653\n",
      "    Params:  tensor([  5.3662, -17.2962])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4487,Loss 2.927653\n",
      "Epoch 4487, Loss 2.927653\n",
      "    Params:  tensor([  5.3662, -17.2962])\n",
      "    Grad  :  tensor([-0.0003,  0.0015])\n",
      "Epoch 4488,Loss 2.927652\n",
      "Epoch 4488, Loss 2.927652\n",
      "    Params:  tensor([  5.3662, -17.2963])\n",
      "    Grad  :  tensor([-0.0003,  0.0014])\n",
      "Epoch 4489,Loss 2.927653\n",
      "Epoch 4489, Loss 2.927653\n",
      "    Params:  tensor([  5.3662, -17.2963])\n",
      "    Grad  :  tensor([-0.0003,  0.0014])\n",
      "Epoch 4490,Loss 2.927652\n",
      "Epoch 4490, Loss 2.927652\n",
      "    Params:  tensor([  5.3662, -17.2963])\n",
      "    Grad  :  tensor([-0.0003,  0.0014])\n",
      "Epoch 4491,Loss 2.927651\n",
      "Epoch 4491, Loss 2.927651\n",
      "    Params:  tensor([  5.3662, -17.2963])\n",
      "    Grad  :  tensor([-0.0003,  0.0014])\n",
      "Epoch 4492,Loss 2.927651\n",
      "Epoch 4492, Loss 2.927651\n",
      "    Params:  tensor([  5.3662, -17.2963])\n",
      "    Grad  :  tensor([-0.0003,  0.0014])\n",
      "Epoch 4493,Loss 2.927653\n",
      "Epoch 4493, Loss 2.927653\n",
      "    Params:  tensor([  5.3662, -17.2963])\n",
      "    Grad  :  tensor([-0.0003,  0.0014])\n",
      "Epoch 4494,Loss 2.927653\n",
      "Epoch 4494, Loss 2.927653\n",
      "    Params:  tensor([  5.3662, -17.2964])\n",
      "    Grad  :  tensor([-0.0003,  0.0014])\n",
      "Epoch 4495,Loss 2.927653\n",
      "Epoch 4495, Loss 2.927653\n",
      "    Params:  tensor([  5.3662, -17.2964])\n",
      "    Grad  :  tensor([-0.0003,  0.0014])\n",
      "Epoch 4496,Loss 2.927651\n",
      "Epoch 4496, Loss 2.927651\n",
      "    Params:  tensor([  5.3662, -17.2964])\n",
      "    Grad  :  tensor([-0.0003,  0.0014])\n",
      "Epoch 4497,Loss 2.927652\n",
      "Epoch 4497, Loss 2.927652\n",
      "    Params:  tensor([  5.3662, -17.2964])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4498,Loss 2.927652\n",
      "Epoch 4498, Loss 2.927652\n",
      "    Params:  tensor([  5.3662, -17.2964])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4499,Loss 2.927653\n",
      "Epoch 4499, Loss 2.927653\n",
      "    Params:  tensor([  5.3662, -17.2964])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4500,Loss 2.927651\n",
      "Epoch 4500, Loss 2.927651\n",
      "    Params:  tensor([  5.3662, -17.2964])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4501,Loss 2.927652\n",
      "Epoch 4501, Loss 2.927652\n",
      "    Params:  tensor([  5.3662, -17.2964])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4502,Loss 2.927653\n",
      "Epoch 4502, Loss 2.927653\n",
      "    Params:  tensor([  5.3662, -17.2965])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4503,Loss 2.927653\n",
      "Epoch 4503, Loss 2.927653\n",
      "    Params:  tensor([  5.3663, -17.2965])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4504,Loss 2.927652\n",
      "Epoch 4504, Loss 2.927652\n",
      "    Params:  tensor([  5.3663, -17.2965])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4505,Loss 2.927651\n",
      "Epoch 4505, Loss 2.927651\n",
      "    Params:  tensor([  5.3663, -17.2965])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4506,Loss 2.927652\n",
      "Epoch 4506, Loss 2.927652\n",
      "    Params:  tensor([  5.3663, -17.2965])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4507,Loss 2.927651\n",
      "Epoch 4507, Loss 2.927651\n",
      "    Params:  tensor([  5.3663, -17.2965])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4508,Loss 2.927652\n",
      "Epoch 4508, Loss 2.927652\n",
      "    Params:  tensor([  5.3663, -17.2965])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4509,Loss 2.927651\n",
      "Epoch 4509, Loss 2.927651\n",
      "    Params:  tensor([  5.3663, -17.2966])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4510,Loss 2.927652\n",
      "Epoch 4510, Loss 2.927652\n",
      "    Params:  tensor([  5.3663, -17.2966])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4511,Loss 2.927650\n",
      "Epoch 4511, Loss 2.927650\n",
      "    Params:  tensor([  5.3663, -17.2966])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4512,Loss 2.927651\n",
      "Epoch 4512, Loss 2.927651\n",
      "    Params:  tensor([  5.3663, -17.2966])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4513,Loss 2.927652\n",
      "Epoch 4513, Loss 2.927652\n",
      "    Params:  tensor([  5.3663, -17.2966])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4514,Loss 2.927652\n",
      "Epoch 4514, Loss 2.927652\n",
      "    Params:  tensor([  5.3663, -17.2966])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4515,Loss 2.927650\n",
      "Epoch 4515, Loss 2.927650\n",
      "    Params:  tensor([  5.3663, -17.2966])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4516,Loss 2.927651\n",
      "Epoch 4516, Loss 2.927651\n",
      "    Params:  tensor([  5.3663, -17.2966])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4517,Loss 2.927653\n",
      "Epoch 4517, Loss 2.927653\n",
      "    Params:  tensor([  5.3663, -17.2967])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4518,Loss 2.927652\n",
      "Epoch 4518, Loss 2.927652\n",
      "    Params:  tensor([  5.3663, -17.2967])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4519,Loss 2.927650\n",
      "Epoch 4519, Loss 2.927650\n",
      "    Params:  tensor([  5.3663, -17.2967])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4520,Loss 2.927651\n",
      "Epoch 4520, Loss 2.927651\n",
      "    Params:  tensor([  5.3663, -17.2967])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4521,Loss 2.927651\n",
      "Epoch 4521, Loss 2.927651\n",
      "    Params:  tensor([  5.3663, -17.2967])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4522,Loss 2.927652\n",
      "Epoch 4522, Loss 2.927652\n",
      "    Params:  tensor([  5.3663, -17.2967])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4523,Loss 2.927652\n",
      "Epoch 4523, Loss 2.927652\n",
      "    Params:  tensor([  5.3663, -17.2967])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4524,Loss 2.927653\n",
      "Epoch 4524, Loss 2.927653\n",
      "    Params:  tensor([  5.3663, -17.2968])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4525,Loss 2.927652\n",
      "Epoch 4525, Loss 2.927652\n",
      "    Params:  tensor([  5.3663, -17.2968])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4526,Loss 2.927652\n",
      "Epoch 4526, Loss 2.927652\n",
      "    Params:  tensor([  5.3663, -17.2968])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4527,Loss 2.927653\n",
      "Epoch 4527, Loss 2.927653\n",
      "    Params:  tensor([  5.3663, -17.2968])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4528,Loss 2.927652\n",
      "Epoch 4528, Loss 2.927652\n",
      "    Params:  tensor([  5.3663, -17.2968])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4529,Loss 2.927651\n",
      "Epoch 4529, Loss 2.927651\n",
      "    Params:  tensor([  5.3663, -17.2968])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4530,Loss 2.927651\n",
      "Epoch 4530, Loss 2.927651\n",
      "    Params:  tensor([  5.3663, -17.2968])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4531,Loss 2.927651\n",
      "Epoch 4531, Loss 2.927651\n",
      "    Params:  tensor([  5.3663, -17.2969])\n",
      "    Grad  :  tensor([-0.0002,  0.0014])\n",
      "Epoch 4532,Loss 2.927650\n",
      "Epoch 4532, Loss 2.927650\n",
      "    Params:  tensor([  5.3663, -17.2969])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4533,Loss 2.927652\n",
      "Epoch 4533, Loss 2.927652\n",
      "    Params:  tensor([  5.3663, -17.2969])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4534,Loss 2.927651\n",
      "Epoch 4534, Loss 2.927651\n",
      "    Params:  tensor([  5.3663, -17.2969])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4535,Loss 2.927651\n",
      "Epoch 4535, Loss 2.927651\n",
      "    Params:  tensor([  5.3663, -17.2969])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4536,Loss 2.927651\n",
      "Epoch 4536, Loss 2.927651\n",
      "    Params:  tensor([  5.3663, -17.2969])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4537,Loss 2.927653\n",
      "Epoch 4537, Loss 2.927653\n",
      "    Params:  tensor([  5.3663, -17.2969])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4538,Loss 2.927651\n",
      "Epoch 4538, Loss 2.927651\n",
      "    Params:  tensor([  5.3663, -17.2969])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4539,Loss 2.927650\n",
      "Epoch 4539, Loss 2.927650\n",
      "    Params:  tensor([  5.3663, -17.2970])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4540,Loss 2.927651\n",
      "Epoch 4540, Loss 2.927651\n",
      "    Params:  tensor([  5.3663, -17.2970])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4541,Loss 2.927651\n",
      "Epoch 4541, Loss 2.927651\n",
      "    Params:  tensor([  5.3663, -17.2970])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4542,Loss 2.927651\n",
      "Epoch 4542, Loss 2.927651\n",
      "    Params:  tensor([  5.3663, -17.2970])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4543,Loss 2.927651\n",
      "Epoch 4543, Loss 2.927651\n",
      "    Params:  tensor([  5.3663, -17.2970])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4544,Loss 2.927650\n",
      "Epoch 4544, Loss 2.927650\n",
      "    Params:  tensor([  5.3663, -17.2970])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4545,Loss 2.927651\n",
      "Epoch 4545, Loss 2.927651\n",
      "    Params:  tensor([  5.3664, -17.2970])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4546,Loss 2.927652\n",
      "Epoch 4546, Loss 2.927652\n",
      "    Params:  tensor([  5.3664, -17.2971])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4547,Loss 2.927651\n",
      "Epoch 4547, Loss 2.927651\n",
      "    Params:  tensor([  5.3664, -17.2971])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4548,Loss 2.927650\n",
      "Epoch 4548, Loss 2.927650\n",
      "    Params:  tensor([  5.3664, -17.2971])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4549,Loss 2.927651\n",
      "Epoch 4549, Loss 2.927651\n",
      "    Params:  tensor([  5.3664, -17.2971])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4550,Loss 2.927652\n",
      "Epoch 4550, Loss 2.927652\n",
      "    Params:  tensor([  5.3664, -17.2971])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4551,Loss 2.927652\n",
      "Epoch 4551, Loss 2.927652\n",
      "    Params:  tensor([  5.3664, -17.2971])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4552,Loss 2.927653\n",
      "Epoch 4552, Loss 2.927653\n",
      "    Params:  tensor([  5.3664, -17.2971])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4553,Loss 2.927651\n",
      "Epoch 4553, Loss 2.927651\n",
      "    Params:  tensor([  5.3664, -17.2971])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4554,Loss 2.927652\n",
      "Epoch 4554, Loss 2.927652\n",
      "    Params:  tensor([  5.3664, -17.2972])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4555,Loss 2.927651\n",
      "Epoch 4555, Loss 2.927651\n",
      "    Params:  tensor([  5.3664, -17.2972])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4556,Loss 2.927651\n",
      "Epoch 4556, Loss 2.927651\n",
      "    Params:  tensor([  5.3664, -17.2972])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4557,Loss 2.927652\n",
      "Epoch 4557, Loss 2.927652\n",
      "    Params:  tensor([  5.3664, -17.2972])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4558,Loss 2.927651\n",
      "Epoch 4558, Loss 2.927651\n",
      "    Params:  tensor([  5.3664, -17.2972])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4559,Loss 2.927651\n",
      "Epoch 4559, Loss 2.927651\n",
      "    Params:  tensor([  5.3664, -17.2972])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4560,Loss 2.927650\n",
      "Epoch 4560, Loss 2.927650\n",
      "    Params:  tensor([  5.3664, -17.2972])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4561,Loss 2.927651\n",
      "Epoch 4561, Loss 2.927651\n",
      "    Params:  tensor([  5.3664, -17.2973])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4562,Loss 2.927652\n",
      "Epoch 4562, Loss 2.927652\n",
      "    Params:  tensor([  5.3664, -17.2973])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4563,Loss 2.927651\n",
      "Epoch 4563, Loss 2.927651\n",
      "    Params:  tensor([  5.3664, -17.2973])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4564,Loss 2.927650\n",
      "Epoch 4564, Loss 2.927650\n",
      "    Params:  tensor([  5.3664, -17.2973])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4565,Loss 2.927651\n",
      "Epoch 4565, Loss 2.927651\n",
      "    Params:  tensor([  5.3664, -17.2973])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4566,Loss 2.927652\n",
      "Epoch 4566, Loss 2.927652\n",
      "    Params:  tensor([  5.3664, -17.2973])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4567,Loss 2.927650\n",
      "Epoch 4567, Loss 2.927650\n",
      "    Params:  tensor([  5.3664, -17.2973])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4568,Loss 2.927650\n",
      "Epoch 4568, Loss 2.927650\n",
      "    Params:  tensor([  5.3664, -17.2973])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4569,Loss 2.927651\n",
      "Epoch 4569, Loss 2.927651\n",
      "    Params:  tensor([  5.3664, -17.2974])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4570,Loss 2.927652\n",
      "Epoch 4570, Loss 2.927652\n",
      "    Params:  tensor([  5.3664, -17.2974])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4571,Loss 2.927650\n",
      "Epoch 4571, Loss 2.927650\n",
      "    Params:  tensor([  5.3664, -17.2974])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4572,Loss 2.927649\n",
      "Epoch 4572, Loss 2.927649\n",
      "    Params:  tensor([  5.3664, -17.2974])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4573,Loss 2.927650\n",
      "Epoch 4573, Loss 2.927650\n",
      "    Params:  tensor([  5.3664, -17.2974])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4574,Loss 2.927650\n",
      "Epoch 4574, Loss 2.927650\n",
      "    Params:  tensor([  5.3664, -17.2974])\n",
      "    Grad  :  tensor([-0.0002,  0.0013])\n",
      "Epoch 4575,Loss 2.927650\n",
      "Epoch 4575, Loss 2.927650\n",
      "    Params:  tensor([  5.3664, -17.2974])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4576,Loss 2.927651\n",
      "Epoch 4576, Loss 2.927651\n",
      "    Params:  tensor([  5.3664, -17.2975])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4577,Loss 2.927650\n",
      "Epoch 4577, Loss 2.927650\n",
      "    Params:  tensor([  5.3664, -17.2975])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4578,Loss 2.927651\n",
      "Epoch 4578, Loss 2.927651\n",
      "    Params:  tensor([  5.3664, -17.2975])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4579,Loss 2.927651\n",
      "Epoch 4579, Loss 2.927651\n",
      "    Params:  tensor([  5.3664, -17.2975])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4580,Loss 2.927652\n",
      "Epoch 4580, Loss 2.927652\n",
      "    Params:  tensor([  5.3664, -17.2975])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4581,Loss 2.927649\n",
      "Epoch 4581, Loss 2.927649\n",
      "    Params:  tensor([  5.3664, -17.2975])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4582,Loss 2.927653\n",
      "Epoch 4582, Loss 2.927653\n",
      "    Params:  tensor([  5.3664, -17.2975])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4583,Loss 2.927651\n",
      "Epoch 4583, Loss 2.927651\n",
      "    Params:  tensor([  5.3664, -17.2975])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4584,Loss 2.927649\n",
      "Epoch 4584, Loss 2.927649\n",
      "    Params:  tensor([  5.3664, -17.2976])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4585,Loss 2.927650\n",
      "Epoch 4585, Loss 2.927650\n",
      "    Params:  tensor([  5.3664, -17.2976])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4586,Loss 2.927650\n",
      "Epoch 4586, Loss 2.927650\n",
      "    Params:  tensor([  5.3664, -17.2976])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4587,Loss 2.927651\n",
      "Epoch 4587, Loss 2.927651\n",
      "    Params:  tensor([  5.3664, -17.2976])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4588,Loss 2.927651\n",
      "Epoch 4588, Loss 2.927651\n",
      "    Params:  tensor([  5.3664, -17.2976])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4589,Loss 2.927650\n",
      "Epoch 4589, Loss 2.927650\n",
      "    Params:  tensor([  5.3665, -17.2976])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4590,Loss 2.927650\n",
      "Epoch 4590, Loss 2.927650\n",
      "    Params:  tensor([  5.3665, -17.2976])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4591,Loss 2.927652\n",
      "Epoch 4591, Loss 2.927652\n",
      "    Params:  tensor([  5.3665, -17.2976])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4592,Loss 2.927650\n",
      "Epoch 4592, Loss 2.927650\n",
      "    Params:  tensor([  5.3665, -17.2976])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4593,Loss 2.927651\n",
      "Epoch 4593, Loss 2.927651\n",
      "    Params:  tensor([  5.3665, -17.2977])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4594,Loss 2.927651\n",
      "Epoch 4594, Loss 2.927651\n",
      "    Params:  tensor([  5.3665, -17.2977])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4595,Loss 2.927650\n",
      "Epoch 4595, Loss 2.927650\n",
      "    Params:  tensor([  5.3665, -17.2977])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4596,Loss 2.927651\n",
      "Epoch 4596, Loss 2.927651\n",
      "    Params:  tensor([  5.3665, -17.2977])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4597,Loss 2.927650\n",
      "Epoch 4597, Loss 2.927650\n",
      "    Params:  tensor([  5.3665, -17.2977])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4598,Loss 2.927651\n",
      "Epoch 4598, Loss 2.927651\n",
      "    Params:  tensor([  5.3665, -17.2977])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4599,Loss 2.927652\n",
      "Epoch 4599, Loss 2.927652\n",
      "    Params:  tensor([  5.3665, -17.2977])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4600,Loss 2.927650\n",
      "Epoch 4600, Loss 2.927650\n",
      "    Params:  tensor([  5.3665, -17.2977])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4601,Loss 2.927651\n",
      "Epoch 4601, Loss 2.927651\n",
      "    Params:  tensor([  5.3665, -17.2977])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4602,Loss 2.927650\n",
      "Epoch 4602, Loss 2.927650\n",
      "    Params:  tensor([  5.3665, -17.2978])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4603,Loss 2.927648\n",
      "Epoch 4603, Loss 2.927648\n",
      "    Params:  tensor([  5.3665, -17.2978])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4604,Loss 2.927650\n",
      "Epoch 4604, Loss 2.927650\n",
      "    Params:  tensor([  5.3665, -17.2978])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4605,Loss 2.927651\n",
      "Epoch 4605, Loss 2.927651\n",
      "    Params:  tensor([  5.3665, -17.2978])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4606,Loss 2.927651\n",
      "Epoch 4606, Loss 2.927651\n",
      "    Params:  tensor([  5.3665, -17.2978])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4607,Loss 2.927651\n",
      "Epoch 4607, Loss 2.927651\n",
      "    Params:  tensor([  5.3665, -17.2978])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4608,Loss 2.927651\n",
      "Epoch 4608, Loss 2.927651\n",
      "    Params:  tensor([  5.3665, -17.2978])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4609,Loss 2.927651\n",
      "Epoch 4609, Loss 2.927651\n",
      "    Params:  tensor([  5.3665, -17.2978])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4610,Loss 2.927649\n",
      "Epoch 4610, Loss 2.927649\n",
      "    Params:  tensor([  5.3665, -17.2978])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4611,Loss 2.927649\n",
      "Epoch 4611, Loss 2.927649\n",
      "    Params:  tensor([  5.3665, -17.2979])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4612,Loss 2.927650\n",
      "Epoch 4612, Loss 2.927650\n",
      "    Params:  tensor([  5.3665, -17.2979])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4613,Loss 2.927649\n",
      "Epoch 4613, Loss 2.927649\n",
      "    Params:  tensor([  5.3665, -17.2979])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4614,Loss 2.927649\n",
      "Epoch 4614, Loss 2.927649\n",
      "    Params:  tensor([  5.3665, -17.2979])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4615,Loss 2.927650\n",
      "Epoch 4615, Loss 2.927650\n",
      "    Params:  tensor([  5.3665, -17.2979])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4616,Loss 2.927650\n",
      "Epoch 4616, Loss 2.927650\n",
      "    Params:  tensor([  5.3665, -17.2979])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4617,Loss 2.927650\n",
      "Epoch 4617, Loss 2.927650\n",
      "    Params:  tensor([  5.3665, -17.2979])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4618,Loss 2.927650\n",
      "Epoch 4618, Loss 2.927650\n",
      "    Params:  tensor([  5.3665, -17.2979])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4619,Loss 2.927651\n",
      "Epoch 4619, Loss 2.927651\n",
      "    Params:  tensor([  5.3665, -17.2980])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4620,Loss 2.927650\n",
      "Epoch 4620, Loss 2.927650\n",
      "    Params:  tensor([  5.3665, -17.2980])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4621,Loss 2.927650\n",
      "Epoch 4621, Loss 2.927650\n",
      "    Params:  tensor([  5.3665, -17.2980])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4622,Loss 2.927651\n",
      "Epoch 4622, Loss 2.927651\n",
      "    Params:  tensor([  5.3665, -17.2980])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4623,Loss 2.927650\n",
      "Epoch 4623, Loss 2.927650\n",
      "    Params:  tensor([  5.3665, -17.2980])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4624,Loss 2.927651\n",
      "Epoch 4624, Loss 2.927651\n",
      "    Params:  tensor([  5.3665, -17.2980])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4625,Loss 2.927651\n",
      "Epoch 4625, Loss 2.927651\n",
      "    Params:  tensor([  5.3665, -17.2980])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4626,Loss 2.927651\n",
      "Epoch 4626, Loss 2.927651\n",
      "    Params:  tensor([  5.3665, -17.2980])\n",
      "    Grad  :  tensor([-0.0002,  0.0012])\n",
      "Epoch 4627,Loss 2.927651\n",
      "Epoch 4627, Loss 2.927651\n",
      "    Params:  tensor([  5.3665, -17.2980])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4628,Loss 2.927650\n",
      "Epoch 4628, Loss 2.927650\n",
      "    Params:  tensor([  5.3665, -17.2981])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4629,Loss 2.927651\n",
      "Epoch 4629, Loss 2.927651\n",
      "    Params:  tensor([  5.3665, -17.2981])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4630,Loss 2.927651\n",
      "Epoch 4630, Loss 2.927651\n",
      "    Params:  tensor([  5.3665, -17.2981])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4631,Loss 2.927650\n",
      "Epoch 4631, Loss 2.927650\n",
      "    Params:  tensor([  5.3665, -17.2981])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4632,Loss 2.927651\n",
      "Epoch 4632, Loss 2.927651\n",
      "    Params:  tensor([  5.3665, -17.2981])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4633,Loss 2.927651\n",
      "Epoch 4633, Loss 2.927651\n",
      "    Params:  tensor([  5.3665, -17.2981])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4634,Loss 2.927650\n",
      "Epoch 4634, Loss 2.927650\n",
      "    Params:  tensor([  5.3665, -17.2981])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4635,Loss 2.927650\n",
      "Epoch 4635, Loss 2.927650\n",
      "    Params:  tensor([  5.3665, -17.2981])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4636,Loss 2.927650\n",
      "Epoch 4636, Loss 2.927650\n",
      "    Params:  tensor([  5.3665, -17.2981])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4637,Loss 2.927649\n",
      "Epoch 4637, Loss 2.927649\n",
      "    Params:  tensor([  5.3665, -17.2982])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4638,Loss 2.927650\n",
      "Epoch 4638, Loss 2.927650\n",
      "    Params:  tensor([  5.3665, -17.2982])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4639,Loss 2.927650\n",
      "Epoch 4639, Loss 2.927650\n",
      "    Params:  tensor([  5.3666, -17.2982])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4640,Loss 2.927649\n",
      "Epoch 4640, Loss 2.927649\n",
      "    Params:  tensor([  5.3666, -17.2982])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4641,Loss 2.927650\n",
      "Epoch 4641, Loss 2.927650\n",
      "    Params:  tensor([  5.3666, -17.2982])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4642,Loss 2.927649\n",
      "Epoch 4642, Loss 2.927649\n",
      "    Params:  tensor([  5.3666, -17.2982])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4643,Loss 2.927650\n",
      "Epoch 4643, Loss 2.927650\n",
      "    Params:  tensor([  5.3666, -17.2982])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4644,Loss 2.927650\n",
      "Epoch 4644, Loss 2.927650\n",
      "    Params:  tensor([  5.3666, -17.2982])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4645,Loss 2.927649\n",
      "Epoch 4645, Loss 2.927649\n",
      "    Params:  tensor([  5.3666, -17.2982])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4646,Loss 2.927649\n",
      "Epoch 4646, Loss 2.927649\n",
      "    Params:  tensor([  5.3666, -17.2983])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4647,Loss 2.927650\n",
      "Epoch 4647, Loss 2.927650\n",
      "    Params:  tensor([  5.3666, -17.2983])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4648,Loss 2.927650\n",
      "Epoch 4648, Loss 2.927650\n",
      "    Params:  tensor([  5.3666, -17.2983])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4649,Loss 2.927649\n",
      "Epoch 4649, Loss 2.927649\n",
      "    Params:  tensor([  5.3666, -17.2983])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4650,Loss 2.927650\n",
      "Epoch 4650, Loss 2.927650\n",
      "    Params:  tensor([  5.3666, -17.2983])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4651,Loss 2.927649\n",
      "Epoch 4651, Loss 2.927649\n",
      "    Params:  tensor([  5.3666, -17.2983])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4652,Loss 2.927650\n",
      "Epoch 4652, Loss 2.927650\n",
      "    Params:  tensor([  5.3666, -17.2983])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4653,Loss 2.927651\n",
      "Epoch 4653, Loss 2.927651\n",
      "    Params:  tensor([  5.3666, -17.2983])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4654,Loss 2.927650\n",
      "Epoch 4654, Loss 2.927650\n",
      "    Params:  tensor([  5.3666, -17.2984])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4655,Loss 2.927650\n",
      "Epoch 4655, Loss 2.927650\n",
      "    Params:  tensor([  5.3666, -17.2984])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4656,Loss 2.927651\n",
      "Epoch 4656, Loss 2.927651\n",
      "    Params:  tensor([  5.3666, -17.2984])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4657,Loss 2.927650\n",
      "Epoch 4657, Loss 2.927650\n",
      "    Params:  tensor([  5.3666, -17.2984])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4658,Loss 2.927651\n",
      "Epoch 4658, Loss 2.927651\n",
      "    Params:  tensor([  5.3666, -17.2984])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4659,Loss 2.927650\n",
      "Epoch 4659, Loss 2.927650\n",
      "    Params:  tensor([  5.3666, -17.2984])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4660,Loss 2.927649\n",
      "Epoch 4660, Loss 2.927649\n",
      "    Params:  tensor([  5.3666, -17.2984])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4661,Loss 2.927649\n",
      "Epoch 4661, Loss 2.927649\n",
      "    Params:  tensor([  5.3666, -17.2984])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4662,Loss 2.927648\n",
      "Epoch 4662, Loss 2.927648\n",
      "    Params:  tensor([  5.3666, -17.2984])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4663,Loss 2.927649\n",
      "Epoch 4663, Loss 2.927649\n",
      "    Params:  tensor([  5.3666, -17.2985])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4664,Loss 2.927648\n",
      "Epoch 4664, Loss 2.927648\n",
      "    Params:  tensor([  5.3666, -17.2985])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4665,Loss 2.927648\n",
      "Epoch 4665, Loss 2.927648\n",
      "    Params:  tensor([  5.3666, -17.2985])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4666,Loss 2.927649\n",
      "Epoch 4666, Loss 2.927649\n",
      "    Params:  tensor([  5.3666, -17.2985])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4667,Loss 2.927649\n",
      "Epoch 4667, Loss 2.927649\n",
      "    Params:  tensor([  5.3666, -17.2985])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4668,Loss 2.927649\n",
      "Epoch 4668, Loss 2.927649\n",
      "    Params:  tensor([  5.3666, -17.2985])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4669,Loss 2.927649\n",
      "Epoch 4669, Loss 2.927649\n",
      "    Params:  tensor([  5.3666, -17.2985])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4670,Loss 2.927650\n",
      "Epoch 4670, Loss 2.927650\n",
      "    Params:  tensor([  5.3666, -17.2985])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4671,Loss 2.927649\n",
      "Epoch 4671, Loss 2.927649\n",
      "    Params:  tensor([  5.3666, -17.2985])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4672,Loss 2.927649\n",
      "Epoch 4672, Loss 2.927649\n",
      "    Params:  tensor([  5.3666, -17.2986])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4673,Loss 2.927649\n",
      "Epoch 4673, Loss 2.927649\n",
      "    Params:  tensor([  5.3666, -17.2986])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4674,Loss 2.927650\n",
      "Epoch 4674, Loss 2.927650\n",
      "    Params:  tensor([  5.3666, -17.2986])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4675,Loss 2.927650\n",
      "Epoch 4675, Loss 2.927650\n",
      "    Params:  tensor([  5.3666, -17.2986])\n",
      "    Grad  :  tensor([-0.0002,  0.0011])\n",
      "Epoch 4676,Loss 2.927649\n",
      "Epoch 4676, Loss 2.927649\n",
      "    Params:  tensor([  5.3666, -17.2986])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4677,Loss 2.927649\n",
      "Epoch 4677, Loss 2.927649\n",
      "    Params:  tensor([  5.3666, -17.2986])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4678,Loss 2.927650\n",
      "Epoch 4678, Loss 2.927650\n",
      "    Params:  tensor([  5.3666, -17.2986])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4679,Loss 2.927650\n",
      "Epoch 4679, Loss 2.927650\n",
      "    Params:  tensor([  5.3666, -17.2986])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4680,Loss 2.927648\n",
      "Epoch 4680, Loss 2.927648\n",
      "    Params:  tensor([  5.3666, -17.2986])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4681,Loss 2.927648\n",
      "Epoch 4681, Loss 2.927648\n",
      "    Params:  tensor([  5.3666, -17.2987])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4682,Loss 2.927649\n",
      "Epoch 4682, Loss 2.927649\n",
      "    Params:  tensor([  5.3666, -17.2987])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4683,Loss 2.927649\n",
      "Epoch 4683, Loss 2.927649\n",
      "    Params:  tensor([  5.3666, -17.2987])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4684,Loss 2.927648\n",
      "Epoch 4684, Loss 2.927648\n",
      "    Params:  tensor([  5.3666, -17.2987])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4685,Loss 2.927650\n",
      "Epoch 4685, Loss 2.927650\n",
      "    Params:  tensor([  5.3666, -17.2987])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4686,Loss 2.927649\n",
      "Epoch 4686, Loss 2.927649\n",
      "    Params:  tensor([  5.3666, -17.2987])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4687,Loss 2.927651\n",
      "Epoch 4687, Loss 2.927651\n",
      "    Params:  tensor([  5.3666, -17.2987])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4688,Loss 2.927649\n",
      "Epoch 4688, Loss 2.927649\n",
      "    Params:  tensor([  5.3666, -17.2987])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4689,Loss 2.927649\n",
      "Epoch 4689, Loss 2.927649\n",
      "    Params:  tensor([  5.3666, -17.2987])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4690,Loss 2.927649\n",
      "Epoch 4690, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2987])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4691,Loss 2.927650\n",
      "Epoch 4691, Loss 2.927650\n",
      "    Params:  tensor([  5.3667, -17.2987])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4692,Loss 2.927649\n",
      "Epoch 4692, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2988])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4693,Loss 2.927649\n",
      "Epoch 4693, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2988])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4694,Loss 2.927648\n",
      "Epoch 4694, Loss 2.927648\n",
      "    Params:  tensor([  5.3667, -17.2988])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4695,Loss 2.927650\n",
      "Epoch 4695, Loss 2.927650\n",
      "    Params:  tensor([  5.3667, -17.2988])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4696,Loss 2.927648\n",
      "Epoch 4696, Loss 2.927648\n",
      "    Params:  tensor([  5.3667, -17.2988])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4697,Loss 2.927649\n",
      "Epoch 4697, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2988])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4698,Loss 2.927648\n",
      "Epoch 4698, Loss 2.927648\n",
      "    Params:  tensor([  5.3667, -17.2988])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4699,Loss 2.927650\n",
      "Epoch 4699, Loss 2.927650\n",
      "    Params:  tensor([  5.3667, -17.2988])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4700,Loss 2.927649\n",
      "Epoch 4700, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2988])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4701,Loss 2.927649\n",
      "Epoch 4701, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2988])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4702,Loss 2.927649\n",
      "Epoch 4702, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2989])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4703,Loss 2.927649\n",
      "Epoch 4703, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2989])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4704,Loss 2.927647\n",
      "Epoch 4704, Loss 2.927647\n",
      "    Params:  tensor([  5.3667, -17.2989])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4705,Loss 2.927650\n",
      "Epoch 4705, Loss 2.927650\n",
      "    Params:  tensor([  5.3667, -17.2989])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4706,Loss 2.927649\n",
      "Epoch 4706, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2989])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4707,Loss 2.927649\n",
      "Epoch 4707, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2989])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4708,Loss 2.927649\n",
      "Epoch 4708, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2989])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4709,Loss 2.927649\n",
      "Epoch 4709, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2989])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4710,Loss 2.927650\n",
      "Epoch 4710, Loss 2.927650\n",
      "    Params:  tensor([  5.3667, -17.2989])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4711,Loss 2.927650\n",
      "Epoch 4711, Loss 2.927650\n",
      "    Params:  tensor([  5.3667, -17.2989])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4712,Loss 2.927648\n",
      "Epoch 4712, Loss 2.927648\n",
      "    Params:  tensor([  5.3667, -17.2989])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4713,Loss 2.927649\n",
      "Epoch 4713, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2990])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4714,Loss 2.927649\n",
      "Epoch 4714, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2990])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4715,Loss 2.927650\n",
      "Epoch 4715, Loss 2.927650\n",
      "    Params:  tensor([  5.3667, -17.2990])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4716,Loss 2.927647\n",
      "Epoch 4716, Loss 2.927647\n",
      "    Params:  tensor([  5.3667, -17.2990])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4717,Loss 2.927649\n",
      "Epoch 4717, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2990])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4718,Loss 2.927648\n",
      "Epoch 4718, Loss 2.927648\n",
      "    Params:  tensor([  5.3667, -17.2990])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4719,Loss 2.927648\n",
      "Epoch 4719, Loss 2.927648\n",
      "    Params:  tensor([  5.3667, -17.2990])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4720,Loss 2.927649\n",
      "Epoch 4720, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2990])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4721,Loss 2.927649\n",
      "Epoch 4721, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2990])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4722,Loss 2.927649\n",
      "Epoch 4722, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2990])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4723,Loss 2.927649\n",
      "Epoch 4723, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2991])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4724,Loss 2.927648\n",
      "Epoch 4724, Loss 2.927648\n",
      "    Params:  tensor([  5.3667, -17.2991])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4725,Loss 2.927649\n",
      "Epoch 4725, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2991])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4726,Loss 2.927650\n",
      "Epoch 4726, Loss 2.927650\n",
      "    Params:  tensor([  5.3667, -17.2991])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4727,Loss 2.927648\n",
      "Epoch 4727, Loss 2.927648\n",
      "    Params:  tensor([  5.3667, -17.2991])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4728,Loss 2.927648\n",
      "Epoch 4728, Loss 2.927648\n",
      "    Params:  tensor([  5.3667, -17.2991])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4729,Loss 2.927649\n",
      "Epoch 4729, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2991])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4730,Loss 2.927649\n",
      "Epoch 4730, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2991])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4731,Loss 2.927648\n",
      "Epoch 4731, Loss 2.927648\n",
      "    Params:  tensor([  5.3667, -17.2991])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4732,Loss 2.927649\n",
      "Epoch 4732, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2991])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4733,Loss 2.927649\n",
      "Epoch 4733, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2991])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4734,Loss 2.927649\n",
      "Epoch 4734, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2992])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4735,Loss 2.927649\n",
      "Epoch 4735, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2992])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4736,Loss 2.927650\n",
      "Epoch 4736, Loss 2.927650\n",
      "    Params:  tensor([  5.3667, -17.2992])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4737,Loss 2.927649\n",
      "Epoch 4737, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2992])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4738,Loss 2.927650\n",
      "Epoch 4738, Loss 2.927650\n",
      "    Params:  tensor([  5.3667, -17.2992])\n",
      "    Grad  :  tensor([-0.0002,  0.0010])\n",
      "Epoch 4739,Loss 2.927648\n",
      "Epoch 4739, Loss 2.927648\n",
      "    Params:  tensor([  5.3667, -17.2992])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4740,Loss 2.927649\n",
      "Epoch 4740, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2992])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4741,Loss 2.927648\n",
      "Epoch 4741, Loss 2.927648\n",
      "    Params:  tensor([  5.3667, -17.2992])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4742,Loss 2.927648\n",
      "Epoch 4742, Loss 2.927648\n",
      "    Params:  tensor([  5.3667, -17.2992])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4743,Loss 2.927649\n",
      "Epoch 4743, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2992])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4744,Loss 2.927648\n",
      "Epoch 4744, Loss 2.927648\n",
      "    Params:  tensor([  5.3667, -17.2993])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4745,Loss 2.927649\n",
      "Epoch 4745, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2993])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4746,Loss 2.927648\n",
      "Epoch 4746, Loss 2.927648\n",
      "    Params:  tensor([  5.3667, -17.2993])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4747,Loss 2.927649\n",
      "Epoch 4747, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2993])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4748,Loss 2.927649\n",
      "Epoch 4748, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2993])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4749,Loss 2.927649\n",
      "Epoch 4749, Loss 2.927649\n",
      "    Params:  tensor([  5.3667, -17.2993])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4750,Loss 2.927650\n",
      "Epoch 4750, Loss 2.927650\n",
      "    Params:  tensor([  5.3668, -17.2993])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4751,Loss 2.927649\n",
      "Epoch 4751, Loss 2.927649\n",
      "    Params:  tensor([  5.3668, -17.2993])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4752,Loss 2.927648\n",
      "Epoch 4752, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2993])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4753,Loss 2.927647\n",
      "Epoch 4753, Loss 2.927647\n",
      "    Params:  tensor([  5.3668, -17.2993])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4754,Loss 2.927648\n",
      "Epoch 4754, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2993])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4755,Loss 2.927647\n",
      "Epoch 4755, Loss 2.927647\n",
      "    Params:  tensor([  5.3668, -17.2994])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4756,Loss 2.927649\n",
      "Epoch 4756, Loss 2.927649\n",
      "    Params:  tensor([  5.3668, -17.2994])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4757,Loss 2.927647\n",
      "Epoch 4757, Loss 2.927647\n",
      "    Params:  tensor([  5.3668, -17.2994])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4758,Loss 2.927649\n",
      "Epoch 4758, Loss 2.927649\n",
      "    Params:  tensor([  5.3668, -17.2994])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4759,Loss 2.927648\n",
      "Epoch 4759, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2994])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4760,Loss 2.927649\n",
      "Epoch 4760, Loss 2.927649\n",
      "    Params:  tensor([  5.3668, -17.2994])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4761,Loss 2.927649\n",
      "Epoch 4761, Loss 2.927649\n",
      "    Params:  tensor([  5.3668, -17.2994])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4762,Loss 2.927648\n",
      "Epoch 4762, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2994])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4763,Loss 2.927649\n",
      "Epoch 4763, Loss 2.927649\n",
      "    Params:  tensor([  5.3668, -17.2994])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4764,Loss 2.927647\n",
      "Epoch 4764, Loss 2.927647\n",
      "    Params:  tensor([  5.3668, -17.2994])\n",
      "    Grad  :  tensor([-0.0001,  0.0009])\n",
      "Epoch 4765,Loss 2.927649\n",
      "Epoch 4765, Loss 2.927649\n",
      "    Params:  tensor([  5.3668, -17.2995])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4766,Loss 2.927649\n",
      "Epoch 4766, Loss 2.927649\n",
      "    Params:  tensor([  5.3668, -17.2995])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4767,Loss 2.927649\n",
      "Epoch 4767, Loss 2.927649\n",
      "    Params:  tensor([  5.3668, -17.2995])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4768,Loss 2.927649\n",
      "Epoch 4768, Loss 2.927649\n",
      "    Params:  tensor([  5.3668, -17.2995])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4769,Loss 2.927648\n",
      "Epoch 4769, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2995])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4770,Loss 2.927648\n",
      "Epoch 4770, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2995])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4771,Loss 2.927648\n",
      "Epoch 4771, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2995])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4772,Loss 2.927648\n",
      "Epoch 4772, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2995])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4773,Loss 2.927650\n",
      "Epoch 4773, Loss 2.927650\n",
      "    Params:  tensor([  5.3668, -17.2995])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4774,Loss 2.927649\n",
      "Epoch 4774, Loss 2.927649\n",
      "    Params:  tensor([  5.3668, -17.2995])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4775,Loss 2.927650\n",
      "Epoch 4775, Loss 2.927650\n",
      "    Params:  tensor([  5.3668, -17.2995])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4776,Loss 2.927647\n",
      "Epoch 4776, Loss 2.927647\n",
      "    Params:  tensor([  5.3668, -17.2996])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4777,Loss 2.927648\n",
      "Epoch 4777, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2996])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4778,Loss 2.927647\n",
      "Epoch 4778, Loss 2.927647\n",
      "    Params:  tensor([  5.3668, -17.2996])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4779,Loss 2.927650\n",
      "Epoch 4779, Loss 2.927650\n",
      "    Params:  tensor([  5.3668, -17.2996])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4780,Loss 2.927649\n",
      "Epoch 4780, Loss 2.927649\n",
      "    Params:  tensor([  5.3668, -17.2996])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4781,Loss 2.927648\n",
      "Epoch 4781, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2996])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4782,Loss 2.927648\n",
      "Epoch 4782, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2996])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4783,Loss 2.927649\n",
      "Epoch 4783, Loss 2.927649\n",
      "    Params:  tensor([  5.3668, -17.2996])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4784,Loss 2.927649\n",
      "Epoch 4784, Loss 2.927649\n",
      "    Params:  tensor([  5.3668, -17.2996])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4785,Loss 2.927648\n",
      "Epoch 4785, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2996])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4786,Loss 2.927648\n",
      "Epoch 4786, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2997])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4787,Loss 2.927650\n",
      "Epoch 4787, Loss 2.927650\n",
      "    Params:  tensor([  5.3668, -17.2997])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4788,Loss 2.927648\n",
      "Epoch 4788, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2997])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4789,Loss 2.927648\n",
      "Epoch 4789, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2997])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4790,Loss 2.927648\n",
      "Epoch 4790, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2997])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4791,Loss 2.927648\n",
      "Epoch 4791, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2997])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4792,Loss 2.927647\n",
      "Epoch 4792, Loss 2.927647\n",
      "    Params:  tensor([  5.3668, -17.2997])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4793,Loss 2.927650\n",
      "Epoch 4793, Loss 2.927650\n",
      "    Params:  tensor([  5.3668, -17.2997])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4794,Loss 2.927648\n",
      "Epoch 4794, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2997])\n",
      "    Grad  :  tensor([-0.0001,  0.0009])\n",
      "Epoch 4795,Loss 2.927650\n",
      "Epoch 4795, Loss 2.927650\n",
      "    Params:  tensor([  5.3668, -17.2997])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4796,Loss 2.927648\n",
      "Epoch 4796, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2997])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4797,Loss 2.927648\n",
      "Epoch 4797, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2997])\n",
      "    Grad  :  tensor([-0.0002,  0.0009])\n",
      "Epoch 4798,Loss 2.927649\n",
      "Epoch 4798, Loss 2.927649\n",
      "    Params:  tensor([  5.3668, -17.2998])\n",
      "    Grad  :  tensor([-0.0001,  0.0009])\n",
      "Epoch 4799,Loss 2.927648\n",
      "Epoch 4799, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2998])\n",
      "    Grad  :  tensor([-0.0001,  0.0009])\n",
      "Epoch 4800,Loss 2.927648\n",
      "Epoch 4800, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2998])\n",
      "    Grad  :  tensor([-0.0001,  0.0009])\n",
      "Epoch 4801,Loss 2.927646\n",
      "Epoch 4801, Loss 2.927646\n",
      "    Params:  tensor([  5.3668, -17.2998])\n",
      "    Grad  :  tensor([-0.0001,  0.0009])\n",
      "Epoch 4802,Loss 2.927649\n",
      "Epoch 4802, Loss 2.927649\n",
      "    Params:  tensor([  5.3668, -17.2998])\n",
      "    Grad  :  tensor([-0.0001,  0.0009])\n",
      "Epoch 4803,Loss 2.927647\n",
      "Epoch 4803, Loss 2.927647\n",
      "    Params:  tensor([  5.3668, -17.2998])\n",
      "    Grad  :  tensor([-0.0001,  0.0009])\n",
      "Epoch 4804,Loss 2.927648\n",
      "Epoch 4804, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2998])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4805,Loss 2.927649\n",
      "Epoch 4805, Loss 2.927649\n",
      "    Params:  tensor([  5.3668, -17.2998])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4806,Loss 2.927647\n",
      "Epoch 4806, Loss 2.927647\n",
      "    Params:  tensor([  5.3668, -17.2998])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4807,Loss 2.927648\n",
      "Epoch 4807, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2998])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4808,Loss 2.927648\n",
      "Epoch 4808, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2998])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4809,Loss 2.927649\n",
      "Epoch 4809, Loss 2.927649\n",
      "    Params:  tensor([  5.3668, -17.2998])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4810,Loss 2.927648\n",
      "Epoch 4810, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2998])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4811,Loss 2.927648\n",
      "Epoch 4811, Loss 2.927648\n",
      "    Params:  tensor([  5.3668, -17.2999])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4812,Loss 2.927649\n",
      "Epoch 4812, Loss 2.927649\n",
      "    Params:  tensor([  5.3668, -17.2999])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4813,Loss 2.927647\n",
      "Epoch 4813, Loss 2.927647\n",
      "    Params:  tensor([  5.3669, -17.2999])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4814,Loss 2.927648\n",
      "Epoch 4814, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.2999])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4815,Loss 2.927648\n",
      "Epoch 4815, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.2999])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4816,Loss 2.927647\n",
      "Epoch 4816, Loss 2.927647\n",
      "    Params:  tensor([  5.3669, -17.2999])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4817,Loss 2.927647\n",
      "Epoch 4817, Loss 2.927647\n",
      "    Params:  tensor([  5.3669, -17.2999])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4818,Loss 2.927648\n",
      "Epoch 4818, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.2999])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4819,Loss 2.927647\n",
      "Epoch 4819, Loss 2.927647\n",
      "    Params:  tensor([  5.3669, -17.2999])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4820,Loss 2.927648\n",
      "Epoch 4820, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.2999])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4821,Loss 2.927649\n",
      "Epoch 4821, Loss 2.927649\n",
      "    Params:  tensor([  5.3669, -17.2999])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4822,Loss 2.927648\n",
      "Epoch 4822, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.2999])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4823,Loss 2.927647\n",
      "Epoch 4823, Loss 2.927647\n",
      "    Params:  tensor([  5.3669, -17.2999])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4824,Loss 2.927649\n",
      "Epoch 4824, Loss 2.927649\n",
      "    Params:  tensor([  5.3669, -17.3000])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4825,Loss 2.927649\n",
      "Epoch 4825, Loss 2.927649\n",
      "    Params:  tensor([  5.3669, -17.3000])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4826,Loss 2.927648\n",
      "Epoch 4826, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3000])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4827,Loss 2.927648\n",
      "Epoch 4827, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3000])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4828,Loss 2.927649\n",
      "Epoch 4828, Loss 2.927649\n",
      "    Params:  tensor([  5.3669, -17.3000])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4829,Loss 2.927648\n",
      "Epoch 4829, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3000])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4830,Loss 2.927647\n",
      "Epoch 4830, Loss 2.927647\n",
      "    Params:  tensor([  5.3669, -17.3000])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4831,Loss 2.927648\n",
      "Epoch 4831, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3000])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4832,Loss 2.927649\n",
      "Epoch 4832, Loss 2.927649\n",
      "    Params:  tensor([  5.3669, -17.3000])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4833,Loss 2.927646\n",
      "Epoch 4833, Loss 2.927646\n",
      "    Params:  tensor([  5.3669, -17.3000])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4834,Loss 2.927649\n",
      "Epoch 4834, Loss 2.927649\n",
      "    Params:  tensor([  5.3669, -17.3000])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4835,Loss 2.927648\n",
      "Epoch 4835, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3000])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4836,Loss 2.927647\n",
      "Epoch 4836, Loss 2.927647\n",
      "    Params:  tensor([  5.3669, -17.3000])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4837,Loss 2.927648\n",
      "Epoch 4837, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3001])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4838,Loss 2.927647\n",
      "Epoch 4838, Loss 2.927647\n",
      "    Params:  tensor([  5.3669, -17.3001])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4839,Loss 2.927648\n",
      "Epoch 4839, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3001])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4840,Loss 2.927647\n",
      "Epoch 4840, Loss 2.927647\n",
      "    Params:  tensor([  5.3669, -17.3001])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4841,Loss 2.927650\n",
      "Epoch 4841, Loss 2.927650\n",
      "    Params:  tensor([  5.3669, -17.3001])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4842,Loss 2.927648\n",
      "Epoch 4842, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3001])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4843,Loss 2.927648\n",
      "Epoch 4843, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3001])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4844,Loss 2.927649\n",
      "Epoch 4844, Loss 2.927649\n",
      "    Params:  tensor([  5.3669, -17.3001])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4845,Loss 2.927647\n",
      "Epoch 4845, Loss 2.927647\n",
      "    Params:  tensor([  5.3669, -17.3001])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4846,Loss 2.927647\n",
      "Epoch 4846, Loss 2.927647\n",
      "    Params:  tensor([  5.3669, -17.3001])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4847,Loss 2.927648\n",
      "Epoch 4847, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3001])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4848,Loss 2.927647\n",
      "Epoch 4848, Loss 2.927647\n",
      "    Params:  tensor([  5.3669, -17.3001])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4849,Loss 2.927648\n",
      "Epoch 4849, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3001])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4850,Loss 2.927647\n",
      "Epoch 4850, Loss 2.927647\n",
      "    Params:  tensor([  5.3669, -17.3002])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4851,Loss 2.927649\n",
      "Epoch 4851, Loss 2.927649\n",
      "    Params:  tensor([  5.3669, -17.3002])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4852,Loss 2.927648\n",
      "Epoch 4852, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3002])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4853,Loss 2.927648\n",
      "Epoch 4853, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3002])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4854,Loss 2.927649\n",
      "Epoch 4854, Loss 2.927649\n",
      "    Params:  tensor([  5.3669, -17.3002])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4855,Loss 2.927647\n",
      "Epoch 4855, Loss 2.927647\n",
      "    Params:  tensor([  5.3669, -17.3002])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4856,Loss 2.927648\n",
      "Epoch 4856, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3002])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4857,Loss 2.927647\n",
      "Epoch 4857, Loss 2.927647\n",
      "    Params:  tensor([  5.3669, -17.3002])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4858,Loss 2.927648\n",
      "Epoch 4858, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3002])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4859,Loss 2.927648\n",
      "Epoch 4859, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3002])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4860,Loss 2.927647\n",
      "Epoch 4860, Loss 2.927647\n",
      "    Params:  tensor([  5.3669, -17.3002])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4861,Loss 2.927648\n",
      "Epoch 4861, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3002])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4862,Loss 2.927645\n",
      "Epoch 4862, Loss 2.927645\n",
      "    Params:  tensor([  5.3669, -17.3002])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4863,Loss 2.927648\n",
      "Epoch 4863, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3003])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4864,Loss 2.927648\n",
      "Epoch 4864, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3003])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4865,Loss 2.927647\n",
      "Epoch 4865, Loss 2.927647\n",
      "    Params:  tensor([  5.3669, -17.3003])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4866,Loss 2.927648\n",
      "Epoch 4866, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3003])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4867,Loss 2.927648\n",
      "Epoch 4867, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3003])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4868,Loss 2.927648\n",
      "Epoch 4868, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3003])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4869,Loss 2.927648\n",
      "Epoch 4869, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3003])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4870,Loss 2.927648\n",
      "Epoch 4870, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3003])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4871,Loss 2.927648\n",
      "Epoch 4871, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3003])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4872,Loss 2.927646\n",
      "Epoch 4872, Loss 2.927646\n",
      "    Params:  tensor([  5.3669, -17.3003])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4873,Loss 2.927648\n",
      "Epoch 4873, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3003])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4874,Loss 2.927649\n",
      "Epoch 4874, Loss 2.927649\n",
      "    Params:  tensor([  5.3669, -17.3003])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4875,Loss 2.927647\n",
      "Epoch 4875, Loss 2.927647\n",
      "    Params:  tensor([  5.3669, -17.3003])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4876,Loss 2.927648\n",
      "Epoch 4876, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3004])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4877,Loss 2.927647\n",
      "Epoch 4877, Loss 2.927647\n",
      "    Params:  tensor([  5.3669, -17.3004])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4878,Loss 2.927647\n",
      "Epoch 4878, Loss 2.927647\n",
      "    Params:  tensor([  5.3669, -17.3004])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4879,Loss 2.927647\n",
      "Epoch 4879, Loss 2.927647\n",
      "    Params:  tensor([  5.3669, -17.3004])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4880,Loss 2.927648\n",
      "Epoch 4880, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3004])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4881,Loss 2.927648\n",
      "Epoch 4881, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3004])\n",
      "    Grad  :  tensor([-0.0001,  0.0008])\n",
      "Epoch 4882,Loss 2.927648\n",
      "Epoch 4882, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3004])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4883,Loss 2.927648\n",
      "Epoch 4883, Loss 2.927648\n",
      "    Params:  tensor([  5.3669, -17.3004])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4884,Loss 2.927647\n",
      "Epoch 4884, Loss 2.927647\n",
      "    Params:  tensor([  5.3669, -17.3004])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4885,Loss 2.927647\n",
      "Epoch 4885, Loss 2.927647\n",
      "    Params:  tensor([  5.3669, -17.3004])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4886,Loss 2.927649\n",
      "Epoch 4886, Loss 2.927649\n",
      "    Params:  tensor([  5.3669, -17.3004])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4887,Loss 2.927647\n",
      "Epoch 4887, Loss 2.927647\n",
      "    Params:  tensor([  5.3670, -17.3004])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4888,Loss 2.927649\n",
      "Epoch 4888, Loss 2.927649\n",
      "    Params:  tensor([  5.3670, -17.3004])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4889,Loss 2.927648\n",
      "Epoch 4889, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3005])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4890,Loss 2.927648\n",
      "Epoch 4890, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3005])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4891,Loss 2.927648\n",
      "Epoch 4891, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3005])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4892,Loss 2.927647\n",
      "Epoch 4892, Loss 2.927647\n",
      "    Params:  tensor([  5.3670, -17.3005])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4893,Loss 2.927648\n",
      "Epoch 4893, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3005])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4894,Loss 2.927646\n",
      "Epoch 4894, Loss 2.927646\n",
      "    Params:  tensor([  5.3670, -17.3005])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4895,Loss 2.927648\n",
      "Epoch 4895, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3005])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4896,Loss 2.927648\n",
      "Epoch 4896, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3005])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4897,Loss 2.927648\n",
      "Epoch 4897, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3005])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4898,Loss 2.927647\n",
      "Epoch 4898, Loss 2.927647\n",
      "    Params:  tensor([  5.3670, -17.3005])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4899,Loss 2.927647\n",
      "Epoch 4899, Loss 2.927647\n",
      "    Params:  tensor([  5.3670, -17.3005])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4900,Loss 2.927648\n",
      "Epoch 4900, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3005])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4901,Loss 2.927648\n",
      "Epoch 4901, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3005])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4902,Loss 2.927649\n",
      "Epoch 4902, Loss 2.927649\n",
      "    Params:  tensor([  5.3670, -17.3006])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4903,Loss 2.927648\n",
      "Epoch 4903, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3006])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4904,Loss 2.927647\n",
      "Epoch 4904, Loss 2.927647\n",
      "    Params:  tensor([  5.3670, -17.3006])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4905,Loss 2.927647\n",
      "Epoch 4905, Loss 2.927647\n",
      "    Params:  tensor([  5.3670, -17.3006])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4906,Loss 2.927646\n",
      "Epoch 4906, Loss 2.927646\n",
      "    Params:  tensor([  5.3670, -17.3006])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4907,Loss 2.927648\n",
      "Epoch 4907, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3006])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4908,Loss 2.927646\n",
      "Epoch 4908, Loss 2.927646\n",
      "    Params:  tensor([  5.3670, -17.3006])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4909,Loss 2.927647\n",
      "Epoch 4909, Loss 2.927647\n",
      "    Params:  tensor([  5.3670, -17.3006])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4910,Loss 2.927648\n",
      "Epoch 4910, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3006])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4911,Loss 2.927647\n",
      "Epoch 4911, Loss 2.927647\n",
      "    Params:  tensor([  5.3670, -17.3006])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4912,Loss 2.927648\n",
      "Epoch 4912, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3006])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4913,Loss 2.927647\n",
      "Epoch 4913, Loss 2.927647\n",
      "    Params:  tensor([  5.3670, -17.3006])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4914,Loss 2.927648\n",
      "Epoch 4914, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3006])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4915,Loss 2.927648\n",
      "Epoch 4915, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3006])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4916,Loss 2.927648\n",
      "Epoch 4916, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3007])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4917,Loss 2.927648\n",
      "Epoch 4917, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3007])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4918,Loss 2.927649\n",
      "Epoch 4918, Loss 2.927649\n",
      "    Params:  tensor([  5.3670, -17.3007])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4919,Loss 2.927648\n",
      "Epoch 4919, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3007])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4920,Loss 2.927648\n",
      "Epoch 4920, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3007])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4921,Loss 2.927647\n",
      "Epoch 4921, Loss 2.927647\n",
      "    Params:  tensor([  5.3670, -17.3007])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4922,Loss 2.927647\n",
      "Epoch 4922, Loss 2.927647\n",
      "    Params:  tensor([  5.3670, -17.3007])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4923,Loss 2.927648\n",
      "Epoch 4923, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3007])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4924,Loss 2.927647\n",
      "Epoch 4924, Loss 2.927647\n",
      "    Params:  tensor([  5.3670, -17.3007])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4925,Loss 2.927648\n",
      "Epoch 4925, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3007])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4926,Loss 2.927646\n",
      "Epoch 4926, Loss 2.927646\n",
      "    Params:  tensor([  5.3670, -17.3007])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4927,Loss 2.927647\n",
      "Epoch 4927, Loss 2.927647\n",
      "    Params:  tensor([  5.3670, -17.3007])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4928,Loss 2.927648\n",
      "Epoch 4928, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3007])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4929,Loss 2.927647\n",
      "Epoch 4929, Loss 2.927647\n",
      "    Params:  tensor([  5.3670, -17.3008])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4930,Loss 2.927648\n",
      "Epoch 4930, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3008])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4931,Loss 2.927648\n",
      "Epoch 4931, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3008])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4932,Loss 2.927648\n",
      "Epoch 4932, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3008])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4933,Loss 2.927646\n",
      "Epoch 4933, Loss 2.927646\n",
      "    Params:  tensor([  5.3670, -17.3008])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4934,Loss 2.927649\n",
      "Epoch 4934, Loss 2.927649\n",
      "    Params:  tensor([  5.3670, -17.3008])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4935,Loss 2.927648\n",
      "Epoch 4935, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3008])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4936,Loss 2.927646\n",
      "Epoch 4936, Loss 2.927646\n",
      "    Params:  tensor([  5.3670, -17.3008])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4937,Loss 2.927648\n",
      "Epoch 4937, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3008])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4938,Loss 2.927646\n",
      "Epoch 4938, Loss 2.927646\n",
      "    Params:  tensor([  5.3670, -17.3008])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4939,Loss 2.927647\n",
      "Epoch 4939, Loss 2.927647\n",
      "    Params:  tensor([  5.3670, -17.3008])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4940,Loss 2.927646\n",
      "Epoch 4940, Loss 2.927646\n",
      "    Params:  tensor([  5.3670, -17.3008])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4941,Loss 2.927649\n",
      "Epoch 4941, Loss 2.927649\n",
      "    Params:  tensor([  5.3670, -17.3008])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4942,Loss 2.927648\n",
      "Epoch 4942, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3009])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4943,Loss 2.927646\n",
      "Epoch 4943, Loss 2.927646\n",
      "    Params:  tensor([  5.3670, -17.3009])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4944,Loss 2.927649\n",
      "Epoch 4944, Loss 2.927649\n",
      "    Params:  tensor([  5.3670, -17.3009])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4945,Loss 2.927646\n",
      "Epoch 4945, Loss 2.927646\n",
      "    Params:  tensor([  5.3670, -17.3009])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4946,Loss 2.927647\n",
      "Epoch 4946, Loss 2.927647\n",
      "    Params:  tensor([  5.3670, -17.3009])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4947,Loss 2.927648\n",
      "Epoch 4947, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3009])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4948,Loss 2.927649\n",
      "Epoch 4948, Loss 2.927649\n",
      "    Params:  tensor([  5.3670, -17.3009])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4949,Loss 2.927646\n",
      "Epoch 4949, Loss 2.927646\n",
      "    Params:  tensor([  5.3670, -17.3009])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4950,Loss 2.927648\n",
      "Epoch 4950, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3009])\n",
      "    Grad  :  tensor([-9.9009e-05,  6.6358e-04])\n",
      "Epoch 4951,Loss 2.927646\n",
      "Epoch 4951, Loss 2.927646\n",
      "    Params:  tensor([  5.3670, -17.3009])\n",
      "    Grad  :  tensor([-9.5758e-05,  6.6289e-04])\n",
      "Epoch 4952,Loss 2.927646\n",
      "Epoch 4952, Loss 2.927646\n",
      "    Params:  tensor([  5.3670, -17.3009])\n",
      "    Grad  :  tensor([-9.6755e-05,  6.6185e-04])\n",
      "Epoch 4953,Loss 2.927648\n",
      "Epoch 4953, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3009])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4954,Loss 2.927647\n",
      "Epoch 4954, Loss 2.927647\n",
      "    Params:  tensor([  5.3670, -17.3009])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4955,Loss 2.927647\n",
      "Epoch 4955, Loss 2.927647\n",
      "    Params:  tensor([  5.3670, -17.3009])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4956,Loss 2.927647\n",
      "Epoch 4956, Loss 2.927647\n",
      "    Params:  tensor([  5.3670, -17.3009])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4957,Loss 2.927648\n",
      "Epoch 4957, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3009])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4958,Loss 2.927646\n",
      "Epoch 4958, Loss 2.927646\n",
      "    Params:  tensor([  5.3670, -17.3009])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4959,Loss 2.927648\n",
      "Epoch 4959, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3010])\n",
      "    Grad  :  tensor([-9.7708e-05,  6.5474e-04])\n",
      "Epoch 4960,Loss 2.927647\n",
      "Epoch 4960, Loss 2.927647\n",
      "    Params:  tensor([  5.3670, -17.3010])\n",
      "    Grad  :  tensor([-9.9832e-05,  6.5335e-04])\n",
      "Epoch 4961,Loss 2.927648\n",
      "Epoch 4961, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3010])\n",
      "    Grad  :  tensor([-9.8055e-05,  6.5266e-04])\n",
      "Epoch 4962,Loss 2.927646\n",
      "Epoch 4962, Loss 2.927646\n",
      "    Params:  tensor([  5.3670, -17.3010])\n",
      "    Grad  :  tensor([-0.0001,  0.0007])\n",
      "Epoch 4963,Loss 2.927648\n",
      "Epoch 4963, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3010])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4964,Loss 2.927647\n",
      "Epoch 4964, Loss 2.927647\n",
      "    Params:  tensor([  5.3670, -17.3010])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4965,Loss 2.927647\n",
      "Epoch 4965, Loss 2.927647\n",
      "    Params:  tensor([  5.3670, -17.3010])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4966,Loss 2.927648\n",
      "Epoch 4966, Loss 2.927648\n",
      "    Params:  tensor([  5.3670, -17.3010])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4967,Loss 2.927646\n",
      "Epoch 4967, Loss 2.927646\n",
      "    Params:  tensor([  5.3671, -17.3010])\n",
      "    Grad  :  tensor([-9.7795e-05,  6.4676e-04])\n",
      "Epoch 4968,Loss 2.927647\n",
      "Epoch 4968, Loss 2.927647\n",
      "    Params:  tensor([  5.3671, -17.3010])\n",
      "    Grad  :  tensor([-9.7145e-05,  6.4572e-04])\n",
      "Epoch 4969,Loss 2.927647\n",
      "Epoch 4969, Loss 2.927647\n",
      "    Params:  tensor([  5.3671, -17.3010])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4970,Loss 2.927648\n",
      "Epoch 4970, Loss 2.927648\n",
      "    Params:  tensor([  5.3671, -17.3010])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4971,Loss 2.927648\n",
      "Epoch 4971, Loss 2.927648\n",
      "    Params:  tensor([  5.3671, -17.3010])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4972,Loss 2.927647\n",
      "Epoch 4972, Loss 2.927647\n",
      "    Params:  tensor([  5.3671, -17.3010])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4973,Loss 2.927648\n",
      "Epoch 4973, Loss 2.927648\n",
      "    Params:  tensor([  5.3671, -17.3010])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4974,Loss 2.927646\n",
      "Epoch 4974, Loss 2.927646\n",
      "    Params:  tensor([  5.3671, -17.3010])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4975,Loss 2.927647\n",
      "Epoch 4975, Loss 2.927647\n",
      "    Params:  tensor([  5.3671, -17.3010])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4976,Loss 2.927647\n",
      "Epoch 4976, Loss 2.927647\n",
      "    Params:  tensor([  5.3671, -17.3011])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4977,Loss 2.927647\n",
      "Epoch 4977, Loss 2.927647\n",
      "    Params:  tensor([  5.3671, -17.3011])\n",
      "    Grad  :  tensor([-9.5454e-05,  6.3688e-04])\n",
      "Epoch 4978,Loss 2.927648\n",
      "Epoch 4978, Loss 2.927648\n",
      "    Params:  tensor([  5.3671, -17.3011])\n",
      "    Grad  :  tensor([-9.8185e-05,  6.3549e-04])\n",
      "Epoch 4979,Loss 2.927648\n",
      "Epoch 4979, Loss 2.927648\n",
      "    Params:  tensor([  5.3671, -17.3011])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4980,Loss 2.927647\n",
      "Epoch 4980, Loss 2.927647\n",
      "    Params:  tensor([  5.3671, -17.3011])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4981,Loss 2.927646\n",
      "Epoch 4981, Loss 2.927646\n",
      "    Params:  tensor([  5.3671, -17.3011])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4982,Loss 2.927648\n",
      "Epoch 4982, Loss 2.927648\n",
      "    Params:  tensor([  5.3671, -17.3011])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4983,Loss 2.927647\n",
      "Epoch 4983, Loss 2.927647\n",
      "    Params:  tensor([  5.3671, -17.3011])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4984,Loss 2.927648\n",
      "Epoch 4984, Loss 2.927648\n",
      "    Params:  tensor([  5.3671, -17.3011])\n",
      "    Grad  :  tensor([-8.9775e-05,  6.3099e-04])\n",
      "Epoch 4985,Loss 2.927647\n",
      "Epoch 4985, Loss 2.927647\n",
      "    Params:  tensor([  5.3671, -17.3011])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4986,Loss 2.927648\n",
      "Epoch 4986, Loss 2.927648\n",
      "    Params:  tensor([  5.3671, -17.3011])\n",
      "    Grad  :  tensor([-9.6668e-05,  6.2804e-04])\n",
      "Epoch 4987,Loss 2.927647\n",
      "Epoch 4987, Loss 2.927647\n",
      "    Params:  tensor([  5.3671, -17.3011])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4988,Loss 2.927647\n",
      "Epoch 4988, Loss 2.927647\n",
      "    Params:  tensor([  5.3671, -17.3011])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4989,Loss 2.927647\n",
      "Epoch 4989, Loss 2.927647\n",
      "    Params:  tensor([  5.3671, -17.3011])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4990,Loss 2.927648\n",
      "Epoch 4990, Loss 2.927648\n",
      "    Params:  tensor([  5.3671, -17.3011])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4991,Loss 2.927646\n",
      "Epoch 4991, Loss 2.927646\n",
      "    Params:  tensor([  5.3671, -17.3011])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4992,Loss 2.927648\n",
      "Epoch 4992, Loss 2.927648\n",
      "    Params:  tensor([  5.3671, -17.3011])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4993,Loss 2.927647\n",
      "Epoch 4993, Loss 2.927647\n",
      "    Params:  tensor([  5.3671, -17.3011])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4994,Loss 2.927646\n",
      "Epoch 4994, Loss 2.927646\n",
      "    Params:  tensor([  5.3671, -17.3012])\n",
      "    Grad  :  tensor([-9.2333e-05,  6.2041e-04])\n",
      "Epoch 4995,Loss 2.927647\n",
      "Epoch 4995, Loss 2.927647\n",
      "    Params:  tensor([  5.3671, -17.3012])\n",
      "    Grad  :  tensor([-9.9399e-05,  6.1833e-04])\n",
      "Epoch 4996,Loss 2.927648\n",
      "Epoch 4996, Loss 2.927648\n",
      "    Params:  tensor([  5.3671, -17.3012])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4997,Loss 2.927647\n",
      "Epoch 4997, Loss 2.927647\n",
      "    Params:  tensor([  5.3671, -17.3012])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4998,Loss 2.927647\n",
      "Epoch 4998, Loss 2.927647\n",
      "    Params:  tensor([  5.3671, -17.3012])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 4999,Loss 2.927647\n",
      "Epoch 4999, Loss 2.927647\n",
      "    Params:  tensor([  5.3671, -17.3012])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n",
      "Epoch 5000,Loss 2.927648\n",
      "Epoch 5000, Loss 2.927648\n",
      "    Params:  tensor([  5.3671, -17.3012])\n",
      "    Grad  :  tensor([-0.0001,  0.0006])\n"
     ]
    }
   ],
   "source": [
    "## 规范化梯度  更改输入使梯度差别不要太大\n",
    "t_un = 0.1 * t_u  ## 规范化输入\n",
    "params = training_loop(n_epochs=5000,learning_rate=1e-2,params=torch.tensor([1.0,0.0]),t_u = t_un,t_c = t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x113529c1ee0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAADT8AAAofCAYAAAA/FwegAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAFxGAABcRgEUlENBAAEAAElEQVR4nOzdebzXA97//9fZWtEiKSktUtJCyZKsiRbrzCBjGyPbMJi5xpAlYqYxZpgxxt41Zpi5DBkTxpBUKEIlaZEtEUVKRU6d6pzz+6Pv9btmBqft/f583uec+/1280/nfZ7v1+d2I/+cx+0UVFZWVgYAAAAAAAAAAAAAAABAxhTm+wAAAAAAAAAAAAAAAACAryN+AgAAAAAAAAAAAAAAADJJ/AQAAAAAAAAAAAAAAABkkvgJAAAAAAAAAAAAAAAAyCTxEwAAAAAAAAAAAAAAAJBJ4icAAAAAAAAAAAAAAAAgk8RPAAAAAAAAAAAAAAAAQCaJnwAAAAAAAAAAAAAAAIBMEj8BAAAAAAAAAAAAAAAAmSR+AgAAAAAAAAAAAAAAADJJ/AQAAAAAAAAAAAAAAABkkvgJAAAAAAAAAAAAAAAAyCTxEwAAAAAAAAAAAAAAAJBJ4icAAAAAAAAAAAAAAAAgk8RPAAAAAAAAAAAAAAAAQCaJnwAAAAAAAAAAAAAAAIBMEj8BAAAAAAAAAAAAAAAAmSR+AgAAAAAAAAAAAAAAADJJ/AQAAAAAAAAAAAAAAABkkvgJAAAAAAAAAAAAAAAAyCTxEwAAAAAAAAAAAAAAAJBJ4icAAAAAAAAAAAAAAAAgk8RPAAAAAAAAAAAAAAAAQCaJnwAAAAAAAAAAAAAAAIBMEj8BAAAAAAAAAAAAAAAAmSR+AgAAAAAAAAAAAAAAADJJ/AQAAAAAAAAAAAAAAABkkvgJAAAAAAAAAAAAAAAAyCTxEwAAAAAAAAAAAAAAAJBJ4icAAAAAAAAAAAAAAAAgk8RPAAAAAAAAAAAAAAAAQCaJnwAAAAAAAAAAAAAAAIBMEj8BAAAAAAAAAAAAAAAAmSR+AgAAAAAAAAAAAAAAADJJ/AQAAAAAAAAAAAAAAABkkvgJAAAAAAAAAAAAAAAAyCTxEwAAAAAAAAAAAAAAAJBJ4icAAAAAAAAAAAAAAAAgk8RPAAAAAAAAAAAAAAAAQCaJnwAAAAAAAAAAAAAAAIBMEj8BAAAAAAAAAAAAAAAAmSR+AgAAAAAAAAAAAAAAADJJ/AQAAAAAAAAAAAAAAABkkvgJAAAAAAAAAAAAAAAAyCTxEwAAAAAAAAAAAAAAAJBJ4icAAAAAAAAAAAAAAAAgk8RPAAAAAAAAAAAAAAAAQCaJnwAAAAAAAAAAAAAAAIBMEj8BAAAAAAAAAAAAAAAAmSR+AgAAAAAAAAAAAAAAADJJ/AQAAAAAAAAAAAAAAABkkvgJAAAAAAAAAAAAAAAAyCTxEwAAAAAAAAAAAAAAAJBJ4icAAAAAAAAAAAAAAAAgk8RPAAAAAAAAAAAAAAAAQCaJnwAAAAAAAAAAAAAAAIBMKs73AQC1WYsWLWLFihVf+fOSkpJo06ZN7g8CAAAAAAAAAAAAACCTPvjgg1i3bt1X/rxx48bx8ccf5+Gi3CiorKyszPcRALVVvXr1oqysLN9nAAAAAAAAAAAAAABQTdWtWzfWrFmT7zNSU5jvAwAAAAAAAAAAAAAAAAC+jvgJAAAAAAAAAAAAAAAAyCTxEwAAAAAAAAAAAAAAAJBJ4icAAAAAAAAAAAAAAAAgk4rzfQBAbVZSUhJlZWVf+fO6detGhw4d8nARAAAAAAAAAAAAAABZ9O67737tz5+XlJTk4ZrcET8B5FGbNm1i7ty5X/nzDh06xJw5c/JwEQAAAAAAAAAAAAAAWbTHHnt87c+ft2nTJg/X5E5hvg8AAAAAAAAAAAAAAAAA+DriJwAAAAAAAAAAAAAAACCTxE8AAAAAAAAAAAAAAABAJomfAAAAAAAAAAAAAAAAgEwSPwEAAAAAAAAAAAAAAACZJH4CAAAAAAAAAAAAAAAAMkn8BAAAAAAAAAAAAAAAAGSS+AkAAAAAAAAAAAAAAADIJPETAAAAAAAAAAAAAAAAkEniJwAAAAAAAAAAAAAAACCTxE8AAAAAAAAAAAAAAABAJomfAAAAAAAAAAAAAAAAgEwSPwEAAAAAAAAAAAAAAACZJH4CAAAAAAAAAAAAAAAAMkn8BAAAAAAAAAAAAAAAAGSS+AkAAAAAAAAAAAAAAADIJPETAAAAAAAAAAAAAAAAkEniJwAAAAAAAAAAAAAAACCTxE8AAAAAAAAAAAAAAABAJomfAAAAAAAAAAAAAAAAgEwSPwEAAAAAAAAAAAAAAACZJH4CAAAAAAAAAAAAAAAAMkn8BAAAAAAAAAAAAAAAAGSS+AkAAAAAAAAAAAAAAADIJPETAAAAAAAAAAAAAAAAkEniJwAAAAAAAAAAAAAAACCTxE8AAAAAAAAAAAAAAABAJomfAAAAAAAAAAAAAAAAgEwSPwEAAAAAAAAAAAAAAACZJH4CAAAAAAAAAAAAAAAAMkn8BAAAAAAAAAAAAAAAAGSS+AkAAAAAAAAAAAAAAADIJPETAAAAAAAAAAAAAAAAkEniJwAAAAAAAAAAAAAAACCTxE8AAAAAAAAAAAAAAABAJomfAAAAAAAAAAAAAAAAgEwSPwEAAAAAAAAAAAAAAACZJH4CAAAAAAAAAAAAAAAAMkn8BAAAAAAAAAAAAAAAAGSS+AkAAAAAAAAAAAAAAADIJPETAAAAAAAAAAAAAAAAkEniJwAAAAAAAAAAAAAAACCTxE8AAAAAAAAAAAAAAABAJomfAAAAAAAAAAAAAAAAgEwSPwEAAAAAAAAAAAAAAACZJH4CAAAAAAAAAAAAAAAAMkn8BAAAAAAAAAAAAAAAAGSS+AkAAAAAAAAAAAAAAADIJPETAAAAAAAAAAAAAAAAkEniJwAAAAAAAAAAAAAAACCTxE8AAAAAAAAAAAAAAABAJomfAAAAAAAAAAAAAAAAgEwSPwEAAAAAAAAAAAAAAACZJH4CAAAAAAAAAAAAAAAAMkn8BAAAAAAAAAAAAAAAAGSS+AkAAAAAAAAAAAAAAADIJPETAAAAAAAAAAAAAAAAkEniJwAAAAAAAAAAAAAAACCTxE8AAAAAAAAAAAAAAABAJomfAAAAAAAAAAAAAAAAgEwSPwEAAAAAAAAAAAAAAACZJH4CAAAAAAAAAAAAAAAAMkn8BAAAAAAAAAAAAAAAAGSS+AkAAAAAAAAAAAAAAADIJPETAAAAAAAAAAAAAAAAkEniJwAAAAAAAAAAAAAAACCTxE8AAAAAAAAAAAAAAABAJhXn+wAAAAAAAAAAAAAAAIBaq6I8YulbEYtei1gyN2LNioj1ZRHlayOK6kQU142o1ziieZeInfaKaNYxorAoz0dD7oifAAAAAAAAAAAAAAAAcqWyMmLB5Ig3/xnx0asRH78esa5007+/pGFEi24RrXpGdBoU0bZvREFBevdCnomfAAAAAAAAAAAAAAAA0rZ6RcTMv0ZM++8Nv+lpS637MmLhSxv+een2iGa7Rex9VkSPIRH1Gyd1LWSG+AkAAAAAAAAAAAAAACAtn82PmPzbiFmjN+83PG2qpW9FPHVZxPgREd1OiOh7SUTT9sm/B/KkMN8HAAAAAAAAAAAAAAAA1Djl6yMm/ybitv0iXv1TOuHTv1pXuuE9t+23IbaqKE/3fZAj4icAAAAAAAAAAAAAAIAkffpmxB+OiHjm2ojysty+u7ws4plrIv77iA13QDUnfgIAAAAAAAAAAAAAAEhCRUXEC7dE3HlgxEfT83vLR9M23PHCLRvugmqqON8HAAAAAAAAAAAAAAAAVHvl6yLG/CBi1kP5vuT/lJdFjBse8fHsiONujygqyfdFsNn85icAAAAAAAAAAAAAAICtsW5NxIOnZSt8+lezHtpw37o1+b4ENpv4CQAAAAAAAAAAAAAAYEuVr4sY/b2It57M9yVVe+vJiIfP3HAvVCPiJwAAAAAAAAAAAAAAgC1RUREx5gfZD5/+15v/3HBvRUW+L4FNJn4CAAAAAAAAAAAAAADYElNujZj1UL6v2DyzHoqY8vt8XwGbTPwEAAAAAAAAAAAAAACwuT59M2LCz/N9xZaZ8LMN90M1IH4CAAAAAAAAAAAAAADYHOXrI8acH1Felu9Ltkx5WcSYH0RUlOf7Etgo8RMAAAAAAAAAAAAAAMDmmPL7iI+m5/uKrfPRtIgXb833FbBR4icAAAAAAAAAAAAAAIBN9dn8iIkj831FMiaO3PB5IMPETwAAAAAAAAAAAAAAAJtq8m8jysvyfUUyyss2fB7IMPETAAAAAAAAAAAAAADApli9ImLW6HxfkaxZoyPWrMz3FfCNxE8AAAAAAAAAAAAAAACbYuZfI9aV5vuKZK0r3fC5IKPETwAAAAAAAAAAAAAAABtTWRkxdVS+r0jH1FEbPh9kkPgJAAAAAAAAAAAAAABgYxZMjlj2dr6vSMfStyLefyHfV8DXEj8BAAAAAAAAAAAAAABszJv/zPcF6ZpXwz8f1Zb4CQAAAAAAAAAAAAAAYGM+ejXfF6RrUQ3/fFRb4icAAAAAAAAAAAAAAICqVJRHfPx6vq9I1+LXN3xOyBjxEwAAAAAAAAAAAAAAQFWWvhWxrjTfV6Rr3ZcRS9/O9xXwFeInAAAAAAAAAAAAAACAqix6Ld8X5Mbi1/J9AXyF+AkAAAAAAAAAAAAAAKAqS+bm+4LcqC2fk2pF/AQAAAAAAAAAAAAAAFCVNSvyfUFurF6R7wvgK8RPAAAAAAAAAAAAAAAAVVlflu8LcqO2fE6qFfETAAAAAAAAAAAAAABAVcrX5vuC3CgXP5E94icAAAAAAAAAAAAAAICqFNXJ9wW5UVQ33xfAV4ifAAAAAAAAAAAAAAAAqlJcS6Kg2vI5qVbETwAAAAAAAAAAAAAAAFWp1zjfF+RG/cb5vgC+QvwEAAAAAAAAAAAAAABQleZd8n1BbtSWz0m1In4CAAAAAAAAAAAAAACoyk575vuC3Gi5Z74vgK8QPwEAAAAAAAAAAAAAAFSl2W4RJQ3yfUW6ShpGNOuY7yvgK8RPAAAAAAAAAAAAAAAAVSksimjRPd9XpKtl9w2fEzJG/AQAAAAAAAAAAAAAALAxrXrm+4J07VTDPx/VlvgJAAAAAAAAAAAAAABgYzoNyvcF6epcwz8f1Zb4CQAAAAAAAAAAAAAAYGPa9o3YvmO+r0hHs90idjkg31fA1xI/AQAAAAAAAAAAAAAAbExBQUTvofm+Ih29h274fJBB4icAAAAAAAAAAAAAAIBN0WNIREmDfF+RrJIGGz4XZJT4CQAAAAAAAAAAAAAAYFPUbxzR7YR8X5GsbidE1GuU7yvgG4mfAAAAAAAAAAAAAAAANlXfSyKK6ub7imQU1d3weSDDxE8AAAAAAAAAAAAAAACbqmn7iEOvyPcVyTj0ig2fBzJM/AQAAAAAAAAAAAAAALA59r8wolWvfF+xdVrtHdHnh/m+AjZK/AQAAAAAAAAAAAAAALA5ioojjrsjoqhuvi/ZMkV1I467PaKwKN+XwEaJnwAAAAAAAAAAAAAAADbXDp0iDrsy31dsmcOu2nA/VAPiJwAAAAAAAAAAAAAAgC2x/w8jup2Y7ys2T7cTI/a/MN9XwCYTPwEAAAAAAAAAAAAAAGyJwsKI426P2G1gvi/ZNJ0Gbbi3UE5C9eHfVgAAAAAAAAAAAAAAgC1VVBJxwh+zH0B1GhTxnXs33AvViPgJAAAAAAAAAAAAAABga5TUizjp/ohuJ+b7kq/X7cSIE+/bcCdUM+InAAAAAAAAAAAAAACArVVUEnH8XRH9r4soqpvvazYoqhvR//oNd/mNT1RT4icAAAAAAAAAAAAAAIAkFBZGHHBxxHmTIlr1yu8trfbecMcBF224C6op//YCAAAAAAAAAAAAAAAkaYdOEd9/OuLwEbn/LVBFdTf89qmznt5wB1Rzxfk+AAAAAAAAAAAAAAAAoMYpKo7oe0lEl2MiJv82YtboiHWl6b2vpEFEtxM2vLNp+/TeAzkmfgIAAAAAAAAAAAAAAEhL0/YRx/wu4ojrI2b+NWLqqIilbyW332y3iN5DI3oMiajXKLldyAjxEwAAAAAAAAAAAAAAQNrqNYrY99yIfc6JeP+FiHn/jFj0asTimZv3G6FKGka07B6xU8+IzoMidjkgoqAgvbshz8RPAAAAAAAAAAAAAAAAuVJQENG274Z/IiIqyiOWvh2x+LWIJXMjVq+IWF8WUV4WUVQ3orhuRP3GEc27RLTcM6JZx4jCovzdDzkmfgIAAAAAAAAAAAAAAMiXwqKI5p03/AN8RWG+DwAAAAAAAAAAAAAAAAD4OuInAAAAAAAAAAAAAAAAIJPETwAAAAAAAAAAAAAAAEAmiZ8AAAAAAAAAAAAAAACATBI/AQAAAAAAAAAAAAAAAJkkfgIAAAAAAAAAAAAAAAAySfwEAAAAAAAAAAAAAAAAZJL4CQAAAAAAAAAAAAAAAMgk8RMAAAAAAAAAAAAAAACQSeInAAAAAAAAAAAAAAAAIJPETwAAAAAAAAAAAAAAAEAmiZ8AAAAAAAAAAAAAAACATBI/AQAAAAAAAAAAAAAAAJkkfgIAAAAAAAAAAAAAAAAySfwEAAAAAAAAAAAAAAAAZJL4CQAAAAAAAAAAAAAAAMgk8RMAAAAAAAAAAAAAAACQSeInAAAAAAAAAAAAAAAAIJPETwAAAAAAAAAAAAAAAEAmiZ8AAAAAAAAAAAAAAACATBI/AQAAAAAAAAAAAAAAAJkkfgIAAAAAAAAAAAAAAAAySfwEAAAAAAAAAAAAAAAAZJL4CQAAAAAAAAAAAAAAAMgk8RMAAAAAAAAAAAAAAACQSeInAAAAAAAAAAAAAAAAIJPETwAAAAAAAAAAAAAAAEAmiZ8AAAAAAAAAAAAAAACATBI/AQAAAAAAAAAAAAAAAJkkfgIAAAAAAAAAAAAAAAAySfwEAAAAAAAAAAAAAAAAZJL4CQAAAAAAAAAAAAAAAMgk8RMAAAAAAAAAAAAAAACQSeInAAAAAAAAAAAAAAAAIJPETwAAAAAAAAAAAAAAAEAmiZ8AAAAAAAAAAAAAAACATBI/AQAAAAAAAAAAAAAAAJkkfgIAAAAAAAAAAAAAAAAySfwEAAAAAAAAAAAAAAAAZJL4CQAAAAAAAAAAAAAAAMgk8RMAAAAAAAAAAAAAAACQSeInAAAAAAAAAAAAAAAAIJPETwAAAAAAAAAAAAAAAEAmFef7AAAAAAAAAAAAAAAAgNqusrIyXnx3WdwzaX68sfjzKFtfEY3rl8Rxe7WKE/ZuHa0a18/3iZAX4icAAAAAAAAAAAAAAIA8emn+shhy90tf+fMVpevit8+8Hfc8Pz/uOWPv6NOhWR6ug/wqzPcBAAAAAAAAAAAAAAAAtdXQP0372vDpX325tjy+d+/UeGn+shxdBdkhfgIAAAAAAAAAAAAAAMixj1euibaXPxHPvPHJJj2/dn1F/HrsmylfBdkjfgIAAAAAAAAAAAAAAMihe194L/b7xfjN/r5p7y+P1xauSP4gyLDifB8AAAAAAAAAAAAAAABQG6xdXxHdrh0bZesrtnjj7U++iD1bN07uKMg48RMAAAAAAAAAAAAAAEDKpi74LE64c8pW76zZinAKqiPxEwAAAAAAAAAAAAAAQIrOu396PDXn40S2mjWsk8gOVBfiJwAAAAAAAAAAAAAAgBQs+XxN7DNyfGJ7jeqXxKGdmye2B9VBYb4PAAAAAAAAAAAAAAAAqGn+9OKCRMOniIhT92sT9UqKEt2ErPObnwAAAAAAAAAAAAAAABKydn1F9BjxdKxeV57o7jE9doof9++U6CZUB+InAAAAAAAAAAAAAACABEx//7P49h1TUtm+6cQeUVRYkMo2ZJn4CQAAAAAAAAAAAAAAYCtd8D+vxhOvL05898S9d44bv9Mj8V2oLsRPAAAAAAAAAAAAAAAAW2jJF2tin5+PT2X78Qv7RredG6WyDdWF+AkAAAAAAAAAAAAAAGAL3P/S+3H1mNmJ7+6wbd2YcvlhUVxUmPg2VDfiJwAAAAAAAAAAAAAAgM2wrrwiel0/Lj5fsz7x7V9+u1uc1LtN4rtQXYmfAAAAAAAAAAAAAAAANtGrHyyPb93+Yirb0686PLbfpm4q21BdiZ8AAAAAAAAAAAAAAAA2wUUPzIjHZi5KfPdbPVvFzSfumfgu1ATiJwAAAAAAAAAAAAAAgCp8+kVZ9P75M6lsP3rBAdGjdeNUtqEmED8BAAAAAAAAAAAAAAB8g7+8/H5c+ffZie8226ZOvDSsXxQXFSa+DTWJ+AkAAAAAAAAAAAAAAOA/rC+viN4/fyaWl65LfPsX3+oWJ+/TJvFdqInETwAAAAAAAAAAAAAAAP/itYUr4rjbXkhle9pVh0ezbeqmsg01kfgJAAAAAAAAAAAAAADg//nxg6/FIzM+Snz32D13iluG7JX4LtR04icAAAAAAAAAAAAAAKDWW7aqLHr97JlUth/5QZ/o2aZJKttQ04mfAAAAAAAAAAAAAACAWu2vr3wQlz8yK/Hdxg1KYuqVh0dJUWHi21BbiJ8AAAAAAAAAAAAAAIBaaX15Rez3i/GxdNXaxLevP65rnLbfLonvQm0jfgIAAAAAAAAAAAAAAGqdmQtXxLG3vZDK9itX9ovm29ZLZRtqG/ETAAAAAAAAAAAAAABQq1w6emaMnv5h4rtHdW8Zv/9uz8R3oTYTPwEAAAAAAAAAAAAAALXCZ1+ujZ7Xj0tl+2/n94leuzRJZRtqM/ETAAAAAAAAAAAAAABQ4z00bWH89OHXE9/dtm5xvDq8f5QUFSa+DYifAAAAAAAAAAAAAACAGqy8ojL63DA+Pvm8LPHtEcfsEWf0aZv4LvB/xE8AAAAAAAAAAAAAAECNNPujlXHUrZNT2X7lin7RfLt6qWwD/0f8BAAAAAAAAAAAAAAA1DiXPfx6PDhtYeK7A7u2iDtO7ZX4LvD1xE8AAAAAAAAAAAAAAECNsfzLtbHX9eNS2R593v7Ru23TVLaBryd+AgAAAAAAAAAAAAAAaoS/Tf8w/mv0zMR365cUxcxrjog6xYWJbwNVEz8BAAAAAAAAAAAAAADVWnlFZRx048T4aMXqxLevObpLnHlAu8R3gU0jfgIAAAAAAAAAAAAAAKqtOYtWxuDfTU5l++Ur+sWO29VLZRvYNOInAAAAAAAAAAAAAACgWrry77PiLy9/kPjuEV12jLtP3zvxXWDziZ8AAAAAAAAAAAAAAIBqZUXp2tjzunGpbD94zn6xb/vtU9kGNp/4CQAAAAAAAAAAAAAAqDbGzPgoLnnwtcR36xQVxqwRR0Td4qLEt4EtJ34CAAAAAAAAAAAAAAAyr6KiMg759bPxwWeliW9fNXj3GHpg+8R3ga0nfgIAAAAAAAAAAAAAADLtjcWfx8BbJqWyPWXYYdGyUf1UtoGtJ34CAAAAAAAAAAAAAAAy6+oxs+P+l95PfPfw3ZvHqDN6J74LJEv8BAAAAAAAAAAAAAAAZM7K1euix4inU9l+4Oz9Yv8O26eyDSRL/AQAAAAAAAAAAAAAAGTKYzMXxUUPzEh8t7Ag4o3rB0Td4qLEt4F0iJ8AAAAAAAAAAAAAAIBMqKiojMNvfi7mL/0y8e0rB+0eZx/UPvFdIF3iJwAAAAAAAAAAAAAAIO/e/PiLOPK3z6ey/eLlh8VOjeunsg2kS/wEAAAAAAAAAAAAAADk1bWPzYk/vrgg8d2Dd9sh/vT9fRLfBXJH/AQAAAAAAAAAAAAAAOTFytXroseIp1PZ/svQfeOAXZulsg3kjvgJAAAAAAAAAAAAAADIucdnLoofPjAjle151w+IeiVFqWwDuSV+AgAAAAAAAAAAAAAAcqaiojL6/+a5ePfTLxPfvmxA5zj/kA6J7wL5I34CAAAAAAAAAAAAAABy4u1Pvoj+v3k+le3Jlx0aOzdpkMo2kD/iJwAAAAAAAAAAAAAAIHU/+8fcGDX5vcR3D+zYLO77/j5RUFCQ+DaQf+InAAAAAAAAAAAAAAAgNV+sWRfdrn06le0/n7Vv9O3YLJVtIBvETwAAAAAAAAAAAAAAQCqenLU4zv/Lq6lsz7t+QNQrKUplG8gO8RMAAAAAAAAAAAAAAJCoysrKGHjLpJj38ReJb196ZKe44NBdE98Fskn8BAAAAAAAAAAAAAAAJOadJV/E4Tc/n8r2pJ8eGq2bNkhlG8gm8RMAAAAAAAAAAAAAAJCIX/zzjbjr+fmJ7/bpsH38Zei+UVBQkPg2kG3iJwAAAAAAAAAAAAAAYKusKlsfXa8Zm8r2n76/Txy82w6pbAPZJ34CAAAAAAAAAAAAAAC22FOzP47z/jw9le151w+IeiVFqWwD1YP4CQAAAAAAAAAAAAAA2GyVlZVx9O8nx+yPPk98+8f9d4uL+nVMfBeofsRPAAAAAAAAAAAAAADAZnn301XR76bnUtl+/tJDo832DVLZBqof8RMAAAAAAAAAAAAAALDJfvnUvLjj2XcT392nXdN48Jz9oqCgIPFtoPoSPwEAAAAAAAAAAAAAABv1Zdn62OOasals33tm7zi0U/NUtoHqTfwEAAAAAAAAAAAAAABU6ek5H8c5909PZfuN6wZE/TpFqWwD1Z/4CQAAAAAAAAAAAAAA+FqVlZVx7G0vxOsfrkx8++J+HeNH/XdLfBeoWcRPAAAAAAAAAAAAAADAV7y39Ms49NfPprL93KWHxC7bN0xlG6hZxE8AAAAAAAAAAAAAAMC/uenpN+PWCe8kvttrlybx8Hn7R0FBQeLbQM0kfgIAAAAAAAAAAAAAACIionTt+ugyfGwq23/43t5xWOcdU9kGai7xEwAAAAAAAAAAAAAAEOPf+CTO+tO0VLbnjDgyGtaVMACbz98cAAAAAAAAAAAAAABQi1VWVsa37ngxZnywIvHtCw/dNX5yZKfEd4HaQ/wEAAAAAAAAAAAAAAC11IKlX8Yhv342le2JPzkk2jVrmMo2UHuInwAAAAAAAAAAAAAAoBa6edxb8bvxbye+26N14xjzgz5RUFCQ+DZQ+4ifAAAAAAAAAAAAAACgFilduz66DB+byvY9p+8d/bvsmMo2UDuJnwAAAAAAAAAAAAAAoJaY+OaSOPPeqalszxlxZDSsK1MAkuVvFQAAAAAAAAAAAAAAqOEqKyvjxLumxNQFyxPf/sEhHeKnAzonvgsQIX6CLbJu3bqYN29ezJ49O+bMmROzZ8+ODz/8MFasWBErVqyIlStXRlFRUdSrVy+aNm0aO+20U7Rr1y66d+8evXv3jj59+kSdOnXy/TEAAAAAAAAAAAAAgFrgg2WlcdCvJqayPeG/Do72O2yTyjZAhPgJNklFRUXMmDEjJkyYEOPHj49JkyZFaWlpld+zfv36KCsri5UrV8Z7770XL7zwwv//tQYNGsQRRxwRZ5xxRhx11FFRXJyb/xTbtm0b77//fk7e9XXuueeeGDp0aN7eDwAAAAAAAAAAAAC1ze/Gvx03j3sr8d2urbaLxy/sGwUFBYlvA/wr8RN8g/Xr18f48ePjwQcfjEcffTQ+++yzxLZLS0tjzJgxMWbMmGjXrl1cfvnlcdZZZ0VRUVFi7wAAAAAAAAAAAAAAaq/Va8tj9+FPpbJ956m9YkDXFqlsA/ynwnwfAFkzZ86cOPvss6NFixYxYMCAuPfeexMNn/7Te++9F+eee27ss88+MWPGjNTeAwAAAAAAAAAAAADUDs+99Wlq4dPsEUcKn4CcEj/Bf3j88cdj1KhRsWzZspy+99VXX439998/7rrrrpy+FwAAAAAAAAAAAACoGSorK2PI3VPijD+8kvj2uQe1jwU3DI5t6hYnvg1QFX/rQIaUlZXFeeedF4sWLYoRI0bk+xwAAAAAAAAAAAAAoJpY+FlpHHjjxFS2n/nxwbFr821S2QbYGPETbKWioqLYY489Yvfdd4927dpFs2bNomHDhrFmzZpYtmxZLF68OCZPnhxvvvnmJm9ed9110aBBg7jssstSvBwAAAAAAAAAAAAAqAlum/hO/Grspv+88qbq0nK7eOKivlFQUJD4NsCmEj/BFujcuXMcffTRMXDgwNh3332jQYMGG/2exYsXx9133x233nprLFu2bKPPDxs2LLp16xaDBg1K4uSN6tOnT5x55pmpvuPAAw9MdR8AAAAAAAAAAAAAapM168qj89VPpbJ956k9Y0DXlqlsA2wO8RNsosaNG8f3vve9OO2006Jnz56b/f0tW7aMa665Jn7yk5/EJZdcEqNGjary+crKyhg6dGjMnTs3GjduvIVXb7qOHTvG0KFDU38PAAAAAAAAAAAAALD1Jr39aZz236+ksj3r2iNi23olqWwDbK7CfB8AWbfrrrvGXXfdFR999FH85je/2aLw6V81bNgw7rnnnvjTn/4URUVFVT67ePHi+OUvf7lV7wMAAAAAAAAAAAAAao7Kyso4ddTLqYRPQ/u2iwU3DBY+AZkifoJvsNtuu8Wf//znmDdvXpxzzjnRoEGDRPdPP/30uPXWWzf63K233hqff/55ou8GAAAAAAAAAAAAAKqfD5eXRrth/4zJ7yxNfHvcjw6Kq47qkvguwNYSP8F/2HHHHeP222+POXPmxCmnnLLR3860Nc4///w4/fTTq3zmyy+/jIceeii1GwAAAAAAAAAAAACA7Lv92Xei7y8nJr7bsfk2MX/koOi447aJbwMkoTjfB0DWnHnmmTl938iRI+Phhx+O0tLSb3xmzJgxMXTo0BxeBQAAAAAAAAAAAABkwZp15dH56qdS2f79d/eKo7rvlMo2QFL85ifIs1atWsXJJ59c5TOTJk2KioqKHF0EAAAAAAAAAAAAAGTBC+8sTS18ev3aI4RPQLUgfoIMOOqoo6r8+ueffx7vv/9+jq4BAAAAAAAAAAAAAPLtjD+8EqeMejnx3TMPaBsLbhgc29UrSXwbIA3F+T4AiDjooIM2+sz8+fOjXbt2ObgGAAAAAAAAAAAAAMiXRStWR58bJqSyPfaSg6JTi21T2QZIi/gJMqBp06ZRp06dWLt27Tc+s2LFitwdBAAAAAAAAAAAAADk3N3Pvxsj/zkv8d32OzSMZ350cBQWFiS+DZA28RNkRLNmzWLRokXf+PXVq1fn8BoAAAAAAAAAAAAAIFfK1pdHp6ueSmX7liF7xrF7tkplGyAXxE+QEaWlpVV+vV69ejm6BAAAAAAAAAAAAADIlSnvLouT73kple2Zw4+IRg1KUtkGyBXxE2TAF198EStXrqzymSZNmuToGgAAAAAAAAAAAAAgF87649QYP29J4run779LXHds18R3AfJB/AQZMGPGjKisrKzymQ4dOuToGgAAAAAAAAAAAAAgTYtXro79fzEhle0nLz4wdm+5XSrbAPkgfoIMeOKJJ6r8+nbbbRdt2rTJ0TUR5eXl8d5778UHH3wQn376aaxevTqKioqiQYMGsd1228XOO+8crVu3jm222SZnNwEAAAAAAAAAAABATTBq0vz42RNvJL7bdvsGMeG/DonCwoLEtwHySfwEeVZeXh4PPvhglc/07ds3CgsLU73jgw8+iGuuuSbGjx8fM2bMiNLS0o1+T/v27aNXr15x2GGHxaBBg3IaaAEAAAAAAAAAAABAdbJ2fUV0vWZsrC2vSHz7liF7xrF7tkp8FyALxE+QZ2PGjIn333+/ymeOOeaY1O+YOHFiTJw4cbO+Z/78+TF//vwYPXp0REQceOCBce6558ZJJ50UxcX+egEAAAAAAAAAAACAiIiX5y+Lk+5+KZXtmcOPiEYNSlLZBsiCdH+VDFCl8vLyGD58eJXP1KlTJ0444YQcXbR1Jk2aFKeeemrsvvvuG/1tVgAAAAAAAAAAAABQG5xz37RUwqdT9m0TC24YLHwCajzxE+TRHXfcEXPnzq3ymTPOOCOaNm2ao4uS8c4778SQIUPi6KOPjo8//jjf5wAAAAAAAAAAAABAzn3y+Zpoe/kT8fTcTxLffuKivvHz47slvguQReInyJMFCxbEsGHDqnympKQkLrvsshxdlLx//OMf0atXr5g+fXq+TwEAAAAAAAAAAACAnLn3hfdi35HjE9/duUn9eHfkoNhjp0aJbwNkVXG+D4DaqLy8PM4444xYtWpVlc9dcskl0aFDhxxdlY5FixbFQQcdFE888UQccsgh+T5nk912221x++23p/6ed999N/V3AAAAAAAAAAAAAJAba9dXRLdrx0bZ+orEt28+sUd8q+fOie8CZJ34CfLg6quvjueff77KZ1q3bh1XX311Tu7p0KFD7LvvvtGtW7fo2rVrtGvXLho1ahSNGjWK+vXrx/Lly2PZsmWxbNmymDZtWjz33HMxadKkWLp06Sbtl5aWxtFHHx0TJkyI3r17p/xpkvHpp5/G3Llz830GAAAAAAAAAAAAANXE1AWfxQl3Tklle8bV/aNJwzqpbANknfgJcuzxxx+PG264ocpnCgoK4g9/+ENsu+22qd1x0EEHxbHHHhuDBw+OTp06VfnsDjvsEDvssENERBxwwAFx8cUXR3l5eYwePTpuvPHGmDFjxkbft2rVqvj2t78dr776ajRr1iyRzwAAAAAAAAAAAAAAWXD+n6fHk7M/Tnx3SO/WccO3uye+C1CdiJ8gh2bPnh2nnHJKVFZWVvnchRdeGIcffnji72/SpEkcd9xxcf755280eNqYoqKiGDJkSAwZMiQeeOCBOPfcc+OLL76o8nsWLlwY55xzTjzyyCNb9W4AAAAAAAAAAAAAyIIln6+JfUaOT2X7Hz/sG11bNUplG6A6ET9BjixZsiSOPvrojQZCvXv3jl//+tep3DB16tQoLk7+P/uTTz459t577/jOd74Tr7/+epXP/v3vf48nn3wyBg4cmPgdAAAAAAAAAAAAAJAr901ZEMMfnZP4bstG9WLyZYdFUWFB4tsA1VFhvg+A2mDVqlUxaNCgWLBgQZXPbb/99jF69OioU6dOKnekET79r44dO8Zzzz0XPXr02OizV155ZWp3AAAAAAAAAAAAAECa1pVXxB7Dn0olfLrxO91jyrB+wieAf+E3P0HK1q5dG8cff3xMnz69yufq168fjz76aOyyyy45uix5jRs3jsceeyx69uwZy5Yt+8bnZsyYEePHj49+/frl8LrNs8MOO0SXLl1Sf8+7774bZWVlqb8HAAAAAAAAAAAAgK03/f3P4tt3TEll+9Wr+0fThun8EgWA6kz8BCkqLy+Pk08+OZ555pkqnyspKYnRo0fHAQcckKPL0tOmTZu4+eab44wzzqjyufvuuy/T8dMFF1wQF1xwQerv2WOPPWLu3LmpvwcAAAAAAAAAAACArXPB/7waT7y+OPHd7/TaOX59Qo/EdwFqisJ8HwA1VWVlZQwdOjQeeeSRKp8rLCyM++67LwYPHpyjy9J32mmnRffu3at85tFHH41169bl6CIAAAAAAAAAAAAA2DJLvlgTbS9/IpXw6bELDxA+AWyE+AlScvHFF8cf//jHjT535513xpAhQ9I/KIcKCgrikksuqfKZlStXxowZM3JzEAAAAAAAAAAAAABsgftfej/2+fn4xHd32LZuvPPzgdF958aJbwPUNOInSMEVV1wRt95660afu+mmm+Lss8/OwUW5d/zxx0dJSUmVz0yZMiVH1wAAAAAAAAAAAADApltXXhHdrx0bV4+Znfj2L7/dLaZeeXgUF/lxfoBN4W9LSNjIkSPjF7/4xUafGzFiRPz4xz/OwUX50bhx49hzzz2rfGbevHm5OQYAAAAAAAAAAAAANtGrHyyPjlc+GZ+vWZ/49vSrDo+TerdJfBegJhM/QYJuueWWuPLKKzf63KWXXhrDhw/PwUX51bNnzyq/vmDBgtwcAgAAAAAAAAAAAACb4OK/zohv3f5i4rvf6tkqFtwwOLbfpm7i2wA1XXG+D4Ca4u67745LLrlko89deOGFceONN6Z/UAa0bdu2yq8vWbIkN4cAAAAAAAAAAAAAQBWWriqLvX/2TCrbYy44IPZs3TiVbYDaQPwECbj//vvjvPPO2+hzZ511Vvzud7/LwUXZ0KhRoyq/XlpamqNLAAAAAAAAAAAAAODrPfDKBzHskVmJ7zZtWCdeuaJfFBcVJr4NUJuIn2ArjR49Os4888yorKys8rmTTz457r777igoKMjRZflXp06dKr++bt26HF0CAAAAAAAAAAAAAP9ufXlF7DNyfHz25drEt0ce3y2+u2+bxHcBaiPxE2yFxx57LE455ZQoLy+v8rnjjz8+7rvvvigsrF3V9urVq6v8ev369XN0CQAAAAAAAAAAAAD8n9cWrojjbnshle1pVx0ezbapm8o2QG0kfoItNHbs2DjxxBM3+tuLBg4cGH/961+juLj2/ef28ccfV/n1bbbZJkeXAAAAAAAAAAAAAMAGP37wtXhkxkeJ7x67505xy5C9Et8FqO1qX40BCXj22Wfj+OOPj7KysiqfO+yww+KRRx6JOnXq5OiybHnnnXeq/HqrVq1ydAkAAAAAAAAAAAAAtd2yVWXR62fPpLL9yA/6RM82TVLZBqjtxE+wmaZMmRJHH310rF69usrn+vbtG4899ljUq1cvR5dlz8svv1zl19u1a5ejSwAAAAAAAAAAAACozR6aujB++rfXE99t3KAkpl55eJQUFSa+DcAG4ifYDNOnT4+BAwfGqlWrqnyud+/e8cQTT0TDhg1zdFn2zJ07NxYsWFDlM927d8/NMQAAAAAAAAAAAADUSuvLK2L/GybEp1+UJb59/XFd47T9dkl8F4B/J36CTTRr1qw48sgjY+XKlVU+16NHjxg7dmxst912Obosm+67776NPtOnT58cXAIAAAAAAAAAAABAbfT6hyvimN+/kMr2K1f2i+bb1ktlG4B/J36CTfDWW29F//79Y9myZVU+16VLlxg3blw0adIkR5dl0/Lly+Ouu+6q8pkOHTpEhw4dcnQRAAAAAAAAAAAAALXJpaNnxujpHya+O7h7y7jtuz0T3wXgm4mfYCMWLFgQ/fr1i08++aTK5zp27BjPPPNM7LDDDjm6LLuGDRsWK1asqPKZE088MTfHAAAAAAAAAAAAAFBrfPbl2uh5/bhUtv92/v7Ra5emqWwD8M3ET1CFRYsWRb9+/eLDD6uuvtu2bRsTJkyIli1b5uiy7Hr44Yc3+lufioqK4qyzzsrRRQAAAAAAAAAAAADUBg9NWxg/ffj1xHcb1imK1645IkqKChPfBmDjxE/wDT799NPo169fzJ8/v8rndt5555gwYULsvPPOObps88ydOzdatmwZTZo0Sf1d48aNi9NOO22jz51wwgnRoUOH1O8BAAAAAAAAAAAAoOYrr6iMPjeMj08+L0t8e8Qxe8QZfdomvgvAppOewtdYsWJFHHHEETFv3rwqn2vRokVMmDAh2rVrl6PLNt/TTz8d7du3j+uvvz6WLVuWyjsqKyvjhhtuiEGDBsWaNWuqfLZ+/foxcuTIVO4AAAAAAAAAAAAAoHaZ/dHK6HDFP1MJn165op/wCSADxE/wH1atWhUDBw6M1157rcrnmjVrFuPHj4+OHTvm5rCtsGLFihg+fHi0adMmzj777HjhhRcS237ttddi4MCBMWzYsFi/fv1Gn7/22mszHYsBAAAAAAAAAAAAUD0Me+T1OOrWyYnvDuzaIhbcMDiab1cv8W0ANl9xvg+ArDn55JPjpZde2uhzJ510Urz44ovx4osv5uCqiJYtW8bgwYO3aqO0tDRGjRoVo0aNitatW8fgwYOjf//+0adPn2jRosUm7yxfvjyeffbZuOOOO2LcuHGb/H3HHHNMXHrppVtyOgAAAAAAAAAAAABERMTyL9fGXtdv+s+wbo7R5+0fvds2TWUbgC0jfoL/MGvWrE167rbbbkv5kn938MEHb3X89K8WLlwYd955Z9x5550RsSGu6ty5c7Rv3z5atGgRTZs2jXr16kVRUVEsX748Pvvss1i6dGlMmzYtZs+eHZWVlZv1vv333z/+/Oc/R0FBQWKfAQAAAAAAAAAAAIDa5W/TP4z/Gj0z8d26xYUx69ojo05xYeLbAGwd8RMQERGLFy+OxYsXx8SJExPfPuSQQ+Kxxx6LbbfdNvFtAAAAAAAAAAAAAGq+8orKOOjGifHRitWJbw8/qkt8v2+7xHcBSIb4CUjVRRddFDfddFMUF/vrBgAAAAAAAAAAAIDNN2fRyhj8u8mpbL80rF+0aFQvlW0AkqFGAFKx2267xZ133hmHHnpovk8BAAAAAAAAAAAAoJq68u+z4i8vf5D4bv8uO8Y9p++d+C4AyRM/QQ3XuXPn6NKlS8ydOzcn7+vYsWNcfvnlcdppp0VJSUlO3gkAAAAAAAAAAABAzbKydF30uO7pVLYfPGe/2Lf99qlsA5A88RPUcAMGDIgBAwbEkiVLYuLEifHcc8/F1KlTY/bs2bFmzZpE3tG6desYMGBAnHrqqXHggQdGQUFBIrsAAAAAAAAAAAAA1D6PvvZRXPzX1xLfrVNUGLNGHBF1i4sS3wYgPeIn+A8LFizI9wmpaN68eZx00klx0kknRUREeXl5vPHGGzFz5syYP39+LFy4MBYuXBgffvhhrFy5MkpLS6O0tDTKysqiuLg46tWrF9tuu220bNkyWrVqFZ06dYpu3bpF7969o1OnTnn+dAAAAAAAAAAAAABUdxUVlXHYTc/GgmWliW9fNXj3GHpg+8R3AUif+AlqqaKioujatWt07do136cAAAAAAAAAAAAAUMu9sfjzGHjLpFS2pww7LFo2qp/KNgDpEz8BAAAAAAAAAAAAAJA31zw6O/405f3Edw/r3Dz+8L3eie8CkFviJwAAAAAAAAAAAAAAcm7l6nXRY8TTqWz/z9n7Rp8OzVLZBiC3xE8AAAAAAAAAAAAAAOTUYzMXxUUPzEh8t7Ag4o3rB0Td4qLEtwHID/ETAAAAAAAAAAAAAAA5UVFRGYff/FzMX/pl4ttXDOoc5xzUIfFdAPJL/AQAAAAAAAAAAAAAQOre/PiLOPK3z6ey/eLlh8VOjeunsg1AfomfAAAAAAAAAAAAAABI1YjH58S9LyxIfPfg3XaIP31/n8R3AcgO8RMAAAAAAAAAAAAAAKn4fM266H7t06ls/2XovnHArs1S2QYgO8RPAAAAAAAAAAAAAAAk7onXF8cF//NqKtvzrh8Q9UqKUtkGIFvETwAAAAAAAAAAAAAAJKaiojKO/O3z8faSVYlv/3RAp/jBIbsmvgtAdomfAAAAAAAAAAAAAABIxNuffBH9f/N8KtuTLzs0dm7SIJVtALJL/AQAAAAAAAAAAAAAwFb72T/mxqjJ7yW+23fXZnH/WftEQUFB4tsAZJ/4CQAAAAAAAAAAAACALfbFmnXR7dqnU9m+/6x94sCOO6SyDUD1IH4CAAAAAAAAAAAAAGCLPDlrcZz/l1dT2Z53/YCoV1KUyjYA1Yf4CQAAAAAAAAAAAACAzVJZWRkDb5kU8z7+IvHtS4/sFBccumviuwBUT+InAAAAAAAAAAAAAAA22TtLVsXhNz+Xyvaknx4arZs2SGUbgOpJ/AQAAAAAAAAAAAAAwCb5xT/fiLuen5/47n7tm8YDZ+8XBQUFiW8DUL2JnwAAAAAAAAAAAAAAqNKqsvXR9ZqxqWz/8czecUin5qlsA1D9iZ8AAAAAAAAAAAAAAPhGY+d8HOfePz2V7TeuGxD16xSlsg1AzSB+AgAAAAAAAAAAAADgKyorK+Po30+O2R99nvj2jw7fLS4+vGPiuwDUPOInAAAAAAAAAAAAAAD+zbufrop+Nz2Xyvbzlx4abbZvkMo2ADWP+AkAAAAAAAAAAAAAgP/fjU/Ni9uffTfx3X3aNY0Hz9kvCgoKEt8GoOYSPwEAAAAAAAAAAAAAEF+WrY89rhmbyva9Z/aOQzs1T2UbgJpN/AQAAAAAAAAAAAAAUMuNm/tJnH3ftFS237huQNSvU5TKNgA1n/gJAAAAAAAAAAAAAKCWqqysjONufzFmLlyR+PZF/TrGj/vvlvguALWL+AkAAAAAAAAAAAAAoBZ6b+mXceivn01l+9mfHBJtmzVMZRuA2kX8BAAAAAAAAAAAAABQy9z09Jtx64R3Et/ttUuTePi8/aOgoCDxbQBqJ/ETAAAAAAAAAAAAAEAtUbp2fXQZPjaV7f8+Y+/ot/uOqWwDUHuJnwAAAAAAAAAAAAAAaoEJ8z6J7/9xWirbc0YcGQ3r+vF0AJLn/y4AAAAAAAAAAAAAADVYZWVlfOfOKTH9/eWJb1946K7xkyM7Jb4LAP9L/AQAAAAAAAAAAAAAUEO9v+zLOPhXz6ayPfEnh0S7Zg1T2QaA/yV+AgAAAAAAAAAAAACogX4z7q24Zfzbie/2aN04xvygTxQUFCS+DQD/SfwEAAAAAAAAAAAAAFCDrF5bHrsPfyqV7btP6xVH7NEilW0A+DriJwAAAAAAAAAAAACAGmLim0vizHunprI9e8SRsU1dP4IOQG75Pw8AAAAAAAAAAAAAQDVXWVkZJ941JaYuWJ749vmHdIjLBnROfBcANoX4CQAAAAAAAAAAAACgGvtgWWkc9KuJqWyP/6+Do8MO26SyDQCbQvwEAAAAAAAAAAAAAFBN3Tr+7bhp3FuJ73ZttV08fmHfKCgoSHwbADaH+AkAAAAAAAAAAAAAoJpZs648Ol/9VCrbd57aKwZ0bZHKNgBsLvETAAAAAAAAAAAAAEA18vxbn8bpf3glle3ZI46Mber6MXMAssP/lQAAAAAAAAAAAAAAqoHKyso4ZdTL8eK7yxLfPveg9jFs0O6J7wLA1hI/AQAAAAAAAAAAAABk3MLPSuPAGyemsv3Mjw+KXZtvm8o2AGwt8RMAAAAAAAAAAAAAQIbdNvGd+NXYNxPf7dxi23jy4gOjoKAg8W0ASIr4CQAAAAAAAAAAAAAgg9asK4/OVz+Vyvbtp/SMQd1aprINAEkSPwEAAAAAAAAAAAAAZMyktz+N0/77lVS2Z117RGxbrySVbQBImvgJAAAAAAAAAAAAACAjKisr4/Q/vBKT3l6a+PbQvu3iqqO6JL4LAGkSPwEAAAAAAAAAAAAAZMBHK1bHATdMSGV73I8Oio47bpvKNgCkSfwEAAAAAAAAAAAAAJBndz73btzw5LzEdzs23ybGXnJQFBYWJL4NALkgfgIAAAAAAAAAAAAAyJM168qj89VPpbL9++/uFUd13ymVbQDIFfETAAAAAAAAAAAAAEAevPjO0vjuqJdT2X792iNiu3olqWwDQC6JnwAAAAAAAAAAAAAAcuyMP7wSz731aeK73+vTNq49Zo/EdwEgX8RPAAAAAAAAAAAAAAA5smjF6uhzw4RUtp+65MDo3GK7VLYBIF/ETwAAAAAAAAAAAAAAOXD38+/GyH/OS3y3fbOG8cyPD47CwoLEtwEg38RPAAAAAAAAAAAAAAApKltfHrtf/VRUVCa/fcuQPePYPVslPwwAGSF+AgAAAAAAAAAAAABIyZR3l8XJ97yUyvbM4UdEowYlqWwDQFaInwAAAAAAAAAAAAAAUnDWH6fG+HlLEt89ff9d4rpjuya+CwBZJH4CAAAAAAAAAAAAAEjQ4pWrY/9fTEhl+8mLD4zdW26XyjYAZJH4CQAAAAAAAAAAAAAgIaMmzY+fPfFG4rttmjaIiT85JIoKCxLfBoAsEz8BAAAAAAAAAAAAAGyltesrous1Y2NteUXi2785qUccv9fOie8CQHUgfgIAAAAAAAAAAAAA2Aovz18WJ939Uirbrw3vH40b1EllGwCqA/ETAAAAAAAAAAAAAMAWOue+afH03E8S3/3uvm1i5PHdEt8FgOpG/AQAAAAAAAAAAAAAsJk++XxN7DtyfCrbT1zUN/bYqVEq2wBQ3YifAAAAAAAAAAAAAAA2wx9feC+ufXxu4rs7N6kfz116aBQVFiS+DQDVlfgJAAAAAAAAAAAAAGATrF1fET1GPB2r15Unvn3ziT3iWz13TnwXAKo78RMAAAAAAAAAAAAAwEZMW/BZfOfOKalsz7i6fzRpWCeVbQCo7sRPAAAAAAAAAAAAAABV+MFfpsc/Z32c+O6Q3q3jhm93T3wXAGoS8RMAAAAAAAAAAAAAwNdY8vma2Gfk+FS2//HDvtG1VaNUtgGgJhE/AQAAAAAAAAAAAAD8h/umLIjhj85JfLdlo3ox+bLDoqiwIPFtAKiJxE8AAAAAAAAAAAAAAP/PuvKK2Ou6cbGqbH3i2zd+p3ucuHfrxHcBoCYTPwEAAAAAAAAAAAAARMT095fHt+94MZXtV6/uH00b1kllGwBqMvETAAAAAAAAAAAAAFDr/fCBGfH4zEWJ736n187x6xN6JL4LALWF+AkAAAAAAAAAAAAAqLU+/aIsev/8mVS2H7vwgOi+c+NUtgGgthA/AQAAAAAAAAAAAAC10p9fej+uGjM78d1m29SNl4YdFsVFhYlvA0BtI34CAAAAAAAAAAAAAGqVdeUV0ev6cfH5mvWJb9/wrW4xZJ82ie8CQG0lfgIAAAAAAAAAAAAAao1XP1ge37r9xVS2p111eDTbpm4q2wBQW4mfAAAAAAAAAAAAAIBa4eK/zohHX1uU+O639moVN5+0Z+K7AID4CQAAAAAAAAAAAACo4ZauKou9f/ZMKttjLjgg9mzdOJVtAED8BAAAAAAAAAAAAADUYA+88kEMe2RW4rtNG9aJV67oF8VFhYlvAwD/R/wEAAAAAAAAAAAAANQ468srYp+R4+OzL9cmvj3y+G7x3X3bJL4LAHyV+AkAAAAAAAAAAAAAqFFmLlwRx972Qirb0646PJptUzeVbQDgq8RPAAAAAAAAAAAAAECN8V8PzYy/vfph4rvH9NgpfnfyXonvAgBVEz8BAAAAAAAAAAAAANXeslVl0etnz6Sy/bfz+0SvXZqksg0AVE38BAAAAAAAAAAAAABUaw9NXRg//dvrie9uV684pl/dP0qKChPfBgA2jfgJAAAAAAAAAAAAAKiWyisqY79fjI9PvyhLfPv647rGafvtkvguALB5xE8AAAAAAAAAAAAAQLUz68OVcfTvJ6ey/cqV/aL5tvVS2QYANo/4CQAAAAAAAAAAAACoVi57+PV4cNrCxHcHd28Zt323Z+K7AMCWEz8BAAAAAAAAAAAAANXC8i/Xxl7Xj0tl+2/n7x+9dmmayjYAsOXETwAAAAAAAAAAAABA5j08/cP4yeiZie82rFMUr11zRJQUFSa+DQBsPfETAAAAAAAAAAAAAJBZ5RWV0feXE2LxyjWJb484Zo84o0/bxHcBgOSInwAAAAAAAAAAAACATJr90co46tbJqWy/ckW/aL5dvVS2AYDkiJ8AAAAAAAAAAAAAgMwZ9sjr8cArCxPfPXKPHeOu0/ZOfBcASIf4CQAAAAAAAAAAAADIjBWla2PP68alsv3QufvHPu2aprINAKRD/AQAAAAAAAAAAAAAZMLfZ3wYP3pwZuK7dYsLY9a1R0ad4sLEtwGAdImfAAAAAAAAAAAAAIC8Kq+ojIN/NTE+XL468e3hR3WJ7/dtl/guAJAb4icAAAAAAAAAAAAAIG/mLvo8Bv1uUirbLw3rFy0a1UtlGwDIDfETAAAAAAAAAAAAAJAXV42ZFX9+6YPEd/t32THuOX3vxHcBgNwTPwEAAAAAAAAAAAAAObWydF30uO7pVLb/es5+sV/77VPZBgByT/wEAMD/x959RllZ3vsf/s0MTZAiAoIVEBBBxAY2sCAiJWpMrDG2WKKJJqQq2EWBGKOxl5hiPElsiRoDihQLCjaaCFJEIIqoCNKlzez/C/85JZGhPffs2TPXtZZv8tx+nnvWOckS1/7OBgAAAAAAAACACvP05AXxw0cmZ96tUVwU0244LmrXKMm8DQDkj/ETAAAAAAAAAAAAAJBcWVkuevzqxZi3eHXm7av67R0XdG+deRcAyD/jJwAAAAAAAAAAAAAgqRkfL4/evx6bpD1+QI9o0XC7JG0AIP+MnwAAAAAAAAAAAACAZK59+p14aPz8zLs92jeL353bJfMuAFC5GD8BAAAAAAAAAAAAAJlb9sX66Hz980naf77w4DhszyZJ2gBA5WL8BAAAAAAAAAAAAABk6pkpH8Vlf5mUebe4KOLdQb2jdo2SzNsAQOVk/AQAAAAAAAAAAAAAZKKsLBfH3vZSzFm0KvP2wL7t46Ij9sy8CwBUbsZPAAAAAAAAAAAAAMA2m/nxijju1y8nab96RY/YpdF2SdoAQOVm/AQAAAAAAAAAAAAAbJPrn5kWv391XubdI9s1jYe+0zXzLgBQOIyfAAAAAAAAAAAAAICtsnzN+tj3uueTtP90wcFxeJsmSdoAQOEwfgIAAAAAAAAAAAAAttiwtxfG9/88MUl7xqDeUadmSZI2AFBYjJ8AAAAAAAAAAAAAgM1WVpaLPrePjZmfrMi8/fPee8X3jmqTeRcAKFzGTwAAAAAAAAAAAADAZpn9yYo49raXk7Rfufzo2HWHuknaAEDhMn4CAAAAAAAAAAAAADbppmHT4zdj52be7damSTx8ftcoKirKvA0AFD7jJwAAAAAAAAAAAABgo1asWR+drns+Sfvh87tG97ZNk7QBgKrB+AkAAAAAAAAAAAAA+ErPTl0Yl/xpYpL2jEG9o07NkiRtAKDqMH4CAAAAAAAAAAAAAP6PXC4XfW4fGzM+XpF5+yfHtovLjmmbeRcAqJqMnwAAAAAAAAAAAACA//bepyuj560vJWmP/fnRsVvjuknaAEDVZPwEAAAAAAAAAAAAAERExNBnZ8R9L83JvHtI68bxlwsPiaKioszbAEDVZvwEAAAAAAAAAAAAANXcyrUbYp9rRyRp/+G8LnHUXs2StAGAqs/4CQAAAAAAAAAAAACqsRHTPo7vPjwhSfvdG3rHdrVKkrQBgOrB+AkAAAAAAAAAAAAAqqFcLhfH3/VKvLNgeebtH/VsFz/s2TbzLgBQ/Rg/AQAAAAAAAAAAAEA18/6ildHjVy8lab/8s6Nj9x3rJmkDANWP8RMAAAAAAAAAAAAAVCO/HDEj7n5hTubdLi13iMe+e2gUFRVl3gYAqi/jJwAAAAAAAAAAAACoBlat3RAdrx2RpP37c7vE0e2bJWkDANWb8RMAAAAAAAAAAAAAVHGjpn8SF/zxrSTt6TccF3Vr+VgyAJCGf8oAAAAAAAAAAAAAgCoql8vFSfeMi8kfLM28/YNj2saPj22XeRcA4H8zfgIAAAAAAAAAAACAKmjeZ6viqFteTNJ+8adHRcsm9ZK0AQD+N+MnAAAAAAAAAAAAAKhibn1+Ztwx5r3MuwfusUM8cfGhUVRUlHkbAOCrGD8BAAAAAAAAAAAAQBWxet2G6HDNiCTt355zUByz905J2gAAG2P8BAAAAAAAAAAAAABVwJgZn8R3/vBWkva064+LerV99BgAqHj+CQQAAAAAAAAAAAAAClgul4uT7xsfE+Z/nnn70qPbxE+P2yvzLgDA5jJ+AgAAAAAAAAAAAIACNX/xqjjyly8maY/5yZHRuun2SdoAAJvL+AkAAAAAAAAAAAAACtCvR82KX4+anXl3310bxtPfPzyKiooybwMAbCnjJwAAAAAAAAAAAAAoIF+sK429r3kuSfuBsw6MXh2bJ2kDAGwN4ycAAAAAAAAAAAAAKBAvzvw0zv39m0na71x/XGxf28eLAYDKxT+dAAAAAAAAAAAAAEAll8vl4rQHXos35i7JvH3JUXvG5b3bZ94FAMiC8RMAAAAAAAAAAAAAVGIfLFkd3W9+IUl79E+OjD2bbp+kDQCQBeMnAAAAAAAAAAAAAKik7hw9O341clbm3Q4tGsSwH3SLoqKizNsAAFkyfgIAAAAAAAAAAACASmbN+tJof/VzSdr3ffuA6L1PiyRtAICsGT8BAAAAAAAAAAAAQCXy8qxFcfbv3kjSnnpdr6hfp2aSNgBACsZPAAAAAAAAAAAAAFAJ5HK5OPPB12PcnMWZty86onUM7Lt35l0AgNSMnwAAAAAAAAAAAAAgzz5Ysjq63/xCkvaoHx8RbZrVT9IGAEjN+AkAAAAAAAAAAAAA8ujuF96LX46YmXm3ffP68ewPu0dRUVHmbQCAimL8BAAAAAAAAAAAAAB5sGZ9abS/+rkk7XvOPCD6dmqRpA0AUJGMnwAAAAAAAAAAAACggr0y+7P49m9fT9Keel2vqF+nZpI2AEBFM34CAAAAAAAAAAAAgAqSy+Xi7N+9EWNnf5Z5+/xureLqr3XIvAsAkE/GTwAAAAAAAAAAAABQARYs/SIOHzomSfv5Hx0R7Xaqn6QNAJBPxk8AAAAAAAAAAAAAkNh9L82Joc/OyLzbttn2MaL/EVFcXJR5GwCgMjB+AgAAAAAAAAAAAIBE1qwvjfZXP5ekfde39o+v7btzkjYAQGVh/AQAAAAAAAAAAAAACYyb81l86zevJ2lPubZXNNyuZpI2AEBlYvwEAAAAAAAAAAAAABk77/dvxAszF2XePfewlnHdCR0z7wIAVFbGTwAAAAAAAAAAAACQkY+WfhGHDR2TpP1c/+7RvnmDJG0AgMrK+AkAAAAAAAAAAAAAMvCbl9+Pm4a/m3m3dZN6MerHR0ZxcVHmbQCAys74CQAAAAAAAAAAAAC2wdoNpbH31c9FWS779u2n7xcn7rdL9mEAgAJh/AQAAAAAAAAAAAAAW2n8nMVxxm9eS9Keck2vaFi3ZpI2AEChMH4CAAAAAAAAAAAAgK1wwUNvxqh3P828e9Yhe8Sgr++TeRcAoBAZPwEAAAAAAAAAAADAFvh42Zo4ZMjoJO3hP+geHXZukKQNAFCIjJ8AAAAAAAAAAAAAYDP99pW5Megf0zPv7t64brzw06OipLgo8zYAQCEzfgIAAAAAAAAAAACATVi3oSz2uXZErCsty7x922md46T9d828CwBQFRg/AQAAAAAAAAAAAEA53pi7JE69f3yS9uRrjo1GdWslaQMAVAXGTwAAAAAAAAAAAACwERf98a14fvonmXe/dfDuMfikTpl3AQCqGuMnAAAAAAAAAAAAAPg3nyxfEwcPHp2k/Y/LusU+uzRM0gYAqGqMnwAAAAAAAAAAAADgf/nDq3PjumemZ97dpdF28fLPj46S4qLM2wAAVZXxEwAAAAAAAAAAAABExLoNZdH5+ufji/WlmbdvOaVznHzgrpl3AQCqOuMnAAAAAAAAAAAAAKq9t+YtiZPvG5+kPenqY2OHerWStAEAqjrjJwAAAAAAAAAAAACqte//aWIMm7ow8+7pXXaLod/cN/MuAEB1YvwEAAAAAAAAAAAAQLX06Yo10fWm0Una/7isW+yzS8MkbQCA6sT4CQAAAAAAAAAAAIBq5+Hx8+Lqp6dl3m3eoE68ekWPKCkuyrwNAFAdGT8BAAAAAAAAAAAAUG2sLy2LA24YGSvWbsi8ffPJ+8apB+2WeRcAoDozfgIAAAAAAAAAAACgWpgw//P45r3jkrQnXn1sNK5XK0kbAKA6M34CAAAAAAAAAAAAoMq77C+T4pkpH2XePfnAXeOWUzpn3gUA4EvGTwAAAAAAAAAAAABUWYtWrI0uN41K0v77pYfHvrs2StIGAOBLxk8AAAAAAAAAAAAAVEl/en1+XPnkO5l3m2xfK14bcEzUKCnOvA0AwP9l/AQAAAAAAAAAAABAlbKhtCwOumlULF29PvP20G90itO77p55FwCAr2b8BAAAAAAAAAAAAECVMemfn8dJ94xL0n7rqp7RZPvaSdoAAHw14ycAAAAAAAAAAAAAqoQfPTo5npy0IPPuN/bfJW49bb/MuwAAbJrxEwAAAAAAAAAAAAAF7bOVa+OgG0claT/5vcNi/913SNIGAGDTjJ8AAAAAAAAAAAAAKFh/eeOfMeBvUzPvNqpbM966smfUKCnOvA0AwOYzfgIAAAAAAAAAAACg4GwoLYuug0fHklXrMm/fdNI+cebBe2TeBQBgyxk/AQAAAAAAAAAAAFBQpnywNE68+9Uk7Tev7BlN69dO0gYAYMsZPwEAAAAAAAAAAABQMH76+JR4YsKHmXdP6Lxz3HHG/pl3AQDYNsZPAAAAAAAAAAAAwP9VVhrx2ayIjyZHfDo9Ys3SiA1rI0rXRZTUiqhRO6JOo4hmHSJ23j+iSduI4pI8X5qqbvHKtXHgjaOStP96yWFx4B47JGkDALBtjJ8AAAAAAAAAAACgusvlIua9EjFzeMSCiREfvx2xfvXm//0160U07xSxywERe/WNaNktoqgo3X2pdh5784P4+V/fzrzboE6NmHD1sVGzpDjzNgAA2TB+AgAAAAAAAAAAgOrqi6URUx6JeOu3X37T09Zavyrig9e+/Ou1eyKatIs46PyIzqdHbNcoq9tSDZWW5eKwoaPjk+VrM28P+vo+cdYhe2TeBQAgW8ZPAAAAAAAAAAAAUN0seT/ilV9HTH18y77haXN9NiviucsjRl8f0emUiG79Ixq3zv49VGlTP1wWx9/1SpL2G1ceE83q10nSBgAgW8ZPAAAAAAAAAAAAUF2UbogYf2fEC0MiSrP/Jp3/sH51xMSHvvx2qaMHRhx2WURxSfr3UvAuf+LtePStDzLv9uvUIu4+84DMuwAApGP8BAAAAAAAAAAAANXBopkRT10SsWBCxb+7dG3EqGsj3n0m4uv3RDTdq+LvQEH4fNW62H/QyCTtJy4+NA5q2ThJGwCAdIrzfQEAAAAAAAAAAAAgobKyiFdvj7ive36GT//bgre+vMert395L/hfnpjwYZLhU71aJTHrxj6GTwAABco3PwEAAAAAAAAAAEBVVbo+4qnvRUx9LN83+R+layNGXhPx8TtffgtUSc1834g8Ky3LxRE3vxALln6Refv6EzrGOYe1zLwLAEDFMX4CAAAAAAAAAACAqmj9mojHz42Y9Wy+b/LVpj4WsXZFxCl/iKhZJ9+3IU/eWbAsvnbnK0nabww8Jpo18P9bAACFrjjfFwAAAAAAAAAAAAAyVrq+cg+f/mXWsxFPnPflfal2Bj45Ncnw6biOO8W8of0MnwAAqgjf/AQAAAAAAAAAAABVSVlZxFPfq/zDp3+ZOfzL+550f0Sx3+leHSxdvS72u2FkkvZj3z00urZqnKQNAEB+GD8BAAAAAAAAAABAVTL+zoipj+X7Fltm6mMRzTtFHP6DfN+ExJ6c9GH86NEpmXdr1yiOqdcdF7VqGNABAFQ1xk8AAAAAAAAAAABQVSyaGTHmpnzfYuuMuTGi3XERTffK901IoLQsF0f+8oX48PMvMm9f/bUOcX63Vpl3AQCoHIyfAAAAAAAAAAAAoCoo3RDx1CURpWvzfZOtU7o24qnvRZz/fERxSb5vQ4amf7Q8+t4xNkn7tQHHRPOGdZK0AQCoHHy3JwAAAAAAAAAAAFQF4++KWDAh37fYNgveihh3Z75vQYaufuqdJMOnnns3i3lD+xk+AQBUA775CQAAAAAAAAAAAArdkvcjXhic71tk44XBER1OiGjcOt83YRssW70+Ot/wfJL2IxcdEoe03jFJGwCAysc3PwEAAAAAAAAAAEChe+XXEaVr832LbJSu/fLnoWA9PXlBkuFTjeKimHljb8MnAIBqxjc/AQAAAAAAAAAAQCH7YmnE1MfzfYtsTX08otegiDoN830TtkBZWS56/OrFmLd4debtq/rtHRd0921gAADVkfETAAAAAAAAAAAAFLIpj0Ssz35sklfrV3/5cx383XzfhM004+Pl0fvXY5O0xw/oES0abpekDQBA5Vec7wsAAAAAAAAAAAAAWymXi3jzwXzfIo03H/zy56PSu/bpd5IMn47eq2nMG9rP8AkAoJrzzU8AAAAAAAAAAABQqOa9ErF4dr5vkcZnsyLmvxrRslu+b8JGLPtifXS+/vkk7T9fcHAc1qZJkjYAAIXF+AkAAAAAAAAAAAAK1czh+b5BWjOGGz9VUs9M+Sgu+8ukJO0Zg3pHnZolSdoAABQe4ycAAAAAAAAAAAAoVAsm5vsGaX1UxX++AlRWlotjb3sp5ixalXl7QJ/28d0j98y8CwBAYTN+AgAAAAAAAAAAgEJUVhrx8dv5vkVaC9/+8ucs9i1AlcGsT1ZEr9teTtJ+9YoesUuj7ZK0AQAobMZPAAAAAAAAAAAAUIg+mxWxfnW+b5HW+lURn82OaNY+3zep9gb9Y3r89pW5mXePbNc0HvpO18y7AABUHcZPAAAAAAAAAAAAUIg+mpzvG1SMhZONn/Jo+Zr1se91zydp/+mCg+PwNk2StAEAqDqMnwAAAAAAAAAAAKAQfTo93zeoGNXl56yEhk9dGN/708Qk7RmDekedmiVJ2gAAVC3GTwAAAAAAAAAAAFCI1izN9w0qxhdL832DaqesLBd9bh8bMz9ZkXn75733iu8d1SbzLgAAVZfxEwAAAAAAAAAAABSiDWvzfYOKUV1+zkpi9icr4tjbXk7SHvvzo2O3xnWTtAEAqLqMnwAAAAAAAAAAAKAQla7L9w0qRqnxU0UZPPzdeODl9zPvdmvTJB4+v2sUFRVl3gYAoOozfgIAAAAAAAAAAIBCVFIr3zeoGCW1832DKm/FmvXR6brnk7T/+J2ucUS7pknaAABUD8ZPAAAAAAAAAAAAUIhqVJNRUHX5OfPkuXcWxsX/NTFJe8ag3lGnZkmSNgAA1YfxEwAAAAAAAAAAABSiOo3yfYOKsV2jfN+gSsrlctHvjldi+sLlmbd/cmy7uOyYtpl3AQConoyfAAAAAAAAAAAAoBA165DvG1SM6vJzVqD3Pl0ZPW99KUl77M+Pjt0a103SBgCgejJ+AgAAAAAAAAAAgEK08375vkHFaLFfvm9QpQx9dkbc99KczLsHt2ocj1x0SBQVFWXeBgCgejN+AgAAAAAAAAAAgELUpF1EzboR61fn+ybp1KwX0aRtvm9RJaxcuyH2uXZEkvYfzusSR+3VLEkbAACMnwAAAAAAAAAAAKAQFZdENN834oPX8n2TdFrs++XPyTZ5ftrHcdHDE5K0372hd2xXy/+NAABIx/gJAAAAAAAAAAAACtUuB1Tt8dPOB+T7BgUtl8vFiXe/Gm9/uCzzdv+ebaN/z3aZdwEA4N8ZPwEAAAAAAAAAAECh2qtvxGv35PsW6bTvm+8bFKz3F62MHr96KUn7pZ8dFXvsWC9JGwAA/p3xEwAAAAAAAAAAABSqlt0idmwbsXh2vm+SvSbtIvY4PN+3KEi/HDEj7n5hTubdLi13iMe+e2gUFRVl3gYAgI0xfgIAAAAAAAAAAIBCVVQU0eWCiOcuz/dNstflgi9/PjbbqrUbouO1I5K0f39ulzi6fbMkbQAAKE9xvi8AAAAAAAAAAAAAbIPOp0fUrJvvW2SrZt0vfy4226jpnyQbPk2/4TjDJwAA8sY3PwEAAAAAAAAAAEAh265RRKdTIiY+lO+bZKfTKRF1Gub7FgUhl8vFN+4dF5P+uTTz9g96tIkf99or8y4AAGwJ4ycAAAAAAAAAAAAodN36R0x5JKJ0bb5vsu1Kan/587BJ8z5bFUfd8mKS9os/PSpaNqmXpA0AAFuiON8XAAAAAAAAAAAAALZR49YRRw/M9y2ycfTAL38eynXr8zOTDJ/2371RzB3S1/AJAIBKwzc/AQAAAAAAAAAAQFVw6KUR7/49YsGEfN9k6+1yUMRhl+X7FpXa6nUbosM1I5K0Hzz7oOjZYackbQAA2Fq++QkAAAAAAAAAAACqgpIaEV+/N6Kkdr5vsnVKakd8/Z6I4pJ836TSemHGp8mGT9OuP87wCQCASsn4CQAAAAAAAAAAAKqKpntF9Lgy37fYOj2u+vL+/IdcLhen3DcuzvvDm5m3Lz26Tcwb2i/q1a6ReRsAALLgn1QBAAAAAAAAAACgKjn0soiP34mY+li+b7L5Op0aceil+b5FpfTPxavjiF++kKQ95idHRuum2ydpAwBAVoyfAAAAAAAAAAAAoCopLo74+j0Ra1dEzHo237fZtL36fnnf4uJ836TSuX3U7Lht1KzMu/vu2jCe/v7hUVRUlHkbAACyZvwEAAAAAAAAAAAAVU1JzYhT/hDx+LmVewC1V9+Ik3//5X35b1+sK429r3kuSfuBsw6MXh2bJ2kDAEAKfk0CAAAAAAAAAAAAVEU160Sc9nBEp1PzfZOv1unUiFP/+OU9+W8vzvw02fDpneuPM3wCAKDg+OYnAAAAAAAAAAAAqKpKakacdH9E830ixtwUUbo23zeKKKkd0eOqiEMvjSj2O9z/JZfLxekPvBavz12Sefu7R7aOAX32zrwLAAAVwfgJAAAAAAAAAAAAqrLi4ojDfxjRrnfEU5dELJiQv7vsclDE1++JaLpX/u5QCX2wZHV0v/mFJO1RPz4y2jTbPkkbAAAqgl+ZAAAAAAAAAAAAANVB070ivvN8RM/rv/z2pYpUUjvi2Bsizn/e8Onf3DVmdpLhU4cWDWLukL6GTwAAFDzf/AQAAAAAAAAAAADVRUmNiG79IzqcEPHKryOmPh6xfnW699WsG9HplC/f2bh1uvcUoDXrS6P91c8lad/37QOi9z4tkrQBAKCiGT8BAAAAAAAAAABAddO4dcQJd0T0GhQx5ZGINx+M+GxWdv0m7SK6XBDR+fSIOg2z61YRL89aFGf/7o0k7anX9Yr6dWomaQMAQD4YPwEAAAAAAAAAAEB1VadhxMHfjeh6UcT8VyNmDI/4aGLEwilb9o1QNetFtNg3YucDItr3jdjj8IiionT3LlC5XC7OfPD1GDdncebti45oHQP77p15FwAA8s34CSjXhg0bYs6cOTFv3rxYsWJFrFy5MurUqRMNGjSIFi1axF577RV169bN9zUBAAAAAAAAAIBtUVQU0bLbl39FRJSVRnw2O2Lh5IhPp0d8sTRiw9qI0rURJbUjatSO2K5RRLMOES32i2jSNqK4JH/3LwAfLFkd3W9+IUl75I+OiLY71U/SBgCAfDN+gq2wfv36mDFjRrzzzjsxbdq0eOedd+LDDz+MpUuXxtKlS2PZsmVRUlISderUicaNG8fOO+8crVq1in333Te6dOkShx12WNSqVSvfP8ZGTZ06Nf72t7/F8OHDY/LkybFu3bqNni0qKoq2bdtG796944QTTogePXpEkd/YAgAAAAAAAAAAha24JKJZ+y//Ypvd/cJ78csRMzPv7rVT/Xj2h92juNhntgAAqLqMn2AzlJWVxaRJk2LMmDExevToGDt2bKxeXf5XOm/YsCHWrl0by5Yti7lz58arr77638/q1q0bvXr1inPOOSe+9rWvRY0aleO/iiNGjIihQ4fGiy++uNl/Ty6Xi1mzZsWsWbPijjvuiHbt2sWPfvSjuPDCC6OkxG9yAQAAAAAAAAAAqq8160uj/dXPJWnf/a0Dot++LZK0AQCgMinK5XK5fF8CKqMNGzbE6NGj49FHH42nn346lixZkuQ9rVq1iiuuuCLOP//8vI2FFixYEJdddlk8+eSTmTU7d+4c999/fxx88MGZNauijh07xvTp0//jP+/QoUNMmzYtDzcCAAAAAAAAAACy8Op7n8WZD76epP32db2iQZ2aSdoAAFRe1fXz58X5vgBUNtOmTYsLL7wwmjdvHr17947f//73yYZPERFz586N7373u9G1a9eYNGlSsvdszNixY+OAAw7IdPgUETFlypTo3r173HvvvZl2AQAAAAAAAAAAKruzf/dGkuHTdw5vFfOG9jN8AgCgWjF+gn/zzDPPxIMPPhiLFy+u0PdOnDgxDj300Lj//vsr7J1PP/10HHPMMfHpp58m6a9fvz6+973vxRVXXJGkDwAAAAAAAAAAUJksWPpFtLxiWLw8a1Hm7ed/dERcc3yHzLsAAFDZGT9BJbJ27dq4+OKL49prr03+rpEjR8Zpp50W69evT/6uX/ziFzFo0KDk7wEAAAAAAAAAAMiX+1+aE4cPHZN5t22z7eP9wX2j3U71M28DAEAhqJHvC0ChKykpiY4dO8bee+8drVq1iiZNmkS9evVizZo1sXjx4li4cGG88sorMXPmzM1u3nDDDVG3bt24/PLLk9x53rx5ceqpp8batWs3ebZTp05x1llnRffu3aNt27bRsGHDWLVqVXzwwQfx2muvxaOPPhqjR4+OXC5Xbueaa66JfffdN0488cSsfgwAAAAAAAAAAIC8W7O+NNpf/VyS9p1n7B/Hd945SRsAAAqF8RNshfbt28fxxx8fffr0iYMPPjjq1q27yb9n4cKF8cADD8Sdd94Zixcv3uT5AQMGRKdOnaJv375ZXPm/bdiwIU477bRYunRpued22mmnuPPOO+OUU075j2cNGzaMhg0bxj777BMXXHBBvPnmm3HxxRfHxIkTy22ed955MXny5Nh999235UcAAAAAAAAAAACoFMbN+Sy+9ZvXk7SnXNsrGm5XM0kbAAAKSXG+LwCFolGjRtG/f/+YMGFCvPvuu3HzzTfH0UcfvVnDp4iIFi1axLXXXhvz58+PCy64YJPnc7lcXHDBBZscKW2pu+66K954441yz3Tu3DkmTpz4lcOnr9KlS5cYN25cnHHGGeWe+/zzz6N///6be1UAAAAAAAAAAIBK67zfv5Fk+HTuYS1j3tB+hk8AAPD/GT/BJrRp0ybuv//+WLBgQdx2221xwAEHbFOvXr168Zvf/CYeeuihKCkpKffswoUL4xe/+MU2ve9/W7RoUVx33XXlnmnTpk2MHDkydt55y74quXbt2vHwww/HiSeeWO65J598MkaNGrVFbQAAAAAAAAAAgMpi4bIvouUVw+KFmYsybz/Xv3tcd0LHzLsAAFDIjJ9gI9q1axf/9V//FTNmzIiLLrpos7/haXOdffbZceedd27y3J133hnLly/P5J233HJLLFu2bKPPa9WqFY899lg0bdp0q/olJSXx0EMPRcuWLcs9d80112xVHwAAAAAAAAAAIJ8eHPt+HDpkTObd1k3qxfuD+0b75g0ybwMAQKEzfoJ/s9NOO8U999wT06ZNizPPPHOT3860LS655JI4++yzyz2zatWqeOyxx7b5XcuXL4/777+/3DP9+/eP/ffff5ve07Bhw7j99tvLPTN+/PgYO3bsNr0HAAAAAAAAAACgoqzdUBptBg6PG4e9m3n79tP3izE/PSqKi4sybwMAQFVg/AT/5rzzzotLLrkkatSoUSHvGzx48Ca/Veqpp57a5vc89NBD5X7rU6NGjeLKK6/c5vdERJxwwgnRvXv3cs/ccccdmbwLAAAAAAAAAAAgpdfeXxx7XfVcbCjLZd6eck2vOHG/XTLvAgBAVWL8BHm2yy67xBlnnFHumbFjx0ZZWdk2vefhhx8u9/lFF10UDRpk95XJP/nJT8p9/swzz5Q7xgIAAAAAAAAAAMi3Cx56K05/4LXMu2cdskfMG9ovGtatmXkbAACqGuMnqAS+9rWvlft8+fLlMX/+/K3uz549O958881yz1x44YVb3f8qxx9/fLRo0WKjz9euXRt//etfM30nAAAAAAAAAABAFj5etiZaXjEsRr37Sebt4T/oHoO+vk/mXQAAqKqMn6ASOOKIIzZ55v3339/q/jPPPFPu8wMPPDDatGmz1f2vUlxcHKeeemq5ZzZ1LwAAAAAAAAAAgIr221fmxiFDRmfe3a3xdjFncN/osHODzNsAAFCVGT9BJdC4ceOoVatWuWeWLl261f1Ro0aV+7xfv35b3d6W7gsvvBClpaVJ3g0AAAAAAAAAALAl1m0oi3ZXPhuD/jE98/atp3aOsT/vESXFRZm3AQCgqjN+gkqiSZMm5T7/4osvtqq7YcOGePnll8s907Nnz61qb0r37t2jTp06G32+bNmyePPNN5O8GwAAAAAAAAAAYHO9OW9JtLvq2VhXWpZ5e/I1x8Y3Dtg18y4AAFQXxk9QSaxevbrc5+WNiMozbdq0WLVq1Uaf16xZM7p27bpV7U2pU6dO7L///uWeMX4CAAAAAAAAAADy6eKHJ8Qp943PvHtG191j3tB+0ahurczbAABQndTI9wWAiBUrVsSyZcvKPbPDDjtsVXvixInlPu/QoUPUrl17q9qb46CDDorx4zf+LwYmTZqU7N0AAAAAAAAAAAAb8+nyNdF18Ogk7X9c1i322aVhkjYAAFQ3xk9QCUyaNClyuVy5Z/bcc8+tak+ePLnc5/vuu+9WdTfXpvrGTwAAAAAAAAAAQEV7aNy8uPbv0zLv7tJou3j550dHSXFR5m0AAKiujJ+gEhg2bFi5zxs0aBC77777VrVnzZpV7vO2bdtuVXdztWnTptzns2fPTvp+AAAAAAAAAACAf1m3oSw6X/98fLG+NPP2Lad0jpMP3DXzLgAAVHfGT5BnpaWl8eijj5Z7plu3blFcXLxV/blz55b7fFPjpG21qf6qVati0aJF0bRp06T3AAAAAAAAAAAAqrcJ85fEN+8dn6Q96epjY4d6tZK0AQCgujN+gjx76qmnYv78+eWeOeGEE7aqncvlNtneeeedt6q9uZo3bx7FxcVRVla20TNz5841fgIAAAAAAAAAAJL5/p8mxrCpCzPvnnrQrnHzyZ0z7wIAAP/D+AnyqLS0NK655ppyz9SqVStOOeWUrep//vnnsWbNmnLPNG/efKvam6tGjRqx4447xqJFizZ65qOPPkp6BwAAAAAAAAAAoHr6dMWa6HrT6CTtZy7tFp12bZikDQAA/I/ifF8AqrN77703pk+fXu6Zc845Jxo3brxV/cWLF2/yTLNmzbaqvSV22mmncp9vzj0BAAAAAAAAAAC2xMOvzU8yfNqpQe2YM7iv4RMAAFQQ3/wEeTJv3rwYMGBAuWdq1qwZl19++Va/Y8mSJZs806BBg63ub65NvWNz7gkAAAAAAAAAALA51peWxYGDRsbyNRsyb9/8zX3j1C67Zd4FAAA2zvgJ8qC0tDTOOeecWLlyZbnn+vfvH3vuuedWv+fzzz8v9/l2220XJSUlW93fXPXr1y/3eWUcP919991xzz33JH/PnDlzkr8DAAAAAAAAAACqi4n//Dy+cc+4NO2rj43G9WolaQMAABtn/AR5cPXVV8fLL79c7pnddtstrr766m16z5o1a8p9Xq9evW3qb67tt9++3Oebumc+LFq0KKZPn57vawAAAAAAAAAAAJvpB3+ZFH+f8lHm3ZMP3DVuOaVz5l0AAGDzGD9BBXvmmWdi6NCh5Z4pKiqK3/3ud5v8xqRNWbduXbnPa9SomP8J2NR7NnVPAAAAAAAAAACAjVm0Ym10uWlUkvbT3z88Ou/WKEkbAADYPMZPUIHeeeedOPPMMyOXy5V77tJLL42ePXtu8/uMnwAAAAAAAAAAgKrsT6/PjyuffCfzbpPta8VrA46JGiXFmbcBAIAtY/wEFeTTTz+N448/PlasWFHuuS5dusQtt9ySyTvLysrKfV5SUpLJezZlU+8pLS2tkHsAAAAAAAAAAABVw4bSsjjoplGxdPX6zNtDv9EpTu+6e+ZdAABg6xg/QQVYuXJl9O3bN+bNm1fuuR133DEef/zxqFWrVibv3dQ3Lm3YsCGT92zKpt5Ts2bNCrkHAAAAAAAAAABQ+CZ/sDS+fverSdpvXdUzmmxfO0kbAADYOsZPkNi6devipJNOigkTJpR7brvttounn3469thjj8zevakRVUWNn9avL/+3q2Q19spS06ZNo0OHDsnfM2fOnFi7dm3y9wAAAAAAAAAAQFXw40cnx98mLci8+/X9do5fn75/5l0AAGDbGT9BQqWlpXHGGWfEqFGjyj1Xs2bNePzxx+Pwww/P9P2b+kaldevWZfq+jSnE8dP3v//9+P73v5/8PR07dozp06cnfw8AAAAAAAAAABSyxSvXxoE3lv85rK315PcOi/133yFJGwAA2HbGT5BILpeLCy64IP72t7+Ve664uDj++Mc/Rr9+/TK/w/bbb1/u85UrV2b+zq+yYsWKcp9v6p4AAAAAAAAAAED19cgb/4wr/jY1826jujXjzSt7Rs2S4szbAABAdoyfIJEf/vCH8Yc//GGT5+677744/fTTk9yhcePG5T5fv359rFmzJurUqZPk/f+yfPnycp9v6p4AAAAAAAAAAED1s6G0LA4ZMjo+W7ku8/ZNJ+0TZx68R+ZdAAAge8ZPkMDAgQPjzjvv3OS5X/3qV3HhhRcmu8eOO+64yTNLly6N5s2bJ7vDv95Rns25JwAAAAAAAAAAUH1M+WBpnHj3q0nab17ZM5rWr52kDQAAZM/4CTI2ePDgGDJkyCbPXX/99fHjH/846V2aNGmyyTMff/xx8vHTxx9/XO5z4ycAAAAAAAAAAOBffvr4lHhiwoeZd4/vvHPcecb+mXcBAIC0jJ8gQ7fffntceeWVmzz3s5/9LK655prk96lbt27suOOOsXjx4o2e+eSTT5LeYfXq1bFixYpyz+yxh6+PBgAAAAAAAACA6m7xyrVx4I2jkrT/eslhceAeOyRpAwAAaRk/QUYeeOCB6N+//ybPXXrppXHzzTenv9D/17Jly3LHT/Pnz0/6/s3pt2zZMukdAAAAAAAAAACAyu2xtz6Inz/xdubd+rVrxMRrjo2aJcWZtwEAgIph/AQZePjhh+Piiy/e5Lnzzz8/7rjjjgq40f9o1apVTJgwYaPPZ8+enfT97733XrnPd9ppp6hbt27SOwAAAAAAAAAAAJVTaVkuDhs6Oj5Zvjbz9qATO8ZZh7bMvAsAAFQsv8oAttHjjz8e5513XuRyuXLPnXHGGfHAAw9EUVFRBd3sSx07diz3+cyZM5O+f1P9Td0PAAAAAAAAAAComt5ZsCz2HDg8yfDpjSuPMXwCAIAqwjc/wTb4+9//HmeeeWaUlpaWe+6kk06KP/7xj1FcXPF7wwMOOKDc55MmTUr6/okTJ5b7fP/990/6fgAAAAAAAAAAoPK5/Im349G3Psi8269Ti7j7zPI/MwUAABQW4yfYSiNGjIhTTz011q9fX+65Pn36xCOPPBI1auTnv26bGj99+OGH8emnn0azZs2SvH/ChAnlPjd+AgAAAAAAAACA6uPzVeti/0Ejk7SfuPjQOKhl4yRtAAAgfyr+a2igCnjxxRfjpJNOirVry/+65R49esTf/va3qFWrVgXd7D/tuuuusccee5R75sUXX0zy7o8++ihmzZpV7plu3boleTcAAAAAAAAAAFC5/HXCh0mGT3VrlcSsG/sYPgEAQBVl/ARbaPz48XH88cfHF198Ue65bt26xd///veoU6dOBd1s43r27Fnu85Ej0/wmlVGjRpX7vG3btpscZgEAAAAAAAAAAIWttCwXhw8dEz95fErm7euO7xDTb+gdtWr4OCQAAFRV/mkftsCECROiT58+sXLlynLPdenSJYYNGxb16tWroJuV79hjjy33+d///vcoLS3N/L1PPPFEuc979eqV+TsBAAAAAAAAAIDKY9pHy2LPgcNjwdLyf9n01nh94DFx7uGtMu8CAACVi/ETbKapU6fGcccdF8uWLSv3XOfOnWPEiBHRoEGDCrrZpvXr1y/q1q270eeffvrpJr+laUstWbIkRowYUe6ZU045JdN3AgAAAAAAAAAAlceVT06Nfne8knn3uI47xbyh/WKnBnUybwMAAJWP8RNshlmzZsWxxx4bixcvLvdchw4dYuTIkbHDDjtU0M02z/bbbx8nnHBCuWfuvPPOTN953333xbp16zb6fLfddosjjjgi03cCAAAAAAAAAAD5t3T1umh5xbD40+v/zLz92HcPjfvPOijzLgAAUHkZP8EmzJs3L4455pj45JNPyj3Xtm3bGDVqVDRt2rSCbrZlvvOd75T7fPjw4TF58uRM3rVy5cpNjqnOPvvsKCoqyuR9AAAAAAAAAABA5fDUpAWx3w0jM+/WrlEcs27sE11bNc68DQAAVG7GT1COjz76KI455pj48MMPyz3XsmXLGDNmTLRo0aKCbrbljj322Nh33303+jyXy0X//v0zedeQIUPi448/3ujz2rVrx2WXXZbJuwAAAAAAAAAAgPwrK8vFETe/EP0fnZx5++qvdYiZN/aJWjV85BEAAKojfxKAjVi0aFEcc8wx8f7775d7btddd40xY8bErrvuWkE323qXX355uc9feumluO2227bpHePGjYubb7653DPnnntu7LTTTtv0HgAAAAAAAAAAoHJ4d+HyaD1wePxzyerM268NOCbO79Yq8y4AAFA4jJ/gKyxdujR69eoVM2bMKPdc8+bNY8yYMdGqVWH84fqMM86ILl26lHvm8ssvj2eeeWar+rNnz46TTz45NmzYsNEz9evXj+uuu26r+gAAAAAAAAAAQOVy9VPvRJ/bx2be7bl3s5g3tF80b1gn8zYAAFBYjJ/g36xcuTL69OkTkydPLvdckyZNYvTo0dG2bduKuVgGioqK4q677oqioqKNnlm/fn2ccsop8eCDD25R+9VXX40jjzwyFi5cWO65a6+9Npo3b75FbQAAAAAAAAAAoHJZtnp9tLxiWDz82vzM249cdEg8eE75v+QZAACoPmrk+wJQ2Zxxxhnx2muvbfLcaaedFuPGjYtx48ZVwK0iWrRoEf369dvmTteuXWPAgAExePDgjZ5Zu3ZtXHjhhfHXv/41brjhhnK/LWr+/Pnxi1/8In7zm9+U+41PERFHHnlk9O/ff2uvDgAAAAAAAAAAVAJPT14QP3xkcubdkuKimH7DcVG7RknmbQAAoHAV5XK5XL4vAZVJy5YtY/787H8bybY68sgj48UXX8ykVVpaGj169IiXX355s863b98+unfvHm3bto0GDRrEqlWr4oMPPojXX389Xnvttdic/xlp1qxZTJo0KXbeeedtvX6V0rFjx5g+ffp//OcdOnSIadOm5eFGAAAAAAAAAADw1UrLcrHnwOFJ2lf23TsuPKJ1kjYAAFQV1fXz5775CaqhkpKSeOqpp+Loo4+OKVOmbPL8jBkzYsaMGVv9vkaNGsWIESMMnwAAAAAAAAAAoEC9+t5nceaDrydpj7uiR+zcaLskbQAAoPAV5/sCQH7ssMMOMXLkyDjooIOSvqdZs2YxYsSI2G+//ZK+BwAAAAAAAAAASOPoW15MMnw6aq+mMW9oP8MnAACgXMZPUI01bdo0xo4dG2effXaSfpcuXeKtt96Krl27JukDAAAAAAAAAADpLFqxNlpeMSzmfrYq8/afLzg4/nCezxUBAACbZvwE1VydOnXioYcein/84x/RunXrTJr169ePW2+9NcaPHx+77bZbJk0AAAAAAAAAAKDi3Pr8zOhy06gk7RmDesdhbZokaQMAAFWP8RMQERH9+vWLGTNmxMMPPxxdunTZqsYee+wRQ4YMiXnz5sWPfvSjKCkpyfiWAAAAAAAAAABASmVluWh5xbC4Y8x7mbev6NM+5g3tF3Vq+lwRAACw+Wrk+wJQ2cybNy/fV8ibmjVrxre//e349re/HR988EE8++yz8eabb8b06dNj/vz5sXz58li9enXUrl076tevHy1atIi999479ttvvzjuuOOic+fO+f4RAAAAAAAAAACArTR+zuI44zevJWm/ekWP2KXRdknaAABA1Wb8BHyl3XbbLS666KK46KKL8n0VAAAAAAAAAAAgsV63vRSzPlmZebd72ybxx+90jaKioszbAABA9WD8BAAAAAAAAAAAANXUZyvXxkE3jkrS/q/zD45ubZskaQMAANWH8RMAAAAAAAAAAABUQ3eMnh23jpyVpD1jUO+oU7MkSRsAAKhejJ8AAAAAAAAAAACgGikry0XrgcOTtC/o1iqu+lqHJG0AAKB6Mn4CAAAAAAAAAACAauKNuUvi1PvHJ2kP/0H36LBzgyRtAACg+jJ+AgAAAAAAAAAAgGqgz+1j492Fy5O05w7pG0VFRUnaAABA9Wb8BAAAAAAAAAAAAFXYklXr4oBBI5O0b/z6PvHtQ/ZI0gYAAIgwfgIAAAAAAAAAAIAq6+4X3otfjpiZpD31ul5Rv07NJG0AAIB/MX4CAAAAAAAAAACAKqasLBetBw5P0u7etkk8fP7BSdoAAAD/zvgJAAAAAAAAAAAAqpAJ85fEN+8dn6T9j8u6xT67NEzSBgAA+CrGTwAAAAAAAAAAAFBFnHDXK/H2h8uStOcO6RtFRUVJ2gAAABtj/AQAAAAAAAAAAAAF7vNV62L/QSOTtK87vkOce3irJG0AAIBNMX4CAAAAAAAAAACAAnbfS3Ni6LMzkrTfvq5XNKhTM0kbAABgcxg/AQAAAAAAAAAAQAHK5XLRasDwJO1DW+8Yf7nokCRtAACALWH8BAAAAAAAAAAAAAVm4j8/j2/cMy5J+++XHh777tooSRsAAGBLGT8BAAAAAAAAAABAAfnGPa/GxH8uTdKeO6RvFBUVJWkDAABsDeMnAAAAAAAAAAAAKADLVq+Pzjc8n6R9Vb+944LurZO0AQAAtoXxEwAAAAAAAAAAAFRyD459P24c9m6S9pRre0XD7WomaQMAAGwr4ycAAAAAAAAAAACopHK5XLQaMDxJu0vLHeLxiw9L0gYAAMiK8RMAAAAAAAAAAABUQpM/WBpfv/vVJO0nv3dY7L/7DknaAAAAWTJ+AgAAAAAAAAAAgErm1PvGxxvzliRpzx3SN4qKipK0AQAAsmb8BAAAAAAAAAAAAJXEsi/WR+frn0/SHti3fVx0xJ5J2gAAAKkYPwEAAAAAAAAAAEAl8LtX5sYN/5iepD35mmOjUd1aSdoAAAApGT8BAAAAAAAAAABAHuVyuWg1YHiS9n67NYqnvn94kjYAAEBFMH4CAAAAAAAAAACAPJn64bI4/q5XkrT/eslhceAeOyRpAwAAVBTjJwAAAAAAAAAAAMiDMx98LV59b3GS9twhfaOoqChJGwAAoCIZPwEAAAAAAAAAAEAFWrFmfXS67vkk7ct7t49LjtozSRsAACAfjJ8AAAAAAAAAAACggvxx/Ly45ulpSdqTrj42dqhXK0kbAAAgX4yfAAAAAAAAAAAAILFcLhetBgxP0t5nlwbxj8u6J2kDAADkm/ETAAAAAAAAAAAAJPTOgmXxtTtfSdJ+/OJDo0vLxknaAAAAlYHxEwAAAAAAAAAAACRy9u/eiJdnLUrSfn9w3yguLkrSBgAAqCyMnwAAAAAAAAAAACBjK9duiH2uHZGk/dNe7eLSHm2TtAEAACob4ycAAAAAAAAAAADI0J9enx9XPvlOkvaEq3rGjtvXTtIGAACojIyfAAAAAAAAAAAAIAO5XC5aDRiepN2+ef14rv8RSdoAAACVmfETAAAAAAAAAAAAbKPpHy2PvneMTdJ+5KJD4pDWOyZpAwAAVHbGTwAAAAAAAAAAALANvvOHN2PMjE+TtN8f3DeKi4uStAEAAAqB8RMAAAAAAAAAAABshVVrN0THa0ckaffv2Tb692yXpA0AAFBIjJ8AAAAAAAAAAABgC/3ljX/GgL9NTdJ+66qe0WT72knaAAAAhcb4CQAAAAAAAAAAALZAyyuGJenu2bRejP7JUUnaAAAAhcr4CQAAAAAAAAAAADbDzI9XxHG/fjlJ+88XHhyH7dkkSRsAAKCQGT8BAAAAAAAAAADAJnz34bdixLRPkrTnDO4bJcVFSdoAAACFzvgJAAAAAAAAAAAANmL1ug3R4ZoRSdqX9WgTP+m1V5I2AABAVWH8BAAAAAAAAAAAAF/hsbc+iJ8/8XaS9htXHhPN6tdJ0gYAAKhKjJ8AAAAAAAAAAADg37S8Ylia7o5148WfHZ2kDQAAUBUZPwEAAAAAAAAAAMD/N/uTFXHsbS8naf/pgoPj8DZNkrQBAACqKuMnAAAAAAAAAAAAiIjv/2liDJu6MEl7zuC+UVJclKQNAABQlRk/AQAAAAAAAAAAUK19sa409r7muSTtS47aMy7v3T5JGwAAoDowfgIAAAAAAAAAAKDa+tvED+PHj01J0n594DGxU4M6SdoAAADVhfETAAAAAAAAAAAA1VLLK4Yl6e7SaLt49YoeSdoAAADVjfETAAAAAAAAAAAA1cp7n66Mnre+lKT90He6xpHtmiZpAwAAVEfGTwAAAAAAAAAAAFQbP/jLpPj7lI+StN+7qU/UKClO0gYAAKiujJ8AAAAAAAAAAACo8tasL432Vz+XpH3REa1jYN+9k7QBAACqO+MnAAAAAAAAAAAAqrSnJy+IHz4yOUn7tQHHRPOGdZK0AQAAMH4CAAAAAAAAAACgCmt5xbAk3Z0a1I7XB/ZM0gYAAOB/GD8BAAAAAAAAAABQ5by/aGX0+NVLSdq/P7dLHN2+WZI2AAAA/5fxEwAAAAAAAAAAAFXKjx+bHH+buCBJ+72b+kSNkuIkbQAAAP6T8RMAAAAAAAAAAABVwpr1pdH+6ueStM87vGVce3zHJG0AAAA2zvgJAAAAAAAAAACAgvfMlI/isr9MStIed0WP2LnRdknaAAAAlM/4CQAAAAAAAAAAgILWesCwKMtl321cr1ZMvPrY7MMAAABsNuMnAAAAAAAAAAAACtK8z1bFUbe8mKT923MOimP23ilJGwAAgM1n/AQAAAAAAAAAAEDB+dnjU+LxCR8mac++qU/ULClO0gYAAGDLGD8BAAAAAAAAAABQMNZuKI29rnouSfucQ/eI60/cJ0kbAACArWP8BAAAAAAAAAAAQEEYPnVhfO9PE5O0X7n86Nh1h7pJ2gAAAGw94ycAAAAAAAAAAAAqvXZXPRvrNpRl3q1fu0ZMvf64zLsAAABkw/gJAAAAAAAAAACASuuDJauj+80vJGnff9aBcVzH5knaAAAAZMP4CQAAAAAAAAAAgEppwN+mxl/e+GeS9qwb+0StGsVJ2gAAAGTH+AkAAAAAAAAAAIBKZd2Gsmh31bNJ2mcevHvcdFKnJG0AAACyZ/wEAAAAAAAAAABApfHcOx/Hxf81IUl77M+Pjt0a103SBgAAIA3jJwAAAAAAAAAAACqFfa4dESvXbsi8W6dmccwY1CfzLgAAAOkZPwEAAAAAAAAAAJBXHyxZHd1vfiFJ+94zD4g+nVokaQMAAJCe8RMAAAAAAAAAAAB5c/VT78TDr81P0p55Y++oXaMkSRsAAICKYfwEAAAAAAAAAABAhVtfWhZtr3w2Sfu0g3aLX5y8b5I2AAAAFcv4CQAAAAAAAAAAgAo1cvonceEf30rSfulnR8UeO9ZL0gYAAKDiGT8BAAAAAAAAAABQYfa74flYunp95t2S4qKYM7hv5l0AAADyy/gJAAAAAAAAAACA5BYs/SIOHzomSfuub+0fX9t35yRtAAAA8sv4CQAAAAAAAAAAgKSu+/u0+MO4eUnaM2/sHbVrlCRpAwAAkH/GTwAAAAAAAAAAACSxvrQs2l75bJL2yQfuGrec0jlJGwAAgMrD+AkAAAAAAAAAAIDMjZnxSXznD28lab/w06OiVZN6SdoAAABULsZPAAAAAAAAAAAAZOqgG0fFZyvXJmnPG9ovSRcAAIDKyfgJAAAAAAAAAACATCxc9kUcOmRMkvbtp+8XJ+63S5I2AAAAlZfxEwAAAAAAAAAAANvspmHT4zdj5yZpzxjUO+rULEnSBgAAoHIzfgIAAAAAAAAAAGCrbSgtizZXPpuk/fX9do5fn75/kjYAAACFwfgJAAAAAAAAAACArfLSrEVxzu/eSNIe/ZMjY8+m2ydpAwAAUDiMnwAAAAAAAAAAANhihw0ZHR8tW5OkPW9ovyRdAAAACo/xEwAAAAAAAAAAAJvtk+Vr4uDBo5O0bzutc5y0/65J2gAAABQm4ycAAAAAAAAAAAA2y9BnZ8R9L81J0p4xqHfUqVmSpA0AAEDhMn4CAAAAAAAAAACgXKVludhz4PAk7X77toi7v3VAkjYAAACFz/gJAAAAAAAAAACAjRo7e1Gc9ds3krRH/fiIaNOsfpI2AAAAVYPxEwAAAAAAAAAAAF/piJtfiH8uWZ2kPW9ovyRdAAAAqhbjJwAAAAAAAAAAAP6PT1esia43jU7SvuWUznHygbsmaQMAAFD1GD8BAAAAAAAAAADw324ZMTPueuG9JO3pNxwXdWv52BoAAACbz58iAQAAAAAAAAAAiNKyXOw5cHiSdu+OzeO+sw5M0gYAAKBqM34CAAAAAAAAAACo5sa991l868HXk7Sf/9ER0W6n+knaAAAAVH3GTwAAAAAAAAAAANVYj1tejPc/W5WkPW9ovyRdAAAAqg/jJwAAAAAAAAAAgGpo0Yq10eWmUUnav/hmpzity+5J2gAAAFQvxk8AAAAAAAAAAADVzK0jZ8Udo2cnaU+7/rioV9tH0wAAAMiGP2ECAAAAAAAAAABUE2VluWg9cHiSds+9m8WD53RJ0gYAAKD6Mn4CAAAAAAAAAACoBl57f3Gc/sBrSdrP/rB77N2iQZI2AAAA1ZvxEwAAAAAAAAAAQBXX67aXYtYnK5O05w7pG0VFRUnaAAAAYPwEAAAAAAAAAABQRS1euTYOvHFUkvbgkzrFtw7ePUkbAAAA/sX4CQAAAAAAAAAAoAq6c/Ts+NXIWUna71x/XGxf28fPAAAASM+fPgEAAAAAAAAAAKqQsrJctB44PEn7qL2axh/O65qkDQAAAF/F+AkAAAAAAAAAAKCKeGPukjj1/vFJ2sN+0C067twwSRsAAAA2xvgJAAAAAAAAAACgCuh7+9iYvnB5kvbcIX2jqKgoSRsAAADKY/wEAAAAAAAAAABQwD5ftS72HzQySXvQiR3jrENbJmkDAADA5jB+AgAAAAAAAAAAKFD3vPhe3PzczCTtqdf1ivp1aiZpAwAAwOYyfgIAAAAAAAAAACgwuVwuWg0YnqTdvW2TePj8g5O0AQAAYEsZPwEAAAAAAAAAABSQCfOXxDfvHZ+k/Y/LusU+uzRM0gYAAICtYfwEAAAAAAAAAABQIE6865WY8uGyJO25Q/pGUVFRkjYAAABsLeMnAAAAAAAAAACASm7p6nWx3w0jk7SvO75DnHt4qyRtAAAA2FbGTwAAAAAAAAAAAJXY/S/NiSHPzkjSfvu6XtGgTs0kbQAAAMiC8RMAAAAAAAAAAEAllMvlotWA4UnaB7dqHI9+99AkbQAAAMiS8RMAAAAAAAAAAEAlM+mfn8dJ94xL0n76+4dH590aJWkDAABA1oyfAAAAAAAAAAAAKpFv3jsuJsz/PEl77pC+UVRUlKQNAAAAKRg/AQAAAAAAAAAAVALLVq+Pzjc8n6R9Vb+944LurZO0AQAAICXjJwAAAAAAAAAAgDx7cOz7ceOwd5O0p1zbKxpuVzNJGwAAAFIzfgIAAAAAAAAAAMiTXC4XrQYMT9I+aI8d4olLDkvSBgAAgIpi/AQAAAAAAAAAAJAHUz5YGife/WqS9pPfOyz2332HJG0AAACoSMZPAAAAAAAAAAAAFey0+8fH63OXJGnPHdI3ioqKkrQBAACgohk/AQAAAAAAAAAAVJDla9bHvtc9n6Q9oE/7+O6ReyZpAwAAQL4YPwEAAAAAAAAAAFSA3786N65/ZnqS9uRrjo1GdWslaQMAAEA+GT8BAAAAAAAAAAAklMvlotWA4UnanXdrFE9///AkbQAAAKgMjJ8AAAAAAAAAAAASeWfBsvjana8kaf/1ksPiwD12SNIGAACAysL4CQAAAAAAAAAAIIFvP/h6vPLeZ0nac4f0jaKioiRtAAAAqEyMnwAAAAAAAAAAADK0Ys366HTd80naP++9V3zvqDZJ2gAAAFAZGT8BAAAAAAAAAABk5OHx8+Lqp6claU+6+tjYoV6tJG0AAACorIyfAAAAAAAAAAAAtlEul4tWA4YnaXfcuUEM+0H3JG0AAACo7IyfAAAAAAAAAAAAtsG0j5ZFvzteSdJ+/OJDo0vLxknaAAAAUAiMnwAAAAAAAAAAALbSub9/I16cuShJ+/3BfaO4uChJGwAAAAqF8RMAAAAAAAAAAMAWWrl2Q+xz7Ygk7Z/2aheX9mibpA0AAACFxvgJAAAAAAAAAABgC/zp9flx5ZPvJGlPuKpn7Lh97SRtAAAAKETGTwAAAAAAAAAAAJshl8tFqwHDk7TbN68fz/U/IkkbAAAACpnxEwAAAAAAAAAAwCa8u3B59Ll9bJL2IxcdEoe03jFJGwAAAAqd8RMAAAAAAAAAAEA5LnjozRj17qdJ2u8P7hvFxUVJ2gAAAFAVGD8BAAAAAAAAAAB8hVVrN0THa0ckaf/wmLbxo2PbJWkDAABAVWL8BAAAAAAAAAAA8G8effOfcflfpyZpv3llz2hav3aSNgAAAFQ1xk8AAAAAAAAAAAD/S8srhiXptm5aL8b85KgkbQAAAKiqjJ8AAAAAAAAAAAAiYubHK+K4X7+cpP3nCw6Ow9o0SdIGAACAqsz4CQAAAAAAAAAAqPa++/BbMWLaJ0nacwb3jZLioiRtAAAAqOqMnwAAAAAAAAAAgGpr9boN0eGaEUnal/VoEz/ptVeSNgAAAFQXxk8AAAAAAAAAAEC19PhbH8TPnng7SfuNK4+JZvXrJGkDAABAdWL8BAAAAAAAAAAAVDstrxiWpLt747rx8s+PTtIGAACA6sj4CQAAAAAAAAAAqDbe+3RF9Lz15STth8/vGt3bNk3SBgAAgOrK+AkAAAAAAAAAAKgWvv/niTHs7YVJ2nMG942S4qIkbQAAAKjOjJ8AAAAAAAAAAIAqbc360mh/9XNJ2pcctWdc3rt9kjYAAABg/AQAAAAAAAAAAFRhT076MH706JQk7dcHHhM7NaiTpA0AAAB8yfgJAAAAAAAAAACoklpeMSxJd5dG28WrV/RI0gYAAAD+L+MnAAAAAAAAAACgSpmzaGUc86uXkrQf+k7XOLJd0yRtAAAA4D8ZPwEAAAAAAAAAAFVG/0cmxVOTP0rSfu+mPlGjpDhJGwAAAPhqxk8AAAAAAAAAAEDBW7O+NNpf/VyS9oXdW8WV/TokaQMAAADlM34CAAAAAAAAAAAK2tOTF8QPH5mcpD1+QI9o0XC7JG0AAABg04yfAAAAAAAAAACAgtXyimFJuk22rx1vXdUzSRsAAADYfMZPAAAAAAAAAABAwZn72ao4+pYXk7R/d+5B0aP9TknaAAAAwJYxfgIAAAAAAAAAAArKTx6bEn+d+GGS9ns39YkaJcVJ2gAAAMCWM34CAAAAAAAAAAAKwpr1pdH+6ueStM87vGVce3zHJG0AAABg6xk/AQAAAAAAAAAAld4/3v4oLv3zpCTtcVf0iJ0bbZekDQAAAGwb4ycAAAAAAAAAAKBS23Pg8Cgty2XebVS3Zky+plfmXQAAACA7xk8AAAAAAAAAAEClNH/xqjjyly8maT949kHRs8NOSdoAAABAdoyfAAAAAAAAAACASufyJ96OR9/6IEl79k19omZJcZI2AAAAkC3jJwAAAAAAAAAAoNJYu6E09rrquSTtsw/dI244cZ8kbQAAACAN4ycAAAAAAAAAAKBSeHbqwrjkTxOTtF+5/OjYdYe6SdoAAABAOsZPAAAAAAAAAABA3u111bOxdkNZ5t36tWvE1OuPy7wLAAAAVAzjJwAAAAAAAAAAIG8+WLI6ut/8QpL2/WcdGMd1bJ6kDQAAAFQM4ycAAAAAAAAAACAvBj45Nf78+j+TtGfd2Cdq1ShO0gYAAAAqjvETAAAAAAAAAABQodZtKIt2Vz2bpP2tg3ePwSd1StIGAAAAKp7xEwAAAAAAAAAAUGGen/ZxXPTwhCTtsT8/OnZrXDdJGwAAAMgP4ycAAAAAAAAAAKBCdLpuRKxYsyHzbu0axTHzxj6ZdwEAAID8M34CAAAAAAAAAACS+vDz1dHtFy8kad975gHRp1OLJG0AAAAg/4yfAAAAAAAAAACAZK59+p14aPz8JO2ZN/aO2jVKkrQBAACAysH4CQAAAAAAAAAAyNz60rJoe+WzSdqnHrRr3Hxy5yRtAAAAoHIxfgIAAAAAAAAAADI1avonccEf30rSfulnR8UeO9ZL0gYAAAAqH+MnAAAAAAAAAAAgM/vf8Hx8vnp95t2S4qKYM7hv5l0AAACgcjN+AgAAAAAAAAAAttlHS7+Iw4aOSdK+61v7x9f23TlJGwAAAKjcjJ8AAAAAAAAAAIBtcsMz0+N3r85N0p4xqHfUqVmSpA0AAABUfsZPAAAAAAAAAADAVtlQWhZtrnw2SfsbB+wSt566X5I2AAAAUDiMnwAAAAAAAAAAgC32woxP47w/vJmm/dOjolWTeknaAAAAQGExfgIAAAAAAAAAALZIl5tGxaIVa5O05w3tl6QLAAAAFCbjJwAAAAAAAAAAYLMsXPZFHDpkTJL27afvFyfut0uSNgAAAFC4jJ8AAAAAAAAAAIBNumnY9PjN2LlJ2jMG9Y46NUuStAEAAIDCZvwEAAAAAAAAAABs1IbSsmhz5bNJ2ifut3Pcfvr+SdoAAABA1WD8BAAAAAAAAAAAfKWXZi2Kc373RpL26J8cGXs23T5JGwAAAKg6jJ8AAAAAAAAAAID/cPjQMbFg6RdJ2vOG9kvSBQAAAKoe4ycAAAAAAAAAAOC/fbJ8TRw8eHSS9q2ndo5vHLBrkjYAAABQNRk/AQAAAAAAAAAAERHxi+dmxL0vzknSfveG3rFdrZIkbQAAAKDqMn4CAAAAAAAAAIBqrrQsF3sOHJ6k3W/fFnH3tw5I0gYAAACqPuMnAAAAAAAAAACoxl6Z/Vl8+7evJ2mP+vER0aZZ/SRtAAAAoHowfgIAAAAAAAAAgGrqyF++EPMXr07Snje0X5IuAAAAUL0YPwEAAAAAAAAAQDXz6Yo10fWm0Unavzx53zjloN2StAEAAIDqx/gJAAAAAAAAAACqkVufnxl3jHkvSXv6DcdF3Vo+kgQAAABkx79pAAAAAAAAAACAaqC0LBd7DhyepH1cx53i/rMOStIGAAAAqjfjJwAAAAAAAAAAqOLGzfksvvWb15O0R/Q/IvZqXj9JGwAAAMD4CQAAAAAAAAAAqrBjfvVizFm0Kkl73tB+SboAAAAA/2L8BAAAAAAAAAAAVdBnK9fGQTeOStIe+o1OcXrX3ZO0AQAAAP434ycAAAAAAAAAAKhibhs5K24fPTtJe9r1x0W92j52BAAAAFQM/xYCAAAAAAAAAACqiLKyXLQeODxJu+fezeLBc7okaQMAAABsjPETAAAAAAAAAABUAa+/vzhOe+C1JO1nf9g99m7RIEkbAAAAoDzGTwAAAAAAAAAAUOB6//rlmPHxiiTtuUP6RlFRUZI2AAAAwKYYPwEAAAAAAAAAQIFavHJtHHjjqCTtm07aJ848eI8kbQAAAIDNZfwEAAAAAAAAAAAF6M7Rs+NXI2clab9z/XGxfW0fLQIAAADyz7+hAAAAAAAAAACAAlJWlovWA4cnaR/Zrmk89J2uSdoAAAAAW8P4CQAAAAAAAAAACsSb85bEKfeNT9Ie9oNu0XHnhknaAAAAAFvL+AkAAAAAAAAAAApAvzvGxrSPlidpzx3SN4qKipK0AQAAALaF8RMAAAAAAAAAAFRin69aF/sPGpmkPejEjnHWoS2TtAEAAACyYPwEAAAAAAAAAACV1D0vvhc3PzczSXvqdb2ifp2aSdoAAAAAWTF+AgAAAAAAAACASiaXy0WrAcOTtA9vs2P86YJDkrQBAAAAsmb8BAAAAAAAAAAAlciE+Z/HN+8dl6T9zKXdotOuDZO0AQAAAFIwfgIAAAAAAAAAgEri63e/GpM/WJqkPXdI3ygqKkrSBgAAAEjF+AkAAAAAAAAAAPJs6ep1sd8NI5O0rz2+Q5x3eKskbQAAAIDUjJ8AAID/x96dh2lZF+oDv2cGBNwgBde0AQXUBDdcUCklVyizUrNz6pwWW7QsWw/umhun3zmdMjMtW9Q6lVZaHdBwwV0TURFzwW1cwA0UF5ARZub3x6Rpwsgy33lm+Xyu673ozPvM/dyPefpjhvv9AgAAAAAAFfrxdQ/l9Mn3Fcm+66R9snbf3kWyAQAAADqC8RMAAAAAAAAAAFSgpaUlg4+eXCR758Hr5LefH10kGwAAAKAjGT8BAAAAAAAAAEAHu+Ox5/Ohs28qkv3HL+6WbTYZUCQbAAAAoKMZPwEAAAAAAAAAQAc6+JybMq3h+SLZj5wxLjU1NUWyAQAAAKpg/AQAAAAAAAAAAB3ghVcWZ5uTpxTJPm78ljlszJAi2QAAAABVMn4CAAAAAAAAAIDCfnrDIznl/+4pkj3jhH3Sf/XeRbIBAAAAqmb8BAAAAAAAAAAAhbS0tGTw0ZOLZG+/6YD84YjdimQDAAAAdBbGTwAAAAAAAAAAUMCMx+fngz+8sUj2H47YNdtv+o4i2QAAAACdifETAAAAAAAAAAC0s0N/fHNuefi5ItmPnDEuNTU1RbIBAAAAOhvjJwAAAAAAAAAAaCcvLlqckSdNKZJ99P5b5PPv3axINgAAAEBnZfwEAAAAAAAAAADt4PybGnLin/5WJPvOE/bOgNVXK5INAAAA0JkZPwEAAAAAAAAAwCpoaWnJ4KMnF8ne5p3988cv7V4kGwAAAKArMH4CAAAAAAAAAICVdPfsF/L+H9xQJPv3h4/ODu9ap0g2AAAAQFdh/AQAAAAAAAAAACvhEz/9a65/YG6R7IdPH5fa2poi2QAAAABdifETAAAAAAAAAACsgJcWLc6Ik6YUyf7mvsPzxT03L5INAAAA0BUZPwEAAAAAAAAAwHK68JZHc/yldxfJvv34vbPOGqsVyQYAAADoqoyfAAAAAAAAAADgbbS0tGTw0ZOLZL97o7Uz6ctjimQDAAAAdHXGTwAAAAAAAAAA0IZ75ryYcWdeXyT74i+Mzo716xTJBgAAAOgOjJ8AAAAAAAAAAGAZPvXzWzP1/meLZD98+rjU1tYUyQYAAADoLoyfAAAAAAAAAADgnyxoXJJ3n/iXItlf23tYvvy+oUWyAQAAALob4ycAAAAAAAAAAHiDX9/6WI7+w8wi2dOP2yvrrtmnSDYAAABAd2T8BAAAAAAAAAAASVpaWjL46MlFsoevv1b+8tX3FMkGAAAA6M6MnwAAAAAAAAAA6PHue+rF7Pe964tk/+Zzu2SXIesWyQYAAADo7oyfAAAAAAAAAADo0Q47/7Zcee/TRbIfPn1camtrimQDAAAA9ATGTwAAAAAAAAAA9EgLGpfk3Sf+pUj2l983NF/be1iRbAAAAICexPgJAAAAAAAAAIAe56Jpj+dbv7+rSPa0Y/fKoLX6FMkGAAAA6GmMnwAAAAAAAAAA6FHqJ0wqkjtk4Bq5+ht7FMkGAAAA6KmMnwAAAAAAAAAA6BFmPf1S9vmf64pk/+qwnbPb5gOLZAMAAAD0ZMZPAAAAAAAAAAB0e4f/cnouu/upItkPnT4udbU1RbIBAAAAejrjJwAAAAAAAAAAuq1XXm3KlidcXiT7i3tulm/uu0WRbAAAAABaGT9BO2hoaMhtt932+mv69OmZP39+m9/T0tLSMeXeoL6+Po8++miH3/c1P/nJT3LYYYdVdn8AAAAAAACAJElzUzJ3VjLnzuSZe5JF85MljUnTq0ndakmvPknfAcl6WyUbbZcMHJrU1lVcmpXxu+lP5BsXzyiSfesx78t6a/ctkg0AAADAPxg/wQp64okn3jJ0mjt3btW1AAAAAAAAAFiWlpak4Ybk/snJ7NuTp+5KFi9c/u/vvUaywYhk4+2T4eOS+t2TmppyfWkX9RMmFcndZJ1+uf5bY4tkAwAAAPBWxk/QhqeffjrTpk1709jp6aefrroWAAAAAAAAAMvjlfnJjN8kt/209aSnlbV4QfL4La2vW85OBg5LRn0m2ebQpN+A9mpLO3nwmZey13evK5J94Wd2ypihg4pkAwAAALB0xk/Qhn333TczZsyougYAAAAAAAAAK+K5h5MbvpfMvHjFTnhaXnNnJZf/R3LVycmIg5Pdj0rWGdL+92GFHfnrO/LnGXOKZD90+rjU1TrxCwAAAKCjGT8BAAAAAAAAAN1D05Lk5h8kU89ImhrL32/xwuT281tPl9rzmGTXI5PauvL35S0WLW7KFsdfXiT78+8dkqP337JINgAAAABvz/gJAAAAAAAAAOj6nr0/ufTwZPb0jr93U2Ny5YnJvX9ODjw7GTS84zv0YJfc8US++tsZRbL/esz7sv7afYtkAwAAALB8jJ+AJMmuu+6aT33qU0XvMWbMmKL5AAAAAAAAQA/U3Nx62tPVp3XMaU9tmX1bcs6YZOyxyegjk9raavv0APUTJhXJ3bB/39x89PuKZAMAAACwYoyfoJ3V19dn2LBhmTJlStVVVsjQoUNz2GGHVV0DAAAAAAAAYPk1LU4uPSKZeVHVTf6hqTG54oTkqbtbT4Gq6111o27p4Wdfztj/vrZI9i8+tWP2GL5ekWwAAAAAVpzxE6yCTTbZJKNGjcoOO+yQUaNGZdSoUVl33XXT0NCQwYMHV10PAAAAAAAAoPtavCi5+JPJrMuqbrJ0My9KGl9KDv5F0rtv1W26la/+9s5ccsfsItkPnrZ/etU5sQsAAACgMzF+guW00UYbvT5w2mGHHbLjjjtm0KBBVdcCAAAAAAAA6HmaFnfu4dNrZl2W/O5TySEXOAGqHSxa3JQtjr+8SPZnxwzOseO3KpINAAAAwKoxfoI2HHnkkVl//fUzatSobLDBBlXXAQAAAAAAAKC5Obn0iM4/fHrN/ZNb+37o3KTWiUIr608z5uTLv76jSPbNR4/Nhv37FckGAAAAYNUZP0EbPvOZz1RdAQAAAAAAAIA3uvkHycyLqm6xYmZelGwwItnty1U36ZLqJ0wqkjtwzT657bi9imQDAAAA0H58pBAAAAAAAAAA0DU8e39y9WlVt1g5V5/a2p/l1jB3QbHh088+OcrwCQAAAKCLcPITAAAAAAAAAND5NS1JLj08aWqsusnKaWpMLj0i+cyUpLau6jad3jcunpHfTX+iSPYDp+2f3nU+LxgAAACgq/CTHAAAAAAAAACg87v5rGT29KpbrJrZtyU3/aDqFp1a45Km1E+YVGT49Mld69MwcbzhEwAAAEAX4+QnAAAAAAAAAKBze+7hZOrpVbdoH1NPT7Y6IFlnSNVNOp1Jdz2ZL/7v7UWyb5wwNhsP6FckGwAAAICyjJ8AAAAAAAAAgM7thu8lTY1Vt2gfTY2tz3PAmVU36VSGHjs5i5ta2j23f7/emXHiPu2eCwAAAEDHcY43AAAAAAAAANB5vTI/mXlx1S3a18yLk0UvVN2iU3hs3sLUT5hUZPj0k38bZfgEAAAA0A04+QkAAAAAAAAA6Lxm/CZZvLDqFu1r8cLW59r581U3qdTRf7grv7718SLZD5y2f3rX+UxgAAAAgO7AT3kAAAAAAAAAgM6ppSWZdl7VLcqYdl7r8/VAry5pTv2ESUWGT/82+l1pmDje8AkAAACgG3HyE/AWTU1NeeSRR/LYY4/l2WefzSuvvJK6urqsvvrqWXvttfPOd74zm2yySdZcc82qqwIAAAAAAADdWcMNybwHqm5RxtxZyaM3JvW7V92kQ11+95P5wi9vL5J9/bf2zCbrrF4kGwAAAIDqGD8BSZLHHnssJ554Yq666qrccccdWbhw4dt+z5AhQ7LDDjtk7NixGTduXDbddNMOaAoAAAAAAAD0GPdPrrpBWfdN7lHjpy2PvzyvLG5q99w1VqvL3769X7vnAgAAANA5GD8BSZKpU6dm6tSpK/Q9Dz/8cB5++OFcfPHFSZIxY8bk85//fD760Y+mVy//8wIAAAAAAACsotllTgjqNOZ08+f7u8efW5gx31mx30cvr3M+vkP223qDItkAAAAAdA61VRcAuo/rr78+H//4x7Plllvmt7/9bdV1AAAAAAAAgK6suSl56q6qW5T15F2tz9mNHXvJzGLDp1mn7m/4BAAAANADGD8B7e7BBx/MoYcemg984AN56qmnqq4DAAAAAAAAdEVzZyWLF1bdoqzFC5K5D1TdoohXlzSnfsKk/Oqvj7V79sd22jQNE8dntV7+2gsAAABAT+CnQEAx//d//5cddtgh06dPr7oKAAAAAAAA0NXMubPqBh3jyTurbtDupvztqQw77rIi2dd/a8+c8eERRbIBAAAA6Jx6VV0A6N7mzJmT97znPZk0aVL22GOPqusstx/+8Ic5++yzi9/noYceKn4PAAAAAAAA6JKeuafqBh2jmz3nyJP+khcXLWn33NV61WbWqfu3ey4AAAAAnZ/xE5DNNtssO++8c0aMGJGtt946gwcPTv/+/dO/f//069cvzz//fObNm5d58+bltttuy7XXXpvrr78+c+fOXa78hQsX5gMf+ECuvvrq7LjjjoWfpn08++yzueee7vVLBgAAAAAAAOhSFs2vukHHeGV+1Q3axRPPL8zu/zm1SPbZ/7p9xo3YsEg2AAAAAJ2f8RP0UO95z3vywQ9+MOPHj8/w4cPbvHbQoEEZNGhQkmS33XbLV77ylTQ1NeXiiy/Od77zndxxxx1ve7+XX345H/nIR3L77bdn4MCB7fIMAAAAAAAAQDe2pLHqBh2jGzzniX+8O+ff/GiR7PtP3S99etUVyQYAAACga6itugDQcd7xjnfkK1/5Su67775ce+21+drXvva2w6dlqaury6GHHprbb789//u//5u11lrrbb/n8ccfz+c+97mVuh8AAAAAAADQwzS9WnWDjtHUdcdPi5uaUz9hUpHh0yGj3pmGieMNnwAAAABw8hP0JNOmTUuvXu3///Yf+9jHMmrUqBx00EG566672rz2kksuyWWXXZb999+/3XsAAAAAAAAA3UjdalU36Bh1fapusFKuuvfpfOb824pkX/ONPVI/cI0i2QAAAAB0PU5+gh6kxPDpNUOHDs21116bbbbZ5m2vPfbYY4v1AAAAAAAAALqJXl1zFLTCuuBz7nDKFUWGT7U1ScPE8YZPAAAAALyJk5+AdjNgwID86U9/yvbbb5958+Yt87o77rgjV111Vd73vvd1YLsVM2jQoGy11VbF7/PQQw+lsbGx+H0AAAAAAACgy+k7oOoGHaPfgKobLLc581/JrhOvLpL9g49tlw9ss1GRbAAAAAC6NuMnoF1tuumm+e53v5t///d/b/O6Cy64oFOPn774xS/mi1/8YvH7vPvd784999xT/D4AAAAAAADQ5axX/sMKO4Uu8pyn/N89+ekNjxTJvu+U/dK3d12RbAAAAAC6vtqqCwDdzyc+8YmMHDmyzWv++Mc/ZvHixR3UCAAAAAAAAOhyNtq26gYdY8Ntq27QpiVNzamfMKnI8OnD22+chonjDZ8AAAAAaJPxE9DuampqctRRR7V5zQsvvJA77rijYwoBAAAAAAAAXc/AYUnv1atuUVbvNZKBQ6tusUxT738mmx97WZHsq7/+3nz3kG2LZAMAAADQvRg/AUV86EMfSu/evdu85uabb+6gNgAAAAAAAECXU1uXbDCy6hZlbTiy9Tk7oV1Ovyqf+vm0ItkNE8dnyKA1i2QDAAAA0P0YPwFFDBgwINtuu22b19x3330dUwYAAAAAAADomjbevuoGZW3U+Z7vqRcWpX7CpDz14qJ2z/7+odumYeL4ds8FAAAAoHszfgKK2X77tn9Q39DQ0DFFAAAAAAAAgK5p+LiqG5S1Red6vjMm35tdzriqSPZ9p+yXD267cZFsAAAAALq3XlUXALqv+vr6Nt9/5plnOqYIAAAAAAAA0DXV756sOzSZ90DVTdrfwGHJu3arukWSZElTczY/9rIi2Qdss1HO/Nh2RbIBAAAA6Bmc/AQU079//zbfX7hwYQc1AQAAAAAAALqkmppkx8OqblHGjoe1Pl/Frp31bLHh05Vfe6/hEwAAAACrzMlPQDGrrbZam+8vXry4g5oAAAAAAAAAXdY2hyZXnZws7kYfrth79dbnqthuE6/O7PmvFMlumDi+SC4AAAAAPY+Tn4BiXnml7R+S9+vXr4OaAAAAAAAAAF1WvwHJiIOrbtG+Rhyc9O1f2e2feXFR6idMKjJ8+u4h2xg+AQAAANCunPwEFPPUU0+1+f6aa67ZQU0AAAAAAACALm33o5IZv0maGqtusurq+rQ+T0W+c/l9Ofuah4pk3/vt/dJvtboi2QAAAAD0XMZPQDEPPvhgm+9vvPHGHdQEAAAAAAAA6NLWGZLseUxy5YlVN1l1ex7T+jwdrKm5JZsdM7lI9vgRG+aH/7p9kWwAAAAAMH4CivnrX//a5vuDBw/uoCYAAAAAAABAlzf6S8m9f0pmT6+6ycrbeFSy65EdftsbHpibj/+07d/frqwrvvqeDF1/rSLZAAAAAJAYPwGF3HPPPWloaGjzmpEjR3ZMGQAAAAAAAKDrq+uVHPij5JwxSVNj1W1WXF2f5MCzk9q6Dr3te//f1Dw6b2GR7IaJ44vkAgAAAMAb1VZdAOieLrjggre9Ztddd+2AJgAAAAAAAEC3MWh4MvbYqlusnLHHtfbvIM++1Jj6CZOKDJ++c9BIwycAAAAAOoyTn4B29/zzz+fcc89t85rNNtssm222WQc1AgAAAAAAALqN0UcmT92dzLyo6ibLb8Qhyegvddjtvjvl/px59YNFsu/59r5ZfTV/3QQAAACAjuOnUUC7O/roozN//vw2rznkkEM6pgwAAAAAAADQvdTWJgeenTS+lMy6rOo2b2/4uNa+tbXFb9Xc3JIhx0wukr3vu9fPuZ8YVSQbAAAAANpS/idrQI/yu9/97m1Pfaqrq8tnPvOZDmoEAAAAAAAAdDt1vZODf5EM27/qJm0bPi456OetfQu7+aF5xYZPfznqPYZPAAAAAFTG+Am6uXvuuSfPP/98h9zriiuuyCc+8Ym3ve7ggw/OZptt1gGNAAAAAAAAgG6rd9/koxcmIw6pusnSjTgkOeSC1p6F7f3da/Oxn9xSJLth4vgM32CtItkAAAAAsDyMn6CbmzJlSoYMGZJTTjkl8+bNK3KPlpaWTJw4MePGjcuiRYvavLZfv345/fTTi/QAAAAAAAAAepi63smHzk32/nZS16fqNq3q+iR7n9Laq/CJT3Nfbkz9hEl54JmX2z174odHpGHi+HbPBQAAAIAVZfwEPcD8+fNzwgknZNNNN81nP/vZ3Hjjje2Wfeedd2b//ffP0UcfnSVLlrzt9SeddFIGDx7cbvcHAAAAAAAAerja2mS3ryRfuD7ZeIdqu2w8qrXHbl9u7VXQ9698IKNOvbJI9t9O3jeH7rRpkWwAAAAAWFG9qi4And11112XWbNmrdD3LM8JS+edd94Kd3nve9+boUOHrvD3vWbhwoU577zzct5552WTTTbJ+PHjs/fee2fXXXfNBhtssNw5zz//fK655pr86Ec/yhVXXLHc33fAAQfkm9/85spUBwAAAAAAAGjboOHJp6ckN5+VTD09aWrsuHvX9UnGHpuM/lJSW1f0Vs3NLRlyzOQi2WO3WC8/++SORbIBAAAAYGUZP8Hb+NnPfpbzzz+/3XM/+9nPrvD3/PznP1+l8dMbPf744znnnHNyzjnnJEk23HDDbLHFFhkyZEg22GCDrLPOOunbt2/q6ury/PPP57nnnsvcuXNz22235e67705LS8sK3W/06NH55S9/mZqamnbpDwAAAAAAAPAWdb2S3Y9KtjogueF7ycyLk8ULy92v9+rJiINb77nOkHL3+bu/PjwvH/3xLUWyJ395TLbaaO0i2QAAAACwKoyfgCTJk08+mSeffDJTp05t9+w99tgjf/rTn7LWWmu1ezYAAAAAAADAW6wzJDngzGSfU5IZv0mmnZfMndV++QOHJTselmxzaNK3f/vltmG/712X+556qUj2I2eM80GWAAAAAHRaxk9AUV/+8pfz3//93+nVy//cAAAAAAAAAB2sb/9k588nO30uefTG5L7JyZzbkydnrNiJUL3XSDYcmWy0fbLFuORduyUdNBZ6bsGr2f6UK4pkn3rg1vn4Lu8qkg0AAAAA7cUaAShi2LBhOeecc7LnnntWXQUAAAAAAADo6WpqkvrdW19J0tyUzH0gefLO5Jl7klfmJ0sak6bGpK5P0qtP0m9Ast5WyYbbJgOHJrV1HV77h1MfzP/7y/1Fsu8+ed+s2cdfGwEAAACg8/NTLOjmtthii2y11Va55557OuR+Q4cOzYQJE/KJT3wivXv37pB7AgAAAAAAAKyQ2rpkvS1aX51Qc3NLhhwzuUj2e4YNygWf3qlINgAAAACUYPwE3dx+++2X/fbbL88880ymTp2aa6+9NtOmTcvdd9+dRYsWtcs9Ntlkk+y33375+Mc/njFjxqSmpqZdcgEAAAAAAKBLa25K5s5K5tzZerrQovl/P13o1aRutdbThfoOaD1daKPtKjtdiM7ltobnctA5NxfJ/r8jd8/WG/cvkg0AAAAApdS0tLS0VF0C6HhNTU259957M2PGjDz88MN5/PHH8/jjj+eJJ57ICy+8kIULF2bhwoVpbGxMr1690rdv36y11lrZcMMNs/HGG2f48OEZMWJEdtxxxwwfPrzqx+my3v3udy/1VK6tttoqf/vb3ypoBAAAAAAAwEpraUkabkjun5zMvj156q5k8cLl//7eayQbjEg23j4ZPi6p3z3xwYM9ygd+cENmzn6hSPYjZ4zzQZYAAAAAXVxP/fvnTn6CHqquri5bb711tt5666qrAAAAAAAAQNf2yvxkxm+S237aetLTylq8IHn8ltbXLWcnA4cloz6TbHNo0m9Ae7WlE3p+wavZ7pQrimR/+4Pvzr+Nri+SDQAAAAAdwfgJAAAAAAAAAFbGcw8nN3wvmXnxip3wtLzmzkou/4/kqpOTEQcnux+VrDOk/e9Dpc6+5sF85/L7i2TPPGmfrNW3d5FsAAAAAOgoxk8AAAAAAAAAsCKaliQ3/yCZekbS1Fj+fosXJref33q61J7HJLsemdTWlb8vRbW0tGTw0ZOLZO+2+br51WG7FMkGAAAAgI5m/AQAAAAAAAAAy+vZ+5NLD09mT+/4ezc1JleemNz75+TAs5NBwzu+A+1i+qPP5yM/uqlI9p+/tHtGvLN/kWwAAAAAqILxEwAAAAAAAAC8nebm1tOerj6tY057asvs25JzxiRjj01GH5nU1lbbhxXyobNvzB2PzS+S/cgZ41JTU1MkGwAAAACqYvwEAAAAAAAAAG1pWpxcekQy86Kqm/xDU2NyxQnJU3e3ngJV17vqRryNFxYuzjbfnlIk+4T3b5VP7z64SDYAAAAAVM34CQAAAAAAAACWZfGi5OJPJrMuq7rJ0s28KGl8KTn4F0nvvlW3YRl+ct3DOW3yvUWyZ5y4T/r3M34DAAAAoPsyfgIAAAAAAACApWla3LmHT6+ZdVnyu08lh1zgBKhOpqWlJYOPnlwke6fB6+Siz48ukg0AAAAAnUlt1QUAAAAAAAAAoNNpbk4uPaLzD59ec//k1r7NzVU34e/ufHx+seHTH7+4m+ETAAAAAD2Gk58AAAAAAAAA4J/d/INk5kVVt1gxMy9KNhiR7Pblqpv0eAefc1OmNTxfJPuRM8alpqamSDYAAAAAdEbGTwAAAAAAAADwRs/en1x9WtUtVs7VpybD9k0GDa+6SY/0wiuLs83JU4pkHzd+yxw2ZkiRbAAAAADozGqrLgAAAAAAAAAAnUbTkuTSw5OmxqqbrJymxuTSI5Lmpqqb9Dg/u+GRYsOnGSfsY/gEAAAAQI/l5CcAAAAAAAAAeM3NZyWzp1fdYtXMvi256QfJ7kdV3aRHaGlpyeCjJxfJ3n7TAfnDEbsVyQYAAACArsL4CQAAAAAAAACS5LmHk6mnV92ifUw9PdnqgGQdpwWVNPOJF/KBs24okv2HI3bN9pu+o0g2AAAAAHQlxk8AAAAAAAAAkCQ3fC9paqy6Rftoamx9ngPOrLpJt/UvP7klNz00r0j2I2eMS01NTZFsAAAAAOhqaqsuAAAAAAAAAACVe2V+MvPiqlu0r5kXJ4teqLpFt/PiosWpnzCpyPBpwv5bpGHieMMnAAAAAHgDJz8BAAAAAAAAwIzfJIsXVt2ifS1e2PpcO3++6ibdxvk3NeTEP/2tSPYdx++dd6yxWpFsAAAAAOjKjJ8AAAAAAAAA6NlaWpJp51Xdooxp5yU7fS5xktAqaWlpyeCjJxfJHvnO/vnTl3Yvkg0AAAAA3YHxEwAAAAAAAAA9W8MNybwHqm5RxtxZyaM3JvXGNSvr7tkv5P0/uKFI9u++MDqj6tcpkg0AAAAA3YXxEwAAAAAAAAA92/1lTvTpNO6bbPy0kv7tZ7fmulnPFsl++PRxqa11IhcAAAAAvB3jJwAAAAAAAAB6ttm3V92grDnd/PkKeLlxSbY+8S9Fsr+57/B8cc/Ni2QDAAAAQHdk/AQAAAAAAABAz9XclDx1V9UtynryrtbnrK2rukmX8MtbHs1xl95dJPv24/fOOmusViQbAAAAALor4ycAAAAAAAAAeq65s5LFC6tuUdbiBcncB5L1tqi6SafW0tKSwUdPLpK95YZr57KvjCmSDQAAAADdnfETAAAAAAAAAD3XnDurbtAxnrzT+KkN98x5MePOvL5I9kWfH52dBq9TJBsAAAAAegLjJwAAAAAAAAB6rmfuqbpBx+gpz7kSPvXzWzP1/meLZD98+rjU1tYUyQYAAACAnsL4CQAAAAAAAICea9H8qht0jFfmV92g01nQuCTvPvEvRbK/tvewfPl9Q4tkAwAAAEBPY/wEAAAAAAAAQM+1pLHqBh2jpzzncvr1rY/l6D/MLJI9/bi9su6afYpkAwAAAEBPZPwEAAAAAAAAQM/V9GrVDTpGk/HTa+onTCqSO2z9NTPlq+8tkg0AAAAAPZnxEwAAAAAAAAA9V91qVTfoGHVOIrr/qZey7/euK5L968/uktGbrVskGwAAAAB6OuMnAAAAAAAAAHquXj1kFNRTnnMZPnfBbZlyz9NFsh8+fVxqa2uKZAMAAAAAxk8AAAAAAAAA9GR9B1TdoGP0G1B1g0osfHVJtjrhL0Wyv/y+ofna3sOKZAMAAAAA/2D8BAAAAAAAAEDPtd5WVTfoGD3lOd/gommP51u/v6tI9rRj98qgtXr2aVoAAAAA0FGMnwAAAAAAAADouTbatuoGHWPDbatu0KHqJ0wqkjt44BqZ+o09imQDAAAAAEtn/AQAAAAAAABAzzVwWNJ79WTxwqqblNN7jWTg0KpbdIhZT7+Uff7nuiLZvzps5+y2+cAi2QAAAADAshk/AQAAAAAAANBz1dYlG4xMHr+l6iblbDiy9Tm7ucN/OT2X3f1UkeyHTh+XutqaItkAAAAAQNuMnwAAAAAAAADo2TbevnuPnzbavuoGRb3yalO2POHyItlf3HOzfHPfLYpkAwAAAADLx/gJAAAAAAAAgJ5t+LjklrOrblHOFuOqblDM76c/ka9fPKNI9q3HvC/rrd23SDYAAAAAsPyMnwAAAAAAAADo2ep3T9Ydmsx7oOom7W/gsORdu1Xdooj6CZOK5L7zHf1yw3+MLZINAAAAAKy42qoLAAAAAAAAAEClamqSHQ+rukUZOx7W+nzdyIPPvFxs+HTBp3cyfAIAAACATsbJTwAAAAAAAACwzaHJVScnixdW3aT99F699bm6kSN/fUf+PGNOkewHT9s/vep8hiwAAAAAdDZ+agcAAAAAAAAA/QYkIw6uukX7GnFw0rd/1S3axaLFTamfMKnI8Onz7x2ShonjDZ8AAAAAoJNy8hMAAAAAAAAAJMnuRyUzfpM0NVbdZNXV9Wl9nm7gkjueyFd/O6NI9l+PeV/WX7tvkWwAAAAAoH0YPwEAAAAAAABAkqwzJNnzmOTKE6tusur2PKb1ebq4+gmTiuRusHbf3HLM+4pkAwAAAADty5ntAAAAAAAAAPCa0V9KNt6h6harZuNRya5HVt1ilTz87MvFhk+/+NSOhk8AAAAA0IU4+QkAAAAAAAAAXlPXKznwR8k5Y5KmxqrbrLi6PsmBZye1dVU3WWlf++2d+cMds4tkP3ja/ulV53NiAQAAAKAr8RM9AAAAAAAAAHijQcOTscdW3WLljD2utX8XtGhxU+onTCoyfDps98FpmDje8AkAAAAAuiAnPwEAAAAAAADAPxt9ZPLU3cnMi6pusvxGHJKM/lLVLVbKn2fMyZG/vqNI9s1Hj82G/fsVyQYAAAAAyjN+AgAAAAAAAIB/VlubHHh20vhSMuuyqtu8veHjWvvWdr2TjQYfPSktLe2fO3DN1XLbcXu3fzAAAAAA0KG63k89AQAAAAAAAKAj1PVODv5FMmz/qpu0bfi45KCft/btQhrmLkj9hDLDp599cpThEwAAAAB0E05+AgAAAAAAAIBl6d03+eiFyaVHJDMvqrrNW404pPXEpy42fPrGxTPyu+lPFMl+4LT907vOZ8ECAAAAQHdh/AQAAAAAAAAAbanrnXzo3GSDrZOrT0uaGqtulNT1ScYel4z+UlLbdYY+jUuaMvy4y4tkf3LX+px0wLuLZAMAAAAA1TF+AgAAAAAAAIC3U1ub7PaVZNh+yaWHJ7OnV9dl41Gtpz0NGl5dh5Uw6a4n88X/vb1I9o0TxmbjAf2KZAMAAAAA1TJ+AgAAAAAAAIDlNWh48ukpyc1nJVNP79hToOr6JGOP/ftpT3Udd992MOzYy/JqU3O75/bv1zszTtyn3XMBAAAAgM7D+AkAAAAAAAAAVkRdr2T3o5KtDkhu+F4y8+Jk8cJy9+u9ejLi4NZ7rjOk3H0KeGzewrzn/00tkv2TfxuVvbdav0g2AAAAANB5GD8BAAAAAAAAwMpYZ0hywJnJPqckM36TTDsvmTur/fIHDkt2PCzZ5tCkb//2y+0gR//hrvz61seLZM86df+s1qu2SDYAAAAA0LkYPwEAAAAAAADAqujbP9n588lOn0sevTG5b3Iy5/bkyRkrdiJU7zWSDUcmG22fbDEuedduSU1Nud6FvLqkOcOOu6xI9sd32TSnHjiiSDYAAAAA0DkZPwEAAAAAAABAe6ipSep3b30lSXNTMveB5Mk7k2fuSV6ZnyxpTJoak7o+Sa8+Sb8ByXpbJRtumwwcmtTWVde/HVx+95P5wi9vL5J9/bf2zCbrrF4kGwAAAADovIyfAAAAAAAAAKCE2rpkvS1aXz3AlsdfnlcWN7V77hqr1eVv396v3XMBAAAAgK7B+AkAAAAAAAAAWGmPP7cwY74ztUj2OR/fIfttvUGRbDqJ5qZk7qxkzp2tJ6Qtmv/3E9JeTepWaz0hre+A1hPSNtquW5yQBgAAAMCKMX4CAAAAAAAAAFbKcZfOzC9veaxI9qxT989qvWqLZFOhlpak4Ybk/snJ7NuTp+5KFi9c/u/vvUaywYhk4+2T4eOS+t2TmppyfQEAAAConPETAAAAAAAAALBCXl3SnGHHXVYk+2M7bZIzPjyySDYVemV+MuM3yW0/bT3paWUtXpA8fkvr65azk4HDklGfSbY5NOk3oL3aAgAAANCJGD8BAAAAAAAAAMttyt+eyucunF4k+7pv7plN1129SDYVee7h5IbvJTMvXrETnpbX3FnJ5f+RXHVyMuLgZPejknWGtP99AAAAAKiM8RMAAAAAAAAAsFxGnvSXvLhoSbvnrlZXm1mn7d/uuVSoaUly8w+SqWckTY3l77d4YXL7+a2nS+15TLLrkUltXfn7AgAAAFCc8RMAAAAAAAAA0KYnnl+Y3f9zapHsH/7L9hk/csMi2VTk2fuTSw9PZpc5IaxNTY3JlScm9/45OfDsZNDwju8AAAAAQLsyfgIAAAAAAAAAlunEP96d829+tEj2/afulz69nM7TbTQ3t572dPVpHXPaU1tm35acMyYZe2wy+siktrbaPgAAAACsNOMnAAAAAAAAAOAtFjc1Z+ixlxXJPmTUO/Odg7Ypkk1FmhYnlx6RzLyo6ib/0NSYXHFC8tTdradA1fWuuhEAAAAAK8H4CQAAAAAAAAB4k6vufTqfOf+2ItnXfGOP1A9co0g2FVm8KLn4k8msMmO5VTbzoqTxpeTgXyS9+1bdBgAAAIAVZPwEAAAAAAAAALxuh1OuyLwFr7Z7bk1N8sgZ49s9l4o1Le7cw6fXzLos+d2nkkMucAIUAAAAQBdTW3UBAAAAAAAAAKB6T77wSuonTCoyfDrzY9sZPnVHzc3JpUd0/uHTa+6f3Nq3ubnqJgAAAACsACc/AQAAAAAAAEAPd8r/3ZOf3vBIkez7TtkvfXvXFcmmYjf/IJl5UdUtVszMi5INRiS7fbnqJgAAAAAsJ+MnAAAAAAAAAOihljQ1Z/Njy5za8+HtNs53P7ptkWw6gWfvT64+reoWK+fqU5Nh+yaDhlfdBAAAAIDlUFt1AQAAAAAAAACg4029/5liw6erv/5ew6furGlJcunhSVNj1U1WTlNjcukRSXNT1U0AAAAAWA5OfgIAAAAAAACAHmaX06/KUy8uKpLdMHF8kVw6kZvPSmZPr7rFqpl9W3LTD5Ldj6q6CQAAAABvw8lPAAAAAAAAANBDPPXCotRPmFRk+PS9j25r+NQTPPdwMvX0qlu0j6mntz4PAAAAAJ2a8RMAAAAAAAAA9ABnTL43u5xxVZHs+07ZLwdut3GRbDqZG76XNDVW3aJ9NDW2Pg8AAAAAnZrxEwAAAAAAAAB0Y03NLamfMCnnXtf+J9x8YJuN0jBxfPr2rmv3bDqhV+YnMy+uukX7mnlxsuiFqlsAAAAA0IZeVRcAAAAAAAAAAMq4btaz+bef3Vok+8qvvTebr7dmkWw6qRm/SRYvrLpF+1q8sPW5dv581U0AAAAAWAbjJwAAAAAAAADohnabeHVmz3+lSHbDxPFFcunEWlqSaedV3aKMaeclO30uqampugkAAAAAS2H8BAAAAAAAAADdyDMvLspOp19VJPu/D94mH9nhnUWy6eQabkjmPVB1izLmzkoevTGp373qJgAAAAAshfETAAAAAAAAAHQT37n8vpx9zUNFsu/99n7pt1pdkWy6gPsnV92grPsmGz8BAAAAdFLGTwAAAAAAAADQxTU1t2SzY8qMU8aN2CBn/+sORbLpQmbfXnWDsuZ08+cDAAAA6MKMnwAAAAAAAACgC7vxwbn51/P+WiT7iq++J0PXX6tINl1Ic1Py1F1Vtyjrybtan7PW6WYAAAAAnY3xEwAAAAAAAAB0UXv8v6lpmLewSHbDxPFFcumC5s5KFpf596zTWLwgmftAst4WVTcBAAAA4J8YPwEAAAAAAABAF/PsS43Z8bQri2R/5yMjc8iOmxTJpouac2fVDTrGk3caPwEAAAB0QsZPAAAAAAAAANCFfHfK/Tnz6geLZN/z7X2z+mr+KgH/5Jl7qm7QMXrKcwIAAAB0MX5iCQAAAAAAAABdQHNzS4YcM7lI9j5brZ8f/9uoItl0A4vmV92gY7wyv+oGAAAAACyF8RMAAAAAAAAAdHI3PzQvH/vJLUWy/3LUezJ8g7WKZNNNLGmsukHH6CnPCQAAANDFGD8BAAAAAAAAQCe213evzYPPvFwku2Hi+CK5dDNNr1bdoGM0GT8BAAAAdEbGTwAAAAAAAADQCc19uTGjTr2ySPbED4/IoTttWiSbbqhutaobdIy6PlU3AAAAAGApjJ8AAAAAAAAAoJP5/pUP5H+unFUk+28n75s1+vjrAqyAXj1kFNRTnhMAAACgi/HTTAAAAAAAAADoJJqbWzLkmMlFssdusV5+9skdi2TTzfUdUHWDjtFvQNUNAAAAAFgK4ycAAAAAAAAA6AT++vC8fPTHtxTJnvzlMdlqo7WLZNMDrLdV1Q06Rk95TgAAAIAuxvgJAAAAAAAAACq2//evz71Pvlgk+5EzxqWmpqZINj3ERttW3aBjbLht1Q0AAAAAWArjJwAAAAAAAACoyHMLXs32p1xRJPvUA7fOx3d5V5FsepiBw5LeqyeLF1bdpJzeayQDh1bdAgAAAIClMH4CAAAAAAAAgAqcdfUD+a8ps4pk333yvlmzj78SQDuprUs2GJk8fkvVTcrZcGTrcwIAAADQ6fhJJwAAAAAAAAB0oObmlgw5ZnKR7DFDB+bCz+xcJJsebuPtu/f4aaPtq24AAAAAwDLUVl0AAAAAAAAAAHqKaQ3PFRs+/d+Ruxs+Uc7wcVU3KGuLbv58AAAAAF2Yk58AAAAAAAAAoAN84Ac3ZObsF4pkP3LGuNTU1BTJhiRJ/e7JukOTeQ9U3aT9DRyWvGu3qlsAAAAAsAxOfgIAAAAAAACAgp5f8GrqJ0wqMnw6+YB3p2HieMMnyqupSXY8rOoWZex4WOvzAQAAANApGT8BAAAAAAAAQCHnXPtQtjvliiLZd520T/591/oi2bBU2xya9F696hbtq/fqrc8FAAAAQKfVq+oCAAAAAAAAANDdtLS0ZPDRk4tk77rZuvnfz+5SJBva1G9AMuLg5Pbzq27SfkYcnPTtX3ULAAAAANpg/AQAAAAAAAAA7Wj6o8/nIz+6qUj2n760W0a+c0CRbFguux+VzPhN0tRYdZNVV9en9XkAAAAA6NSMnwAAAAAAAACgnXzo7Btzx2Pzi2Q/csa41NTUFMmG5bbOkGTPY5IrT6y6yarb85jW5wEAAACgU6utugAAAAAAAAAAdHXzF76a+gmTigyfTnj/VmmYON7wic5j9JeSjXeousWq2XhUsuuRVbcAAAAAYDk4+QkAAAAAAAAAVsFPrns4p02+t0j2jBP3Sf9+vYtkw0qr65Uc+KPknDFJU2PVbVZcXZ/kwLOT2rqqmwAAAACwHIyfAAAAAAAAAGAltLS0ZPDRk4tk71S/Ti76wugi2dAuBg1Pxh6bXHFC1U1W3NjjWvsDAAAA0CUYPwEAAAAAAADACrrz8fk58Ic3Fsm+9Iu7ZdtNBhTJhnY1+sjkqbuTmRdV3WT5jTgkGf2lqlsAAAAAsAKMnwAAAAAAAABgBRxyzs25teG5ItmPnDEuNTU1RbKh3dXWJgeenTS+lMy6rOo2b2/4uNa+tbVVNwEAAABgBfhpDgAAAAAAAAAshxdeWZz6CZOKDJ+OHbdlGiaON3yi66nrnRz8i2TY/lU3advwcclBP2/tCwAAAECXYvwEAAAAAAAAAG/jZzc8km1OnlIke8YJ++Sz7xlSJBs6RO++yUcvTEYcUnWTpRtxSHLIBa09AQAAAOhyelVdAAAAAAAAAAA6q5aWlgw+enKR7O03HZA/HLFbkWzocHW9kw+dm2ywdXL1aUlTY9WNkro+ydjjktFfSmp9PjAAAABAV2X8BAAAAAAAAABLcdcT83PAWTcWyf7DEbtm+03fUSQbKlNbm+z2lWTYfsmlhyezp1fXZeNRyYFnJ4OGV9cBAAAAgHZh/AQAAAAAAAAA/+RjP74lNz88r0j2I2eMS01NTZFs6BQGDU8+PSW5+axk6ukdewpUXZ9k7LF/P+2pruPuCwAAAEAxxk8AAAAAAAAA8HcvLlqckSdNKZL9H/ttkcP32KxINnQ6db2S3Y9KtjogueF7ycyLk8ULy92v9+rJiINb77nOkHL3AQAAAKDDGT8BAAAAAAAAQJLzb2rIiX/6W5HsO47fO+9YY7Ui2dCprTMkOeDMZJ9Tkhm/Saadl8yd1X75A4clOx6WbHNo0rd/++UCAAAA0GkYPwEAAAAAAADQo7W0tGTw0ZOLZI/YuH/+fOTuRbKhS+nbP9n588lOn0sevTG5b3Iy5/bkyRkrdiJU7zWSDUcmG22fbDEuedduSU1Nud4AAAAAVM74CQAAAAAAAIAe6+7ZL+T9P7ihSPbvvjA6o+rXKZINXVZNTVK/e+srSZqbkrkPJE/emTxzT/LK/GRJY9LUmNT1SXr1SfoNSNbbKtlw22Tg0KS2rrr+AAAAAHQ44ycAAAAAAAAAeqRP/PSvuf6BuUWyHz59XGprnUYDb6u2Lllvi9YXAAAAACyF8RMAAAAAAAAAPcpLixZnxElTimR/Y59h+dLYoUWyAQAAAAB6IuMnAAAAAAAAAHqMC295NMdfeneR7NuP3zvrrLFakWwAAAAAgJ7K+AkAAAAAAACAbq+lpSWDj55cJHvLDdfOZV8ZUyQbAAAAAKCnM34CAAAAAAAAoFu7Z86LGXfm9UWyf/u5XbLzkHWLZAMAAAAAYPwEAAAAAAAAQDf26V9My9X3PVMk++HTx6W2tqZINgAAAAAArYyfAAAAAAAAAOh2FjQuybtP/EuR7K/uNSxf2WtokWwAAAAAAN7M+AkAAAAAAACAbuXXtz6Wo/8ws0j2bcftlYFr9imSDQAAAADAWxk/AQAAAAAAANAttLS0ZPDRk4tkb77emrnya+8tkg0AAAAAwLIZPwEAAAAAAADQ5d3/1EvZ93vXFcn+9Wd3yejN1i2SDQAAAABA24yfAAAAAAAAAOjSPnvBbbninqeLZD98+rjU1tYUyQYAAAAA4O0ZPwEAAAAAAADQJS18dUm2OuEvRbK/PHbzfG2f4UWyAQAAAABYfsZPAAAAAAAAAHQ5F017PN/6/V1Fsqcdu1cGrdWnSDYAAAAAACvG+AkAAAAAAACALqV+wqQyueuunmu+uWeRbAAAAAAAVo7xEwAAAAAAAABdwgNPv5S9/+e6Itm/Omzn7Lb5wCLZAAAAAACsPOMnAAAAAAAAADq9I341PZNnPlUk+6HTx6WutqZINgAAAAAAq8b4CQAAAAAAAIBO65VXm7LlCZcXyT58j83yH/ttUSQbAAAAAID2YfwEAAAAAAAAQKf0++lP5OsXzyiSfesx78t6a/ctkg0AAAAAQPsxfgIAAAAAAACg06mfMKlI7sYD+uXGCWOLZAMAAAAA0P6MnwAAAAAAAADoNB585uXs9d1ri2Rf8Omd8p5hg4pkAwAAAABQhvETAAAAAAAAAJ3Ckb++I3+eMadI9oOn7Z9edbVFsgEAAAAAKMf4CQAAAAAAAIBKLVrclC2Ov7xI9ufeMyTHjNuySDYAAAAAAOUZPwEAAAAAAABQmUvvmJ2jfntnkexbjn5fNujft0g2AAAAAAAdw/gJAAAAAAAAgErUT5hUJHf9tfvkr8fsVSQbAAAAAICOZfwEAAAAAAAAQId6+NmXM/a/ry2S/fNP7Zg9h69XJBsAAAAAgI5n/AQAAAAAAABAh/nqb+/MJXfMLpL94Gn7p1ddbZFsAAAAAACqYfwEAAAAAAAAQHGLFjdli+MvL5L9md0H5/j3b1UkGwAAAACAahk/AQAAAAAAAFDUn2bMyZd/fUeR7JuPHpsN+/crkg0AAAAAQPWMnwAAAAAAAAAoZvDRk9LS0v65666xWqYfv3f7BwMAAAAA0KkYPwEAAAAAAADQ7hrmLsge/3VNkeyf/vuovG/L9YtkAwAAAADQuRg/AQAAAAAAANCuvnnxjFw8/Yki2Q+ctn9619UWyQYAAAAAoPMxfgIAAAAAAACgXTQuacrw4y4vkv3JXetz0gHvLpINAAAAAEDnZfwEAAAAAAAAwCqbPPPJHPGr24tk3zhhbDYe0K9INgAAAAAAnZvxEwAAAAAAAACrZNixl+XVpuZ2z127b6/cddK+7Z4LAAAAAEDXYfwEAAAAAAAAwEp5bN7CvOf/TS2S/eNP7JB93r1BkWwAAAAAALoO4ycAAAAAAAAAVtjRf7grv7718SLZs07dP6v1qi2SDQAAAABA12L8BAAAAAAAAMBye3VJc4Ydd1mR7I/vsmlOPXBEkWwAAAAAALom4ycAAAAAAAAAlsvldz+VL/xyepHs67+1ZzZZZ/Ui2QAAAAAAdF3GTwAAAAAAAAC8rXefcHkWvNrU7rn9etfl3lP2a/dcAAAAAAC6B+MnAAAAAAAAAJbp8ecWZsx3phbJ/tG/bp/9R2xYJBsAAAAAgO7B+AkAAAAAAACApTru0pn55S2PFcm+/9T90qdXXZFsAAAAAAC6D+MnAAAAAAAAAN7k1SXNGXbcZUWyD91xk0z8yMgi2QAAAAAAdD/GTwAAAAAAAAC8bsrfnsrnLpxeJPu6b+6ZTdddvUg2AAAAAADdk/ETAAAAAAAAAEmSkSf9JS8uWtLuub3ravLAaePaPRcAAAAAgO7P+AkAAAAAAACgh3vi+YXZ/T+nFsn+4b9sn/EjNyySDQAAAABA92f8BAAAAAAAANCDnfSnv+UXNzUUyb7/1P3Sp1ddkWwAAAAAAHoG4ycAAAAAAACAHmhxU3OGHntZkeyDdnhn/uvgbYpkAwAAAADQsxg/AQAAAAAAAPQwV9/3dD79i9uKZF/zjT1SP3CNItkAAAAAAPQ8xk8AAAAAAAAAPcgOp1yReQteLZLdMHF8kVwAAAAAAHou4ycAAAAAAACAHuDJF17J6DOuLpJ95se2ywHbbFQkGwAAAACAns34CQAAAAAAAKCbO/X/7sl5NzxSJPu+U/ZL3951RbIBAAAAAMD4CQAAAAAAAKCbWtLUnM2PvaxI9oe22zj/89Fti2QDAAAAAMBrjJ8AAAAAAAAAuqGp9z+TT/18WpHsq7/+3gwZtGaRbAAAAAAAeCPjJwAAAAAAAIBuZpfTr8pTLy4qkt0wcXyRXAAAAAAAWBrjJwAAAAAAAIBu4ukXF2Xn068qkv29j26bA7fbuEg2AAAAAAAsi/ETAAAAAAAAQDdwxmX35txrHy6Sfd8p+6Vv77oi2QAAAAAA0BbjJwAAAAAAAIAurKm5JZsdM7lI9vtHbpiz/mX7ItkAAAAAALA8jJ8AAAAAAAAAuqjrZj2bf/vZrUWyr/zae7L5emsVyQYAAAAAgOVl/LQMzz//fL75zW+mubl5mdeMHTs2H//4xzuw1bItWrQo3/rWt/Lyyy8v85pdd901hx12WAe2AgAAAAAAAErZ/T+vzhPPv1Iku2Hi+CK5AAAAAACwooyfluG4447Lz372s9TU1Cz1/ZEjR+bMM8/s4FbL1rdv34wbNy4HHHBAmpqalnrNr3/96+y5557ZbLPNOrgdAAAAAAAA0F6eeXFRdjr9qiLZ/3XwNjloh3cWyQYAAAAAgJVRW3WBzuiuu+7Kueeem5qamrS0tLzltf7662fy5MlZc801q676Jvvtt1/OPPPMtLS0JMlbejc2NuarX/1qxS0BAAAAAACAlfWdy+8rNny699v7GT4BAAAAANDpOPlpKU466aQ0NzenpqbmTSc/tbS0pLa2NhdccEE23HDDChsu2xe+8IVce+21+e1vf/uWU6taWloyadKk/PWvf83OO+9cUUMAAAAAAABgRTU1t2SzYyYXyd5/6w3yo4/vUCSbdtLclMydlcy5M3nmnmTR/GRJY9L0alK3WtKrT9J3QLLeVslG2yUDhya1dRWXBgAAAABoH8ZP/+Suu+7KH//4x9eHQy0tLa+fAFVTU5NvfOMb2WuvvSpu2bYf//jH+etf/5pHH300yT+e4TUnnXRSLrvssqrqAQAAAAAAACvgxgfn5l/P+2uR7ClffU+Grb9WkWxWQUtL0nBDcv/kZPbtyVN3JYsXLv/3914j2WBEsvH2yfBxSf3uyT99eCYAAAAAQFdh/PRPzjzzzLcMnl5TX1+fk08+ucJ2y2ettdbKmWeemQMOOGCpI64pU6bk3nvvzZZbbllxUwAAAAAAAKAte/7XNXlk7oIi2Q0TxxfJZRW8Mj+Z8Zvktp+2nvS0shYvSB6/pfV1y9nJwGHJqM8k2xya9BvQXm0BAAAAADpEbdUFOpMXX3wxv/nNb940eEr+MRz6/ve/nz59+lTUbsW8//3vz/vf//63DLhe86Mf/aiCVgAAAAAAAMDyePalxtRPmFRk+PSdj4w0fOpsnns4+dOXk+9umVz+H6s2fFqaubNac7+7Zet9nnu4ffMBAAAAAAoyfnqD3/3ud1m4cGGSvOX0p1122SXvf//7K264Yk4//fTXh09v/LOlpSW//OUvs2TJkirrAQAAAAAAAEvx3Sn3Z8fTriySfc+3980hO25SJJuV0LQkueF/kh/uktx+frJ4Ydn7LV7Yep8f7pLc8L2kuans/QAAAAAA2oHx0xv8/ve/X+Z7Rx99dAc2aR9bb73166c/JXn9zyR54YUXcsUVV1RVDQAAAAAAAPgnzc0tqZ8wKWde/WC7Z++91fppmDg+q6/Wq92zWUnP3p/8bJ/kypOSpsaOvXdTY3LliclP92ntAQAAAADQiRk//d2CBQty1VVXveWkpCTZfPPNu9ypT6/56le/usz3Lrnkkg5sAgAAAAAAACzLzQ/Ny5BjJhfJvvyoMfnJv40qks1KaG5Obvx+cs6YZPb0arvMvq21x43fb+0FAAAAANAJ+Vivv7vpppvy6quvpqamJi0tLW/681/+5V+qrrfS9thjj2yyySZ54okn3jTsamlpydVXX11xOwAAAAAAAGDv716bB555uUj2I2eMe9MHP1KxpsXJpUckMy+qusk/NDUmV5yQPHV3cuDZSV3vqhsBAAAAALyJk5/+7tprr13me115/JQkhx56aFpaWpLk9T+T5JFHHsns2bOrqgUAAAAAAAA92tyXG1M/YVKR4dPpHxqRhonjDZ86k8WLkt9+onMNn95o5kWt/RYvqroJAAAAAMCbGD/93fTp01//z2/8BcAmm2ySoUOHVlGp3ey9997LfG/atGkd2AQAAAAAAABIkjOveiCjTr2ySPbdJ++bf9l50yLZrKSmxcnFn0xmXVZ1k7bNuiz53ada+wIAAAAAdBLGT3939913v2n01NLSkpqamrz3ve+tsFX72HXXXdO7d+8kecsnu919991VVAIAAAAAAIAeqbm5JfUTJuW7V8xq9+w9hw9Kw8TxWbNPr3bPZhU0NyeXHtH5h0+vuX9ya9/m5qqbAAAAAAAkMX5KkixYsCCzZ89O0jp6eqMdd9yxikrtavXVV8+WW275lmdLknvvvbeCRgAAAAAAANDz3PrIcxlyzOQi2ZO/PCY//9RORbJZRTf/IJl5UdUtVszMi5Kbz6q6BQAAAABAEuOnJHl9+LQ0Q4cO7cAm5SzrOZ544okObgIAAAAAAAA9z/7fvz6HnHtzkexHzhiXrTZau0g2q+jZ+5OrT6u6xcq5+tTW/gAAAAAAFTN+SvLkk08u873NNtusA5uU88/PUVNTk5aWljafHQAAAAAAAFg1zy14NfUTJuXeJ19s9+xTDtw6DRPHp6ampt2zaQdNS5JLD0+aGqtusnKaGpNLj0iam6puAgAAAAD0cMZPSZ5//vllvjdgwICOK1LQO97xjqV+va1nBwAAAAAAAFbeD6c+mO1PuaJI9syT9skndnlXkWzayc1nJbOnV91i1cy+LbnpB1W3AAAAAAB6uF5VF+gMXnnllWW+t9Zaa3Vgk3LWXHPNpX69rWcHAAAAAAAAVlxzc0uGHDO5SPaYoQNz4Wd2LpJNO3ru4WTq6VW3aB9TT0+2OiBZZ0jVTQAAAACAHsrJT0kaGxuX+d5qq63WgU3KWdZztPXsAAAAAAAAwIqZ/uhzxYZP/3fk7oZPXcUN30uausnvYpsaW58HAAAAAKAiTn5K2wOnBQsWLPPUpK5k4cKFS/16r17+FQAAAAAAAID2cMBZN+SuJ14okv3IGeNSU1NTJJt29sr8ZObFVbdoXzMvTvY5Jenbv+omAAAAAEAP5OSnJKuvvvoy31vWaKirWbBgwVK/3tazAwAAAAAAAG/v+QWvpn7CpCLDp5M+sFUaJo43fOpKZvwmWdw9fs/8usULW58LAAAAAKACxk9pewA0e/bsDmxSzpw5c5b6deMnAAAAAAAAWHnnXPtQtjvliiLZd520Tz652+Ai2RTS0pJMO6/qFmVMO6/1+QAAAAAAOpjxU5KBAwcu871HHnmkA5uU88/P0fL3H0oPGjSoijoAAAAAAADQpbW0tKR+wqRMvOy+ds8ePWTdNEwcn7X79m73bApruCGZ90DVLcqYOyt59MaqWwAAAAAAPVCvqgt0BvX19ct879577+24IgXdc889qampedPXampq8q53vauiRgAAAAAAANA13f7Y8/nw2TcVyf7Tl3bLyHcOKJJNB7h/ctUNyrpvclK/e9UtAAAAAIAexvgpyTrrrJM111wzCxYseMtA6MYbu/4nVz355JN59NFHU1NTk5aWljc9Y1vDLwAAAAAAAODNPnT2jbnjsflFsh85Y9xbfl9JFzP79qoblDWnmz8fAAAAANAp1VZdoLMYPnx4WlpaXv+/XxsK3XzzzVmyZEmFzVbdNddcs8z3tthii44rAgAAAAAAAF3UCwsXp37CpCLDp+Pfv1UaJo43fOrqmpuSp+6qukVZT97V+pwAAAAAAB3I+OnvRo8e/fp/fuMI6sUXX8zll19eRaV2c9FFFy3zvZ133rkDmwAAAAAAAEDXc971D2ebb08pkj3jxH3ymd0HF8mmg82dlSxeWHWLshYvSOY+UHULAAAAAKCHMX76u1122WWZ7/3qV7/qwCbta968ebn88stf/5S4N35a3BprrJGRI0dWVQ0AAAAAAAA6tZaWltRPmJRTJ93b7tk71r8jDRPHp3+/3u2eTUXm3Fl1g47x5J1VNwAAAAAAepheVRfoLPbYY4+3DIRqamrS0tKS3//+93n44YczZMiQKiuulO9///tpbGx8/Vne+OeYMWNSW2v/BgAAAAAAAP/szsfn58Af3lgk+5Ijds12m76jSDYVeuaeqht0jJ7ynAAAAABAp2H58ncbbbRRRo8enZaWliR5/c8kaWpqysknn1xVtZU2b968nHXWWW867emNDjrooA5uBAAAAAAAAJ3fIefcXGz49MgZ4wyfuqtF86tu0DFemV91AwAAAACghzF+eoN/HgO98aSkX/7yl5k6dWpFzVbOV7/61cyfPz/JP57lNb169cqBBx5YTTEAAAAAAADohF54ZXHqJ0zKrQ3PtXv2MeO2SMPE8cv84EK6gSWNVTfoGD3lOQEAAACATsP46Q3+9V//NX379k2SN/3S4bUB1Kc//enMmzevqnor5KKLLsovf/nL17u/5rUR1IEHHph3vMMnygEAAAAAAECS/OyGR7LNyVOKZN95wt753Hs2K5JNJ9L0atUNOkaT8RMAAAAA0LGMn95g0KBB+cQnPvGWsdBrHnvssRx00EFZvHhxFfWW2+23355Pf/rTbX5q3Ne//vUObAQAAAAAAACdU0tLS+onTMq3/++eds/edpMBaZg4PgNWX63ds+mE6nrIf891fapuAAAAAAD0MMZP/+Qb3/hG6urqkvzj9KfXTktqaWnJddddlw9+8INZtGhRlTWX6bbbbss+++yThQsXJvnHeOu1/jU1NRkzZkx22mmnKmsCAAAAAABA5WY+8UIGHz25SPbvD981l35xtyLZdFK9esgoqKc8JwAAAADQaRg//ZOhQ4fm8MMPf9OJT8mbB1B/+ctfstdee2XOnDkVtVy6Sy+9NHvttVeee+6517smedMJULW1tfmf//mfqioCAAAAAABAp/AvP7klHzjrhiLZj5wxLju86x1FsunE+g6oukHH6Deg6gYAAAAAQA9j/LQUp556atZbb70kbx4OvXEAddNNN2XbbbfNJZdcUlXN1y1YsCBf+cpX8pGPfCQvvvjimzq/5rXun/3sZ7PddttV0BIAAAAAAACq99KixamfMCk3PTSv3bP/Y78t0jBx/FJ/X0cPsN5WVTfoGD3lOQEAAACATsP4aSnWXnvtnHvuuW85/Sn5x4goSebOnZuDDjoo+++/f+66666Orpnm5uacf/75GT58eM4666w3dfvnU59qamoyePDgTJw4scN7AgAAAAAAQGdwwc0NGXHSlCLZdxy/dw7fY7Mi2XQRG21bdYOOseG2VTcAAAAAAHoY46dl+OAHP5hvfOMbbxoUvea1r712CtSUKVOy3XbbZf/998+kSZOyZMmSot2efvrpfPe7381mm22WT3/605kzZ06bw6eWlpb06dMnv/vd77L22msX7QYAAAAAAACdTUtLS+onTMoJf/xbu2dvvfHaaZg4Pu9YY7V2z6aLGTgs6b161S3K6r1GMnBo1S0AAAAAgB6mV9UFOrMzzjgjd911V6ZMmfL60Ok1/zyASpIpU6ZkypQpGTBgQD7wgQ9k7Nix2WOPPbLpppuuUo/m5uZMnz4911xzTS6//PJcd911aW5uXurI6TVv/FptbW1+/OMfZ9ttt12lHgAAAAAAANDV3D37hbz/BzcUyb74C6OzY/06RbLpgmrrkg1GJo/fUnWTcjYc2fqcAAAAAAAdyPipDXV1dbn00kuz33775brrrlvqACp56/jo+eefz4UXXpgLL7wwSbLOOutkq622yhZbbJGNNtooG2ywQQYOHJi+ffumb9++6dWrVxobG9PY2JiXX345zzzzTJ566qk8+uijueeeezJr1qw0NjYu875v/NobvTbQOvPMM/Pxj3+8nf/pAAAAAAAAQOf2bz+7NdfNerZI9sOnj0ttbc3bX0jPsvH23Xv8tNH2VTcAAAAAAHog46e30bdv30yaNCkf+MAHcs011yz1lKW3GyPNmzcvN9xwQ264YcU/UW5po6a2Rk//fOLT9773vRxxxBErfF8AAAAAAADoql5uXJKtT/xLkexv7DMsXxo7tEg23cDwccktZ1fdopwtxlXdAAAAAADogWqrLtAVrLHGGpkyZUoOO+ywpQ6dXtPS0vKm99/4eu29FX0tLeuf7/WaN7635ppr5tJLL82XvvSlYv9cAAAAAAAAoLP55S2PFhs+TT9uL8Mn2la/e7JuN/13ZOCw5F27Vd0CAAAAAOiBjJ+WU69evfLjH/84P/rRj7L66qunpaXlTWOkN1qeAdOKvJaV+Zp/vm6bbbbJzTffnPe///2F/6kAAAAAAABA59DS0pL6CZNy3KV3t3v2FhuslYaJ47Pumn3aPZtupqYm2fGwqluUseNhrc8HAAAAANDBjJ9W0Oc///ncdddd2WOPPZY6bFqalT31aVljp9f88+ipV69eOemkkzJt2rS8+93vLvMPAAAAAAAAADqZe+a8mMFHTy6S/ZvP7ZLLj3pPkWy6qW0OTXqvXnWL9tV79dbnAgAAAACogPHTShg8eHCuvvrqXHLJJdl6662XecJTCUs7EaqmpiYf//jHc9999+WEE05Ir169itwbAAAAAAAAOptP/2Jaxp15fZHsh08fl12GrFskm26s34BkxMFVt2hfIw5O+vavugUAAAAA0EMZP62CD37wg7nzzjtz8cUX533ve1+SLHMItTKDqGV9/2v3WGuttXL44Ydn5syZueCCCzJ48OD2fUAAAAAAAADopBY0Lkn9hEm5+r5n2j37qL2GpmHi+NTWlvnAQ3qA3Y9K6vpU3aJ91PVpfR4AAAAAgIo4ImgV1dTU5CMf+Ug+8pGP5OGHH87//u//ZtKkSZk2bVqam5vfdN0b/1wRr42pkmTttdfO3nvvnQMOOCAHHXRQ+vXrt+oPAQAAAAAAAF3Ir299LEf/YWaR7NuO2ysD1+wmoxWqs86QZM9jkitPrLrJqtvzmNbnAQAAAACoiPFTOxoyZEiOO+64HHfccZk3b16uvfbaTJ8+PXfccUdmzpyZJ5988k2DqLfTt2/fDBkyJNtuu22222677LTTThk9enR69fJfGwAAAAAAAD1T/YRJRXI3G7RGrvr6HkWy6aFGfym590/J7OlVN1l5G49Kdj2y6hYAAAAAQA9nRVPIuuuumw9/+MP58Ic//PrXmpqaMmfOnMyePTsvvPBCFi1alFdeeSVLlixJnz590q9fv/Tr1y8DBw7MO9/5zqy77roVPgEAAAAAAAB0Hvc/9VL2/d51RbL/97M7Z9fNBhbJpger65Uc+KPknDFJU2PVbVZcXZ/kwLOT2rqqmwAAAAAAPZzxUweqq6vLJptskk022aTqKgAAAAAAANBlfO6C2zLlnqeLZD90+rjU1dYUyYYMGp6MPTa54oSqm6y4sce19gcAAAAAqJjxEwAAAAAAANApLXx1SbY64S9Fso8cu3m+vo9hBx1g9JHJU3cnMy+qusnyG3FIMvpLVbcAAAAAAEhi/AQAAAAAAAB0Qhfd9ni+9bu7imTfeuz7st5afYtkw1vU1iYHnp00vpTMuqzqNm9v+LjWvrW1VTcBAAAAAEhi/AQAAAAAAAB0MvUTJpXJXXf1XPPNPYtkQ5vqeicH/yK5+JOdewA1fFxy0M9b+wIAAAAAdBI+qgkAAAAAAADoFB54+qViw6dffmZnwyeq1btv8tELkxGHVN1k6UYckhxyQWtPAAAAAIBOxMlPAAAAAAAAQOW++KvbM2nmk0WyHzp9XOpqa4pkwwqp65186Nxkg62Tq09LmhqrbpTU9UnGHpeM/lJS6/NTAQAAAIDOx/gJAAAAAAAAqMwrrzZlyxMuL5J9+B6b5T/226JINqy02tpkt68kw/ZLLj08mT29ui4bj0oOPDsZNLy6DgAAAAAAb8P4CQAAAAAAAKjE76c/ka9fPKNI9l+PeV/WX7tvkWxoF4OGJ5+ektx8VjL19I49BaquTzL22L+f9lTXcfcFAAAAAFgJxk8AAAAAAABAh6ufMKlI7sYD+uXGCWOLZEO7q+uV7H5UstUByQ3fS2ZenCxeWO5+vVdPRhzces91hpS7DwAAAABAOzJ+AgAAAAAAADrMg8+8nL2+e22R7PM/vVPeO2xQkWwoap0hyQFnJvucksz4TTLtvGTurPbLHzgs2fGwZJtDk7792y8XAAAAAKADGD8BAAAAAAAAHeLLv74jf5oxp0j2g6ftn151tUWyocP07Z/s/Plkp88lj96Y3Dc5mXN78uSMFTsRqvcayYYjk422T7YYl7xrt6SmplxvAAAAAICCjJ+ANi1ZsiQPPfRQGhoa8tJLL+Xll19O3759s/baa2fDDTfM8OHDs/rqq1ddEwAAAAAA6MQWLW7KFsdfXiT7c+8ZkmPGbVkkGypTU5PU7976SpLmpmTuA8mTdybP3JO8Mj9Z0pg0NSZ1fZJefZJ+A5L1tko23DYZODSprauuPwAAAABAOzJ+At5i5syZ+cMf/pDJkyfnzjvvzKuvvrrMa2tqajJ06NDst99+OeCAAzJ27NjU+NQ4AAAAAADg7/545+x85Td3Fsm+5ej3ZYP+fYtkQ6dSW5est0XrCwAAAACghzF+gnbQ0NCQ22677fXX9OnTM3/+/Da/p6WlpWPKrYC//OUvmThxYq655prl/p6WlpbMmjUrs2bNyplnnplhw4blq1/9aj772c+mrs6nyQEAAAAAQE9WP2FSkdz11uqTW4/dq0g2AAAAAADQuRg/wQp64okn3jJ0mjt3btW1Vsns2bNz5JFH5pJLLlnlrFmzZuXwww/POeeck3PPPTc777xzOzQEAAAAAAC6koeffTlj//vaItk//+SO2XOL9YpkAwAAAAAAnY/xE7Th6aefzrRp0940dnr66aerrtWurr/++hx00EF55pln2jV3xowZGTNmTL7//e/n8MMPb9dsAAAAAACg8/rab+/MH+6YXST7wdP2T6+62iLZAAAAAABA52T8BG3Yd999M2PGjKprFPPHP/4xBx98cBYvXlwkf/HixTniiCPy6KOPZuLEiUXuAQAAAAAAdA6LFjdli+MvL5L9qd3qc+IH3l0kGwAAAAAA6NyMn6CHuuKKK/LRj3602PDpjf7zP/8za6yxRo4//vji9wIAAAAAADren2fMyZG/vqNI9k0TxmajAf2KZAMAAAAAAJ2f8RP0QA0NDTnkkEPS2Nj4tteOGDEin/jEJzJmzJgMHTo0/fv3z4IFC/L444/nlltuyW9/+9tcddVVaWlpaTPnhBNOyMiRI/PBD36wvR4DAAAAAADoBIYcPSnNbf+aYKWss8Zquf34vds/GAAAAAAA6FKMn6CHWbJkST760Y9m/vz5bV63/vrr5wc/+EEOPvjgt7zXv3//9O/fP1tvvXUOO+ywTJs2LV/4whdy++23t5n5qU99KnfeeWc23XTTVXkEAAAAAACgE2iYuyB7/Nc1RbJ/+u+j8r4t1y+SDQAAAAAAdC21VReA7qa+vj777LNP1TWW6ayzzsqtt97a5jXbbLNNbr/99qUOn5Zmxx13zE033ZSPfexjbV73/PPP56ijjlreqgAAAAAAQCf1zYtnFBs+PXDa/oZPAAAAAADA65z8BKtgk002yahRo7LDDjtk1KhRGTVqVNZdd900NDRk8ODBVdd7i2effTYnnXRSm9dsvvnmueKKKzJo0KAVyu7Tp08uvPDCLFy4MH/84x+Xed0ll1ySK6+8MnvttdcK5QMAAAAAANVrXNKU4cddXiT730e/Kyd/cOsi2QAAAAAAQNdl/ATLaaONNnp94LTDDjtkxx13XOGBUNX+67/+Ky+88MIy319ttdVy0UUXrfRz1dXV5fzzz8+2226bhoaGZV53wgknGD8BAAAAAEAXM3nmkzniV7cXyb7hP/bMO9+xepFsAAAAAACgazN+gjYceeSRWX/99TNq1KhssMEGVddZJS+++GLOPffcNq856qijst12263Sffr375/vf//7+eAHP7jMa26++eZcf/31GTNmzCrdCwAAAAAA6BjDjrssry5pbvfctfr0ysyT9233XAAAAAAAoPswfoI2fOYzn6m6Qrs5//zz2zz1acCAATn22GPb5V4HHHBAxowZk+uvv36Z15x55pnGTwAAAAAA0Mk9Nm9h3vP/phbJPvcTO2Tfd3ftD58DAAAAAADKq626ANAxLrzwwjbf/9znPpe111673e739a9/vc33//znP7c5xgIAAAAAAKp19B9mFhs+zTp1f8MnAAAAAABguRg/QQ/wwAMPZNq0aW1e89nPfrZd7/mBD3wgG2644TLfb2xszO9///t2vScAAAAAALDqXl3SnPoJk/LrWx9r9+x/3XnTNEwcn9V6+TUlAAAAAACwfPxWAXqAP//5z22+v8MOO2TzzTdv13vW1tbmkEMOafOat+sFAAAAAAB0rMvvfirDjrusSPb139ozp31oRJFsAAAAAACg+zJ+gh7gyiuvbPP98ePHF7nv2+VOnTo1TU1NRe4NAAAAAACsmK1P/Eu+8Mvp7Z7bt3dtGiaOzybrrN7u2QAAAAAAQPdn/ATd3JIlS3Lddde1ec1ee+1V5N5jxoxJ3759l/n+Cy+8kGnTphW5NwAAAAAAsHwef25h6idMysuNS9o9+0f/un3uO2X/ds8FAAAAAAB6DuMn6Ob+9re/ZcGCBct8v3fv3tlpp52K3Ltv377Zbrvt2rzG+AkAAAAAAKpz/KV3Z8x3phbJvv/U/bL/iA2LZAMAAAAAAD2H8RN0c7fffnub72+11Vbp06dPsfuPGjWqzffvuOOOYvcGAAAAAACWbnFTc+onTMqFtzza7tkfHbVJGiaOT59ede2eDQAAAAAA9Dy9qi4AlHXnnXe2+f7IkSOL3v/t8o2fAAAAAACgY11xz9P57AW3Fcm+9pt75F3rrlEkGwAAAAAA6JmMn6CbmzVrVpvvDx06tOj9N9988zbff+CBB4reHwAAAAAA+IdtTp6SF15Z3O65dbU1eej0ce2eCwAAAAAAYPwE3dwjjzzS5vtvN05aVW+Xv2DBgjz77LMZNGhQ0R4AAAAAANCTzZ7/SnabeHWR7LP+Zbu8f+RGRbIBAAAAAACMn6Aba2lpyaOPPtrmNRttVPaXkRtssEFqa2vT3Ny8zGseeeQR4ycAAAAAACjkpD/9Lb+4qaFI9v2n7pc+veqKZAMAAAAAACTGT9CtPf/881m0aFGb12ywwQZFO/Tq1Svrrrtunn322WVeM2fOnKId/j97dx6mdV3vf/w9MwwMuEDIIio6oCyCiCKQKG6oyGLmqTTr12JmlpppnVLANUUgMzMts7LMbFUryxhAEVxQXABBFFlkUUQREBEVGYaZ+f3B6Zw6R4bt/tz3Pff9eFyX/5z79vl93+e66g/p5RcAAAAAAIpRTW1ddLl8QpL2J/vsFz84s3eSNgAAAAAAwL8yfoIC9tZbb23zO+3atUt+R/v27RscP23PnQAAAAAAwPabMv/NOOfXM5K0p377+OjUZrckbQAAAAAAgP/N+AkK2Nq1a7f5nT333DP5Hdt6xvbcCQAAAAAAbJ++ox+KNe9tStJeNm54ki4AAAAAAMDWGD9BAXv77bcb/Lx58+ZRVlaW/I499tijwc/zcfz0k5/8JG677bbkz1m8eHHyZwAAAAAAUBzeeOeDGDB2SpL2j846LD5+2L5J2gAAAAAAAA0xfoICtnHjxgY/32233bJyx+67797g59u6MxdWr14d8+bNy/UZAAAAAACwXUb/Y17cMW1pkvb864ZERXn6f5kaAAAAAADAhzF+ggK2adOmBj9v0iQ7/xWwreds604AAAAAAODDba6ti4Mun5Ckffph+8TNZx2epA0AAAAAALC9jJ+ggBk/AQAAAABA4Xpkwao4+85nk7Qf/s/j4sC2uydpAwAAAAAA7AjjJyhgdXV1DX5eVlaWlTu29Zza2tqs3AEAAAAAAIViwNiH4413NiZpLxs3PEkXAAAAAABgZxg/QQHb1huXNm/enJU7tvWc8vLyrNwBAAAAAACN3ZvrN8ZHxzycpP3DT/eO/zh8vyRtAAAAAACAnWX8BAWsadOmDX6erfFTTU1Ng59v685caNu2bfTo0SP5cxYvXhzV1dXJnwMAAAAAQOM3dsJL8bNHlyRpz79uSFSUlyVpAwAAAAAA7ArjJyhg23qj0qZNm7JyR2McP1144YVx4YUXJn9Oz549Y968ecmfAwAAAABA41VbVx8HjqpK0h5+aIf4yWf7JGkDAAAAAABkgvETFLDdd9+9wc/fe++9rNzx7rvvNvj5tu4EAAAAAIBi9fii1fH5Xz6TpD35W8fGQe32SNIGAAAAAADIFOMnKGCtW7du8POamprYuHFjVFRUJL1j/fr1DX6+rTsBAAAAAKAYDfzelHjt7Q+StJeNG56kCwAAAAAAkGnGT1DA9tprr21+Z926dbH33nsnvWPdunUNfr49dwIAAAAAQLFYtX5j9B/zcJL2jWf0jk8dsV+SNgAAAAAAQArGT1DA2rRps83vrFy5Mvn4aeXKlQ1+bvwEAAAAAABbfH/S/PjJ1MVJ2vOuPSVaNPXHgwAAAAAAQOPiTzeggLVo0SL22muveOutt7b6nTfffDPpDRs2bIh33323we8ccMABSW8AAAAAAIB8V1tXHweOqkrSHtJz77j980ckaQMAAAAAAKRm/AQFrrKyssHx0yuvvJL0+dvTr6ysTHoDAAAAAADksydfXhOfvePpJO0Hv3lsdG2/R5I2AAAAAABANhg/QYHr1KlTzJw5c6ufL1q0KOnzX3755QY/b9++fbRo0SLpDQAAAAAAkK8G3fhILFnzfpL2snHDk3QBAAAAAACyqTTXBwBp9ezZs8HPFyxYkPT52+pv6z4AAAAAAChEq9+tjsoR45MMn773yV6GTwAAAAAAQMHw5icocH369Gnw8+eeey7p82fNmtXg54cffnjS5wMAAAAAQL656cEFccuUl5O0X/zuKbFbM38ECAAAAAAAFA5/8gEFblvjp9deey1WrVoV7dq1S/L8mTNnNvi58RMAAAAAAMWirq4+Oo+qStI+6eB2cccX+yVpAwAAAAAA5FJprg8A0tpvv/3igAMOaPA7jzzySJJnv/7667Fw4cIGvzNw4MAkzwYAAAAAgHwyffFbyYZPEy4+xvAJAAAAAAAoWMZPUAROOumkBj9/6KGHkjx38uTJDX7epUuXbQ6zAAAAAACgsRv8w0fjM794Kkl76dhhcXCHPZO0AQAAAAAA8oHxExSBk08+ucHP//73v0dtbW3Gn3vfffc1+PngwYMz/kwAAAAAAMgXb71XHZUjxsfCN9/LeHvMf/SKZeOGR0lJScbbAAAAAAAA+cT4CYrA8OHDo0WLFlv9fNWqVdt8S9OOWrt2bUyaNKnB75xxxhkZfSYAAAAAAOSLWx9eFEeMzuw/e/+nF757Snz2o/snaQMAAAAAAOQb4ycoArvvvnucdtppDX7n1ltvzegzb7/99ti0adNWP+/YsWMce+yxGX0mAAAAAADkWl1dfVSOGB8/eGhhxtvHdW0by8YNj92bNcl4GwAAAAAAIF8ZP0GROOeccxr8vKqqKmbPnp2RZ7333nvbHFN94QtfiJKSkow8DwAAAAAA8sEzS9dG51FVSdrjvzEw7jqnf5I2AAAAAABAPjN+giJx8sknx6GHHrrVz+vr6+OSSy7JyLPGjh0bK1eu3OrnzZo1i4suuigjzwIAAAAAgHww7EePx5k/m56kvXTssOi5T8skbQAAAAAAgHxn/ARF5LLLLmvw80cffTR++MMf7tIznnzyybjhhhsa/M7ZZ58d7du336XnAAAAAABAPlj7/qaoHDE+5r2xPuPt6z7eM5aNGx4lJSUZbwMAAAAAADQWxk9QRD7zmc9Ev379GvzOZZddFg888MBO9RctWhSf+tSnYvPmzVv9zh577BHXXHPNTvUBAAAAACCf/GTqy9HnuoeStOdeMzg+P6AySRsAAAAAAKAxMX6CIlJSUhI//vGPG/w3RNbU1MQZZ5wRd9xxxw61n3jiiTjuuOPijTfeaPB7V199dey999471AYAAAAAgHxSX18flSPGx/cnLch4+5gubWLZuOGxR0V5xtsAAAAAAACNUZNcHwD57rHHHouFCxfu0N/z1ltvbfM7Ozouiog47rjjokuXLjv89/2r/v37x8iRI2PMmDFb/U51dXV85StfiT//+c9x7bXXNvi2qFdeeSW+973vxS9+8YsG3/gUseX+Sy65ZGdPBwAAAACAnJv5ytr45E+nJ2n/46KBcci+LZO0AQAAAAAAGivjJ9iGX/3qV3HXXXdlvPuVr3xlh/+eO++8c5fHTxER1157bUybNi0ee+yxBr83ceLEmDhxYnTv3j2OOeaY6NKlS+y5557x/vvvx/Lly+Ppp5+Op556Kurr67f5zHbt2sXvf//7KCsr2+X7AQAAAAAgFz7+42kx57V3krSXjh0WJSUlSdoAAAAAAACNmfETFKGysrK4//7744QTTog5c+Zs8/vz58+P+fPn7/TzWrVqFZMmTYp99tlnpxsAAAAAAJAr6zZsisOufShJ+5qP9Yizj+6UpA0AAAAAAFAISnN9AJAbH/nIR+Khhx6Kvn37Jn1Ou3btYtKkSXHYYYclfQ4AAAAAAKRw+6OLkw2fnr9msOETAAAAAADANhg/QRFr27ZtPP744/GFL3whSb9fv34xY8aM6N+/f5I+AAAAAACkUl9fH5Ujxse4CfMz3v5op9axbNzw2LOiPONtAAAAAACAQmP8BEWuoqIi7rrrrvjHP/4RnTt3zkhzjz32iJtuuimmT58eHTt2zEgTAAAAAACyZdarb0enkVVJ2n+78Oj401cHJGkDAAAAAAAUIuMnICIihg8fHvPnz4+77747+vXrt1ONAw44IMaOHRvLli2Lb37zm1FWVpbhKwEAAAAAIK1P3PZEfOK2J5O0l44dFr07tkrSBgAAAAAAKFQl9fX19bk+Asg/y5cvjwkTJsSzzz4b8+bNi1deeSXWr18fGzZsiGbNmsUee+wRHTp0iIMPPjgOO+ywOOWUU6J37965PrvR6dmzZ8ybN+///N979OgRL774Yg4uAgAAAAAoTu9sqIne1z6YpH3F8IPj3GM6J2kDAAAAAADFo1j/9+dNcn0AkJ86duwY5513Xpx33nm5PgUAAAAAAJK64/ElMXr8S0nac64aHC1blCdpAwAAAAAAFAPjb2jSgQABAABJREFUJwAAAAAAAIpSfX19dBpZlaR9xAEfiT+ff1SSNgAAAAAAQDExfgIAAAAAAKDozF6+Lk7/yRNJ2n+94Kg4fP+PJGkDAAAAAAAUG+MnAAAAAAAAisqZt0+PZ5atTdJeOnZYlJSUJGkDAAAAAAAUI+MnAAAAAAAAisI7H9RE7+8+mKQ9cmj3+OpxByZpAwAAAAAAFDPjJwAAAAAAAArenU8sje8+MC9Je/ZVJ0erFk2TtAEAAAAAAIqd8RMAAAAAAAAFq76+PjqNrErS7t2xVfztwqOTtAEAAAAAANjC+AkAAAAAAICCNPe1d+JjP56WpP3n84+KIw74SJI2AAAAAAAA/8P4CQAAAAAAgILzuTuejmkvr0nSXjp2WJSUlCRpAwAAAAAA8O+MnwAAAAAAACgY726siV7XPJikfemQbnHB8QclaQMAAAAAAPDhjJ8AAAAAAAAoCL+Zviyu+tuLSdqzrjw5Wu/WNEkbAAAAAACArTN+AgAAAAAAoFGrr6+PTiOrkrR77rNnjP/GMUnaAAAAAAAAbJvxEwAAAAAAAI3WCyveiVNvnZakfe/XBkS/ytZJ2gAAAAAAAGwf4ycAAAAAAAAapS/86pl4bOHqJO0lY4ZFaWlJkjYAAAAAAADbz/gJAAAAAACARuW96s1xyNWTkrS/PbhrfH1QlyRtAAAAAAAAdpzxEwAAAAAAAI3G755+JS7/6wtJ2jOvOCn22r1ZkjYAAAAAAAA7x/gJAAAAAACAvFdfXx+dRlYlaXdrv0dM+uaxSdoAAAAAAADsGuMnAAAAAAAA8tpLb6yPoT96PEn7j+cdGUd23itJGwAAAAAAgF1n/AQAAAAAAEDe+vKvn42H569K0l4yZliUlpYkaQMAAAAAAJAZxk8AAAAAAADknferN0fPqyclaX/jxC7xrZO7JmkDAAAAAACQWcZPAAAAAAAA5JU/PPNqjPzL3CTtZy8/Kdru0SxJGwAAAAAAgMwzfgIAAAAAACBvVI4Yn6Tbue1uMeU/j0/SBgAAAAAAIB3jJwAAAAAAAHJuwcp345SbH0vS/v25H42jDmqTpA0AAAAAAEBaxk8AAAAAAADk1FfvnhGTXnwzSXvxmGFRVlqSpA0AAAAAAEB6xk8AAAAAAADkxIZNm6PHVZOStL9+wkHx7VO6JWkDAAAAAACQPcZPAAAAAAAAZN29M5bHd+57Pkn7mctPjHZ7VCRpAwAAAAAAkF3GTwAAAAAAAGRV5YjxSbodWzePxy8dlKQNAAAAAABAbhg/AQAAAAAAkBWL3nw3Tv7hY0nad3+5fxzTpW2SNgAAAAAAALlj/AQAAAAAAEByF/5uVoyf+0aS9uIxw6KstCRJGwAAAAAAgNwyfgIAAAAAACCZDzbVxsFXTUzSPv/4A+OyId2TtAEAAAAAAMgPxk8AAAAAAAAk8ZdZr8W37pmTpP30qBOj/Z4VSdoAAAAAAADkD+MnAAAAAAAAMq5yxPgk3X1aVsSTI09M0gYAAAAAACD/GD8BAAAAAACQMYtXvxcn/uDRJO27zukfx3Vtm6QNAAAAAABAfjJ+AgAAAAAAICMu/uNz8bfZrydpv3z90GhSVpqkDQAAAAAAQP4yfgIAAAAAAGCXbKypje5XTkzS/soxneLy4T2StAEAAAAAAMh/xk8AAAAAAADstL/NXhEX/3F2kvb0kYOiQ8vmSdoAAAAAAAA0DsZPAAAAAAAA7JTKEeOTdNvs3ixmXHFSkjYAAAAAAACNi/ETAAAAAAAAO2TJ6vdi0A8eTdL+1dl9Y1D39knaAAAAAAAAND7GTwAAAAAAAGy3b90zO/4ya0WS9svXD40mZaVJ2gAAAAAAADROxk8AAAAAAABs08aa2uh+5cQk7S8dXRlXf6xnkjYAAAAAAACNm/ETAAAAAAAADXpgzutx0R+eS9J+YsSg2LdV8yRtAAAAAAAAGj/jJwAAAAAAALaq88jxUVef+W6rFuUx+6rBmQ8DAAAAAABQUIyfAAAAAAAA+D+WrXk/jr/xkSTtX3yhb5zco32SNgAAAAAAAIXF+AkAAAAAAIB/851758S9M19L0l50/dAoLytN0gYAAAAAAKDwGD8BAAAAAAAQERHVm2uj2xUTk7S/MOCAuPbjhyRpAwAAAAAAULiMnwAAAAAAAIiquW/EBb+blaQ97bITYr+PtEjSBgAAAAAAoLAZPwEAAAAAABS5rldMiE2b6zLe3aNZk5j73VMy3gUAAAAAAKB4GD8BAAAAAAAUqeVrN8QxN0xN0v7Z54+IU3runaQNAAAAAABA8TB+AgAAAAAAKEKj/jo3fv/0q0naC0cPjaZNSpO0AQAAAAAAKC7GTwAAAAAAAEVk0+a66HrFhCTtz/TfP8Z+oleSNgAAAAAAAMXJ+AkAAAAAAKBITHxhZXzttzOTtB+/9ITo2LpFkjYAAAAAAADFy/gJAAAAAACgCBxy9aR4r3pzxrvNmpTGgtFDM94FAAAAAACACOMnAAAAAACAgrZ87YY45oapSdo//X99YmivDknaAAAAAAAAEGH8BAAAAAAAULCuvP+FuPupV5K0F4weEs2alCVpAwAAAAAAwD8ZPwEAAAAAABSYmtq66HL5hCTtM/vuFzd8qneSNgAAAAAAAPxvxk8AAAAAAAAFZPK8N+Pc38xI0n70O8fHAXvtlqQNAAAAAAAAH8b4CQAAAAAAoEAcdu2DsW5DTca7ZaUlsXjMsIx3AQAAAAAAYFuMnwAAAAAAABq5Fes+iKPHTUnSvvUzh8fHeu+T+XBdbcSahRGvz45YNS9i47qIzdURtZsiyppGNGkWUdEqol2PiH0Oj2jTJaK0LPN3AAAAAAAAkNeMnwAAAAAAABqxa/7+Yvz6yWVJ2vOvGxIV5RkaHNXXRyybFrGgKmLFrIiVz0fUbNj+v798t4i9e0Xs2yei27CIyoERJSWZuQ0AAAAAAIC8ZfwEAAAAAADQCNXU1kWXyyckaX+iz75x05mHZSb2wbqIOX+MmPHLLW962lk170csf2rLX0/dFtGma0TfL0f0PiuieavM3AoAAAAAAEDeMX4CAAAAAABoZKbMfzPO+fWMJO2p3z4+OrXZbddDa5dETLs5Yu69O/aGp+21ZmHExMsiHv5uRK8zIgZeEtG6c+afAwAAAAAAQE4ZPwEAAAAAADQifUdPjjXvVSdpLxs3fNcjtZsjpt8aMXVsRG2aO/9NzYaIWXdtebvUCaMijrooorQs/XMBAAAAAADICuMnAAAAAACARuCNdz6IAWOnJGn/6KzD4uOH7bvrodULIu4/P2LFzF1v7aja6ojJV0e89EDE6bdFtO2W/RsAAAAAAADIOOMnAAAAAACAPHf9+Hnxi8eXJmnPv25IVJTv4puS6uq2vO1pyvXZedtTQ1bMiLj9mIhBl0cMuCiitDS39wAAAAAAALBLjJ8AAAAAAADy1Obaujjo8glJ2h8/bJ/40VmH73qotibi/gsi5t6z661Mqa2OeOiqiJUvbHkLVFl5ri8CAAAAAABgJxk/AQAAAAAA5KFHF66OL/7qmSTtyd86Lg5qt/uuh2o2Rtx7dsTCNAOtXTb3nojqdyPO+HVEeUWurwEAAAAAAGAnGD8BAAAAAADkmaPGPhyvv7MxSXvZuOGZCdXW5Pfw6Z8WToi470sRZ/7GG6AAAAAAAAAaodJcHwAAAAAAAMAWb67fGJUjxicZPt10Zu/MDZ/q6iLuvyD/h0//tKBqy711dbm+BAAAAAAAgB3kzU8AAAAAAAB5YNyE+XH7o4uTtF+6dkg0b1qWueD0WyPm3pO5XjbMvSdi714RR38j15cAAAAAAACwA4yfAAAAAAAAcqi2rj4OHFWVpD380A7xk8/2yWx09YKIKddntpktU0ZHdD0lom23XF8CAAAAAADAdirN9QEAAAAAAADFatqiNcmGT5O/dWzmh0+1myPuPz+itjqz3WyprY64/4KIutpcXwIAAAAAAMB28uYnAAAAAACAHDj2hqnx6toNSdrLxg1P0o3pP45YMTNNO1tWzIh48taIgZfk+hIAAAAAAAC2gzc/AQAAAAAAZNGqdzdG5YjxSYZP3//UoemGT2uXREwdk6adbVPHbPk9AAAAAAAA5D3jJwAAAAAAgCy5cdKC6H/9w0na8649Jc7o2zFJOyIipt0cUVudrp9NtdVbfg8AAAAAAAB5r0muDwAAAAAAACh0tXX1ceCoqiTtU3q2j599vm+S9n/7YF3E3HvTPiPb5t4bMfi6iIqWub4EAAAAAACABnjzEwAAAAAAQEJPvrwm2fBp0iXHph8+RUTM+WNEzYb0z8mmmg1bfhcAAAAAAAB5zZufAAAAAAAAEhl04yOxZM37SdrLxg1P0v0/6usjnr0jO8/KtmfviOh/XkRJSa4vAQAAAAAAYCuMnwAAAAAAADJszXvV0Xf05CTtcZ/oFWf13z9J+0Mtmxbx1qLsPS+b1iyMeOWJiMqBub4EAAAAAACArTB+AgAAAAAAyKAfPrQwfvRwmrHQi989JXZrluU/3llQld3nZdv8KuMnAAAAAACAPGb8BAAAAAAAkAF1dfXReVSaodCJ3dvFL8/ul6S9TStm5ea52fJ6gf8+AAAAAACARs74CQAAAAAAYBc9teStOOvnTyVpT7j4mDi4w55J2ttUVxux8vncPDtb3nh+y+8sLcv1JQAAAAAAAHwI4ycAAAAAAIBdMPiHj8bCN99L0l46dliUlJQkaW+XNQsjajbk7vnZUPN+xJpFEe265/oSAAAAAAAAPoTxEwAAAAAAwE54673qOGL05CTt0acfEp878oAk7R3y+uxcX5Adb8w2fgIAAAAAAMhTxk8AAAAAAAA76NaHF8UPHlqYpP3Cd0+J3ZvlyR/hrJqX6wuyo1h+JwAAAAAAQCOUJ39yBgAAAAAAkP/q6uqj86iqJO3juraNu87pn6S90zauy/UF2fHBulxfAAAAAAAAwFYYPwEAAAAAAGyHZ5etjTNun56kPf4bA6PnPi2TtHfJ5upcX5AdxfI7AQAAAAAAGiHjJwAAAAAAgG0Yfsvj8eLr65O0l44dFiUlJUnau6x2U64vyI5a4ycAAAAAAIB8ZfwEAAAAAACwFW+/vykOv+6hJO1rP94zvjCgMkk7Y8qa5vqC7ChrlusLAAAAAAAA2ArjJwAAAAAAgA9x2yMvxw0TFyRpz71mcOxRUZ6knVFNimQUVCy/EwAAAAAAoBEyfgIAAAAAAPgX9fX10WlkVZL20QftFb8798gk7SQqWuX6guxo3irXFwAAAAAAALAVxk8AAAAAAAD/ZeYra+OTP52epP3A1wdGr/1aJmkn065Hri/IjmL5nQAAAAAAAI2Q8RMAAAAAAEBEfPzH02LOa+8kaS8dOyxKSkqStJPa57BcX5AdHQ7L9QUAAAAAAABshfETAAAAAABQ1NZt2BSHXftQkvbVH+sRXzq6U5J2VrTpGlHeIqJmQ64vSad8t4g2XXJ9BQAAAAAAAFth/AQAAAAAABStnz26OMZOmJ+k/fw1g2PPivIk7awpLYvY+9CI5U/l+pJ0Ohy65XcCAAAAAACQl4yfAAAAAACAolNfXx+dRlYlaffv1Dru+eqAJO2c2LdPYY+f9umT6wsAAAAAAABoQGmuDwAAAAAAAMim5159O9nw6W8XHl1Yw6eIiG7Dcn1BWt0L/PcBAAAAAAA0ct78BAAAAAAAFI1P/vTJmPnK20naS8cOi5KSkiTtnKocGLFXl4i3FuX6ksxr0zXigKNzfQUAAAAAAAAN8OYnAAAAAACg4L2zoSYqR4xPMny6YvjBsWzc8MIcPkVElJRE9Ds311ek0e/cLb8PAAAAAACAvGX8BAAAAAAAFLQ7Hl8Sva99MEl7zlWD49xjOidp55XeZ0WUt8j1FZlV3mLL7wIAAAAAACCvNcn1AQAAAAAAACnU19dHp5FVSdp99m8Vf7ng6CTtvNS8VUSvMyJm3ZXrSzKn1xkRFS1zfQUAAAAAAADb4M1PAAAAAABAwZmzfF2y4dNfLjiquIZP/zTwkoiyZrm+IjPKmm35PQAAAAAAAOQ9b34CAAAAAAAKylk/nx5PLVmbpL107LAoKSlJ0s57rTtHnDAqYvLVub5k150wasvvAQAAAAAAIO958xMAAAAAAFAQ1m+sicoR45MMn0YM7R7Lxg0v3uHTPw34esS+R+T6il2zb9+Ioy7K9RUAAAAAAABsJ29+AgAAAAAAGr07n1ga331gXpL27KtOjlYtmiZpNzplTSJO/2nE7cdE1Fbn+podV9Ys4vTbIkrLcn0JAAAAAAAA28n4CQAAAAAAaLTq6+uj08iqJO1D92sZf//6wCTtRq1tt4hBl0c8dFWuL9lxg67Ycj8AAAAAAACNhvETAAAAAADQKL2w4p049dZpSdr3fW1A9K1snaRdEAZcFLHyhYi59+T6ku3X68yIAV/P9RUAAAAAAADsIOMnAAAAAACg0fncHU/HtJfXJGkvGTMsSktLkrQLRmlpxOm3RVS/G7FwQq6v2bZuw7bcW1qa60sAAAAAAADYQf6EBwAAAAAAaDTe3VgTlSPGJxk+feeUbrFs3HDDp+1VVh5xxq8jug7N9SUN6zYs4lN3brkXAAAAAACARsf4CQAAAAAAaBTunr4sel3zYJL2rCtPjgtPOChJu6CVV0R8+u6IXmfm+pIP1+vMiDN/s+VOAAAAAAAAGqUmuT4AAAAAAACgIfX19dFpZFWSdo8Oe0bVxcckaReNsvKI//hZxN6HREy5PqK2OtcXRZQ1ixh0RcSAr0eU+ncBAgAAAAAANGbGTwAAAAAAQN568fV3Yvgt05K07/nqgOjfqXWSdtEpLY04+uKIrkMi7j8/YsXM3N2yb9+I02+LaNstdzcAAAAAAACQMcZPAAAAAABAXjr7zmfikQWrk7SXjBkWpaUlSdpFrW23iHMejJj+44ipY7L7FqiyZhGDLv+vtz2VZe+5AAAAAAAAJGX8BAAAAAAA5JX3qjfHIVdPStL+1sld4xsndknS5r+UNYkYeElEj9Mipt0cMffeiJoN6Z5X3iKi1xlbntm6c7rnAAAAAAAAkBPGTwAAAAAAQN743dOvxOV/fSFJe+YVJ8VeuzdL0uZDtO4ccdotEYOvi5jzx4hn74hYszBz/TZdI/qdG9H7rIiKlpnrAgAAAAAAkFeMnwAAAAAAgJyrr6+PTiOrkrS7td8jJn3z2CRttkNFy4iPfjWi/3kRrzwRMb8q4vVZEW/M2bE3QpXvFtHh0Ih9+kR0HxZxwNERJSXp7gYAAAAAACAvGD8BAAAAAAA59dIb62Pojx5P0v7jeUfGkZ33StJmB5WURFQO3PJXRERdbcSaRRFvzI5YNS/ig3URm6sjaqsjyppFNGkW0bxVRLseER0Oi2jTJaK0LHf3AwAAAAAAkBPGTwAAAAAAQM6ce9ezMfmlVUnaS8YMi9JSbwbKW6VlEe26b/kLAAAAAAAAtsL4CQAAAAAAyLr3qzdHz6snJWl/48Qu8a2TuyZpAwAAAAAAANll/AQAAAAAAGTVn559NS7789wk7WcvPyna7tEsSRsAAAAAAADIPuMnAAAAAAAgaypHjE/S7dxmt5jy7eOTtAEAAAAAAIDcMX4CAAAAAACSW7Dy3Tjl5seStH937kfj6IPaJGkDAAAAAAAAuWX8BAAAAAAAJPXVu2fEpBffTNJePGZYlJWWJGkDAAAAAAAAuWf8BAAAAAAAJLFh0+bocdWkJO0LTzgwvnNK9yRtAAAAAAAAIH8YPwEAAAAAABl374zl8Z37nk/SfmbUidFuz4okbQAAAAAAACC/GD8BAAAAAAAZVTlifJJux9bN4/FLByVpAwAAAAAAAPnJ+AkAAAAAAMiIl1e9Gyfd9FiS9t1f7h/HdGmbpA0AAAAAAADkL+MnAAAAAABgl134+1kx/vk3krQXjxkWZaUlSdoAAAAAAABAfjN+AgAAAAAAdtrGmtrofuXEJO2vHtc5Rg49OEkbAAAAAAAAaByMnwAAAAAAgJ3y1+dei2/+aU6S9tOjToz2e1YkaQMAAAAAAACNh/ETAAAAAACwwypHjE/S7dCyIqaPPDFJGwAAAAAAAGh8jJ8AAAAAAIDttnj1e3HiDx5N0v71l/rF8d3aJWkDAAAAAAAAjZPxEwAAAAAAsF0u+eNzcf/s15O0X75+aDQpK03SBgAAAAAAABov4ycAAAAAAKBBG2tqo/uVE5O0v3JMp7h8eI8kbQAAAAAAAKDxM34CAAAAAAC26m+zV8TFf5ydpD195KDo0LJ5kjYAAAAAAABQGIyfAAAAAACAD1U5YnySbpvdm8WMK05K0gYAAAAAAAAKi/ETAAAAAADwb5aueT9OuPGRJO1fnd03BnVvn6QNAAAAAAAAFB7jJwAAAAAA4L/95z1z4s+zXkvSXnT90CgvK03SBgAAAAAAAAqT8RMAAAAAABAba2qj+5UTk7TPPqoyrjmtZ5I2AAAAAAAAUNiMnwAAAAAAoMg9MOf1uOgPzyVpPzFiUOzbqnmSNgAAAAAAAFD4jJ8AAAAAAKCIHTSqKjbX1We827J5ecy5enDGuwAAAAAAAEBxMX4CAAAAAIAi9Mpb78dx338kSfsXX+gbJ/don6QNAAAAAAAAFBfjJwAAAAAAKDKX3fd8/GnG8iTtRdcPjfKy0iRtAAAAAAAAoPgYPwEAAAAAQJGo3lwb3a6YmKT9+SMPiOtOPyRJGwAAAAAAAChexk8AAAAAAFAEJsx9I87/3awk7ccvPSE6tm6RpA0AAAAAAAAUN+MnAAAAAAAocN2umBDVm+sy3t2taVm8eO2QjHcBAAAAAAAA/sn4CQAAAAAACtTytRvimBumJmnf/rkjYsgheydpAwAAAAAAAPyT8RMAAAAAABSgUX+dG79/+tUk7YWjh0bTJqVJ2gAAAAAAAAD/yvgJAAAAAAAKyKbNddH1iglJ2p/pv3+M/USvJG0AAAAAAACAD2P8BAAAAAAABeLBF1fGeXfPTNJ+/NITomPrFknaAAAAAAAAAFtj/AQAAAAAAAWg1zWT4t2NmzPebdqkNBaOHprxLgAAAAAAAMD2MH4CAAAAAIBG7LW3N8TA701N0r7t//WJYb06JGkDAAAAAAAAbA/jJwAAAAAAaKSu/tsLcdf0V5K0F4weEs2alCVpAwAAAAAAAGwv4ycAAAAAAGhkamrrosvlE5K0z+y7X9zwqd5J2gAAAAAAAAA7yvgJAAAAAAAakcnz3oxzfzMjSfuRbx8flW12S9IGAAAAAAAA2BnGTwAAAAAA0Egcfu2D8faGmox3S0silowdnvEuAAAAAAAAwK4yfgIAAAAAgDz3+roP4qhxU5K0b/3M4fGx3vskaQMAAAAAAADsKuMnAAAAAADIY9c+MC9+9cTSJO351w2JivKyJG0AAAAAAACATDB+AgAAAACAPLS5ti4OunxCkvYnDt83bvr0YUnaAAAAAAAAAJlk/AQAAAAAAHlm6vxV8aVfP5ukPeU/j4vObXdP0gYAAAAAAADINOMnAAAAAADII/2unxyr361O0l42bniSLgAAAAAAAEAqxk8AAAAAAJAH3njngxgwdkqS9s2fPixOP3zfJG0AAAAAAACAlIyfAAAAAAAgx64fPy9+8fjSJO351w2JivKyJG0AAAAAAACA1IyfAAAAAAAgRzbX1sVBl09I0j6t9z5xy2cOT9IGAAAAAAAAyBbjJwAAAAAAyIFHF66OL/7qmSTtyd86Lg5qt3uSNgAAAAAAAEA2GT8BAAAAAECWHT1uSqxY90GS9rJxw5N0AQAAAAAAAHLB+AkAAAAAALLkzfUb46NjHk7S/sEZveOTR+yXpA0AAAAAAACQK8ZPAAAAAACQBd+bOD9++sjiJO2Xrh0SzZuWJWkDAAAAAAAA5JLxEwAAAAAAJFRbVx8HjqpK0h7Wa++47f8dkaQNAAAAAAAAkA+MnwAAAAAAIJFpi9bE5375dJL2Q988Nrq03yNJGwAAAAAAACBfGD8BAAAAAEACx94wNV5duyFJe9m44Um6AAAAAAAAAPnG+AkAAAAAADJo1bsbo//1Dydp3/CpQ+PMvh2TtAEAAAAAAADykfETAAAAAABkyE0PLohbprycpD3v2lOiRVP/WB8AAAAAAAAoLv6UFAAAAAAAdlFtXX0cOKoqSXtwj/bx8y/0TdIGAAAAAAAAyHfGTwAAAAAAsAueXLwmPvuLp5O0J11ybHTbe48kbQAAAAAAAIDGwPgJAAAAAAB20ok/eCQWr34/SXvZuOFJugAAAAAAAACNifETAAAAAADsoDXvVUff0ZOTtMd9olec1X//JG0AAAAAAACAxsb4CQAAAAAAdsAPH1oYP3p4UZL2i989JXZr5h/dAwAAAAAAAPyTP0EFAAAAAIDtUFdXH51HVSVpD+reLn51dr8kbdgldbURaxZGvD47YtW8iI3rIjZXR9RuiihrGtGkWURFq4h2PSL2OTyiTZeI0rIcHw0AAAAAAEAhMX4CAAAAAIBteHrJW/Hpnz+VpF31jWOixz57JmnDDquvj1g2LWJBVcSKWRErn4+o2bD9f3/5bhF794rYt09Et2ERlQMjSkrS3QsAAAAAAEDBM34CAAAAAIAGDLn5sZi/8t0k7aVjh0WJYQj54IN1EXP+GDHjl1ve9LSzat6PWP7Ulr+eui2iTdeIvl+O6H1WRPNWmboWAAAAAACAImL8BAAAAAAAH+Kt96rjiNGTk7RHn35IfO7IA5K0YYesXRIx7eaIuffu2BuetteahRETL4t4+LsRvc6IGHhJROvOmX8OAAAAAAAABcv4CQAAAAAA/pdbH14UP3hoF95+04AXvntK7N7MP54nx2o3R0y/NWLq2Ija6vTPq9kQMeuuLW+XOmFUxFEXRZSWpX8uAAAAAAAAjZ4/XQUAAAAAgP9SV1cfnUdVJWkf27Vt/Oac/knasENWL4i4//yIFTOz/+za6ojJV0e89EDE6bdFtO2W/RsAAAAAAABoVIyfAAAAAAAgIp5dtjbOuH16kvY/LhoYh+zbMkkbtltd3Za3PU25Pjtve2rIihkRtx8TMejyiAEXRZSW5vYeAAAAAAAA8pbxEwAAAAAARW/4LY/Hi6+vT9JeOnZYlJSUJGnDdqutibj/goi59+T6kv9RWx3x0FURK1/Y8haosvJcXwQAAAAAAEAeMn4CAAAAAKBovf3+pjj8uoeStK/9eM/4woDKJG3YITUbI+49O2LhhFxf8uHm3hNR/W7EGb+OKK/I9TUAAAAAAADkmdJcHwAAAAAAALlw2yMvJxs+zb1msOET+aG2Jr+HT/+0cELEfV/aci8AAAAAAAD8C29+AgAAAACgqNTX10enkVVJ2kcftFf87twjk7Rhh9XVRdx/Qf4Pn/5pQdWWe//jZxGl/v19AAAAAAAAbGH8BAAAAABA0Zj5ytvxyZ8+maT9wNcHRq/9WiZpw06ZfmvE3HtyfcWOmXtPxN69Io7+Rq4vAQAAAAAAIE8YPwEAAAAAUBRO/8kTMXv5uiTtpWOHRUlJSZI27JTVCyKmXJ/rK3bOlNERXU+JaNst15cAAAAAAACQB0pzfQAAAAAAAKS0bsOmqBwxPsnw6apTe8SyccMNn8gvtZsj7j8/orY615fsnNrqiPsviKirzfUlAAAAAAAA5AHjJwAAAAAACtbPH1sch137UJL2nKsHxzkDOyVpwy6Z/uOIFTNzfcWuWTEj4slbc30FAAAAAAAAeaBJrg8AAAAAAIBMq6+vj04jq5K0+3dqHfd8dUCSNuyytUsipo7J9RWZMXVMRI/TIlp3zvUlAAAAAAAA5JA3PwEAAAAAUFCee/XtZMOnv114tOET+W3azRG11bm+IjNqq7f8HgAAAAAAAIqaNz8BAAAAAFAwzrj9yXh22dtJ2kvHDouSkpIkbciID9ZFzL0311dk1tx7IwZfF1HRMteXAAAAAAAAkCPe/AQAAAAAQKP3zgc1UTlifJLh0xXDD45l44YbPpH/5vwxomZDrq/IrJoNW34XAAAAAAAARcubnwAAAAAAaNR+OW1pXPePeUnac64aHC1blCdpQ0bV10c8e0eur0jj2Tsi+p8XYYAIAAAAAABQlIyfAAAAAABolOrr66PTyKok7T77t4q/XHB0kjYksWxaxFuLcn1FGmsWRrzyRETlwFxfAgAAAAAAQA4YPwEAAAAA0OjMWb4uPv6TJ5K0/3LBUdFn/48kaUMyC9IMAfPG/CrjJwAAAAAAgCJl/AQAAAAAQKNy1s+nx1NL1iZpLx07LEpKSpK0IakVs3J9QVqvF/jvAwAAAAAAYKuMnwAAAAAAaBTWb6yJQ695MEn7siHd4/zjD0zShuTqaiNWPp/rK9J64/ktv7O0LNeXAAAAAAAAkGXGTwAAAAAA5L27nlwWV//9xSTt5648OT6yW9MkbciKNQsjajbk+oq0at6PWLMool33XF8CAAAAAABAlhk/AQAAAACQt+rr66PTyKok7UP3axl///rAJG3Iqtdn5/qC7HhjtvETAAAAAABAETJ+AgAAAAAgL72w4p049dZpSdr3fW1A9K1snaQNWbdqXq4vyI5i+Z0AAAAAAAD8G+MnAAAAAADyzud/+XQ8vmhNkvaSMcOitLQkSRtyYuO6XF+QHR+sy/UFAAAAAAAA5IDxEwAAAAAAeePdjTXR65oHk7S/c0q3uPCEg5K0Iac2V+f6guwolt8JAAAAAADAvzF+AgAAAAAgL9z91Ctx5f0vJGnPuvLkaL1b0yRtyLnaTbm+IDtqjZ8AAAAAAACKkfETAAAAAAA5VV9fH51GViVpH9xhz5hw8TFJ2pA3yopk2FfWLNcXAAAAAAAAkAPGTwAAAAAA5MyLr78Tw2+ZlqR9z1cHRP9OrZO0Ia80KZJRULH8TgAAAAAAAP6N8RMAAAAAADnxpTufiakLVidpLxkzLEpLS5K0Ie9UtMr1BdnRvFWuLwAAAAAAACAHjJ8AAAAAAMiq96s3R8+rJyVpf/OkrnHxSV2StCFvteuR6wuyo1h+JwAAAAAAAP/G+AkAAAAAgKz5wzOvxsi/zE3SnnHFSdFm92ZJ2pDX9jks1xdkR4fDcn0BAAAAAAAAOWD8BAAAAABAcvX19dFpZFWSdpd2u8dD3zouSRsahTZdI8pbRNRsyPUl6ZTvFtHGW90AAAAAAACKkfETAAAAAABJzV+5Pobc/HiS9h++cmQMOHCvJG1oNErLIvY+NGL5U7m+JJ0Oh275nQAAAAAAABQd4ycAAAAAAJI5964ZMfmlN5O0l4wZFqWlJUna0Ojs26ewx0/79Mn1BQAAAAAAAORIaa4PAAAAAACg8LxfvTkqR4xPMnz6xoldYtm44YZP8K+6Dcv1BWl1L/DfBwAAAAAAwFZ58xMAAAAAABn1p2dfjcv+PDdJ+9nLT4q2ezRL0oZGrXJgxF5dIt5alOtLMq9N14gDjs71FQAAAAAAAOSI8RMAAAAAABlTOWJ8km6nNrvF1G8fn6QNBaGkJKLfuRETL8v1JZnX79wtvw8AAAAAAICiVJrrAwAAAAAAaPwWvvlusuHT7879qOETbI/eZ0WUt8j1FZlV3mLL7wIAAAAAAKBoefMTAAAAAAC75PzfzowJL6xM0l48ZliUlXrjC2yX5q0iep0RMeuuXF+SOb3OiKhomesrAAAAAAAAyCFvfgIAAAAAYKd8sKk2KkeMTzJ8uuD4A2PZuOGGT7CjBl4SUdYs11dkRlmzLb8HAAAAAACAomb8BAAAAADADrtv5mtx8FUTk7SfGXViXDqke5I2FLzWnSNOGJXrKzLjhFFbfg8AAAAAAABFrUmuDwAAAAAAoHGpHDE+SXe/jzSPaZcNStKGojLg6xEv/T1ixcxcX7Lz9u0bcdRFub4CAAAAAACAPODNTwAAAAAAbJeXV72bbPj0m3P6Gz5BppQ1iTj9pxFlzXJ9yc4paxZx+m0RpWW5vgQAAAAAAIA84M1PAAAAAABs09d/Pyv+8fwbSdovXz80mpT5d3VBRrXtFjHo8oiHrsr1JTtu0BVb7gcAAAAAAIAwfgIAAAAAoAEba2qj+5UTk7S/elznGDn04CRtICIGXBSx8oWIuffk+pLt1+vMiAFfz/UVAAAAAAAA5BHjJwAAAAAAPtRfn3stvvmnOUnaT486MdrvWZGkDfyX0tKI02+LqH43YuGEXF+zbd2Gbbm31JvgAAAAAAAA+B/GTwAAAAAA/B+VI8Yn6e69Z0U8NerEJG3gQ5SVR5zx64h7z87vAVS3YRGfunPLvQAAAAAAAPAv/KvzAAAAAAD4b0tWv5ds+PTrL/UzfIJcKK+I+PTdEb3OzPUlH67XmRFn/mbLnQAAAAAAAPC/ePMTAAAAAAAREfHNP82Ovz63Ikn75euHRpMy/z4uyJmy8oj/+FnE3odETLk+orY61xdFlDWLGHRFxICvR5T67wcAAAAAAAA+nPETAAAAAECR21hTG92vnJik/eWBneLKU3skaQM7qLQ04uiLI7oOibj//IgVM3N3y759I06/LaJtt9zdAAAAAAAAQKNg/AQAAAAAUMT+NntFXPzH2Una00cOig4tmydpA7ugbbeIcx6MmP7jiKljsvsWqLJmEYMu/6+3PZVl77kAAAAAAAA0WsZPAAAAAABFqnLE+CTdNrs3jRlXnJykDWRIWZOIgZdE9DgtYtrNEXPvjajZkO555S0iep2x5ZmtO6d7DgAAAAAAAAXH+AkAAAAAoMgsW/N+HH/jI0navzq7bwzq3j5JG0igdeeI026JGHxdxJw/Rjx7R8SahZnrt+ka0e/ciN5nRVS0zFwXAAAAAACAomH8BAAAAABQRL5975y4b+ZrSdqLrh8a5WWlSdpAYhUtIz761Yj+50W88kTE/KqI12dFvDFnx94IVb5bRIdDI/bpE9F9WMQBR0eUlKS7GwAAAAAAgIJn/AQAAAAAUASqN9dGtysmJmmffVRlXHNazyRtIMtKSiIqB275KyKirjZizaKIN2ZHrJoX8cG6iM3VEbXVEWXNIpo0i2jeKqJdj4gOh0W06RJRWpa7+wEAAAAAACg4xk8AAAAAAAVu/PNvxIW/n5Wk/cSIQbFvq+ZJ2kAeKC2LaNd9y18AAAAAAACQA8ZPAAAAAAAF7KBRVbG5rj7j3ZbNy2PO1YMz3gUAAAAAAACAf1Wa6wOA7CspKcnpX5MnT871/wsAAAAACt4rb70flSPGJxk+/eILfQ2fAAAAAAAAAMgKb34CAAAAACgwI/78fPzx2eVJ2gtHD42mTfx7tQAAAAAAAADIDuMnAAAAAIACsWlzXXS9YkKS9ueO3D9Gn94rSRsAAAAAAAAAtsb4CQAAAACgAEx84Y342m9nJWk/fukJ0bF1iyRtAAAAAAAAAGiI8RMAAAAAQCN38JUT44Oa2ox3WzQti3nXDsl4FwAAAAAAAAC2l/ETAAAAAEAjtXzthjjmhqlJ2rd/rk8MOaRDkjYAAAAAAAAAbC/jJ+DffOxjH4vTTjst6TN69OiRtA8AAABQDC7/69z43dOvJmkvHD00mjYpTdIGAAAAAAAAgB1h/AT8mz59+sS5556b6zMAAAAA2IpNm+ui6xUTkrQ/079jjP3EoUnaAAAAAAAAALAzjJ8AAAAAABqJB19cGefdPTNJ+7HvnBD779UiSRsAAAAAAAAAdpbxEwAAAABAI9Drmknx7sbNGe82LSuNhdcPzXgXAAAAAAAAADLB+AkAAAAAII+99vaGGPi9qUnaP/lsnxh+aIckbQAAAAAAAADIBOMnAAAAAIA8dfXfXoi7pr+SpL1g9JBo1qQsSRsAAAAAAAAAMsX4CQAAAAAgz9TU1kWXyyckaZ9xxH7x/TN6J2kDAAAAAAAAQKYZPwEAAAAA5JGHX3ozvnzXjCTtR759fFS22S1JGwAAAAAAAABSMH4CAAAAAMgTR1z3ULz1/qaMd0tKIpaOHZ7xLgAAAAAAAACkZvwEAAAAAJBjr6/7II4aNyVJ+5bPHB6n9d4nSRsAAAAAAAAAUjN+AgAAAADIoWsfmBe/emJpkvb864ZERXlZkjYAAAAAAAAAZIPxEwAAAABADmyurYuDLp+QpP2Jw/eNmz59WJI2AAAAAAAAAGST8RMAAAAAQJZNXbAqvnTns0naU/7zuOjcdvckbQAAAAAAAADINuMnAAAAAIAsOnLMw7Fy/cYk7WXjhifpAgAAAAAAAECuGD8BW1VTUxOLFy+OV199NdauXRsbN26M8vLyaN68ebRq1Sr222+/6NixYzRv3jzXpwIAAADkvZXvbIwjxz6cpH3zpw+L0w/fN0kbAAAAAAAAAHLJ+An4N/PmzYtLL700pk6dGnPnzo3q6uoGv19aWhpdu3aNvn37xkknnRRDhw6Ndu3aZelaAAAAgMZhbNVL8bPHliRpz79uSFSUlyVpAwAAAAAAAECuGT8B/+bee+/doe/X1dXF/PnzY/78+fHb3/42SktLY8iQIfG1r30tTj311CgpKUl0KQAAAED+21xbFwddPiFJ+2O994lbP3N4kjYAAAAAAAAA5IvSXB8AFJa6urqoqqqK0047Lfr27RuTJ0/O9UkAAAAAOfHowtXJhk+Tv3Wc4RMAAAAAAAAARcH4CUhm1qxZcfLJJ8c555wT69evz/U5AAAAAFlz9Lgp8cVfPZOkvWzc8Dio3e5J2gAAAAAAAACQb5rk+gCg8N15553x1FNPxT/+8Y/o3Llzrs/ZLj/5yU/itttuS/6cxYsXJ38GAAAAkD2r1m+M/mMeTtK+8Yze8akj9kvSBgAAAAAAAIB8ZfwEZMVLL70UH/3oR+ORRx6Jnj175vqcbVq9enXMmzcv12cAAAAAjcgNE+fHbY+k+RedvHTtkGjetCxJGwAAAAAAAADymfET8N8OOeSQOOKII6JXr17Rq1ev6NixY7Rs2TJatmwZTZs2jbVr18Zbb70Vq1atiqeffjoeffTReOKJJ2L9+vXb1V+zZk2cfPLJ8cQTT0SnTp0S/xoAAACA7Kitq48DR1UlaQ/rtXfc9v+OSNIGAAAAAAAAgMbA+AmKWFlZWQwePDg+9rGPxfDhw2P//fdv8Pvt27eP9u3bR48ePeL444+Pyy67LDZu3Bh33XVX3HjjjfHyyy9v85lvvPFGfPKTn4wnn3wyKioqMvVTAAAAAHJi2qI18blfPp2k/dA3j40u7fdI0gYAAAAAAACAxqI01wcA2dehQ4e48sorY9myZVFVVRXnn3/+NodPW1NRURFf/epXY8GCBXHzzTdHeXn5Nv+e5557LkaNGrVTzwMAAADIF8d9f2qy4dOyccMNnwAAAAAAAAAgvPkJitKrr74aTZpk9j/+paWlcfHFF8eAAQPizDPPjFdeeaXB7996663xpS99KXr16pXROwAAAABSW/1udfS7fnKS9g2fPDTO7NcxSRsAAAAAAAAAGiPjJyhCmR4+/av+/fvHY489FgMHDozly5dv9XubN2+Oq666Kv76178mu2VXtG3bNnr06JH8OYsXL47q6urkzwEAAAAy46YHF8QtU15O0p537SnRoql/ZAsAAAAAAAAA/6qkvr6+PtdHAIVn1qxZcdRRRzU47CktLY358+dHly5dsnhZfunZs2fMmzfv//zfe/ToES+++GIOLgIAAAA+TG1dfRw4qipJ++Qe7eMXX+ibpA0AAAAAAABA4SjW//15aa4PAApTnz59YtSoUQ1+p66uLn77299m6SIAAACAnfPk4jXJhk8TLznG8AkAAAAAAAAAGmD8BCRz6aWXRrt27Rr8zn333ZelawAAAAB23Mk3PRqf/cXTSdrLxg2P7nvvmaQNAAAAAAAAAIXC+AlIpqKiIr72ta81+J158+bFqlWrsnQRAAAAwPZZ8151VI4YH4tWvZfx9thP9Ipl44ZnvAsAAAAAAAAAhcj4CUjqzDPP3OZ3pk+fnoVLAAAAALbPjyYvir6jJydpv/jdU+Iz/fdP0gYAAAAAAACAQmT8BCTVs2fPaNeuXYPfmT9/fpauAQAAANi6urr6qBwxPn44eWHG24O6t4tl44bHbs2aZLwNAAAAAAAAAIXM+AlI7vDDD2/w82XLlmXnEAAAAICteHrJW9F5VFWSdtU3jolfnd0vSRsAAAAAAAAACp1/zSiQXGVlZYOfr1q1KjuHAAAAAHyIITc/FvNXvpukvXTssCgpKUnSBgAAAAAAAIBiYPwEJNeyZcsGP9+wYUOWLgEAAAD4H2vf3xR9rnsoSXv06YfE5448IEkbAAAAAAAAAIqJ8ROQXNOmTRv8vKamJkuXAAAAAGzx4ymL4sYHFyZpz71mcOxRUZ6kDQAAAAAAAADFxvgJSO6DDz5o8PPmzZtn6RIAAACg2NXV1UfnUVVJ2sd0aRN3f/mjSdoAAAAAAAAAUKyMn4DkVq5c2eDnu+++e5YuAQAAAIrZjGVr41O3T0/S/sdFA+OQfVsmaQMAAAAAAABAMTN+ApJ7+eWXG/x83333zdIlAAAAQLH62K3TYu6Kd5K0l44dFiUlJUnaAAAAAAAAAFDsjJ+ApKqrq2P27NkNfqdTp07ZOQYAAAAoOm+/vykOv+6hJO3vntYzvnhUZZI2AAAAAAAAALCF8ROQ1MMPPxzV1dUNfufQQw/N0jUAAABAMbntkZfjhokLkrSfv2Zw7FlRnqQNAAAAAAAAAPwP4ycgqd/85jcNfl5eXh79+vXL0jUAAABAMaivr49OI6uStAd03iv+cN6RSdoAAAAAAAAAwP9l/AQks2jRorjvvvsa/M6xxx4bFRUVWboIAAAAKHQzX3k7PvnTJ5O0//71o+PQ/VolaQMAAAAAAAAAH874CUjmG9/4RtTW1jb4nTPPPDNL1wAAAACF7j9ueyKee3VdkvbSscOipKQkSRsAAAAAAAAA2DrjJyCJG2+8MSZOnNjgd/bcc8/49Kc/naWLAAAAgEL1zoaa6H3tg0naV53aI84Z2ClJGwAAAAAAAADYNuMnKBKzZs2Kgw8+OJo3b578WXfddVdceuml2/zeBRdcEC1btkx+DwAAAFC4fvHYkri+6qUk7TlXD46WzcuTtAEAAAAAAACA7VOa6wOA7PjNb34TBx54YNxyyy3x/vvvJ3nGpk2b4pJLLomzzz476uvrG/xu+/bt47LLLktyBwAAAFD46uvro3LE+CTDp/6VrWPZuOGGTwAAAAAAAACQB4yfoIi88cYbcfHFF0fHjh3jm9/8ZsyZMydj7UcffTQGDhwYP/rRj7br+7fccku0atUqY88HAAAAisfs5eui08iqJO37Lzw67vnagCRtAAAAAAAAAGDHNcn1AUD2vf3223HzzTfHzTffHF27do1TTz01Bg0aFAMGDIjWrVtvd2flypXx8MMPxy233BLPPPPMdv99F110UZx55pk7czoAAABQ5M64/cl4dtnbSdpLxw6LkpKSJG0AAAAAAAAAYOcYP0GRW7hwYdx0001x0003RUlJSXTs2DG6d+8elZWVsffee8dHPvKRaNasWURsGU299dZbsXr16nj66adj4cKFO/y8008/PW666aZM/wwAAACgwL3zQU30/u6DSdqXDzs4vnJs5yRtAAAAAAAAAGDXGD8B/62+vj5effXVePXVV5P0P/3pT8fdd98dTZr4rx4AAABg+/1q2tK49h/zkrTnXDU4WrYoT9IGAAAAAAAAAHadBQKQXFlZWYwePTpGjBiR61MAAACARqS+vj46jaxK0u6zf6v4ywVHJ2kDAAAAAAAAAJlj/AQk1a9fv/j5z38ehx12WK5PAQAAABqRua+9Ex/78bQk7b9ccFT02f8jSdoAAAAAAAAAQGYZP0GROPzww6Nz586xZMmSrDyvT58+MWrUqPjEJz4RJSUlWXkmAAAAUBg++4un4snFbyVpLx07zD+rAAAAAAAAAIBGxPgJisQXv/jF+OIXvxivvvpqTJ06NR577LGYMWNGvPTSS1FTU5ORZxx00EFx6qmnxuc///no06dPRpoAAABA8Vi/sSYOvebBJO3LhnSP848/MEkbAAAAAAAAAEjH+AmKzP777//fQ6iIiE2bNsULL7wQzz//fCxdujSWL18ey5cvjxUrVsT69evjgw8+iA0bNkR1dXU0bdo0KioqomXLltGhQ4fYb7/9onv37nHooYfGkUceGfvvv3+Ofx0AAADQWN315LK4+u8vJmk/d+XJ8ZHdmiZpAwAAAAAAAABpGT9BkWvatGn06dPHm5oAAACAnKivr49OI6uStHvt2zIeuGhgkjYAAAAAAAAAkB3GTwAAAABATryw4p049dZpSdr3fm1A9KtsnaQNAAAAAAAAAGSP8RMAAAAAkHWf/+XT8fiiNUnaS8YMi9LSkiRtAAAAAAAAACC7jJ8AAAAAgKx5r3pzHHL1pCTtbw/uGl8f1CVJGwAAAAAAAADIDeMnAAAAACArfvvUK3HF/S8kac+68uRovVvTJG0AAAAAAAAAIHeMnwAAAACApOrr66PTyKok7e577xETLzk2SRsAAAAAAAAAyD3jJwAAAAAgmXmvr49htzyepP2n846Mj3beK0kbAAAAAAAAAMgPxk8AAAAAQBJfuvOZmLpgdZL2kjHDorS0JEkbAAAAAAAAAMgfxk8AAAAAQEa9X705el49KUn7kpO6xCUndU3SBgAAAAAAAADyj/ETAAAAAJAxf3jm1Rj5l7lJ2jOuOCna7N4sSRsAAAAAAAAAyE/GTwAAAADALquvr49OI6uStA9qt3tM/tZxSdoAAAAAAAAAQH4zfgIAAAAAdsmCle/GKTc/lqT9h68cGQMO3CtJGwAAAAAAAADIf8ZPAAAAAMBOO+83M+LBeW8maS8eMyzKSkuStAEAAAAAAACAxsH4CQAAAADYYRs2bY4eV01K0v7GoIPiW4O7JWkDAAAAAAAAAI2L8RMAAAAAsEPueXZ5XPrn55O0n738pGi7R7MkbQAAAAAAAACg8TF+AgAAAAC2W+WI8Wm6e7WIR75zQpI2AAAAAAAAANB4GT8BAAAAANu06M134+QfPpak/btzPxpHH9QmSRsAAAAAAAAAaNyMnwAAAACABl3wu5lRNXdlkvbiMcOirLQkSRsAAAAAAAAAaPyMnwAAAACAD/XBpto4+KqJSdrnH39gXDake5I2AAAAAAAAAFA4jJ8AAAAAgP/jzzNfi/+8d06S9jOjTox2e1YkaQMAAAAAAAAAhcX4CQAAAAD4N5Ujxifp7tuqeTwxYlCSNgAAAAAAAABQmIyfAAAAAICIiHh51Xtx0k2PJmn/5pz+cWzXtknaAAAAAAAAAEDhMn4CAAAAAOKiPzwXD8x5PUn75euHRpOy0iRtAAAAAAAAAKCwGT8BAAAAQBHbWFMb3a+cmKT91WM7x8hhBydpAwAAAAAAAADFwfgJAAAAAIrU/c+tiEv+NDtJ+6mRJ8beLSuStAEAAAAAAACA4mH8BAAAAABFqHLE+CTd9ns2i6dHnZSkDQAAAAAAAAAUH+MnAAAAACgiS1a/F4N+8GiS9p1f6hcndGuXpA0AAAAAAAAAFCfjJwAAAAAoEt/60+z4y3MrkrRfvn5oNCkrTdIGAAAAAAAAAIqX8RMAAAAAFLiNNbXR/cqJSdpfHtgprjy1R5I2AAAAAAAAAIDxEwAAAAAUsAfmvB4X/eG5JO0nRwyKfVo1T9IGAAAAAAAAAIgwfgIAAACAgtVp5Pior898d6/dmsbMK0/OfBgAAAAAAAAA4H8xfgIAAACAArNszftx/I2PJGn/8ot948SD2ydpAwAAAAAAAAD8b8ZPAAAAAFBAvnPvnLh35mtJ2ouuHxrlZaVJ2gAAAAAAAAAAH8b4CQAAAAAKQPXm2uh2xcQk7bOPqoxrTuuZpA0AAAAAAAAA0BDjJwAAAABo5KrmvhEX/G5WkvYTIwbFvq2aJ2kDAAAAAAAAAGyL8RMAAAAANGJdr5gQmzbXZby7Z0WTeP6aUzLeBQAAAAAAAADYEcZPAAAAANAIvfrWhjj2+1OTtH/++SNicM+9k7QBAAAAAAAAAHaE8RMAAAAANDIj//J8/OGZ5UnaC0cPjaZNSpO0AQAAAAAAAAB2lPETAAAAADQSmzbXRdcrJiRpf+7I/WP06b2StAEAAAAAAAAAdpbxEwAAAAA0AhNfWBlf++3MJO3HLz0hOrZukaQNAAAAAAAAALArjJ8AAAAAIM/1uGpibNhUm/Fu8/KyeOm6IRnvAgAAAAAAAABkivETAAAAAOSp5Ws3xDE3TE3S/un/6xNDe3VI0gYAAAAAAAAAyBTjJwAAAADIQ1fe/0Lc/dQrSdoLRg+JZk3KkrQBAAAAAAAAADLJ+AkAAAAA8khNbV10uXxCkvZZ/TrGuE8emqQNAAAAAAAAAJCC8RMAAAAA5IkHX1wZ5909M0n70e8cHwfstVuSNgAAAAAAAABAKsZPAAAAAJAHDr1mUqzfuDnj3fKyklh0/bCMdwEAAAAAAAAAssH4CQAAAABy6LW3N8TA701N0v7JZ/vE8EM7JGkDAAAAAAAAAGSD8RMAAAAA5Mg1f38xfv3ksiTtBaOHRLMmZUnaAAAAAAAAAADZYvwEAAAAAFlWU1sXXS6fkKT9qSP2ixvP6J2kDQAAAAAAAACQbcZPAAAAAJBFU+a/Gef8ekaS9iPfPj4q2+yWpA0AAAAAAAAAkAvGTwAAAACQJX1HPxRr3tuUpL1s3PAkXQAAAAAAAACAXDJ+AgAAAIDE3njngxgwdkqS9i2fOTxO671PkjYAAAAAAAAAQK4ZPwEAAABAQqP/MS/umLY0SXv+dUOiorwsSRsAAAAAAAAAIB8YPwEAAABAAptr6+Kgyyckaf/H4fvGDz99WJI2AAAAAAAAAEA+MX4CAAAAgAx7ZMGqOPvOZ5O0p/zncdG57e5J2gAAAAAAAAAA+cb4CQAAAAAy6MgxD8fK9RuTtJeNG56kCwAAAAAAAACQr4yfAAAAACADVr6zMY4c+3CS9g8/3Tv+4/D9krQBAAAAAAAAAPKZ8RMAAAAUs7raiDULI16fHbFqXsTGdRGbqyNqN0WUNY1o0iyiolVEux4R+xwe0aZLRGlZjo+G/DO26qX42WNLkrTnXzckKsr95w4AAAAAAAAAKE7GTwAAAFBM6usjlk2LWFAVsWJWxMrnI2o2bP/fX75bxN69IvbtE9FtWETlwIiSknT3Qp6rrauPA0dVJWmfemiH+PFn+yRpAwAAAAAAAAA0FsZPAAAAUAw+WBcx548RM3655U1PO6vm/YjlT23566nbItp0jej75YjeZ0U0b5Wpa6FReHzR6vj8L59J0p78rWPjoHZ7JGkDAAAAAAAAADQmxk8AAABQyNYuiZh2c8Tce3fsDU/ba83CiImXRTz83YheZ0QMvCSidefMPwfyzMDvTYnX3v4gSXvZuOFJugAAAAAAAAAAjZHxEwAAABSi2s0R02+NmDo2orY6/fNqNkTMumvL26VOGBVx1EURpWXpnwtZtmr9xug/5uEk7RvP6B2fOmK/JG0AAAAAAAAAgMbK+AkAAAAKzeoFEfefH7FiZvafXVsdMfnqiJceiDj9toi23bJ/AyTy/Unz4ydTFydpv3TtkGje1GAQAAAAAAAAAOB/M34CAACAQlFXt+VtT1Ouz87bnhqyYkbE7cdEDLo8YsBFEaWlub0HdkFtXX0cOKoqSXvoIXvHTz93RJI2AAAAAAAAAEAhMH4CAACAQlBbE3H/BRFz78n1Jf+jtjrioasiVr6w5S1QZeW5vgh22BMvr4n/d8fTSdoPfvPY6Np+jyRtAAAAAAAAAIBCYfwEAAAAjV3Nxoh7z45YOCHXl3y4ufdEVL8bccavI8orcn0NbLcTbnwklq55P0l72bjhSboAAAAAAAAAAIWmNNcHAAAAALugtia/h0//tHBCxH1f2nIv5LnV71ZH5YjxSYZPN3zyUMMnAAAAAAAAAIAdYPwEAAAAjVVdXcT9F+T/8OmfFlRtubeuLteXwFbd9OCC6Hf95CTtedeeEmf265ikDQAAAAAAAABQqJrk+gAAAABgJ02/NWLuPbm+YsfMvSdi714RR38j15fAv6mrq4/Oo6qStE86uH3c8cW+SdoAAAAAAAAAAIXO+AkAAAAao9ULIqZcn+srds6U0RFdT4lo2y3Xl0BERExf/FZ85hdPJWlPvOSY6L73nknaAPx/9u47zMr6zv//e2YoI0UQEbtioYhiAUSlqChNTIyJNUVN1JjYoinGXrCSdWNsqNmY2BJrYnSNCqhgQTE0QRQBRbAgoog0kWGYOb8/2O9vN7s6tPsz58w5j8d1+dc5ed7vs9fuXtGLlzcAAAAAAABQCoyfAAAAoKGpWR3x2OkRNVX5vmTD1FRFPHZGxCmjIsor8n0NJW7g716IWQuWJ2nPuW5IlJWVJWkDAAAAAAAAAJSK8nwfAAAAAKyncbdGzJuU7ys2zryJEa/cku8rKGELl1dF+wueTDJ8uvbbXWPusMMNnwAAAAAAAAAAMuDNTwAAANCQLHo3Ysy1+b4iG2OujehyRESbnfN9CSXm5ufejhuemZWk/cbQQdGiqX/kBgAAAAAAAACQFX8SAwAAABqSsTdG1FTl+4ps1FSt+T1H3JzvSygRtbW52Pmip5K0+3XaIu76Uc8kbQAAAAAAAACAUlae7wMAAACAdfTl4ohpj+T7imxNeyRi5ZJ8X0EJGD9nUbLh01M/62v4BAAAAAAAAACQiDc/AQAAQEMx9cGI6hX5viJb1SvW/K79fpLvSyhiQ256KabPX5qkPee6IVFWVpakDQAAAAAAAACANz8BAABAw5DLRUy4M99XpDHhzjW/DzK26ItV0f6CJ5MMn646co+YO+xwwycAAAAAAAAAgMS8+QkAAAAagrljIz57O99XpLFwVsR7L0e075PvSygiw8e8E9ePnJmkPe2KgdGysnGSNgAAAAAAAAAA/8r4CQAAABqCmU/l+4K0Zjxl/EQmamtzsfNFaf7vpW+HtnHfKfslaQMAAAAAAAAA8NWMnwAAAKAhmDc53xek9VGR/z7qxcS5i+LoO8Ylaf/j7D6xx7atkrQBAAAAAAAAAPh6xk8AAABQ6GprIj5+Pd9XpDX/9TW/s7wi35fQQB1x69h4/cMlSdpzrhsSZWVlSdoAAAAAAAAAANTN+AkAAAAK3cJZEdUr8n1FWtVfRCx8O6Jd53xfQgOzeMWq2PvKZ5K0r/hml/hh752StAEAAAAAAAAAWDfGTwAAAFDoPpqS7wvqx/wpxk+slztemB3Dnp6RpP36FQNj08rGSdoAAAAAAAAAAKw74ycAAAAodJ9Mz/cF9aNUficbLZfLxU4XPpWkvf/ObeLB0w5I0gYAAAAAAAAAYP0ZPwEAAEChW7k43xfUjy8X5/sCGoDJ738e37ntlSTt/zyrd+y5XeskbQAAAAAAAAAANozxEwAAABS61VX5vqB+lMrvZIN957aXY/L7i5O051w3JMrKypK0AQAAAAAAAADYcMZPAAAAUOhqVuX7gvpRY/zEV1uyojr2unJUkval3+gSp/TZKUkbAAAAAAAAAICNZ/wEAAAAha6iSb4vqB8VTfN9AQXozpfejauffCtJe+rlA6PVJo2TtAEAAAAAAAAAyIbxEwAAABS6RiUyCiqV38k6yeVysdOFTyVp79t+s3jkp72StAEAAAAAAAAAyJbxEwAAABS6ytb5vqB+bNI63xdQIKZ8sDiOHP5ykvbfz+gV++ywWZI2AAAAAAAAAADZM34CAACAQteuS74vqB+l8jup07F3jIvxcxclac+5bkiUlZUlaQMAAAAAAAAAkIbxEwAAABS6bfbO9wX1Y+u9830BebTky+rYa+ioJO2LhnSO0w7cJUkbAAAAAAAAAIC0jJ8AAACg0LXtGNG4WUT1inxfkk7j5hFtO+T7CvLkT2PnxJX/mJ6kPeWyAdG6WZMkbQAAAAAAAAAA0jN+AgAAgEJXXhGx1Z4RH7ya70vS2XrPNb+TkpLL5WKnC59K0t5nh9bx9zN6J2kDAAAAAAAAAFB/jJ8AAACgIdi2W3GPn7bplu8LqGfTPlwS37x1bJL2307vFd133CxJGwAAAAAAAACA+mX8BAAAAA1BpyERr96W7yvS6Twk3xdQj75/56vx8jufJWnPuW5IlJWVJWkDAAAAAAAAAFD/jJ8AAACgIWjfJ2LzDhGfvZ3vS7LXtmPEjr3zfQX1YNnK6uh6xagk7fMHd47TD94lSRsAAAAAAAAAgPwpz/cBAAAAwDooK4vY99R8X5HGvqeu+X0UtXvHzU02fHrt0gGGTwAAAAAAAAAARcqbnwAAAKCh2Ov4iOeGRlSvyPcl2WncbM3vomjlcrnY6cKnkrT32HbT+MfZfZO0AQAAAAAAAAAoDN78BAAAAA3FJq0juh6T7yuy1fWYiMpW+b6CRN6YtyTZ8OmRnx5g+AQAAAAAAAAAUAK8+QkAAAAakj7nRkx9MKKmKt+XbLyKpmt+D0XpxD+NjxdnfZqk/e61Q6K8vCxJGwAAAAAAAACAwuLNTwAAANCQtNk5ot9F+b4iG/0uWvN7KCrLq1ZH+wueTDJ8+tXAjjF32OGGTwAAAAAAAAAAJcSbnwAAAKChOeCsiLf+M2LepHxfsuG27RHR6+x8X0HG/vzqe3HJY28kaU+6pH9s3qJpkjYAAAAAAAAAAIXL+AkAAAAamopGEUfeHnFH34iaqnxfs/4qmkYceVtEeUW+LyEjuVwudrrwqSTtzlu1jBHnHpikDQAAAAAAAABA4SvP9wEAAADABtiiU8QhF+f7ig1zyCVr7qcoTP9oabLh04On7W/4BAAAAAAAAABQ4rz5CQAAABqqA86O+PiNiGkP5/uSddf12IgDzsr3FWTklLsnxHMzPknSfvfaIVFeXpakDQAAAAAAAABAw2H8BAAAAA1VeXnEkbdFVC2LmPV0vq9Zu05D1txb7kXUDd0XVatj98tHJmmfc2iH+PmAjknaAAAAAAAAAAA0PP60EQAAADRkFY0jjrk7ouNh+b6kbp2GRBx915p7adAeGP9+suHTxEv6Gz4BAAAAAAAAAPAvvPkJAAAAGrrGlRHH3Rfx2BkR0x7O9zX/V9dj17zxyfCpwWt/wZNJuru2axHP/uKgJG0AAAAAAAAAABo24ycAAAAoBhWNI779+4it9ogYfU1ETVW+L4qoaBpxyCURB5wVUe7l0w3ZzI+XxaAbX0zSvv/H+0WvXdomaQMAAAAAAAAA0PAZPwEAAECxKC+P6H1ORMfBEY+dHjFvUv5u2bbHmrc9bdEpfzeQidPunRijpi9I0p597ZCoKC9L0gYAAAAAAAAAoDgYPwEAAECx2aJTxMmjIsbdGjHm2vp9C1RF04hDLv6vtz1V1N9zydyKVaujy2Ujk7TPPmTX+OVAwzgAAAAAAAAAANbO+AkAAACKUUWjiD7nRnQ5ImLsjRHTHomoXpHueY2bRXQ9Zs0z2+yc7jnUi4cnfhC//uvrSdrjLz402rWsTNIGAAAAAAAAAKD4GD8BAABAMWuzc8QRN0cMvCpi6oMRE+6MWDgru37bjhH7nhqx1/ERla2y65I37S94Mkl3x82bxQvn9UvSBgAAAAAAAACgeBk/AQAAQCmobBWx308iep4W8d7LETOeivhocsT8qev3RqjGzSO23jNim24RnYdE7Ng7oqws3d3Um7cXLIsBv3sxSfvPp+wXfTq0TdIGAAAAAAAAAKC4GT8BAABAKSkri2jfZ81fERG1NREL346YPyXik+kRXy6OWF0VUVMVUdE0olHTiE1aR7TrErH13hFtO0SUV+TvfpI48y+T48lp85O0Z187JCrKDeQAAAAAAAAAANgwxk8AAABQysorItp1XvMXJefLVTWx22UjkrRPP3iXOH+w/70CAAAAAAAAAGDjGD8BAAAAlKBHJ38Yv3h4apL2+IsOjXabViZpAwAAAAAAAABQWoyfAAAAAEpM+wueTNLdtvUm8fIFhyRpAwAAAAAAAABQmoyfAAAAAErEO58sj/43vJCkfc/JPeOgjlskaQMAAAAAAAAAULqMnwAAAABKwM8eeC3+c+pHSdrvXHNYNKooT9IGAAAAAAAAAKC0GT8BAAAAFLGV1TXR+dIRSdqnHbhzXDRktyRtAAAAAAAAAACIMH4CAAAAKFqPT5kX5zw4JUn71QsPja1aVSZpAwAAAAAAAADA/2P8BAAAAFCE2l/wZJJuu5ZNY/zF/ZO0AQAAAAAAAADgfzN+AgAAACgi7366PA757QtJ2nf9cN/o17ldkjYAAAAAAAAAAHwV4ycAAACAIvGLh6bEo6/NS9J+55rDolFFeZI2AAAAAAAAAAB8HeMnAAAAgAZuZXVNdL50RJL2yb13isu+2SVJGwAAAAAAAAAA1sb4CQAAAKABe2LqR3H2A68lab9ywSGxTetNkrQBAAAAAAAAAGBdGD8BAAAANFA7X/hk1Oay77Zp3iQmXzog+zAAAAAAAAAAAKwn4ycAAACABmbuwi/i4H9/Pkn7zhN7RP8uWyZpAwAAAAAAAADA+jJ+AgAAAGhAzntkajwy6cMk7bevOSwaV5QnaQMAAAAAAAAAwIYwfgIAAABoAKpW10SnS0YkaZ90wI4x9Ft7JGkDAAAAAAAAAMDGMH4CAAAAKHBPTZsfZ/xlcpL22PP7xXabNUvSBgAAAAAAAACAjWX8BAAAAFDAOl7ydKxaXZt5t2Vlo5h2xaDMuwAAAAAAAAAAkCXjJwAAAIAC9MGiFdH338Ykaf/+hO4xaPetkrQBAAAAAAAAACBLxk8AAAAABebCR6fFA+PfT9KedfVh0aRReZI2AAAAAAAAAABkzfgJAAAAoECsWl0bHS95Okn7+/vtENd8u2uSNgAAAAAAAAAApGL8BAAAAFAARrzxcfz0z5OStF/6db/Yvk2zJG0AAAAAAAAAAEjJ+AkAAAAgz/a4fGQsr1qdebeycXnMuOqwzLsAAAAAAAAAAFBfjJ8AAAAA8uTDz1dEn9+MSdK+/fvd4rCuWydpAwAAAAAAAABAfTF+AgAAAMiDSx97I+579b0k7ZlXD46mjSqStAEAAAAAAAAAoD4ZPwEAAADUo+qa2uhw8dNJ2sfvu30MO2rPJG0AAAAAAAAAAMgH4ycAAACAevLM9AXx43snJmm/cN7BsePmzZO0AQAAAAAAAAAgX4yfAAAAAOrB3leOisUrqjPvVpSXxexrh2TeBQAAAAAAAACAQmD8BAAAAJDQvMVfRu9ho5O0b/3ePvGNPbdJ0gYAAAAAAAAAgEJg/AQAAACQyBX/+Wbc/crcJO0ZVw2OysYVSdoAAAAAAAAAAFAojJ8AAAAAMlZdUxsdLn46SfuobtvFb4/dK0kbAAAAAAAAAAAKjfETAAAAQIZGz1gQJ989MUl7zK8Ojp3aNk/SBgAAAAAAAACAQmT8BAAAAJCRHlc/GwuXVyVpzx12eJIuAAAAAAAAAAAUMuMnAAAAgI00f8mXccB1o5O0b/7uPnHEXtskaQMAAAAAAAAAQKEzfgIAAADYCNc8OT3+8NKcJO0ZVw2OysYVSdoAAAAAAAAAANAQGD8BAAAAbIDVNbWx68VPJ2kfufc2cePx+yRpAwAAAAAAAABAQ2L8BAAAALCenp/5SfzwrglJ2s/98qDYZYsWSdoAAAAAAAAAANDQGD8BAAAArIdfPjw1/jb5wyTtucMOT9IFAAAAAAAAAICGyvgJAAAAYB0sWVEde105Kkn7d8ftFd/eZ7skbQAAAAAAAAAAaMiMnwAAAADW4rHX5sW5D01J0p5x1eCobFyRpA0AAAAAAAAAAA2d8RMAAADA16itzUW/3z4f7322IvP2N/bcOm79XrfMuwAAAAAAAAAAUEyMnwAAAAC+wlvzl8ZhN72UpP3sLw6MXdu1TNIGAAAAAAAAAIBiYvwEAAAA8L9c9vgbce+495K05w47PEkXAAAAAAAAAACKkfETAAAAwH9ZsqI69rpyVJL2vx+zVxzdfbskbQAAAAAAAAAAKFbGTwAAAAAR8Z9TP4qfPfBakvb0KwdFsyb+MQwAAAAAAAAAAKwvf+oGAAAAKGm1tbnof8ML8e7CLzJvD959q7jjhO6ZdwEAAAAAAAAAoFQYPwEAAAAla+bHy2LQjS8maY/6+YHRccuWSdoAAAAAAAAAAFAqjJ8AAACAkjT0iTfjrpfnJmnPHXZ4ki4AAAAAAAAAAJQa4ycAAACgpCxdWR17XjEqSfv+U/eLXru2TdIGAAAAAAAAAIBSZPwEAAAAlIx/vP5RnHX/a0naM64aHJWNK5K0AQAAAAAAAACgVBk/AQAAAEWvtjYXA298Md75ZHnm7fMHd47TD94l8y4AAAAAAAAAAGD8BAAAABS5WQuWxcDfvZikPfb8frHdZs2StAEAAAAAAAAAAOMnAAAAoIhd/Y/pcefYOZl3+3ZoG/ee3DPKysoybwMAAAAAAAAAAP/N+AkAAAAoOstWVkfXK0Ylaf/5lP2iT4e2SdoAAAAAAAAAAMC/Mn4CAAAAisrT0+bH6X+ZnKQ946rBUdm4IkkbAAAAAAAAAAD4v4yfAAAAgKKQy+XisJteihkfL8u8fd6gTnFmv10z7wIAAAAAAAAAAHUzfgIAAAAavHc+WRb9b3gxSfulX/eL7ds0S9IGAAAAAAAAAADqZvwEAAAANGjXPfVW/P7FdzPv9t518/jzKftFWVlZ5m0AAAAAAAAAAGDdGD8BAAAADdLyqtWxx+Ujk7TvOblnHNRxiyRtAAAAAAAAAABg3Rk/AQAAAA3OiDc+jp/+eVKS9oyrBkdl44okbQAAAAAAAAAAYP0YPwEAAAANRi6Xi2/eOjbemLc08/YvB3SMsw/tkHkXAAAAAAAAAADYcMZPAAAAQIMw+9PlcehvX0jSfunX/WL7Ns2StAEAAAAAAAAAgA1n/AQAAAAUvN+MmBG3Pz87827PndrEQ6ftH2VlZZm3AQAAAAAAAACAjWf8BAAAABSsL6pWx+6Xj0zSvutH+0a/Tu2StAEAAAAAAAAAgGwYPwEAAAAF6ZnpC+LH905M0n7rysGxSZOKJG0AAAAAAAAAACA7xk8AAABAQcnlcnHk8Jdj6odLMm+f279DnNu/Y+ZdAAAAAAAAAAAgDeMnAAAAoGDMWfhF9Pv355O0Xzjv4Nhx8+ZJ2gAAAAAAAAAAQBrGTwAAAEBB+O2omXHL6Hcy73bfcbP4608PiLKysszbAAAAAAAAAABAWsZPAAAAQF6tWLU6ulw2Mkn7Tz/sEYd03jJJGwAAAAAAAAAASM/4CQAAAMib595aEKfcMzFJe/qVg6JZE//oAwAAAAAAAAAAGjJ/AggAAACod7lcLo66/ZWY/P7izNs/O2TX+MXATpl3AQAAAAAAAACA+mf8BAAAANSruQu/iIP//fkk7TG/Ojh2ats8SRsAAAAAAAAAAKh/xk8AAABAvbnhmVlx83NvZ97dZ4fW8ejpvaKsrCzzNgAAAAAAAAAAkD/GTwAAAEByX66qid0uG5Gk/YcTe8SALlsmaQMAAAAAAAAAAPll/AQAAAAkNWbGJ/Gjuyckab85dFA0b+ofbwAAAAAAAAAAQLHyp4MAAACAJHK5XBz7+3ExYe7nmbfPOHiX+PXgzpl3AQAAAAAAAACAwmL8BAAAAGTu/c9WxIHXj0nSHv3Lg2LnLVokaQMAAAAAAAAAAIXF+AkAAADI1M3PvR03PDMr8+6e27WKx8/sHWVlZZm3AQAAAAAAAACAwmT8BAAAAGTiy1U1sdtlI5K0f39C9xi0+1ZJ2gAAAAAAAAAAQOEyfgIAAAA22guzPo2T/jQ+SfuNoYOiRVP/CAMAAAAAAAAAAEqRPzkEAAAAbLBcLhff+8M/Y9y7n2Xe/slBO8eFh+2WeRcAAAAAAAAAAGg4jJ8AAACADfLBohXR99/GJGk/+4uDYtd2LZK0AQAAAAAAAACAhsP4CQAAAFhvw8e8E9ePnJl5t8vWm8aTP+sTZWVlmbcBAAAAAAAAAICGx/gJAAAAWGcrq2ui86UjkrTv+EG3GLzH1knaAAAAAAAAAABAw2T8BAAAAKyTl97+NE744/gk7WlXDIyWlY2TtAEAAAAAAAAAgIbL+AkAAACoUy6XixP+OD7GvrMw8/aP++4UFx/eJfMuAAAAAAAAAABQHIyfAAAAgK/14ecros9vxiRpP/PzA6PDli2TtAEAAAAAAAAAgOJg/AQAAAB8pdufnx2/GTEj826nLVvG0+f0jfLysszbAAAAAAAAAABAcTF+AgAAAP7Fyuqa6HzpiCTt4d/rFofvuXWSNgAAAAAAAAAAUHyMnwAAAID/38vvLIzv3/nPJO3XrxgYm1Y2TtIGAAAAAAAAAACKk/ETAAAAEBERJ/5pfLw469PMuz/q3T4u/+bumXcBAAAAAAAAAIDiZ/wEAAAAJe6jxV9Gr2Gjk7RHnntgdNqqZZJ2waitiVg4K+KjKRGfTI9YuThidVVEzaqIiiYRjZpGVLaOaNclYpt9Itp2iCivyPPRAAAAAAAAAADQMBg/AQAAQAn7jxdnx7VPzci8u8sWzeOZnx8U5eVlmbfzLpeLmDs2YuZTEfMmR3z8ekT1inX/zzduHrFV14htu0V0GhLRvk9EWRH+zwkAAAAAAAAAADJg/AQAAAAlqGp1TXS+dETkctm3b/7uPnHEXttkH863LxdHTH0wYuIf17zpaUNVfxHxwatr/nr1toi2HSN6nBKx1/ERm7TO6loAAAAAAAAAACgKxk8AAABQYsbN/iy++4dXk7SnXj4wWm3SOEk7bxa9GzH2xohpj6zfG57W1cJZESPOj3huaETXYyL6nBvRZufsnwMAAAAAAAAAAA2Q8RMAAACUkFPunhDPzfgk8+4Pe7WPK47YPfNuXtWsjhh3S8SY6yJqqtI/r3pFxOR71rxdqt9FEb3OjiivSP9cAAAAAAAAAAAoYMZPAAAAUALmL/kyDrhudJL2iHP7RuetNk3SzptPZ0Y8dnrEvEn1/+yaqohnL49464mII2+L2KJT/d8AAAAAAAAAAAAFojzfBwAAAABp3fnSu0mGT+03bxbvXjukuIZPtbURL98UcUff/Ayf/qd5E9fc8fJNa+4CAAAAAAAAAIAS5M1PAAAAUKSqVtfEHpePjOqaXObtm47fO76197aZd/OqpjrisTMipj2c70v+W01VxDOXRXz8xpq3QFU0zvdFAAAAAAAAAABQr4yfAAAAoAj9893P4rj/eDVJe+plA6NVsyIb4VSvjHjkhxGzns73JV9t2sMRVcsijrk7onFlvq8BAAAAAAAAAIB6U57vAwAAAIBsnXbvxCTDpx/sv0PMHXZ48Q2faqoLe/j0/8x6OuKvP1pzLwAAAAAAAAAAlAhvfgIAAIAisWDpytjv2ueStJ/6Wd/oss2mSdp5VVsb8dgZhT98+n9mPrXm3m//PqLcv9MGAAAAAAAAAIDi50/JAAAAQBG46+U5SYZP2222Scy+dkhxDp8iIsbdEjHt4XxfsX6mPRwx7tZ8XwEAAAAAAAAAAPXCm58AAACgAVu1ujb2HDoyVlbXZt6+4di94jvdtsu8WzA+nRkx+pp8X7FhRl8d0XFQxBad8n0JAAAAAAAAAAAk5c1PAAAA0EBNmLsoOl7ydJLh05TLBhT38KlmdcRjp0fUVOX7kg1TUxXx2BkRtTX5vgQAAAAAAAAAAJIyfgIAAIAG6PQ/T4pj7hiXefe7PbePucMOj9bNmmTeLijjbo2YNynfV2yceRMjXrkl31cAAAAAAAAAAEBSjfJ9AAAAALDuPlm6Mnpe+1yS9j/O7hN7bNsqSbugLHo3Ysy1+b4iG2OujehyRESbnfN9CQAAAAAAAAAAJOHNTwAAANBA3DtubpLh09atKmP2tUNKY/gUETH2xoiaqnxfkY2aqjW/BwAAAAAAAAAAipQ3PwEAAECBq66pjb2HjoovVtVk3r7+6D3jmB7bZ94tWF8ujpj2SL6vyNa0RyIGXhVRWSLjNQAAAAAAAAAASoo3PwEAAEABm/Teouhw8dNJhk+TLx1QWsOniIipD0ZUr8j3FdmqXrHmdwEAAAAAAAAAQBEyfgIAAIACddb9k+Oo28dl3j22x3Yxd9jh0aZ5k8zbBS2Xi5hwZ76vSGPCnWt+HwAAAAAAAAAAFJlG+T4AAAAA+FefLFsZPa95Lkn7ibP6RNftWiVpF7y5YyM+ezvfV6SxcFbEey9HtO+T70sAAAAAAAAAACBT3vwEAAAABeS+V99LMnxq17JpzL52SOkOnyIiZj6V7wvSmlHkvw8AAAAAAAAAgJLkzU8AAABQAKpraqP7Vc/E0pWrM2//5qiucdy+O2TebXDmTc73BWl9VOS/DwAAAAAAAACAkmT8BAAAAHk2+f3P4zu3vZKkPemS/rF5i6ZJ2g1KbU3Ex6/n+4q05r++5neWV+T7EgAAAAAAAAAAyIzxEwAAAOTROQ++Fo9P+Sjz7ne6bRs3HLt35t0Ga+GsiOoV+b4ireovIha+HdGuc74vAQAAAAAAAACAzBg/AQAAQB4sXF4VPa5+Nkn78TN7x17bt07SbrA+mpLvC+rH/CnGTwAAAAAAAAAAFBXjJwAAAKhnD4x/Py58dFrm3bYtmsSrFx4ajSrKM283eJ9Mz/cF9aNUficAAAAAAAAAACXD+AkAAADqyeqa2uh57XOx6ItVmbev+07X+G7PHTLvFo2Vi/N9Qf34cnG+LwAAAAAAAAAAgEwZPwEAAEA9mPrB4vjW8JeTtCde0j/atmiapF00Vlfl+4L6USq/EwAAAAAAAACAkmH8BKyTqqqqmDVrVnz44YexbNmyWLFiRTRr1ixatmwZ2223XXTq1CmaNGmS7zMBAKAg/eLhKfHo5HmZd4/ce5u48fh9Mu8WpZrs37ZVkGqMnwAAAAAAAAAAKC7GT8DXevXVV+Oxxx6Lp59+Ot58882oqan52u9WVFTE7rvvHkOGDIlvfetbsf/++9fjpQAAUJg+W14V3a9+Nkn70TN6RbcdNkvSLkoVJfIva6jwBjAAAAAAAAAAAIqL8RPwfzz44INx/fXXx+TJk9f5P1NTUxOvv/56vP766zFs2LDo3r17nHfeeXHcccclvBQAAArXQxPej/P/Ni3zbutmjWPCxf2jcUV55u2i1qhERkGl8jsBAAAAAAAAACgZ/qQU8P+bMWNGHHTQQfHd7353vYZPX2XSpElx/PHHR79+/WLmzJkZXQgAAIVvdU1t7HvNs0mGT1cduUdMuWyg4dOGqGyd7wvqxyat830BAAAAAAAAAABkyp+WAiIi4tFHH4199903XnzxxUy7zz//fPTo0SP+/ve/Z9oFAIBCNO3DJbHrxU/Hp8uqMm+Pv/jQOGH/HTPvlox2XfJ9Qf0old8JAAAAAAAAAEDJMH4CYvjw4XH00UfH8uXLk/SXL18eRx11VNx2221J+gAAUAh+/dep8c1bx2be/caeW8fcYYdHu5aVmbdLyjZ75/uC+rH13vm+AAAAAAAAAAAAMtUo3wcA+XXPPffE2WefHblcLulzcrlcnHXWWdGiRYs48cQTkz4LAADq06IvVkW3q55J0v7b6b2i+46bJWmXnLYdIxo3i6heke9L0mncPKJth3xfAQAAAAAAAAAAmfLmJyhh48ePjx//+MfrNHzq1atX3HrrrTF58uRYtGhRVFdXx6JFi2LixIlx8803x3777bfWRi6Xix//+McxYcKELM4HAIC8e2TiB0mGTy2bNoq3rznM8ClL5RURW+2Z7yvS2nrPNb8TAAAAAAAAAACKiDc/QYlaunRpHH/88VFdXV3n9zp06BC33357HHroof/ns8022yy6d+8e3bt3j7PPPjtGjRoVZ5xxRsyePftre6tWrYrjjjsupkyZEptuuulG/w4AAMiHmtpc9B42Oj5eujLz9lXf2j1OOKB95l0iYttuER+8mu8r0tmmW74vAAAAAAAAAACAzHnzE5Soyy67LObMmVPnd/r37x8TJkz4yuHTVxk4cGBMnDgx+vXrV+f35syZE1dcccW6ngoAAAXljXlLYpeLnkoyfBp/0aGGTyl1GpLvC9LqXOS/DwAAAAAAAACAkmT8BCVo+vTpMXz48Dq/c8ABB8Tjjz8erVq1Wq9269at44knnoiePXvW+b1bbrkl3nrrrfVqAwBAvl346OvxjVvGZt49bI+tYu6ww6PdppWZt/kf2veJ2LxDvq9Io23HiB175/sKAAAAAAAAAADInPETlKChQ4fG6tWrv/bzNm3axEMPPRTNmjXboH7z5s3j4YcfjtatW3/td1avXh1XXnnlBvUBAKC+ff7Fqmh/wZPxwPgPMm8/8tMD4vYfdM+8y1coK4vY99R8X5HGvqeu+X0AAAAAAAAAAFBkjJ+gxLz77rvxt7/9rc7vXH311bH99ttv1HN23HHHGDp0aJ3feeSRR2Lu3Lkb9RwAAEjt0ckfxj5XPZN5d5PGFTHr6sNi3/ZtMm9Th72Oj2i8Yf+ih4LVuNma3wUAAAAAAAAAAEXI+AlKzPDhw6OmpuZrP+/QoUOcdtppmTzrjDPOiJ133vlrP6+pqYnhw4dn8iwAAMhaTW0ueg8bHb94eGrm7cu/2SXeumpwNGnkb8vr3SatI7oek+8rstX1mIjKVvm+AgAAAAAAAAAAkvCnrKCE1NTUxAMPPFDnd37+859HRUVFJs9r1KhR/OxnP6vzO/fff3/U1tZm8jwAAMjKmx8tiV0ueirmLf4y8/Y/Lzo0ftR7p8y7rIc+50ZUNM33FdmoaLrm9wAAAAAAAAAAQJEyfoISMnr06Jg/f/7Xfl5ZWRk/+MEPMn3mSSedFE2aNPnazz/66KN4/vnnM30mAABsjIv/Pi0Ov3ls5t1Bu28Zc4cdHltuWpl5m/XUZueIfhfl+4ps9Ltoze8BAAAAAAAAAIAiZfwEJeSJJ56o8/PDDz88WrZsmekzW7duHYcddlid31nbXQAAUB+WrKiO9hc8GX/55/uZtx86bf/4/Qk9Mu+yEQ44K2Lb7vm+YuNs2yOi19n5vgIAAAAAAAAAAJIyfoIS8uyzz9b5+eGHH57kuWvrPvPMM0meCwAA6+qx1+bFXleOyrzbpKI8Zl49OPbbefPM22ykikYRR94eUdE035dsmIqmEUfeFlFeke9LAAAAAAAAAAAgKeMnKBHz58+Pt956q87v9O/fP8mzBwwYUOfnb775Znz88cdJng0AAHWprc3FQdePiXMfmpJ5+5LDd4tZ1xwWTRsZpxSsLTpFHHJxvq/YMIdcsuZ+AAAAAAAAAAAocsZPUCLGjx9f5+fbb799bL/99kme3b59+9h6663r/M6ECROSPBsAAL7OW/OXxs4XPRXvfbYi8/a4Cw+JU/vunHmXBA44O6Lrsfm+Yv10PTbigLPyfQUAAAAAAAAAANQL4ycoEZMnT67z827duiV9fo8ePer8/LXXXkv6fAAA+J8uf/yNOOymlzLv9t+tXcwddnhs3WqTzNskUl4eceRtER0Py/cl66bTkDX3lvtHOgAAAAAAAAAAlAZ/UgZKxJQpU+r8fM8990z6/LX1jZ8AAKgPS76sjvYXPBn3jHsv8/YDP94/7jxp38y71IOKxhHH3F34A6hOQyKOvmvNvQAAAAAAAAAAUCKMn6BEzJo1q87PO3TokPT5u+66a52fv/3220mfDwAA/zn1o9hr6KjMu+VlETOvHhwH7LJ55m3qUePKiOPui+h6bL4v+Wpdj4049t41dwIAAAAAAAAAQAlplO8DgPRyuVzMnTu3zu+sbZy0sdbWX9t9AACwoWprc9H/dy/Eu59+kXn74iG7xY8P3DnzLnlS0Tji27+P2GqPiNHXRNRU5fuiiIqmEYdcEnHAWRHl/h02AAAAAAAAAACUHuMnKAELFiyIlStX1vmdbbbZJukNa+t/8cUX8cknn0S7du2S3gEAQGmZ+fGyGHTji0nar1xwSGzTepMkbfKovDyi9zkRHQdHPHZ6xLxJ+btl2x4RR94WsUWn/N0AAAAAAAAAAAB55l8ZDCXgo48+Wut3ttpqq6Q3rEt/Xe4EAIB1NfSJN5MMnw7quEXMHXa44VOx26JTxMmjIvoPXfP2pfpU0TRiwJURp4wyfAIAAAAAAAAAoOR58xOUgM8++6zOzzfddNNo2jTtH+Zr1qxZtGjRIpYvX/6131nbnQAAsC6WrqyOPa8YlaT9l1P3i967tk3SpgBVNIroc25ElyMixt4YMe2RiOoV6Z7XuFlE12PWPLPNzumeAwAAAAAAAAAADYjxE5SARYsW1fn5pptuWi93bLrppnWOn9Z2Z30aPnx43HbbbcmfM3v27OTPAAAoJU++Pj/OvH9ykvaMqwZHZeOKJG0KXJudI464OWLgVRFTH4yYcGfEwlnZ9dt2jNj31Ii9jo+obJVdFwAAAAAAAAAAioDxE5SAzz//vM7PW7ZsWS93rO05hTR++vTTT2P69On5PgMAgHVUW5uLQTe+GG9/8vVj+w11/uDOcfrBu2TepQGqbBWx308iep4W8d7LETOeivhocsT8qev3RqjGzSO23jNim24RnYdE7Ng7oqws3d0AAAAAAAAAANCAGT9BCVi5cmWdnzdv3rxe7mjRokWdn6/tTgAA+CpvL1gWA373YpL22PP7xXabNUvSpgErK4to32fNXxERtTURC9+OmD8l4pPpEV8ujlhdFVFTFVHRNKJR04hNWke06xKx9d4RbTtElHuLGAAAAAAAAAAArAvjJygBq1atqvPzRo3q5/8VrO05a7sTAAD+t6v/MT3uHDsn827fDm3j3pN7Rpm38bAuyisi2nVe8xcAAAAAAAAAAJAp4ycoAcZPAAAUm2Urq6PrFaOStP98yn7Rp0PbJG0AAAAAAAAAAADWj/ETlIDa2to6P6+oqKiXO9b2nJqamnq5AwCAhu3pafPj9L9MTtKecdXgqGxcP//9GAAAAAAAAAAAgLUzfoISsLY3Lq1evbpe7ljbcxo3blwvd6yLLbbYIrp06ZL8ObNnz46qqqrkzwEAKAa5XC4Ou+mlmPHxsszb5w3qFGf22zXzLgAAAAAAAAAAABvH+AlKQJMmTer8vL7GT9XV1XV+vrY769OZZ54ZZ555ZvLn7L777jF9+vTkzwEAaOje+WR59L/hhSTtl37dL7Zv0yxJGwAAAAAAAAAAgI1j/AQlYG1vVFq1alW93NGQxk8AABSO6556K37/4ruZd3vtsnn85dT9oqysLPM2AAAAAAAAAAAA2TB+ghLQokWLOj9fvnx5vdyxbNmyOj9f250AAJSW5VWrY4/LRyZp33Nyzzio4xZJ2gAAAAAAAAAAAGTH+AlKQJs2ber8fOnSpfVyx9qes7Y7AQAoHSPf/Dh+ct+kJO0ZVw2OysYVSdoAAAAAAAAAAABky/gJSsDmm29e5+eLFy+ulzuWLFlS5+druxMAgOKXy+Xim7eOjTfmZT/Q/+WAjnH2oR0y7wIAAAAAAAAAAJCO8ROUgLZt29b5eVVVVSxevDhat26d7IZFixbFqlWr6vyO8RMAQGl799PlcchvX0jSfunX/WL7Ns2StAEAAAAAAAAAAEjH+AlKwA477LDW7yxYsCDp+GnBggVr/c663AkAQHH6txEz4rbnZ2fe7blTm3jotP2jrKws8zYAAAAAAAAAAADpGT9BCWjRokVsvvnm8dlnn33td957773o1KlTshvmzp1b5+ft2rWL5s2bJ3s+AACF6Yuq1bH75SOTtO/60b7Rr1O7JG0AAAAAAAAAAADqR3m+DwDqx0477VTn52+//XbS57/zzjt1fr62+wAAKD7PTF+QbPj01pWDDZ8AAAAAAAAAAACKgDc/QYnYfffdY+LEiV/7+cyZM5M+f2393XffPenzAQAoHLlcLo687ZWY+sHizNvnHNohfj6gY+ZdAAAAAAAAAAAA8sObn6BEdOvWrc7PX3vttaTPnzx5cp2f77PPPkmfDwBAYZiz8IvY6cKnkgyfXjjvYMMnAAAAAAAAAACAIuPNT1Ai1jZ+mjJlStTU1ERFRUXmz169enVMnTq1zu8YPwEAFL/fjpoZt4x+J/Nu9x03i7/+9IAoKyvLvA0AAAAAAAAAAEB+GT9BiejRo0dUVlbGypUrv/Lz5cuXx6RJk6Jnz56ZP3v8+PGxYsWKr/28srIyunfvnvlzAQAoDCtWrY4ul41M0v7TD3vEIZ23TNIGAAAAAAAAAAAg/8rzfQBQPyorK6N37951fueZZ55J8uxnn322zs/79u0blZWVSZ4NAEB+PffWgmTDp+lXDjJ8AgAAAAAAAAAAKHLGT1BCBgwYUOfnjz76aJLn/vWvf63z84EDByZ5LgAA+ZPL5eI7t70cp9wzMfP22YfsGnOHHR7NmniZMQAAAAAAAAAAQLEzfoIScvTRR9f5+eTJk2PmzJmZPvONN96IadOmfe3nZWVla70LAICG5b3PvoidLnwqJr+/OPP2mF8dHL8c2CnzLgAAAAAAAAAAAIXJ+AlKyC677BL7779/nd+55ZZbMn3mzTffXOfnvXr1ivbt22f6TAAA8ud3z8yKg65/PvPuXtu3jjnXDYmd2jbPvA0AAAAAAAAAAEDhMn6CEnPyySfX+fldd90V8+fPz+RZH374Ydx33311fueHP/xhJs8CACC/vlxVE+0veDJueu7tzNt/OLFHPH5m7ygrK8u8DQAAAAAAAAAAQGEzfoISc8IJJ0S7du2+9vMVK1bEBRdckMmzzj///Fi5cuXXfr7lllvGCSeckMmzAADInzEzP4ndLhuRpP3m0EExoMuWSdoAAAAAAAAAAAAUPuMnKDGVlZVxzjnn1Pmde++9N/7+979v1HMefvjhuP/+++v8zrnnnhtNmzbdqOcAAJA/uVwujr1jXPzorgmZt884eJeYO+zwaN60UeZtAAAAAAAAAAAAGg7jJyhB5557bmy//fZ1fuekk06K8ePHb1D/1VdfjVNOOaXO7+y4445rHWEBAFC43v9sRex04VMxfu6izNujf3lQ/Hpw58y7AAAAAAAAAAAANDzGT1CCmjVrFjfccEOd31m2bFkMHDgw/vGPf6xX+/HHH49BgwbF8uXL6/zeb3/729hkk03Wqw0AQGG4+bm348Drx2Te7bptq5hz3ZDYeYsWmbcBAAAAAAAAAABomIyfoEQdffTR8b3vfa/O7yxZsiSOOOKI+P73vx8zZsyo87vTp0+P448/Po488shYunRpnd/9/ve/H0cdddR63wwAQH59uaom2l/wZNzwzKzM23f8oHs8cXafKCsry7wNAAAAAAAAAABAw9Uo3wcA+fP73/8+Jk2aFDNnzvza7+Ryubj//vvj/vvvj3322Sd69eoVO+20U7Ro0SKWLVsWc+bMiZdffjmmTp26Ts/s3Llz3HHHHVn9BAAA6skLsz6Nk/40Pkn7jaGDokVTf3sKAAAAAAAAAADA/+VPl0EJa9GiRYwcOTL69u0bH3zwwVq//9prr8Vrr722wc/bYYcdYuTIkdGiRYsNbgAAUL9yuVx8/85/xiuzP8u8/ZMDd44Lh+yWeRcAAAAAAAAAAIDiYfwEJW7HHXeM0aNHx+DBg2P27NnJnrPrrrvGiBEjYocddkj2DAAAsvXBohXR99/GJGk/+4uDYtd2RvEAAAAAAAAAAADUrTzfBwD5t+uuu8aECRNi0KBBSfqDBw+OCRMmxC677JKkDwBA9oaPeSfJ8KnL1pvGnOuGGD4BAAAAAAAAAACwToyfgIiI2GyzzWLEiBFx9913R7t27TJptmvXLu655554+umno3Xr1pk0AQBIa2V1TbS/4Mm4fuTMzNt3/KBbPHVO3ygrK8u8DQAAAAAAAAAAQHEyfgL+xUknnRTvvvtuDB8+PHbbbbcNanTp0iWGDx8ec+bMiRNPPDHjCwEASGXs2wuj86UjkrSnXTEwBu+xdZI2AAAAAAAAAAAAxatRvg8ACk/z5s3jjDPOiDPOOCNmzZoVI0aMiMmTJ8ebb74Z8+bNi2XLlsWKFSuiWbNm0bJly9huu+2iS5cu0a1btzjssMOiQ4cO+f4JAACsh1wuFyf+aXy89PbCzNs/7rtTXHx4l8y7AAAAAAAAAAAAlAbjJ6BOHTt2jI4dO+b7DAAAEvnw8xXR5zdjkrSf+fmB0WHLlknaAAAAAAAAAAAAlAbjJwAAgBJ1+/Oz4zcjZmTe7dCuRYw898AoLy/LvA0AAAAAAAAAAEBpMX4CAAAoMSura6LzpSOStG/93j7xjT23SdIGAAAAAAAAAACg9Bg/AQAAlJBX3lkY37vzn0nar18xMDatbJykDQAAAAAAAAAAQGkyfgIAACgRP7xrfDw/89PMuz/q3T4u/+bumXcBAAAAAAAAAADA+AkAAKDIfbT4y+g1bHSS9shzD4xOW7VM0gYAAAAAAAAAAADjJwAAgCL2Hy/OjmufmpF5d5ctmsczPz8oysvLMm8DAAAAAAAAAADA/2P8BAAAUISqVtdE50tHRC6Xffvm7+4TR+y1TfZhAAAAAAAAAAAA+F+MnwAAAIrMuNmfxXf/8GqS9tTLBkarZo2TtAEAAAAAAAAAAOB/M34CAAAoIqfcPSGem/FJ5t0TD9gxrvzWHpl3AQAAAAAAAAAAoC7GTwAAAEVg/pIv44DrRidpP31O39ht602TtAEAAAAAAAAAAKAuxk8AAAAN3J0vvRtXP/lW5t32mzeL0b88OMrLyzJvAwAAAAAAAAAAwLowfgIAAGigVq2ujT0uHxmramozb990/N7xrb23zbwLAAAAAAAAAAAA68P4CQAAoAH657ufxXH/8WqS9tTLBkarZo2TtAEAAAAAAAAAAGB9GD8BAAA0MKfdOzFGTV+QefcH++8QVx/ZNfMuAAAAAAAAAAAAbCjjJwAAgAZiwdKVsd+1zyVpP/mzPrH7Nq2StAEAAAAAAAAAAGBDGT8BAAA0AHe/PCeueGJ65t3tNtskXjivX1SUl2XeBgAAAAAAAAAAgI1l/AQAAFDAVq2ujb2Gjoovq2syb99w7F7xnW7bZd4FAAAAAAAAAACArBg/AQAAFKiJcxfF0XeMS9J+7dIBsVnzJknaAAAAAAAAAAAAkBXjJwAAgAJ0xl8mxVPTPs68e/y+28ewo/bMvAsAAAAAAAAAAAApGD8BAAAUkE+Wroye1z6XpP2Ps/vEHtu2StIGAAAAAAAAAACAFIyfAAAACsR94+bGpY+/mXl361aVMfb8Q6KivCzzNgAAAAAAAAAAAKRk/AQAAJBn1TW1sc+Vz8TyqtWZt68/es84psf2mXcBAAAAAAAAAACgPhg/AQAA5NGk9xbFUbePS9KefOmAaNO8SZI2AAAAAAAAAAAA1AfjJwAAgDw5+4HX4ompH2XePbr7dvHvx+yVeRcAAAAAAAAAAADqm/ETAABAPft0WVXse82zSdr/eVbv2HO71knaAAAAAAAAAAAAUN+MnwAAAOrRn199Ly557I3Mu1u0bBrjLjgkGlWUZ94GAAAAAAAAAACAfDF+AgAAqAfVNbXR/apnYunK1Zm3f3NU1zhu3x0y7wIAAAAAAAAAAEC+GT8BAAAk9tr7n8e3b3slSXvSJf1j8xZNk7QBAAAAAAAAAAAg34yfAAAAEjr3wdfisSkfZd79Trdt44Zj9868CwAAAAAAAAAAAIXE+AkAACCBhcurosfVzyZpP35m79hr+9ZJ2gAAAAAAAAAAAFBIjJ8AAAAy9sD49+PCR6dl3t28eZP450WHRqOK8szbAAAAAAAAAAAAUIiMnwAAADKyuqY2el77XCz6YlXm7Wu/3TW+t98OmXcBAAAAAAAAAACgkBk/AQAAZGDqB4vjW8NfTtKeeEn/aNuiaZI2AAAAAAAAAAAAFDLjJwAAgI30y4enxt8mf5h591t7bxM3Hb9P5l0AAAAAAAAAAABoKIyfAAAANtBny6ui+9XPJmk/ekav6LbDZknaAAAAAAAAAAAA0FAYPwEAAGyAhyd8EL/+2+uZd1s3axwTLu4fjSvKM28DAAAAAAAAAABAQ2P8BAAAsB5qanNxwHXPxSfLqjJvX3XkHnHC/jtm3gUAAAAAAAAAAICGyvgJAABgHU37cEl889axSdrjLz402rWsTNIGAAAAAAAAAACAhsr4CQAAYB38+q9T4+GJH2be/caeW8et3+uWeRcAAAAAAAAAAACKgfETAABAHT7/YlXsc9UzSdp/O/2A6L5jmyRtAAAAAAAAAAAAKAbGTwAAAF/jr5M+jF89MjXzbvMmFTHl8oHRuKI88zYAAAAAAAAAAAAUE+MnAACA/6WmNhd9fjM65i9ZmXl76BG7x0m92mfeBQAAAAAAAAAAgGJk/AQAAPA/vDFvSXzjlrFJ2uMvOjTabVqZpA0AAAAAAAAAAADFyPgJAADgv1z46OvxwPgPMu8etsdWcfsPumfeBQAAAAAAAAAAgGJn/AQAAJS8xStWxd5XPpOk/chPD4h927dJ0gYAAAAAAAAAAIBiZ/wEAACUtEcnfxi/eHhq5t1NGlfE1MsHRpNG5Zm3AQAAAAAAAAAAoFQYPwEAACWppjYXB/7bmJi3+MvM25d/s0v8qPdOmXcBAAAAAAAAAACg1Bg/AQAAJWf6R0tjyM0vJWm/euGhsVWryiRtAAAAAAAAAAAAKDXGTwAAQEm55LFp8edX38+8O6DLlvGHE3tk3gUAAAAAAAAAAIBSZvwEAACUhCUrqmOvK0claT902v6x386bJ2kDAAAAAAAAAABAKTN+AgAAit7jU+bFOQ9OybzbpKI8pg0dGE0bVWTeBgAAAAAAAAAAAIyfAACAIlZbm4tDfvt8zP1sRebtSw7fLU7tu3PmXQAAAAAAAAAAAOC/GT8BAABFacbHS2PwjS8laY+78JDYutUmSdoAAAAAAAAAAADAfzN+AgAAis7lj78R94x7L/Nu/93axZ0n7Zt5FwAAAAAAAAAAAPhqxk8AAEDRWPJldew1dFSS9gM/3j8O2GXzJG0AAAAAAAAAAADgqxk/AQAAReGJqR/F2Q+8lnm3vCzirasGR9NGFZm3AQAAAAAAAAAAgLoZPwEAAA1abW0uBvzuhZj96ReZty8a0jlOO3CXzLsAAAAAAAAAAADAujF+AgAAGqyZHy+LQTe+mKT9ygWHxDatN0nSBgAAAAAAAAAAANaN8RMAANAgDX3izbjr5bmZdw/quEXcc3LPzLsAAAAAAAAAAADA+jN+AgAAGpSlK6tjzytGJWn/5dT9oveubZO0AQAAAAAAAAAAgPVn/AQAADQYT74+P868f3KS9oyrBkdl44okbQAAAAAAAAAAAGDDGD8BAAAFr7Y2F4NvejFmLVieefv8wZ3j9IN3ybwLAAAAAAAAAAAAbDzjJwAAoKC9vWBZDPjdi0naY8/vF9tt1ixJGwAAAAAAAAAAANh4xk8AAEDBuubJ6fGHl+Zk3u2za9u475SeUVZWlnkbAAAAAAAAAAAAyI7xEwAAUHCWrayOrleMStK+75Se0bfDFknaAAAAAAAAAAAAQLaMnwAAgILy9LT5cfpfJidpz7hqcFQ2rkjSBgAAAAAAAAAAALJn/AQAABSEXC4Xh930Usz4eFnm7fMGdYoz++2aeRcAAAAAAAAAAABIy/gJAADIu3c+WR79b3ghSfulX/eL7ds0S9IGAAAAAAAAAAAA0jJ+AgAA8uq6p9+K37/wbubdXrtsHn85db8oKyvLvA0AAAAAAAAAAADUD+MnAAAgL5ZXrY49Lh+ZpH3PyT3joI5bJGkDAAAAAAAAAAAA9cf4CQAAqHcj3/w4fnLfpCTtt64cHJs0qUjSBgAAAAAAAAAAAOqX8RMAAFBvcrlcfPPWsfHGvKWZt3/ev2Oc079D5l0AAAAAAAAAAAAgf4yfAACAevHup8vjkN++kKT94nn9YofNmyVpAwAAAAAAAAAAAPlj/AQAACR3/cgZMXzM7My7PXdqEw+dtn+UlZVl3gYAAAAAAAAAAADyz/gJAABI5ouq1bH75SOTtO/60b7Rr1O7JG0AAAAAAAAAAACgMBg/AQAASTw7fUGceu/EJO23rhwcmzSpSNIGAAAAAAAAAAAACofxEwAAkKlcLhffvu2VmPLB4szb5xzaIX4+oGPmXQAAAAAAAAAAAKAwGT8BAACZmbPwi+j3788nab9w3sGx4+bNk7QBAAAAAAAAAACAwmT8BAAAZOKGUTPj5tHvZN7tvuNm8defHhBlZWWZtwEAAAAAAAAAAIDCZvwEAABslBWrVkeXy0Ymaf/xpB5x6G5bJmkDAAAAAAAAAAAAhc/4CQAA2GCjZyyIk++emKT95tBB0bypv2UBAAAAAAAAAACAUuZPEgIAAOstl8vF0XeMi0nvfZ55+6x+u8avBnXKvAsAAAAAAAAAAAA0PMZPAADAennvsy/ioOufT9Ie86uDY6e2zZO0AQAAAAAAAAAAgIbH+AkAAFhnNz47K2589u3Mu3tt3zoeO6NXlJWVZd4GAAAAAAAAAAAAGi7jJwAAYK2+XFUTu102Ikn7Dyf2iAFdtkzSBgAAAAAAAAAAABo24ycAAKBOY2Z+Ej+6a0KS9ptDB0Xzpv62BAAAAAAAAAAAAPhq/pQhAADwlXK5XBz3H6/G+DmLMm+ffvAucf7gzpl3AQAAAAAAAAAAgOJi/AQAAPwfHyxaEX3/bUyS9nO/PCh22aJFkjYAAAAAAAAAAABQXIyfAACAf3HLc2/Hb5+ZlXl3j203jSfO6hNlZWWZtwEAAAAAAAAAAIDiZPwEAABERMTK6profOmIJO07ftA9Bu+xVZI2AAAAAAAAAAAAULyMnwAAgHhx1qdx4p/GJ2m/MXRQtGjqbz0AAAAAAAAAAACA9edPIAIAQAnL5XLx/Tv/Ga/M/izz9k8O3DkuHLJb5l0AAAAAAAAAAACgdBg/AQBAifpg0Yro+29jkrSf/cVBsWu7FknaAAAAAAAAAAAAQOkwfgIAgBI0fMw7cf3ImZl3d9t603jqZ32irKws8zYAAAAAAAAAAABQeoyfAACghKysronOl45I0r7t+91iSNetk7QBAAAAAAAAAACA0mT8BAAAJWLs2wvjB3/8Z5L2tCsGRsvKxknaAAAAAAAAAAAAQOkyfgIAgCKXy+XixD+Nj5feXph5+9Q+O8Ul3+iSeRcAAAAAAAAAAAAgwvgJAACK2rzFX0bvYaOTtJ/5+YHRYcuWSdoAAAAAAAAAAAAAEcZPAABQtO54YXYMe3pG5t0O7VrEyHMPjPLysszbAAAAAAAAAAAAAP+T8RMAABSZldU10fnSEUnat35vn/jGntskaQMAAAAAAAAAAAD8b8ZPAABQRF55Z2F8785/Jmm/fsXA2LSycZI2AAAAAAAAAAAAwFcxfgIAgCLxw7vGx/MzP828+6Pe7ePyb+6eeRcAAAAAAAAAAABgbYyfAACggfto8ZfRa9joJO0R5/aNzlttmqQNAAAAAAAAAAAAsDbGTwAA0ID94cV345qn3sq8u3Pb5vHsLw6K8vKyzNsAAAAAAAAAAAAA68r4CQAAGqCq1TWx26UjojaXffum4/eOb+29bfZhAAAAAAAAAAAAgPVk/AQAAA3MuNmfxXf/8GqS9tTLBkarZo2TtAEAAAAAAAAAAADWl/ETAAA0IKfeMyGefeuTzLsnHrBjXPmtPTLvAgAAAAAAAAAAAGwM4ycAAGgAPl6yMva/7rkk7afP6Ru7bb1pkjYAAAAAAAAAAADAxjB+AgCAAvfHsXPiqn9Mz7zbfvNmMfqXB0d5eVnmbQAAAAAAAAAAAIAsGD8BAECBWrW6Nva4fGSsqqnNvH3jcXvHkftsm3kXAAAAAAAAAAAAIEvGTwAAUIDGz1kUx/5+XJL2lMsGROtmTZK0AQAAAAAAAAAAALJk/AQAAAXmtHsnxqjpCzLvfm+/HeLab3fNvAsAAAAAAAAAAACQivETAAAUiAVLV8Z+1z6XpP3kz/rE7tu0StIGAAAAAAAAAAAASMX4CQAACsDdL8+JK56Ynnl3u802iRfO6xcV5WWZtwEAAAAAAAAAAABSM34CAIA8WrW6NvYaOiq+rK7JvH3DsXvFd7ptl3kXAAAAAAAAAAAAoL4YPwEAQJ5MnLsojr5jXJL2a5cOiM2aN0nSBgAAAAAAAAAAAKgvxk8AAJAHZ/5lcjw5bX7m3eP33T6GHbVn5l0AAAAAAAAAAACAfDB+AgCAevTJspXR85rnkrT/cXaf2GPbVknaAAAAAAAAAAAAAPlg/AQAAPXkvnFz49LH38y8u3Wryhh7/iFRUV6WeRsAAAAAAAAAAAAgn4yfAAAgseqa2uh25TOxrGp15u1/O3rPOLbH9pl3AQAAAAAAAAAAAAqB8RMAACQ06b3P46jbX0nSnnzpgGjTvEmSNgAAAAAAAAAAAEAhMH4CAIBEzn7gtXhi6keZd4/uvl38+zF7Zd4FAAAAAAAAAAAAKDTGTwAAkLFPl1XFvtc8m6T9n2f1jj23a52kDQAAAAAAAAAAAFBojJ8AACBDf/nne3Hx39/IvLtFy6Yx7oJDolFFeeZtAAAAAAAAAAAAgEJl/AQAABmorqmNHlc/G0u+rM68/ZujusZx++6QeRcAAAAAAAAAAACg0Bk/AQDARnrt/c/j27e9kqQ96ZL+sXmLpknaAAAAAAAAAAAAAIXO+AkAADbCzx+aEn9/bV7m3e/ss23ccNzemXcBAAAAAAAAAAAAGhLjJwAA2AALl1dFj6ufTdJ+7Mzesff2rZO0AQAAAAAAAAAAABoS4ycAAFhPD4x/Py58dFrm3TbNm8T4iw6NRhXlmbcBAAAAAAAAAAAAGiLjJwAAWEera2qj57XPxaIvVmXevvbbXeN7++2QeRcAAAAAAAAAAACgITN+AgCAdTD1g8XxreEvJ2lPvKR/tG3RNEkbAAAAAAAAAAAAoCEzfgIAgLX45cNT42+TP8y8+629t4mbjt8n8y4AAAAAAAAAAABAsTB+AgCAr/HZ8qrofvWzSdqPntEruu2wWZI2AAAAAAAAAAAAQLEwfgIAgK/w8IQP4td/ez3zbqtNGsfES/pH44ryzNsAAAAAAAAAAAAAxcb4CQAA/oea2lz0GvZcLFhalXn7qiP3iBP23zHzLgAAAAAAAAAAAECxMn4CAID/Mu3DJfHNW8cmaY+/+NBo17IySRsAAAAAAAAAAACgWBk/AQBARJz/19fjoYkfZN49fM+tY/j3umXeBQAAAAAAAAAAACgFxk8AAJS0z79YFftc9UyS9t9OPyC679gmSRsAAAAAAAAAAACgFBg/AQBQsv466cP41SNTM+82b1IRUy4fGI0ryjNvAwAAAAAAAAAAAJQS4ycAAEpOTW0u+v5mdHy0ZGXm7aFH7B4n9WqfeRcAAAAAAAAAAACgFBk/AQBQUt6YtyS+ccvYJO3xFx0a7TatTNIGAAAAAAAAAAAAKEXGTwAAlIwLH50WD4x/P/PuYXtsFbf/oHvmXQAAAAAAAAAAAIBSZ/wEAEDRW7xiVex95TNJ2g//5IDouVObJG0AAAAAAAAAAACAUmf8BABAUfv7ax/Gzx+amnm3aaPymHbFoGjSqDzzNgAAAAAAAAAAAABrGD8BAFCUampzcdD1Y+LDz7/MvH3ZN7rEyX12yrwLAAAAAAAAAAAAwL8yfgIAoOhM/2hpDLn5pSTtVy88NLZqVZmkDQAAAAAAAAAAAMC/Mn4CAKCoXPLYtPjzq+9n3h3QZcv4w4k9Mu8CAAAAAAAAAAAA8PWMnwAAKApLVlTHXleOStJ+6LT9Y7+dN0/SBgAAAAAAAAAAAODrGT8BANDgPT5lXpzz4JTMu40ryuKNoYOiaaOKzNsAAAAAAAAAAAAArJ3xEwAADVZtbS4O+e3zMfezFZm3Lzl8tzi1786ZdwEAAAAAAAAAAABYd8ZPAAA0SDM+XhqDb3wpSXvchYfE1q02SdIGAAAAAAAAAAAAYN0ZPwEA0OBc/vgbcc+49zLvHtK5Xfzph/tm3gUAAAAAAAAAAABgwxg/AQDQYCz5sjr2GjoqSfv+H+8XvXZpm6QNAAAAAAAAAAAAwIYxfgIAoEF4YupHcfYDr2XeLS+LeOuqwdG0UUXmbQAAAAAAAAAAAAA2jvETAAAFrbY2FwN+90LM/vSLzNsXDekcpx24S+ZdAAAAAAAAAAAAALJh/AQAQMGatWBZDPzdi0nar1xwSGzTepMkbQAAAAAAAAAAAACyYfwEAEBBuuof0+OPY+dk3j2o4xZxz8k9M+8CAAAAAAAAAAAAkD3jJwAACsrSldWx5xWjkrT/cup+0XvXtknaAAAAAAAAAAAAAGTP+AkAgILx1LT5ccZfJidpz7hqcFQ2rkjSBgAAAAAAAAAAACAN4ycAAPKutjYXh930UsxcsCzz9q8Hd4ozDt418y4AAAAAAAAAAAAA6Rk/AQCQV28vWBYDfvdikvbY8/vFdps1S9IGAAAAAAAAAAAAID3jJwAA8uaaJ6fHH16ak3m3z65t475TekZZWVnmbQAAAAAAAAAAAADqj/ETAAD1btnK6uh6xagk7ftO6Rl9O2yRpA0AAAAAAAAAAABA/TJ+AgCgXo14Y3789M+Tk7RnXDU4KhtXJGkDAAAAAAAAAAAAUP+MnwAAqBe5XC6G3Dw23pq/NPP2eYM6xZn9ds28CwAAAAAAAAAAAEB+GT8BAJDcO58sj/43vJCk/dKv+8X2bZolaQMAAAAAAAAAAACQX8ZPAAAkNezpGXHHC7Mz7+6/c5t44Mf7R1lZWeZtAAAAAAAAAAAAAAqD8RMAAEksr1ode1w+Mkn77h/tGwd3apekDQAAAAAAAAAAAEDhMH4CACBzI9/8OH5y36Qk7beuHBybNKlI0gYAAAAAAAAAAACgsBg/AQCQmVwuF9+8dWy8MW9p5u2f9+8Y5/TvkHkXAAAAAAAAAAAAgMJl/AQAQCbe/XR5HPLbF5K0XzyvX+ywebMkbQAAAAAAAAAAAAAKl/ETAAAb7fqRM2L4mNmZd3vu1CYeOm3/KCsry7wNAAAAAAAAAAAAQOEzfgIAYIN9UbU6dr98ZJL2XT/cN/p1bpekDQAAAAAAAAAAAEDDYPwEAMAGeXb6gjj13olJ2tOvHBTNmvivqgAAAAAAAAAAAAClzp8oBQBgveRyufjO7a/Ea+8vzrz9s0M7xC8GdMy8CwAAAAAAAAAAAEDDZPwEAMA6m7vwizj4359P0n7+VwdH+7bNk7QBAAAAAAAAAAAAaJiMnwCgUNTWRCycFfHRlIhPpkesXByxuiqiZlVERZOIRk0jKltHtOsSsc0+EW07RJRX5PloSskNo2bGzaPfybzbfcfN4q8/PSDKysoybwMAAAAAAAAAAADQsBk/AUC+5HIRc8dGzHwqYt7kiI9fj6hese7/+cbNI7bqGrFtt4hOQyLa94kwHiGBFatWR5fLRiZp//GkHnHoblsmaQMAAAAAAAAAAADQ8Bk/AUB9+3JxxNQHIyb+cc2bnjZU9RcRH7y65q9Xb4to2zGixykRex0fsUnrrK6lxI2esSBOvntikvabQwdF86b+6ygAAAAAAAAAAAAAX8+fNgWA+rLo3YixN0ZMe2T93vC0rhbOihhxfsRzQyO6HhPR59yINjtn/xxKQi6Xi2PuGBcT3/s88/ZZ/XaNXw3qlHkXAAAAAAAAAAAAgOJj/AQAqdWsjhh3S8SY6yJqqtI/r3pFxOR71rxdqt9FEb3OjiivSP9cisb7n62IA68fk6Q95lcHx05tmydpAwAAAAAAAAAAAFB8jJ8AIKVPZ0Y8dnrEvEn1/+yaqohnL49464mII2+L2MKbdli7m559O3737KzMu3tu1yoeP7N3lJWVZd4GAAAAAAAAAAAAoHgZPwFACrW1a972NPqa+nnbU13mTYy4o2/EIRdHHHB2RHl5fu+hIH25qiZ2u2xEkvZ/nNA9Bu6+VZI2AAAAAAAAAAAAAMXN+AkAslZTHfHYGRHTHs73Jf+tpirimcsiPn5jzVugKhrn+yIKyPMzP4kf3jUhSfuN/4+9+wyzqr4WB7xmhjL0IggoSJMi2AsKYgNEbBivXWNQMRZiFDW2GGyJ9ZrYgi0qatSoGHuXoqjYKYooIoqigqD0Pgzz/+DN/edG5pw5M6cN877P44fwW7PWOh/COszea+/L94uGdX3lBAAAAAAAAAAAAKBy3IkKAOlUsjpi9AkRn72Q60427KNHI9Ysizji3ojaxbnuhhwrKyuLo+58O979cmHac5++d+e4YFD3tOcFAAAAAAAAAAAAoGax/AQA6VJakt+LT//y2QsRj50YceT93gBVg81ZuDL2uG58RnKPPXev6NyyYUZyAwAAAAAAAAAAAFCzFOa6AQDYKKxfH/HksPxffPqXGc//1O/69bnuhBy4ZezMjCw+bb154/jy6gMsPgEAAAAAAAAAAACQNt78BADp8NYtER89musuUvPRoxGtt4nY/cxcd0KWrC4pje4jXsxI7tt/uVMM2rp1RnIDAAAAAAAAAAAAUHN58xMAVNWCGRHjrsx1F5Uz7k8/9c9Gb8JnCzK2+DTt8v0sPgEAAAAAAAAAAACQEZafAKAqStdFPHl6ROmaXHdSOaVrIp4cFrG+NNedkCFlZWVx7N/ejl/d827ac5+yZ6eYfc2B0bCul4kCAAAAAAAAAAAAkBnuVAWAqnjrrxHffpDrLqrm2/cjJt4S0Xd4rjshzeYsXBl7XDc+I7nHnLNnbLlpo4zkBgAAAAAAAAAAAIB/8eYnAKishV9EjL8q112kx/irfvo8bDRGjv88I4tP3Vs3ii+vPsDiEwAAAAAAAAAAAABZ4c1PAFBZb9wYUbom112kR+manz7P4Jtz3QlVtLqkNLqPeDEjuW89bsc4YJs2GckNAAAAAAAAAAAAABvizU8AUBmrFkd8NDrXXaTXR6MjVi/JdRdUwRszf8jY4tNHlw20+AQAAAAAAAAAAABA1ll+AoDKmPpwRMnKXHeRXiUrf/pcVDtlZWVx/N3vxC/vfiftuU/u2zFmX3NgNCqunfbcAAAAAAAAAAAAAJBMrVw3AADVTllZxHt35bqLzHjvrohep0QUFOS6Eyro28WrYvdrxmUk9ytn7xldWjXKSG4AAAAAAAAAAAAAqAhvfgKAVM1+I+LHmbnuIjN++Cziqzdz3QUVdMdrszKy+NRl04bxxVUHWHwCAAAAAAAAAAAAIOe8+QkAUjXj+Vx3kFmfPh/RoW+uuyCB1SWl0X3EixnJ/ddjd4iDtt0sI7kBAAAAAAAAAAAAIFWWnwAgVd9OynUHmfXdRv75qrmJs36IY//2TkZyT710YDSpVzsjuQEAAAAAAAAAAACgMiw/AUAq1pdGzPsw111k1twPf/qchUW57oT/cOKod2P8jAVpz3tCnw5x2eCeac8LAAAAAAAAAAAAAFVl+QkAUvHDZxElK3PdRWaVrIj4YWbEpt1z3Qn/47vFq6LPNeMykvvF4XtE99aNM5IbAAAAAAAAAAAAAKrK8hMApOK7KbnuIDvmTrH8lCf+NuGLuPL5T9Ket1OLBjHmnL2isLAg7bkBAAAAAAAAAAAAIF0sPwFAKuZPz3UH2VFTPmceW7OuNLYa8WKsL0t/7puO3j4O2X7z9CcGAAAAAAAAAAAAgDSz/AQAqVi9ONcdZMeqxbnuoEZ7+4sf4+g7385I7qmXDIwm9WtnJDcAAAAAAAAAAAAApJvlJwBIxbo1ue4gO2rK58xDJ9/3foz55Pu05/1V7/ZxxSFbpz0vAAAAAAAAAAAAAGSS5ScASEXp2lx3kB2llp+ybd6S1bHb1WMzkvv5M/eIHps1zkhuAAAAAAAAAAAAAMgky08AkIqiOrnuIDuK6ua6gxrl7je+jD8+Oz3tebdoXj/G/27vKCosSHtuAAAAAAAAAAAAAMgGy08AkIpaNWQpqKZ8zhxbu259bH3pS7G2dH3ac99w1HZx6A5t054XAAAAAAAAAAAAALLJ8hMApKK4aa47yI56TXPdwUbv3S8XxpF3vJWR3FMu2Tea1q8hbykDAAAAAAAAAAAAYKNm+QkAUrFpj1x3kB015XPmyCn3vx8vT/8+7XmP3XWLuOrQbdKeFwAAAAAAAAAAAAByxfITAKRis+1z3UF2tNk+1x1slL5fujp2vWpsRnI/d2bf6LlZk4zkBgAAAAAAAAAAAIBcsfwEAKlo0TWidv2IkpW57iRzajeIaNEl111sdO6bODsuffrjtOdt26xevHbePlFUWJD23AAAAAAAAAAAAACQa5afACAVhUURrbeNmPN2rjvJnDbb/vQ5SYu169bHdpe/HKtKStOe+89HbBeH7dQ27XkBAAAAAAAAAAAAIF9YfgKAVG2+48a9/LTZjrnuYKPxwVcL47Db3spI7skj9o1mDepkJDcAAAAAAAAAAAAA5IvCXDcAANVOtwNy3UFmdd/IP1+W/ObBSRlZfDp6l3Yx+5oDLT4BAAAAAAAAAAAAUCN48xMApKpD34hNukT8ODPXnaRfi64R7XfPdRfV2vxlq6PXlWMzkvvZ3/aNrTdvkpHcAAAAAAAAAAAAAJCPvPkJAFJVUBCxy8m57iIzdjn5p89Hpfz9rdkZWXxq06Q4Zl11gMUnAAAAAAAAAAAAAGocb34CgMrY7uiIsZdHlKzMdSfpU7v+T5+LlJWUro8dr3gllq1Zl/bc1x2+bRy5c7u05wUAAAAAAAAAAACA6sCbnwCgMuo1jdjmiFx3kV7bHBFR7M1Cqfrgq0XR5eIXMrL4NGnEvhafAAAAAAAAAAAAAKjRLD8BQGX1HR5RVDfXXaRHUd2fPg8pOfMfk+Ow2yamPe/hO7WN2dccGM0b1El7bgAAAAAAAAAAAACoTmrlugEAqLaad4rY5/cRYy7NdSdVt8/vf/o8VMiCZWtilyvHZCT302fsHtu2bZqR3AAAAAAAAAAAAABQ3XjzEwBURe8zIjbfKdddVM3mO0f0+W2uu6g2Hnznq4wsPrVoWCc+v3J/i08AAAAAAAAAAAAA8G+8+QkAqqKoVsQvbou4fY+I0jW57iZ1RXUjfnFrRGFRrjvJe+tK18fOV46JxStL0p77mv/aJo7utUXa8wIAAAAAAAAAAABAdefNTwBQVS27RfS7ONddVE6/P/zUPwlN/npRbHnxCxlZfHr/DwMsPgEAAAAAAAAAAABAObz5CQDSofdvI+ZNi/jo0Vx3UnHbHBnR+4xcd5H3zn5kSjwx+du05/2vHTaPvxy1fdrzAgAAAAAAAAAAAMDGxPITAKRDYWHEL26NWLMs4rMXct1Nct0O+KnfQi+BLM8Py9fEzn8ak5HcT/5m99i+XdOM5AYAAAAAAAAAAACAjYk7ngEgXYpqRxxxb0TX/XPdSWLdDog4fNRP/bJBD7/7dUYWn5o3qBOfX7m/xScAAAAAAAAAAAAAqCBvfgKAdKpdHHHU3yOeHBbx0aO57ubntjnypzc+WXzaoHWl62O3q8fGD8vXpj33VYduE8fuukXa8wIAAAAAAAAAAADAxszyEwCkW1HtiEPviGi9dcS4KyNK1+S6o4iiuhH9/hDR+4yIQi9+3JCpcxbHISPfzEju9y4eEC0b1c1IbgAAAAAAAAAAAADYmFl+AoBMKCyM2P2siK6DIp48PeLbD3LXy+Y7//S2p5bdctdDnvvd6Knx2AffpD3v4O02i5uP2SHteQEAAAAAAAAAAACgprD8BACZ1LJbxEkvR7z114jxV2X3LVBFdSP6Xfw/b3sqyl7dauTH5Wtipz+NyUjuf57eJ3Zq3ywjuQEAAAAAAAAAAACgprD8BACZVlQrou/wiB6DI964MeKj0RElKzNXr3b9iG2O+Klm806Zq1PNPfrenDj/nx+mPW/j4lrxwYh9o3ZRYdpzAwAAAAAAAAAAAEBNY/kJALKleaeIwTdHDPxjxNSHI967K+KHz9KXv0XXiF1Ojtju6IjiJunLu5EpXV8Wfa4ZG98vTf9buP74i63j+N3apz0vAAAAAAAAAAAAANRUlp8AINuKm0TsempEr1Mivnoz4tPnI76bFDF3ampvhKrdIKLNthGb7RjR/YCI9rtHFBRkru+NwEffLImD//pGRnK/e3H/2LRRcUZyAwAAAAAAAAAAAEBNZfkJAHKloCCiQ9+f/ouIWF8a8cPMiLlTIuZPj1i1OGLdmojSNRFFdSNq1Y2o1zRi0x4RbbaPaNElorAod/1XMxc89mE88v6ctOc9cNs2MfLYHdOeFwAAAAAAAAAAAACw/AQA+aOwKGLT7j/9R9osWrE2dvjjKxnJ/c/Te8dO7ZtnJDcAAAAAAAAAAAAAYPkJANiI/fODb+Lc0VPTnrdBnaKYfMnAqFOrMO25AQAAAAAAAAAAAID/z/IT1CCzZ8+Ojh075rSHmTNnxpZbbpnTHoCNX+n6stjzuvHx7eJVac99+eCeMaRPh7TnBQAAAAAAAAAAAAB+zvITALBRmfbtkjjoljcykvvd3/ePTRsXZyQ3AAAAAAAAAAAAAPBzlp8AgI3G75/4KB565+u0592vZ6u44/id054XAAAAAAAAAAAAAEjM8hMAUO0tXrk2tr/ilYzkfvTU3tGrY/OM5AYAAAAAAAAAAAAAErP8BABUa09M/ibOfmRq2vPWrVUYH122X9SpVZj23AAAAAAAAAAAAABAxVh+AgCqpdL1ZbHXf4+PbxatSnvuSw7qESf17Zj2vAAAAAAAAAAAAABAaiw/Af/rxBNPjD59+mS0xqabbprR/EDN8MncpbH/Ta9nJPfbF/WP1k2KM5IbAAAAAAAAAAAAAEiN5Sfgf+25555xwgkn5LoNgIRGPDkt/v72V2nPO2CrTeOuIbukPS8AAAAAAAAAAAAAUHmWnwCAamHJypLY7oqXM5L74VN2i906bZKR3AAAAAAAAAAAAABA5Vl+AgDy3lNTvo2zHp6S9ry1Cgvi4yv2i7q1itKeGwAAAAAAAAAAAACoOstPAEDeWr++LPr9+dWY/ePKtOf+w4Fbxcl7dEp7XgAAAAAAAAAAAAAgfSw/AQB56dN5S2PQja9nJPdbF/WLNk3qZSQ3AAAAAAAAAAAAAJA+lp8AgLxz6VPT4r63vkp73n7dN417Ttgl7XkBAAAAAAAAAAAAgMyw/AQA5I0lq0piu8tfzkjuh369a/Tp3CIjuQEAAAAAAAAAAACAzLD8BADkhWemfhe//cfktOctKIj49I+Dom6torTnBgAAAAAAAAAAAAAyy/ITAJBT69eXxb43vBazFqxIe+6L9u8ep+7VOe15AQAAAAAAAAAAAIDssPwEAOTMZ98vi4E3TMhI7jcv7BebN62XkdwAAAAAAAAAAAAAQHZYfgIAcuKPz06Pu9/4Mu159+raMu47qVfa8wIAAAAAAAAAAAAA2Wf5CQDIqqWrS2Lby17OSO4HT941dt+yRUZyAwAAAAAAAAAAAADZZ/kJAMia5z+aG8MenJSR3J/+cVAU1y7KSG4AAAAAAAAAAAAAIDcsPwEbtGrVqpg1a1bMmTMnFi9eHKtXr466detGvXr1onnz5tGuXbto27Zt1KlTJ9etAtXA+vVlsf9Nr8eM75elPff5g7rFsL23THteAAAAAAAAAAAAACD3LD8B/+udd96JSZMmxauvvhrTp0+P0tLShPG1atWKnj17xs477xz77bdfDBw4MJo0aZKlboHq4vP5y2LAXyZkJPcbF+wTbZvVz0huAAAAAAAAAAAAACD3LD8B/+v2229PKX7dunUxderUmDp1atx9991Rp06dOPTQQ+P000+PvfbaK0NdAtXJ1c9/EndM+CLteftu2SL+PrRXFBQUpD03AAAAAAAAAAAAAJA/CnPdALDxWLt2bTzyyCOx9957R//+/eP999/PdUtAjixbXRIdLnwuI4tP95/UKx44eVeLTwAAAAAAAAAAAABQA1h+AjJi3Lhxsdtuu8WFF14Ya9euzXU7QBa9OG1ubHPZyxnJ/ekfB8WeXVtmJDcAAAAAAAAAAAAAkH9q5boBYONVWloa1157bbzxxhvxxBNPRMuW1WdhYeTIkXHrrbdmvM6sWbMyXgOypaysLA68+Y2YPndp2nOfu2/X+G3/LmnPCwAAAAAAAAAAAADkN8tPQMa9+eab0bt375gwYUJsttlmuW6nQhYsWBDTp0/PdRtQbXw+f3kM+MtrGcn9+vn7RLvm9TOSGwAAAAAAAAAAAADIb5afgCgoKIiddtopdthhh9hmm21im222iTZt2kSTJk2iSZMmUVhYGD/++GMsXLgw5s6dGxMnTowJEybEW2+9FatWrapQjVmzZsWAAQPijTfeiObNm2f4EwHZdM0Ln8btr6X/LWa7dWoe//j1blFQUJD23AAAAAAAAAAAAABA9WD5CWqounXrxkEHHRQHHXRQHHDAAbHpppsmjN9ss81is802i6233jr23XffiIhYunRp3H777XHjjTfG3Llzk9b85JNP4vjjj49nn33WMgNsBJavWRdbX/pSRnLfe+IusXe3xH8vAQAAAAAAAAAAAAAbv8JcNwBkV+fOneO6666Lb775Jh577LE44YQTki4+ladx48Zx/vnnx+zZs+PCCy+s0ELT888/H7fcckul6gH54+WP52Vs8emTKwZZfAIAAAAAAAAAAAAAIsKbn6BGadeuXcycOTPtb12qU6dOXH311bHnnnvGL3/5y1i4cGHC+EsuuSSOPPLIaN26dVr7ADKvrKwsDhn5Znz4zZK05z57QNc4a0CXtOcFAAAAAAAAAAAAAKovy09stKZPnx4DBw7MdRtp9c0331Tp54uKitLUyYbtv//+MXbs2Nh7771jyZLyFyOWLFkS1157bdxwww0Z7acqWrZsGT169Mh4nVmzZsWaNWsyXgfS4YsFy6Pfn1/LSO7Xzts72m/SICO5AQAAAAAAAAAAAIDqq6CsrKws101AJkyZMiV22GGHXLeRVtXl/67PPvtsDB48OGG/DRs2jDlz5kTTpk2z11ge6tmzZ0yfPv1nf96jR4/4+OOPc9ARbNh/v/RpjBw/K+15d+nQLB49tXfa30gHAAAAAAAAAAAAABubmnr/eWGuGwA2PgcddFCccMIJCWOWL18eTzzxRHYaAiptxZp10eHC5zKy+DTqhF1i9Gl9LD4BAAAAAAAAAAAAAOWy/ARkxJVXXhl169ZNGPPYY49lqRugMsZM/z56XvpSRnJPv2K/2Kf7phnJDQAAAAAAAAAAAABsPCw/ARnRpk2bOOqooxLGvP7661FaWpqljoCKKisri0NvfTNOvv/9tOc+s3+XmH3NgVG/Tq205wYAAAAAAAAAAAAANj6Wn4CMOfLIIxOeL1u2LKZNm5alboCKmP3Diuh40fMx+evFac/96u/2jnP27Zr2vAAAAAAAAAAAAADAxsvyE5Axe+65ZxQVFSWM+fTTT7PUDZDMX175LPa+/tW0592pfbP48uoDokOLBmnPDQAAAAAAAAAAAABs3GrlugHIlO233z7Kyspy3UaN1qhRo9hyyy1jxowZ5cbMnj07ew0BG7Ry7brocclLGcl91692jgE9WmUkNwAAAAAAAAAAAACw8fPmJyCjOnTokPB8/vz52WkE2KDxn87P2OLTx5fvZ/EJAAAAAAAAAAAAAKgSb34CMqpJkyYJz1euXJmlToB/V1ZWFkfe8Va8N3tR2nOfsc+W8bv9uqU9LwAAAAAAAAAAAABQ81h+AjKqTp06Cc9LSkqy1AnwL1//uDL2/O/xGck97ty9olPLhhnJDQAAAAAAAAAAAADUPJafgIxatWpVwvN69eplqRMgIuKmMTPjhjGfpT3vtm2bxFO/2T0KCgrSnhsAAAAAAAAAAAAAqLksPwEZNW/evITnDRt6Qwxkw6q1pbHVJS9mJPedx+8UA3u2zkhuAAAAAAAAAAAAAKBms/wEZNTnn3+e8HzzzTfPUidQc706Y36cMOq9jOSedvl+0bCurxMAAAAAAAAAAAAAQGa4WxnImK+++iq+//77hDEdO3bMUjdQ85SVlcXRd74d73y5MO25T9+7c1wwqHva8wIAAAAAAAAAAAAA/DvLT0DGPPfcc0ljtt122yx0AjXPnIUrY4/rxmck99hz94rOLRtmJDcAAAAAAAAAAAAAwL+z/ARkzP3335/wvG3bttGuXbssdQM1x1/HzYzrX/4s7Xl7tGkcz53ZNwoKCtKeGwAAAAAAAAAAAABgQyw/ARkxfvz4eOeddxLG7LffflnqBmqG1SWl0X3EixnJffsvd4xBW7fJSG4AAAAAAAAAAAAAgPJYfgLSbu3atXHWWWcljTvyyCOz0A3UDBM+WxC/uufdjOT+6LKB0ai4dkZyAwAAAAAAAAAAAAAkYvkJSLtzzjknPvroo4QxnTt3jv79+2epI9h4lZWVxXF3vRMTZ/2Y9tyn7Nkpfn/AVmnPCwAAAAAAAAAAAABQUZafoAZ45513YqeddopatTL/f/k//vGPMXLkyKRx5513XhQVFWW8H9iYzVm4Mva4bnxGco85Z8/YctNGGckNAAAAAAAAAAAAAFBRhbluAMi8q6++Onr06BH33XdfrF27NiM1li1bFkcffXRccsklSWO33nrrGDp0aEb6gJri1lc/z8jiU/fWjeLLqw+w+AQAAAAAAAAAAAAA5AXLT1BDzJw5M0444YTo0KFDjBgxIj7//PO05C0rK4unn346dtppp3jkkUeSxhcVFcUdd9yRlbdQwcZodUlpdLjwubjuxRlpz33rcTvGi8P3jIKCgrTnBgAAAAAAAAAAAACoDMtPUMPMnTs3/vSnP0WXLl1i++23jz/84Q8xduzYWLZsWUp5vvrqq7jjjjuiZ8+eccghh8TMmTMr9HPXXXdd9OnTpzKtQ4335uc/RPcRL2Yk90eXDYwDtmmTkdwAAAAAAAAAAAAAAJXl1StQg02dOjWmTp0aV155ZRQWFkbHjh2je/fuscUWW0Tr1q2jSZMmUbdu3SgtLY2FCxfGwoULY968eTFx4sT4+uuvU653xhlnxDnnnJOBTwIbv1/d825M+GxB2vOetHvHuOTgHmnPCwAAAAAAAAAAAACQDpafgIiIWL9+fcyaNStmzZqVkfznnHNO/PnPf85IbtiYfbt4Vex+zbiM5H757D2ja6tGGckNAAAAAAAAAAAAAJAOlp+AjKpXr17cdtttMWTIkFy3AtXOHa/Niqtf+DTtebts2jBeGr5nFBYWpD03AAAAAAAAAAAAAEA6WX4CMma//faLW2+9NTp16pTrVqBaWV1SGt1HvJiR3H89doc4aNvNMpIbAAAAAAAAAAAAACDdCnPdAJB5vXv3js02y96yw9577x1jxoyJF1980eITpGjJqpKMLT5NvXSgxScAAAAAAAAAAAAAoFrx5ieoAS644IK44IIL4rPPPovx48fHhAkTYtKkSfHZZ5/F+vXrq5y/oKAgtt566xg8eHD86le/iq5du6aha6h5Vq5dFyfd+17a857Qp0NcNrhn2vMCAAAAAAAAAAAAAGSa5SeoQbp27Rpdu3aNU089NSIiVq5cGR9++GF89NFHMXv27JgzZ05888038d1338WyZcti5cqVsWrVqigpKYk6depEcXFxNGvWLNq0aRPt2rWLHj16xLbbbhu9e/eOVq1a5fjTQfV39fOfxgdfLUprzheH7xHdWzdOa04AAAAAAAAAAAAAgGyx/AQ1WP369WO33XaL3XbbLdetQI23uqQ0npz8bdrydWrRIMacs1cUFhakLScAAAAAAAAAAAAAQLZZfgKAPPDGzB9i2Zp1acl109HbxyHbb56WXAAAAAAAAAAAAAAAuWT5CQDywLr169OSZ+olA6NJ/dppyQUAAAAAAAAAAAAAkGuWnwAgD9StVVSlnz9+t/bxx19snaZuAAAAAAAAAAAAAADyg+UnAMgD27drGvVqF8WqktKUf/b5M/eIHps1zkBXAAAAAAAAAAAAAAC5VZjrBgCAiGYN6sSRO7dN6We2aF4/Zl11gMUnAAAAAAAAAAAAAGCjZfkJAPLEGf26RLdWjSoUe8NR28WE8/eJosKCDHcFAAAAAAAAAAAAAJA7lp8AIE+0bFQ3Hjl1t9i5fbMNntetVRjN6teOKZfsG4fukNpbogAAAAAAAAAAAAAAqqNauW4AAPj/mtavE6NP6x1Tv1kS//zgm1iwbE3UrV0YnVs2jON23SI2aVg31y0CAAAAAAAAAAAAAGSN5ScAyDMFBQWxfbumsX27prluBQAAAAAAAAAAAAAgpwpz3QAAAAAAAAAAAAAAAADAhlh+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPKS5ScAAAAAAAAAAAAAAAAgL1l+AgAAAAAAAAAAAAAAAPJSQVlZWVmumwCoqRo1ahTLly//2Z/XrVs3OnfunIOOAAAAAAAAAAAAAADIR7NmzYo1a9b87M8bNmwYy5Yty0FH2WH5CSCHiouLNzh8AAAAAAAAAAAAAACgIurWrRurV6/OdRsZU5jrBgAAAAAAAAAAAAAAAAA2xPITAAAAAAAAAAAAAAAAkJcsPwEAAAAAAAAAAAAAAAB5yfITAAAAAAAAAAAAAAAAkJdq5boBgJqsadOmsXjx4p/9ee3atWOLLbbIfkNpMmvWrFizZs3P/rxu3brRuXPnHHQEANljDgJQk5mDANRk5iAANZk5CEBNZxYCUJOZg5BdX3/9dZSUlPzsz5s2bZr9ZrLI8hNADs2bNy/XLWREz549Y/r06T/7886dO8fHH3+cg44AIHvMQQBqMnMQgJrMHASgJjMHAajpzEIAajJzEMiGwlw3AAAAAAAAAAAAAAAAALAhlp8AAAAAAAAAAAAAAACAvGT5CQAAAAAAAAAAAAAAAMhLlp8AAAAAAAAAAAAAAACAvGT5CQAAAAAAAAAAAAAAAMhLlp8AAAAAAAAAAAAAAACAvGT5CQAAAAAAAAAAAAAAAMhLlp8AAAAAAAAAAAAAAACAvGT5CQAAAAAAAAAAAAAAAMhLlp8AAAAAAAAAAAAAAACAvGT5CQAAAAAAAAAAAAAAAMhLlp8AAAAAAAAAAAAAAACAvGT5CQAAAAAAAAAAAAAAAMhLlp8AAAAAAAAAAAAAAACAvGT5CQAAAAAAAAAAAAAAAMhLlp8AAAAAAAAAAAAAAACAvGT5CQAAAAAAAAAAAAAAAMhLlp8AAAAAAAAAAAAAAACAvGT5CQAAAAAAAAAAAAAAAMhLlp8AAAAAAAAAAAAAAACAvGT5CQAAAAAAAAAAAAAAAMhLlp8AAAAAAAAAAAAAAACAvGT5CQAAAAAAAAAAAAAAAMhLlp8AAAAAAAAAAAAAAACAvFQr1w0AsPEZNmxYLFiw4Gd/3rJlyxx0AwDZZQ4CUJOZgwDUZOYgADWZOQhATWcWAlCTmYNANhSUlZWV5boJAAAAAAAAAAAAAAAAgP9UmOsGAAAAAAAAAAAAAAAAADbE8hMAAAAAAAAAAAAAAACQlyw/AQAAAAAAAAAAAAAAAHnJ8hMAAAAAAAAAAAAAAACQlyw/AQAAAAAAAAAAAAAAAHnJ8hMAAAAAAAAAAAAAAACQlyw/AQAAAAAAAAAAAAAAAHnJ8hMAAAAAAAAAAAAAAACQlyw/AQAAAAAAAAAAAAAAAHnJ8hMAAAAAAAAAAAAAAACQlyw/AQAAAAAAAAAAAAAAAHnJ8hMAAAAAAAAAAAAAAACQlyw/AQAAAAAAAAAAAAAAAHnJ8hMAAAAAAAAAAAAAAACQlyw/AQAAAAAAAAAAAAAAAHnJ8hMAAAAAAAAAAAAAAACQlyw/AQAAAAAAAAAAAAAAAHnJ8hMAAAAAAAAAAAAAAACQlyw/AQAAAAAAAAAAAAAAAHnJ8hMAAAAAAAAAAAAAAACQlyw/AQAAAAAAAAAAAAAAAHnJ8hMAAAAAAAAAAAAAAACQlyw/AQAAAAAAAAAAAAAAAHnJ8hMAAAAAAAAAAAAAAACQlyw/AQAAAAAAAAAAAAAAAHnJ8hMAAAAAAAAAAAAAAACQlyw/AQAAAAAAAAAAAAAAAHnJ8hMAAAAAAAAAAAAAAACQlyw/AQAAAAAAAAAAAAAAAHmpVq4bAIBUrVu3LmbNmhWzZ8+OZcuWxfLly6O4uDgaN24cbdq0iW7dukX9+vVz3SYAZMSaNWvis88+i2+++SaWLVsWK1eujPr160ejRo2ibdu20a1bt6hTp06u2wSAjDAHAajpzEIAajLXCAGoycxBACqqpKQkZs+eHXPnzo0FCxbEqlWroqSkJOrUqRP16tWLFi1aRJs2baJDhw5Ru3btXLdbIeYgEGH5CWCjUVJSEp9++mlMmzYtPv7445g2bVp88803sXjx4li8eHEsWbIkioqKori4OJo3bx6bbbZZdOzYMbbddtvYZZddok+fPnl9Ufyjjz6Kxx9/PJ5//vmYMmVKrF27ttzYgoKC6NKlSwwaNCgGDx4c/fr1i4KCgix2C0A2rV+/Pr744ov46KOP4vPPP485c+bE119/HXPmzImFCxfGypUrY8WKFbFq1aqoVatWFBcXR7NmzaJ169bRvn376NGjR+y0007Rt2/faNq0aa4/zga9/fbb8eSTT8YLL7wQH3/8cZSWlpYbW1RUFD179owDDjggDjnkkNhtt92y2CkApJ85CEBNZxYCUFXTp0+PcePGxbRp0+Kzzz7735vFli1bFuvXr48GDRpEw4YNo3nz5tGpU6fo3LlzdOvWLXr16hVbb711FBUV5ax31wgBqMnMQQAqYsWKFfH888/H2LFj480334wZM2ZESUlJ0p+rXbt2dO/ePfr27Rv9+/eP/fffP68WiMxB4D8VlJWVleW6CQBSt379+pg8eXKMGzcuxo4dG6+//nqsXLmy0vnq168fAwcOjCFDhsRBBx0UtWrlx37sSy+9FNdcc028+uqrlc7RtWvXOPvss+PXv/51Ti/OAJAes2bNijfffDPefPPNmDJlSkybNq1KM/BfCgsLo3fv3nHkkUfG8ccfH82aNUtDt1Xz8MMPx3//93/HpEmTKp1jp512ivPOOy+OOuqoNHYGQHW3aNGi2GqrreL7779PGjtkyJC49957M9/UfzAHAfhPub5Y/corr8SAAQOyVs8sBKAqPvnkk7jrrrvi4Ycfju+++67SeRo0aBC9evWKQYMGxYEHHhg9e/ZMY5flc40QgOXLl8fDDz+c6zbKdfLJJ2cstzkIQEVMmzYt/vznP8fo0aNjxYoVVc7XsGHDOOqoo+J3v/tddO/ePQ0dVo45CJTH8hNANbJu3boYO3ZsPPLII/HUU0/FwoULM1KnY8eOceGFF8bQoUNz9sXv22+/jd/+9rfxxBNPpC3ndtttF3fccUfsuuuuacsJQPacdtpp8eSTT1boJu2qatCgQQwdOjRGjBgRLVq0yHi9//Tpp5/GqaeeGhMmTEhbzr333jtuv/326NatW9pyAlB9nXTSSTFq1KgKxWZ7+ckcBKA8NWX5ySwEoComTZoUF154YbzyyisZyd+zZ8+YNm1aRnJHuEYIwP83e/bs6NixY67bKFcmbrs0BwGoiHnz5sUFF1wQf//73zMyjwoKCuKkk06Ka665Jqv3zJiDQDKWnwCqgY8//jhuvPHGeOKJJ+LHH3/MWt0dd9wx7rrrrthhhx2yVjMi4vXXX4/DDz885s+fn/bctWvXjptuuilOP/30tOcGILO23HLLmDVrVlZrNmnSJK6//vqMPrntPz3++OMxZMiQWL58edpzN2zYMO6///449NBD054bgOpj3Lhx0b9//wrHZ3P5yRwEIJGasPxkFgJQWUuWLImzzjor7r///ozc/PYvTZo0icWLF2ckt2uEAPy7mrb8ZA4CUBHPP/98DBkyJH744YeM12rdunU88MADKV1XrCxzEKiIwlw3AEByzzzzTNx1111ZXXyK+OnJcL1794477rgjazWfeuqp6N+/f0a+xEZElJSUxLBhw+LCCy/MSH4ANi5LliyJX//613HUUUfF6tWrM15v5MiRcfjhh2fkJreIiOXLl8dhhx0Wt956a0byA5D/Vq1aFaecckqu29ggcxCAms4sBKCy3njjjdhuu+3ivvvuy+jiUya5RghAdZLuh3OYgwBUxG233RYHH3xwVhafIn56w9SgQYPi/vvvz2gdcxCoKMtPACS0Zs2aOO200+LSSy/NeK1XXnkljjrqqCgpKcl4rWuvvTb++Mc/ZrwOABuHRx99NPbdd99YsWJFxmrcd9998dvf/jbjNyeUlZXFGWeckfFfTgGQny699NKsv0mxIsxBAGo6sxCAyvrHP/4R/fv3j6+++irXrVSaa4QAVDd777132nKZgwBUxKhRo2LYsGGxfv36rNZdt25dnHDCCfHoo49mJL85CKSioKy6PvYHoAa55ppr4qKLLqpwfFFRUfTs2TO22mqr6NixY7Ro0SIaNGgQq1evjh9//DHmzp0bb7zxRsyYMSPlPi644IJU26+Q2bNnxw477BCLFy9OGrvNNtvE8ccfH3vssUd06dIlmjRpEitWrIg5c+bE22+/HY888kiMHTu2QjcKPPnkk3HIIYek4RMAkGlbbrll0pu1i4qKYosttohu3bpF586do0mTJtGoUaNo3LhxlJaWxtKlS2Pp0qUxc+bMmDx5csyePTulHgYNGhTPPfdcFBam9zkS7777bvTt27dCv8zp06dPHHvssdGnT5/o0KFDNGrUKJYtWxZffPFFTJw4MR588MF45513kuapU6dOvPHGG7HLLruk4yMAUA1Mnjw5evXqFevWrUvp54YMGRL33ntvZpoKcxCAikv3k7VT9corr8SAAQPSntcsBKCyRo4cmdLybMOGDaNXr17RpUuXaN++fTRs2DBq164dixcvjsWLF8eCBQviww8/jGnTpsXq1as3mKNJkyYVup5XUa4RAlCe2bNnR8eOHXPdxgY98MADcdxxx1U5jzkIQEW8//770adPnwovCO28886x//77x+677x5bbrllNG/ePBo1ahRLly6NRYsWxaeffhoTJ06MZ599Nj788MMK5SwuLo73338/evbsWZWP8n+Yg0CqLD8BVAMVWX7q3r17HHzwwbH//vvHrrvuGvXr10+ad+7cuXHnnXfGLbfcEj/++GPS+IKCgnj22WfjgAMOqHDvFbFu3brYfffd4913300Y16pVq7jlllviiCOOSJrzvffei9NOOy0mTZqUMK5Zs2YxZcqU2GKLLVLqGYDs29DyU9u2baNv376xxx57RN++faN79+5Rp06dCuecN29ePPTQQzFq1KiYNm1ahX7myiuvjN///vcp9Z7I0qVLY/vtt48vv/wyYVyXLl3itttui/79+yfN+fLLL8ewYcOSLot17NgxpkyZEo0bN06pZwCqn9LS0thll11i8uTJKf9sJpefzEEAUpFo+enggw+OwYMHZ7T+AQccEJtttllac5qFAFTWI488Esccc0zSG7vq1asXxxxzTPzqV7+K3XffPWrVqpU0d2lpaUyfPj1eeOGFeOqpp+Ltt9/+36eLp3P5yTVCABLJ1+Wnpk2bxty5c6O4uLhKecxBACpi3bp1sd1228X06dOTxvbt2zeuvvrq6Nu3b4Xzjx07Ni688MJ4//33k8buvPPO8e6776blIVXmIFApZQDkvauvvrosIn72X9OmTcuGDx9e9sEHH1Qp//Lly8tOPvnkDdb4z//atGlTtmjRovR8sP9xww03JK273XbblX377bcp5V29enXZMccckzT3oYcemtbPA0BmdO7cuayoqKhszz33LPvLX/5S9vnnn6ctd2lpadltt91W1qxZs6Rzo27dumWzZ89OW+2zzjorac0BAwaULV68OKW8ixYtKttnn32S5j777LPT9lkAyF/XXnttubOgU6dOCWfFkCFDMtaXOQhAKhL9nX7ppZfmur1KMQsBqIzXX3+9rE6dOkn/nj/55JPLvvvuuyrX+/7778uuueaasvbt25c1adKk6h/gf7hGCEC+mTNnTllhYWHC+TFs2LC01DIHAaiIu+++O+nf6RFRNmLEiLJ169ZVqsbatWvLzjnnnArV+cc//pGWz2UOApXhzU8A1cB/vvlpyy23jPPOOy9++ctfVugNTxV1//33x0knnRSlpaUJ4y688MK4+uqr01JzwYIF0aVLl1iyZEm5MVtuuWVMnDgxWrZsmXL+0tLSOOyww+Kpp55KGPfKK6/EgAEDUs4PQPY888wz0adPn9hkk00yVmPmzJmxzz77xLfffpsw7uSTT46//e1vVa43ffr02G677WLdunXlxvTu3TvGjBlTqZm/YsWK6NevX8In5dSqVSs+/PDD2GqrrVLOD0D1MGvWrNhmm21i1apVPzvr06dPDBgwIK644opyfz5Tb34yBwFIVaInil566aVx2WWXZa+ZNDALAaiMRYsWxbbbbhvffPNNuTHNmjWLhx56KAYNGpTW2qWlpfHKK6+kJa9rhADkoz/96U8xYsSIhDEffPBB7LjjjlWqYw4CUFHbbbddfPjhhwljLrroorjqqquqXOuss86Km2++OWHMrrvuGm+//XaV6piDQGUV5roBACqua9eu8cADD8Snn34ap5xySloXnyIifvWrX8Utt9ySNO6WW26JpUuXpqXm9ddfn/BLbJ06deLRRx+t1JfYiIiioqK47777okOHDgnjLrnkkkrlByB7Dj744IwuPkVEdOnSJV577bVo2LBhwrh//OMfsWzZsirXu/zyyxPe5Na8efN45JFHKj3zGzRoEI8++mg0bdq03Jh169YlvOEdgOrv1FNP3eDiU+3ateOOO+5IeCN5JpmDANR0ZiEAlXHKKackXHzabLPN4o033kj74lPET9fd0pXXNUIA8k1ZWVmMGjUqYcz2229f5cWnCHMQgIqZNm1a0sWnvn37xpVXXpmWejfccEP06tUrYcw777wTs2bNqlIdcxCoLMtPANVAq1at4tZbb42PP/44jjvuuCgqKspYrdNPPz1+9atfJYxZsWJFPProo1WutXTp0rjjjjsSxgwfPjx22GGHKtVp0qRJ3HTTTQlj3nrrrXj99derVAeAjUPnzp3j8ssvTxizYsWKGDduXJXqfPHFF/HPf/4zYcyf/vSnaNeuXZXqtG/fPunnGT16dMyePbtKdQDIT/fcc0+MHTt2g2fnnntubL311lnu6CfmIAA1nVkIQGU899xz8dhjj5V73qhRo3j++eejR48eWewqda4RApCPXn311fjiiy8SxgwdOrTKdcxBACqqvGt8/+7qq69O24MOCwsL45prrkkaN2bMmErXMAeBqrD8BFANnHjiiXH66adHrVq1slLvqquuSvo00SeffLLKde67776EG/xNmzaNiy++uMp1IiIGDx4ce+yxR8KYZK9sBaDm+O1vf5vwydgRERMmTKhSjZEjR0ZpaWm55126dIlTTjmlSjX+ZdiwYdGpU6dyz0tLS2PkyJFpqQVA/vj+++/jd7/73QbPOnXqlNOnmZmDANR0ZiEAqSopKYlzzz03Ycztt98e2223XZY6qjzXCAHIR3fffXfC8+Li4jjuuOOqXMccBKCiJk2alPC8W7du0bdv37TW3GeffWLLLbdMGPP+++9XOr85CFSF5ScAfmbzzTePY445JmHM66+/HuvXr69Snb///e8Jz0855ZRo3LhxlWr8u2QXhJ555pmEX6wBqDlq164dBxxwQMKYTz75pNL5S0tL4x//+EfCmLPPPjttb3usVatWnHnmmQljHnrooSrPdgDyy5lnnhmLFi3a4Nmtt94a9erVy3JHPzEHAajpzEIAKuPuu++OGTNmlHs+ePDgOPbYY7PYUeW5RghAvlmyZEk8/vjjCWMOPfTQaNasWZVrmYMAVNSsWbMSng8cODAjdffbb7+E559//nmlc5uDQFVYfgJggw466KCE50uXLo2vvvqq0vlnzpwZ7733XsKYX//615XOvyEHH3xwtGnTptzzNWvWxD//+c+01gSg+urdu3fC8++++67SuceNGxdz584t97y4uDh++ctfVjr/hgwZMiTq1KlT7vl3330Xr776alprApA7zzzzTDz66KMbPDvqqKOSXrTIJHMQgJrOLAQgVevXr4+//OUv5Z4XFRXFtddem8WOKs81QgDy0UMPPRSrVq1KGDN06NAq1zEHAUhFeQ85/Jdtt902I3WT5f3hhx8qldccBKrK8hMAG7Tnnnsmjfniiy8qnf+ZZ55JeL7TTjslfX1qqgoLC+PII49MGJOsLwBqjlatWiU8X7FiRaVzJ5s3Bx54YDRq1KjS+TekadOmsf/++yeMMQcBNg7Lli2LYcOGbfCsadOmceONN2a3of9gDgJQ05mFAKTq6aefjpkzZ5Z7fthhh0X37t2z2FHluUYIQD665557Ep536NAh+vXrV+U65iAAqVizZk3C8xYtWmSkbsuWLROeJ1sYLo85CFSV5ScANqh58+YJnwQaEbF48eJK5x8zZkzC8wMPPLDSuauSd/z48VFaWpqR2gBUL02aNEl4Xr9+/Urnztc5+Morr2SkLgDZdeGFF8Y333yzwbOrr746WrduneWO/i9zEICaziwEIFWjRo1KeH7aaadlqZOqy9c56BohQM314Ycfxvvvv58w5sQTT4yCgoIq1zIHAUhFsvtWGjRokJG6yfI2bty4UnnNQaCqLD8BUK5kTwao7Ab/unXrYsKECQljBgwYUKncyeyxxx5RXFxc7vmSJUuSvloVgJph/vz5Cc8r+wSduXPnxieffJIwJlNzcN999014/vHHH8e8efMyUhuA7Jg4cWLcdtttGzzr3bt3nHrqqVnu6P8yBwGo6cxCAFK1ePHiePHFF8s9b9OmTey9997Za6gKXCMEIB8le+tTYWFhnHDCCVWuYw4CkKpNNtkk4fmPP/6YkbrJ8ibra0PMQSAdLD8BUK6VK1cmPE/0hTCRjz/+OFasWFHuee3ataNXr16Vyp1McXFx7LDDDgljfJEFICJizpw5Cc87depUqbzvvvtuwvN27dpFu3btKpU7mQ4dOkSbNm0SxpiDANXX2rVr4+STT46ysrKfndWqVSvuuOOOtDydtCrMQQBqOrMQgFQ98cQTsXbt2nLPDzrooJz/W6+iXCMEIN+sXbs2HnjggYQx++67b2yxxRZVrmUOApCqHj16JDzP1IOMkuWtzP0y5iCQDpafANigZcuWxZIlSxLGNGvWrFK5J02alPC8R48eUbdu3Urlroidd9454fnkyZMzVhuA6iPR01QjfnoyTGUkm4M77rhjpfJWlDkIsPG68sory32TxDnnnBPbbLNNljv6OXMQgJrOLAQgVa+88krC8379+mWpk6pzjRCAfPPUU08lfbvF0KFD01LLHAQgVcnuS3n99dczUjfZG5r69u2bck5zEEgHy08AbNDkyZM3+LTwf9e5c+dK5Z4yZUrC82233bZSeSsqWX5fZAH4+uuv48033yz3vFatWpV+3bY5CEAmTJ8+Pa655poNnnXo0CEuvfTSLHe0YeYgADWdWQhAql599dWE57vuumt2GkkDcxCAfHP33XcnPN9kk03ikEMOSUstcxCAVPXr1y+Ki4vLPR83blysWbMmrTVXrVoV48aNK/e8sLAw9tlnn5TzmoNAOtTKdQMA5Kfnnnsu4Xnjxo0r/Vrvzz77LOF5ly5dKpW3orbccsuE5zNnzsxofQDy3/Dhw6O0tLTc88MOOyw222yzSuU2BwFIt/Xr18fJJ58ca9eu3eD5rbfeGvXr189yVxtmDgKQDSUlJTFr1qz4+uuvY+HChbF69eqoXbt21KtXL5o2bRpt27aNdu3aRb169bLem1kIQCo+//zzmDt3brnnTZs2jY4dOybNs27dupg5c2Z8+eWXsWTJklizZk3Ur18/GjVqFO3atYsOHTpEw4YN09n6BpmDAOSTOXPmJH3D4vHHHx916tRJSz1zEIBUNWvWLI477rhyl3UXL14ct912WwwfPjxtNW+55ZZYunRpuecHH3xwtG3bNuW85iCQDpafAPiZ0tLSeOSRRxLG9O3bNwoLK/cCwS+//DLhebIvmlWVLP+KFStiwYIF0bJly4z2AUB+uvHGG+OJJ54o97xWrVpx4YUXVip3WVlZzJ49O2FMrudgsv4AyD8jR46Mt956a4NnRx55ZOy///5Z7mjDzEEAMmn69Olx/vnnx/jx4+Ojjz5K+sTTwsLC6Nq1a+y8884xYMCA2H///WPTTTfNaI9mIQCpSvZk7ER/r//www/x4IMPxjPPPBOvv/56uQ/MiIgoKCiIrbbaKvr27RuHHHJIDBgwIG03ev871wgByCf33ntvrF+/PmHM0KFD01bPHASgMn73u9/F3//+93L/TXfVVVfFEUccEZtvvnmVa3311VdxzTXXJIw555xzKpXbHATSoXJ3rQOwUXvyySfjq6++ShgzePDgSuUuKytLmruyb9KoqNatWydd3Er2ZRuAjU9JSUlceumlcfbZZyeMu+iii2L77bevVI3vv/8+Vq9enTAm03MwWf4VK1bE/PnzM9oDAOkzZ86cuPjiizd41qRJk7jxxhuz21AC5iAAmTR69Oj47//+73j//feTLj5F/PTmxE8//TQeeOCBOOGEE6JNmzZx4IEHxjPPPBNlZWUZ6dEsBCBV06ZNS3jeuXPnn/3Z/Pnz4/TTT48tttgihg8fHmPHjk24+BTx0/W76dOnx5133hkHHnhgtG3bNi6//PJYtGhRlfr/zxquEQKQL8rKyuLee+9NGNOrV6/Yeuut01bPHASgMrp37x6XXHJJuecLFiyIgw46KJYtW1alOgsXLoz9998/4b8DTzzxxNhzzz1Tzm0OAuli+QmA/6O0tDThl+WIiDp16sQRRxxRqfyLFi1KeoG/devWlcpdUbVq1YpNNtkkYcx3332X0R4AyB8lJSXx5JNPxvbbbx9XXHFFwthBgwbFiBEjKl2rIvMl03OwIvnNQYDqY9iwYeVezLjqqquiTZs2We6ofOYgAPls/fr18fzzz8fgwYNj5513jjFjxqS9hlkIQKqmT5+e8LxVq1b/53/ffffd0a1bt7j99ttj1apVla67YMGCuOyyy6Jr167xt7/9rdJ5/p1rhADkk/Hjx8cXX3yRMCadb30yBwGoigsvvDAGDhxY7vmUKVNil112ialTp1Yq/zvvvBM777xzfPLJJ+XGdO7cOW644YZK5TcHgXSx/ATA/3HbbbclvZAyZMiQaN68eaXy//jjj0ljNt1000rlTsV/Xgz6TxXpE4DqpbS0NBYtWhRff/11TJw4MW699dYYOnRotGnTJg499NCk82/QoEHxxBNPRO3atSvdQ7L50rhx46hbt26l81dE/fr1o2HDhgljzEGA6uHhhx+OZ599doNnu+22W5x22mlZ7igxcxCA6mLSpEmx7777xkknnRRLly5NW16zEIBUzZkzJ+F5y5YtI+KnBzwNHTo0Tj755Fi8eHHa6v/www9xyimnxGGHHVblmegaIQD55J577kl4Xr9+/Tj66KPTVs8cBKAqioqK4sknn4y99tqr3JgZM2ZEr1694qSTTqrwEtR7770Xxx13XPTt2zfhW4/atm0bY8aMiSZNmqTce4Q5CKRPrVw3AED+mD17dlx00UUJY2rXrh0XXHBBpWssXLgwaUzjxo0rnb+iktWoSJ8A5Jdp06bFNttsk/a8tWrVihEjRsTFF18cRUVFVcqVbL5kYwb+q87y5cvLPTcHAfLfwoUL46yzztrgWa1ateKOO+6IwsL8eu6ROQhAdTNq1Kh4++2349lnn41OnTpVOZ9ZCECq5s6dm/C8cePGsW7dujjmmGPin//8Z8b6ePzxx+PLL7+Ml1566X8XrlLlGiEA+WLJkiXx+OOPJ4w54ogj0jqXzEEAqqpevXrx4osvxrnnnhu33nrrBmPWrl0bo0aNilGjRsVmm20Wu+++e3Tp0iWaNWsWDRs2jGXLlsWiRYtixowZ8eabb8b333+ftO6OO+4Yo0ePjg4dOlS6d3MQSBfLTwBExE9vwxgyZEjCi94REcOHD4/OnTtXus6iRYsSnterV6/KN5ZXRKNGjRKe+yILQEFBQRxyyCFx2WWXxXbbbZeWnMnmYLL5lC7mIED1d84558T8+fM3eHb22WfHtttum+WOkjMHAaiOPvnkk9h1113j1VdfjZ49e1Ypl1kIQKrmzZuX8LxOnToxbNiwjC4+/cvkyZOjX79+8eabb1bqpjTXCAHIFw899FCsWrUqYczQoUPTWtMcBCAdiouLY+TIkXHQQQfFBRdcEB999FG5sd99912MHj260rXq1KkTZ555Zlx55ZVRp06dSueJMAeB9LH8BEBERIwYMSImTJiQMKZdu3YxYsSIKtVZvXp1wvMGDRpUKX9FNWzYMOF5sj4B2Hh17949Dj300PjlL38ZPXr0SGtucxCAdBgzZkzcd999Gzxr3759XHbZZdltqILMQQAyZeutt46ddtopttlmm9hmm22iXbt20aRJk2jSpEnUqVMnFi5cGD/++GPMnz8/3nnnnXjttdfizTffjKVLl1Yo/w8//BD77rtvvPnmm9GxY8dK92kWApCK1atXx5o1axLGPProozF+/Phyz+vVqxf9+/ePQw45JHbcccdo1apVtGzZMpYsWRLz5s2LGTNmxDPPPBPPPfdc/Pjjj0l7mjZtWhx99NHx3HPPRUFBQcqfJxFzEIBsufvuuxOed+3aNfbYY4+01jQHAUin/fffPwYNGhRPPvlk3HPPPTFmzJi0/R3euHHjOPbYY+P3v/99tGvXLi05zUEgXSw/ARDPPPNMXHPNNQljCgoK4p577qny00fXrl2b8LxWreyMpmR1kvUJwMapVq1a0alTp9h8882jfv36ac9vDgJQVStXroxTTz213PORI0dmZIalgzkIQLoUFRXFwIED4+CDD44DDzwwtthii4TxrVq1ilatWkWPHj1i7733jgsuuCBWr14d9913X1x//fXx+eefJ605d+7cOOyww2LixIlRXFxcqb7NQgBSkeyNFBFR7uJTQUFBHH/88XHttddG69atf3besmXLaNmyZWyzzTZx+OGHx6pVq+Laa6+N6667LmndF154IW655ZY488wzK/ZB/oc5CEA++PDDD+ODDz5IGHPSSSelva45CEC6FRQUxKGHHhpbbbVVPPjgg3H99ddXaXmndu3acf7558fFF18c9erVS2On5iCQPoW5bgCA3Jo2bVocd9xxUVZWljDujDPOiAEDBlS5ni+yAOSzdevWxfPPPx9nnHFGdO7cOf7rv/4r3n777bTlNwcBqKpLLrkkvvjiiw2eHX744XHggQdmuaOKMwcBqKo2bdrEiBEjYvbs2fH888/H6aefnnTxqTzFxcVx6qmnxowZM+LGG2+M2rVrJ/2ZyZMnx+9///tK1YswCwFITWVvWqtfv3688MILcd99921w8WlD6tWrF5dddllMnTo1OnTokDT+oosuiu+++y6lvsxBAPJBsrc+1apVK4YMGZL2uuYgAOm0bt26uP/++2PrrbeOrbbaKv70pz9V+a1FJSUlceWVV0bHjh3jtNNOixkzZqSpW3MQSB/LTwA12Pz58+Pggw+OZcuWJYzbZZdd4vrrr09LzfXr1yc8LyoqSkudZJLVKS0tzUofAOSv9evXxxNPPBG9e/eOY489NhYtWpSWnImYgwAk8sEHH8SNN964wbPGjRvHzTffnN2GUmQOAlBVX3/9dVxxxRXRtm3btOUsLCyMs846K954441o37590vhbbrklPvroo0rVMgsBSEVJSUnKP9OoUaN4+eWXY7/99qtUzS5dusTrr78eXbt2TRi3cuXKuOKKK1LKbQ4CkGtr166NBx98MGHMAQccUOHl4VSYgwCky3PPPRddunSJIUOGxMcff5z2/N9//33ccccd0aNHjzjiiCNi1qxZVc5pDgLpkp1VSQDyzvLly+OAAw6I2bNnJ4zbZJNNYvTo0VGnTp201E22Pb9u3bq01EkmWZ2KPOkVgPyy+eabx9/+9rdyz1etWhWLFy+OxYsXx9dffx3vvvtufP311xXK/Y9//CMmTJgQo0ePjt69e1e6R3MQgMpat25dnHzyyeX+0v2qq66KNm3aZLmr1JiDAFRVJp8A2qtXr5gwYUL07ds35syZU27cunXr4pJLLoknnngi5RpmIQCpqMzNX7fcckvsvvvuVarbtm3bGD16dOyyyy4Jn3p97733xp/+9Kdo0aJFhfKagwDk2pNPPhk//vhjwpihQ4dmpLY5CEBVrVq1Ks4999y47bbbslJv/fr18dhjj8WLL74YN910U5x00kmVzmUOAuli+QmgBlq7dm0ceuih8cEHHySMq1evXjz11FMVeuJpRSVbosrWF9lkT8tL17IXANnTrFmzOPnkk1P6mfnz58fjjz8ed9xxR0yZMiVh7Lfffhv77bdfvPDCC5W+gcAcBKCyrr/++nJnVa9eveL000/PbkOVYA4CkO+22GKLePLJJ6NPnz6xZs2acuOefvrpmDlzZnTp0iWl/GYhAKlI9e/jwYMHx5AhQ9JSe9ttt41LLrkk/vCHP5Qbs2bNmhg1alScd955FcppDgKQa/fcc0/C89atW8cBBxyQkdrmIABVsWrVqjjooINi3LhxSWOLioqiX79+seeee8buu+8ebdu2jU022SQaN24cS5YsiYULF8acOXPizTffjAkTJsS4ceMSvplp+fLlMXTo0Pjggw9i5MiRlerfHATSpTDXDQCQXaWlpXHMMcfEmDFjEsbVrl07Ro8eXeWnw20obyKJniCXTr7IAhARsemmm8Zpp50WkydPjrFjx0bnzp0Txi9btiwGDRoU06dPr1Q9cxCAyvj888/j8ssv3+BZrVq14o477ojCwvz/NZ85CEB1sOOOO8bvf//7hDHr16+PBx54IOXcZiEAqUj17+Mrr7wyrfXPPffc2GSTTRLG/POf/6xwPnMQgFyaM2dOvPLKKwljhgwZkrE3DpuDAFTW2rVrY/DgwUkXn2rXrh2/+c1v4rPPPouXX345/vCHP8Q+++wTXbp0iebNm0etWrVik002iS5dukS/fv1ixIgR8corr8Rnn30Ww4YNSzoDb7311jjjjDMq9RnMQSBd8v+uCADSpqysLE4++eR4/PHHE8YVFhbG/fffHwceeGDae2jYsGHC8+XLl6e95oYsW7Ys4XmyPgHY+PTr1y8+/PDDpK/qXr58efzyl79M+kuRDTEHAaiMU045JVavXr3Bs7POOiu233777DZUSeYgANXF+eefH5tuumnCmMceeyzlvGYhAKmoX79+hWP32GOP2HrrrdNav7i4OE488cSEMe+991788MMPFcpnDgKQS/fee2/Ct1pERNJrhFVhDgJQWZdeemnSB923b98+Xn/99fjrX/8anTp1Sil/586dY+TIkfHaa69Fu3btEsaOHDkybr/99pTyR5iDQPpYfgKoQc4666y49957k8bdfvvtcfTRR2ekh+bNmyc8LykpKfemvnRaunRpwvNkfQKwcapfv37cddddSS9uTJ48Oa699tqU8yebL8nmU7qYgwDVx9133x3jx4/f4Fn79u3LfSNUPjIHAaguiouL47TTTksYM3369Jg/f35Kec1CAFJRu3btaNSoUYViTzjhhIz0kGz5af369fHuu+9WKJdrhADkSllZWYwaNSphzB577BFdu3bNWA/mIACVMXHixLjuuusSxnTp0iXef//92HXXXatUq0+fPvHBBx9E586dE8b97ne/i1mzZqWU2xwE0sXyE0AN8fvf/z5uueWWpHF//vOf49e//nXG+thkk02SxixevDhj9StaoyJ9ArBxKigoiL/97W+x9957J4y76aabYtWqVSnlTjZfsjEDIyKWLFmS8NwcBMgP33//fZx33nnlnv/1r3+NBg0aZLGjqjEHAahOjjzyyKQxb731Vko5zUIAUlXRv5N33333jNTfaqutomnTpgljJk2aVKFcrhECkCvjxo2LL7/8MmHM0KFDM9qDOQhAZVx44YUJ31zYvHnzeO6556JFixZpqdeyZct47rnnEv47cMWKFQmvX26IOQiki+UngBrgqquuiquvvjpp3OWXXx7nnHNORnupyBftefPmZbSHitTwRRagZissLIxbbrklioqKyo354Ycf4v77708pb7I5uGbNmoz/QmfhwoWxdu3ahDHmIEB+OOOMM2LRokUbPDvssMPioIMOynJHVWMOAlCd9OzZMzbddNOEMZ9++mlKOc1CAFJVketqzZo1y9ibKgoKCqJXr14JYyr6xG/XCAHIlXvuuSfheaNGjeKII47IaA/mIACpeu+99+L1119PGHPZZZdFly5d0lq3W7ducckllySMeeqpp1J6+5M5CKSL5SeAjdxNN90UF198cdK48847L+mX1nSoX79+0i+J33//fUZ7WLlyZSxbtixhTPv27TPaAwD5b+utt46jjjoqYczTTz+dUs4tttgiaUym52BF8lekTwAy6+mnn47HHntsg2eNGzeOm2++OcsdVZ05CEB1s8MOOyQ8nz17dkr5zEIAUlWRv5O32mqrKCgoyFgPPXr0SHg+Z86cCuVxjRCAXFi8eHE8/vjjCWOOPvroqF+/fkb7MAcBSFWy5d127drFKaeckpHaw4YNi7Zt25Z7vn79+rjjjjsqnM8cBNLF8hPARuzOO++M4cOHJ40744wz4rrrrst8Q/+jQ4cOCc+/+uqrjNavSP5kPQJQM/ziF79IeP7GG28kfMX4f2rYsGHSX+hkeg4muzlv0003jQYNGmS0BwCSS/RW3j/96U+x2WabZbGb9DAHAahukv2OcP78+SnlMwsBSFXHjh2TxjRt2jSjPTRr1izh+cKFCyucyzVCALLtoYceitWrVyeMGTp0aFZ6MQcBSMX48eMTnh911FFRt27djNSuW7duHHnkkQljxo4dm1JOcxBIh1q5bgCAzPj73/8ep512WtK4oUOHZv2J4R07dowPPvig3POZM2dmtP7nn3+e8LxVq1YZf6oPANXDoEGDorCwsNwFp6VLl8aMGTNiq622qnDOjh07xo8//lju+cyZM2PgwIEp91pRyeZgRW6oACDzfvjhhw3+eePGjaNu3bpx1113pa3WpEmTEp7PnDkzab299torunTpkrSWOQhAddKkSZOE5ytXrkw5p1kIQCo6deqUNCbTy0/J8qcyD10jBCDb7r777oTnPXv2jF133TUrvZiDAFTU/PnzY8aMGQljMvk7xH/l/8tf/lLu+dSpU2Pp0qXRuHHjCuUzB4F0sPwEsBEaPXp0nHjiiVFWVpYw7phjjok777wzCgoKstTZT3r27BmPPfZYuefJvrhXVbL8PXv2zGh9AKqPRo0aRYsWLRI+zXv+/PkpLT/17Nkz3n///XLPzUEAElm6dGmceuqpWa05ceLEmDhxYsKYUaNGVWj5yRwEoDqpU6dOwvOSkpKUc5qFAKRi6623ThpTr169jPaQLP+6desqnMs1QgCyaerUqUkf/JSttz5FmIMAVNyXX36ZNKZXr14Z7SHZcnBpaWnMnDkzdtpppwrlMweBdCjMdQMApNfTTz8dxx13XJSWliaMO/TQQ+P++++PwsLsj4Idd9wx4fnkyZMzWj/ZL7d22GGHjNYHoHpp1apVwvNET+zeEHMQgJrMHASgOlm1alXC88rcbG4WApCKHXbYIem1vCVLlmS0h2T5U5mH5iAA2ZTsrU916tSJ448/PkvdmIMAVFyy+1Dq1KmT9K31VdW0adOoXbt2wphU7pcxB4F0sPwEsBF56aWX4sgjj0z6xNH9998/Hn744ahVKzcvAEz2Rfabb75J+IaNqkr0+tQIX2QB+L+SvaI72c1w/ynZHJwyZUrSJebKWrduXUydOjVhjDkIQCaZgwBUJ/PmzUt43rBhw5RzmoUApKJRo0bRtWvXhDGLFy/OaA+LFi1KeJ7KPHSNEIBsWbNmTTz44IMJYwYPHhwtWrTIUkfmIAAVl+zfYZtssklW+khWJ53LT+YgUBGWnwA2Eq+++moceuihsWbNmoRx/fr1i8cffzzq1KmTpc5+rm3bttG+ffuEMa+++mpGan/33Xfx2WefJYzp27dvRmoDUD2tWLEi4XmDBg1SyrfzzjtHcXFxuefLly9P+kuXynr33Xdj5cqV5Z4XFxdX+JXkAFAZ5iAA1cnnn3+e8HzzzTdPOadZCECqkl23yuTNYRXJn8o8dI0QgGx58sknY+HChQljhg4dmqVufmIOAlBRRUVFCc+T3SOaLqtXr054XlBQUOFc5iCQDpafADYCb731Vhx88MFJ3zzRt2/fePrppxNeXM+WAQMGJDx/5ZVXMlJ3zJgxCc+7dOmS9Es2ADXLnDlzEp43a9YspXzFxcWx++67J4zJ1RzcY4898uJ7AgAbL3MQgOpizZo1MWXKlIQxHTt2TDmvWQhAqvbbb7+E59OnT0+43FpV77//fsLzVK+ruUYIQDbcc889Cc/btWsXAwcOzFI3/585CEBFJHsI76JFizL29vh/KSkpSfqm4fr166eU0xwEqsryE0A198EHH8T+++8fy5cvTxi3yy67xHPPPZfy2ykyZd999014/vTTT2fkC/pjjz2W8DwXv9wCIH99++23SV/T3blz55TzJpuDjz/+eMo5K8IcBCAfmIMAVAdjx45N+gTVbbfdtlK5zUIAUjFgwICET/1et25d0gWlylq5cmV89NFHCWO22267lHK6RghApn399ddJb3I+4YQTorAw+7dOmoMAVETr1q0TnpeVlcW3336b0R6++eabpDGtWrVKKac5CFSV5SeAauyjjz6K/fbbL5YsWZIwbrvttouXXnopGjdunKXOkjvwwAMTbv7Pnz8/6S+jUrVw4cJ46aWXEsYcccQRaa0JQPX28ssvJzxv1KhRbL755innPfzwwxOeT5o0KWbMmJFy3kSmTZuW8EaFgoKCpH0BkD2LFy+OsrKyrPx36aWXJuxlyJAhSXOccMIJFf5s5iAA1cH999+f8Lx27dqxyy67VCq3WQhAKpo2bZr0Rqxkv8esrLFjxya98WzXXXdNKadrhABk2r333hvr168v97ygoCBOPPHELHb0/5mDAFRERd44P27cuIz2MHbs2KQxFenz35mDQFVZfgKopj777LPYd999k76NokePHvHKK69Es2bNstRZxTRs2DAGDx6cMOaWW25Ja83bb7891q5dW+55u3btYs8990xrTQCqt3vvvTfh+R577BEFBQUp5+3cuXPstttuCWPSPQdvvvnmhOd9+vSJDh06pLUmAGyIOQhAvps5c2bSp4HuueeeUVxcXKn8ZiEAqRoyZEjC87vvvjtKSkrSXve2225LeN6hQ4fo1q1bSjldIwQgk8rKymLUqFEJY/r165fyzdrpYg4CUBEtWrSItm3bJox58cUXM9rDCy+8kPC8devWsemmm6aU0xwEqsryE0A1NHv27Ojfv398//33CeO6dOkSY8aMiZYtW2aps9ScdNJJCc+ff/75mDJlSlpqLV++POkX41/96leVuoEdgI3TuHHjYsKECQlj9ttvv0rnTzYHR40aFXPnzq10/n/3zTffxN///veEMam8sQMAqsocBCCfnXnmmUnfcnHkkUdWqYZZCEAqDjnkkGjRokW55/PmzYvRo0entebMmTOTPh37F7/4RaVyu0YIQKaMGzcuZs+enTBm6NCh2WmmHOYgABXRp0+fhOePP/54fPnllxmp/emnn8ZTTz2VMKZ3796Vym0OAlVh+Qmgmvnuu++if//+8c033ySM69ChQ4wbNy7atGmTpc5St++++8a2225b7nlZWVkMHz48LbWuvvrqmDdvXrnndevWjd/+9rdpqQVA9bds2bI45ZRTEsbUrl07jjnmmErXOP744xM+BWflypVx4YUXVjr/v7vgggti9erV5Z63atUqjj/++LTUAoCKMAcByFfXX3990qemNm7cOI466qgq1TELAUhFcXFxnHXWWQljfve738WiRYvSUq+srCxOOeWUWL9+fcK4X//615XK7xohAJly9913Jzxv1qxZHHrooVnqZsPMQQAqItkbkkpKSmLEiBEZqX3xxRcnfTjUwQcfXKnc5iBQFZafAKqRBQsWRP/+/eOLL75IGNe2bdsYN25c0lef5oMLLrgg4flrr70WN9xwQ5VqTJw4Ma677rqEMSeccEK0atWqSnUAyIwxY8bEihUrslZv5cqVceihh8asWbMSxh199NFVertiRW5YuP/+++OJJ56odI2IiEcffTQeeuihhDHDhw+PunXrVqkOAKTCHASgoiZNmhSrVq3KSq377rsvzj///KRxw4YNiyZNmlSpllkIQKrOOOOMhPNn7ty5MWzYsLTUuummm+LVV19NGDNw4MDo0aNHpWu4RghAui1evDjpv6GOO+64KC4uzlJH5TMHAUhm8ODB0bBhw4QxDz74YNx5551prfvnP/85Hn/88YQxxcXFlX4TcIQ5CFSe5SeAamLx4sUxcODA+PTTTxPGtW7dOsaNGxcdO3bMUmdVc8wxx8Quu+ySMOaCCy6IZ555plL5Z86cGYcffnisW7eu3JhGjRrFZZddVqn8AGTeX//61+jYsWNcf/31sXLlyozWmjFjRuyzzz4xduzYhHF16tRJy+wYPnx4tGvXLmHMkCFD4t13361U/rfffjuGDh2aMKZ9+/ZJb7gDgEwwBwGoiPvvvz86d+4cN998c8YejLF27doYPnx4nHDCCVFWVpYwtlWrVkkvzleUWQhAKpo2bRpXXHFFwpiHH344hg0blnSeJXL33XfHueeemzCmoKAgrrnmmkrXiHCNEID0e/DBBxO+9TYikv4bKVvMQQCSadSoUYXetvub3/wmHn744bTUvOeeeyr0cKgTTzwxmjVrVuk65iBQWZafAKqB5cuXx/777x9TpkxJGNeiRYsYO3ZsdOnSJTuNpUFBQUH89a9/jYKCgnJjSkpK4ogjjoi77rorpdxvvvlm7LXXXjF37tyEcZdeemm0bt06pdwAZNeCBQvivPPOi44dO8a5554b77zzTlrzL1u2LP7whz/EtttuW6Gbyi699NLo1KlTlevWr18//vKXvyTtbeDAgfHss8+mlPupp56K/fbbL5YvX54w7s9//nPUq1cvpdwAkA7mIAAVNXfu3DjrrLOiXbt2cfbZZ8fUqVPTlvu1116Lvn37xk033VSh+JtvvjmaNm2altpmIQCp+s1vfhM77rhjwpjbbrstjj766FiwYEFKudesWROXXXZZ/PrXv47169cnjD3ttNNihx12SCn/f3KNEIB0u+eeexKe77jjjrH99ttnp5kkzEEAKuL8889P+gb6devWxTHHHBO/+c1vKv1A4WXLlsWJJ54YQ4cOTfrvwQYNGsRFF11UqTr/Yg4ClVVQVpVH/gCQFQcffHCFLm7/5je/yeovatq0aRMHHnhgWnJdfPHFcdVVVyWNGzRoUFxxxRUJN/+/+uqruPbaa+Nvf/tbwu39iIi99torxo4dG0VFRSn3DEB2/OIXv4innnrqZ3/evn37OPzww6N///6x2267pfxUmWXLlsXrr78eDzzwQDz11FMV/iVQ//7946WXXkrr7DjuuOPioYceShhTUFAQxxxzTIwYMSK6d+9ebtz06dPjiiuuiEceeaRCdR944IGU+wVg43LZZZfF5ZdfXu75kCFD4t57781YfXMQgESGDx++wcWkrl27xkEHHRT9+vWL3r17R/PmzSucc968eTF27Ni4+eabU3qr0m9/+9u4+eabKxxfUWYhAKn45JNPolevXkkXXJs2bRoXX3xx/PKXv0x4Q9fy5cvjmWeeiREjRsSsWbOS1u/WrVtMmjQp6tevn3LvG+IaIQDpMHXq1KT3y4wcOTKGDRuWnYYqyBwEIJnbb789Tj/99ArFbrLJJjFs2LA4+eSTY4sttkga/+WXX8add94Zt99+eyxevLhCNW644YYYPnx4hWKTMQeBVFl+AqgGOnToEF999VWu2/iZvfbaK1599dW05CotLY1+/frFhAkTKhTfvXv32GOPPaJLly7RuHHjWLFiRcyZMyfeeeedePvtt6Mi423TTTeNyZMnx2abbVbV9gHIoPKWn/5dQUFBtGvXLrp16xbt27eP1q1bR/PmzaO4uDiKiopi2bJlsXTp0li2bFl89dVXMWXKlPjyyy8rNC/+3fbbbx+vvfZaNG7cuCof6WeWL18eO++8c8yYMaNC8TvssEP06dMnOnbsGA0bNoxly5bFl19+GW+++WaFn4DevXv3eO+996Jhw4ZVaR2AjUCul5/MQQASKW/56d/969+E3bt3jw4dOkTr1q2jWbNmUbdu3YiIWLRoUfz444+xYMGCeOedd+Kzzz5LuY9f/OIXMXr06KhVq1alPkciZiEAqRo9enQcddRRFfr9ZkFBQey2226x4447RqtWrWKTTTaJpUuXxvfffx+ffvppjB8/PtasWVOhui1atIiJEydGly5dqvoR/pdrhACkw5lnnhm33HJLuefFxcUxd+7ctL3JN13MQQAq4thjj41//OMfKf1Mhw4dom/fvtG2bdto3rx5NGrUKJYuXRoLFy6MOXPmxBtvvBFff/11Sjn/67/+Kx577LGEb2xKhTkIpMryE0A1UBOWnyJ+uglhn332qfAF+qpo2rRpjB8/Pm9eaQ5A+Sqy/JQNe+65Zzz11P9r7/5Cq67/B46/NtufkqULtjSmW7bEltkcGRqUEoEF/YXAIDLpj5RC2FVe6lV3BhFChejowgldLBKcSTomFLZRGdlSonVcUheRpjm1Fed78fv1pW/f1M12dl5fezzAq7Pzfr/O1Xuez56fzzsluyhSKBTizjvvjOHh4ZKs/0ezZ8+O/fv3j+lOPwBc/sodP0U4BwE4v7HET6W2YsWKeOutt6KqqqpkezgLARivzZs3x9q1aydtv/r6+ujp6Ynbb799wtd2jRCAv+PcuXNx3XXXxY8//njen8n85FvnIAAXc/bs2XjkkUeip6enbDPcfffd8e67707YU4B/5xwExqOy3AMAwO/q6+tjz549cdttt5V0n8bGxti9e7dfYgEYk4qKinjxxRfjvffeK+nd4Jqbm2Pv3r1xww03lGyPiIjW1tbYu3evP3IDIBXnIAAZTZkyJV5++eXo6uoqafgU4SwEYPzWrFkTb7zxRsnPqIiIWbNmRV9fX0nCpwjXCAH4e7q7uy8YPkVEPP3005M0zfg5BwG4mNra2uju7o6VK1eWZf8VK1bEzp07Jzx8inAOAuMjfgIglYaGhti/f3/JflFftGhRDAwMlOziDACXl4ULF8a+ffti06ZNUVNTU/L9Wltbo7+/P5YvX16S9e+9997o7+8v+R/TAcClcA4CkMnv3yOuX79+0vZ0FgIwXs8++2z09vZGU1NTyfZ46KGH4tNPP4358+eXbI8I1wgBuHRbtmy54Otz5syJZcuWTc4wl8g5CMDF1NTURGdnZ7z55pslvXHvH1199dWxefPm6OrqiiuvvLJk+zgHgbESPwGQTm1tbXR2dsbOnTtjzpw5E7JmXV1dbNq0KT788MOYNWvWhKwJwORYv359rFu3LubOnTtpey5evDi6urpiYGAgli5dOmn7RvzfXW16enpi27Zt0djYOCFrNjY2RmdnZ+zatWvSvgQDgEvhHATgzxYuXDhh3xGORUdHR7rEYC0AAA/vSURBVLz99ttx4MCBstwF1FkIwHjdcccdMTg4GC+99FJUV1dP2Lpz586Nd955J7q7u+Oaa66ZsHUvxDVCAMbr6NGj8f7771/wZ5566qmoqKiYpIkunXMQgLF45pln4vDhw/HCCy+ULEiqra2NNWvWxOHDh+P5558vyR5/tadzELiYimKxWCz3EABcWEtLSxQKhXKP8V+WLl0avb29Jd1jdHQ0duzYEa+++mr09/eP+/3Nzc3x3HPPxerVqyftwgwApfP111/H7t2744MPPogDBw7EV199FRPxX5rKyspYsGBBPPjgg/Hoo4/GLbfcMgHT/n2nT5+Ozs7OeO2112JwcHDc729ra4u1a9fGqlWrSvL4cQAuDxs2bIiNGzee9/Unn3wytm3bNnkD/T/nIAB/dPTo0di3b1/09fXFwMBADA4Oxujo6ISs3draGvfff3888cQT0dHRMSFrTgRnIQDj9d1338Xrr78eW7ZsiW+//Xbc76+uro577rknVq9eHQ888EBUVpbvfrquEQIwFhs3bowNGzac9/XKysooFAolfUpiKTgHARiLH374IbZv3x7bt2+Pjz76KH777bdLXquysjIWLVoUjz32WDz++OPR0NAwgZOOj3MQOB/xEwD/M4aHh2PXrl3R398fX3zxRRQKhTh58mSMjIxETU1N1NXVxcyZM+Omm26K9vb2WL58edx6663lHhuAEjpx4kT09/fHkSNHYmhoKIaGhuKbb76JEydOxM8//xynT5+OM2fOxJQpU6KmpiamTp0aDQ0Nce2110ZLS0vMmzcv5s+fH0uWLIlp06aV++Nc0JEjR6Knpyc+/vjjOHToUBw7dixOnToVIyMjcdVVV0VdXV00NTVFW1tbdHR0xH333Rc33nhjuccG4H9Ab2/vBW9s0d7eHg8//PCkzfNXnIMA/Nkvv/wSn3/+eXz22WcxNDQUw8PDMTw8HMeOHYuTJ0/GmTNnYmRkJM6dOxfV1dVRW1sb06ZNi5kzZ0ZTU1PMmzcvFixYEIsXL47Zs2eX++NclLMQgPE6ePBg7NmzJw4ePBhffvnlf5wdVVVVMXXq1JgxY0Zcf/31//6OdNmyZSm/J3WNEIB/MucgAGPx008/RV9fX3zyySdx6NChKBQK8f3338fx48fj7NmzMTo6GlVVVVFbWxv19fUxY8aMaG5ujra2tmhvb4+77ror6uvry/0x/otzEPgj8RMAAAAAAAAAAAAAAACQUvmeUQ4AAAAAAAAAAAAAAABwAeInAAAAAAAAAAAAAAAAICXxEwAAAAAAAAAAAAAAAJCS+AkAAAAAAAAAAAAAAABISfwEAAAAAAAAAAAAAAAApCR+AgAAAAAAAAAAAAAAAFISPwEAAAAAAAAAAAAAAAApiZ8AAAAAAAAAAAAAAACAlMRPAAAAAAAAAAAAAAAAQEriJwAAAAAAAAAAAAAAACAl8RMAAAAAAAAAAAAAAACQkvgJAAAAAAAAAAAAAAAASEn8BAAAAAAAAAAAAAAAAKQkfgIAAAAAAAAAAAAAAABSEj8BAAAAAAAAAAAAAAAAKYmfAAAAAAAAAAAAAAAAgJTETwAAAAAAAAAAAAAAAEBK4icAAAAAAAAAAAAAAAAgJfETAAAAAAAAAAAAAAAAkJL4CQAAAAAAAAAAAAAAAEhJ/AQAAAAAAAAAAAAAAACkJH4CAAAAAAAAAAAAAAAAUhI/AQAAAAAAAAAAAAAAACmJnwAAAAAAAAAAAAAAAICUxE8AAAAAAAAAAAAAAABASuInAAAAAAAAAAAAAAAAICXxEwAAAAAAAAAAAAAAAJCS+AkAAAAAAAAAAAAAAABISfwEAAAAAAAAAAAAAAAApCR+AgAAAAAAAAAAAAAAAFISPwEAAAAAAAAAAAAAAAApiZ8AAAAAAAAAAAAAAACAlMRPAAAAAAAAAAAAAAAAQEriJwAAAAAAAAAAAAAAACAl8RMAAAAAAAAAAAAAAACQkvgJAAAAAAAAAAAAAAAASEn8BAAAAAAAAAAAAAAAAKQkfgIAAAAAAAAAAAAAAABSEj8BAAAAAAAAAAAAAAAAKYmfAAAAAAAAAAAAAAAAgJTETwAAAAAAAAAAAAAAAEBK4icAAAAAAAAAAAAAAAAgJfETAAAAAAAAAAAAAAAAkJL4CQAAAAAAAAAAAAAAAEhJ/AQAAAAAAAAAAAAAAACkJH4CAAAAAAAAAAAAAAAAUhI/AQAAAAAAAAAAAAAAACmJnwAAAAAAAAAAAAAAAICUxE8AAAAAAAAAAAAAAABASuInAAAAAAAAAAAAAAAAICXxEwAAAAAAAAAAAAAAAJDSFeUeAAAAAAAAALh87dixI06dOlXuMSIiYuXKlVFdXV3uMQAAAAAAgHGoKBaLxXIPAQAAAAAAAFyeWlpaolAolHuMiIg4fvx4TJ8+vdxjAAAAAAAA41BZ7gEAAAAAAAAAAAAAAAAA/or4CQAAAAAAAAAAAAAAAEhJ/AQAAAAAAAAAAAAAAACkJH4CAAAAAAAAAAAAAAAAUhI/AQAAAAAAAAAAAAAAACmJnwAAAAAAAICy2bp1axSLxUn5N3369HJ/XAAAAAAAYJzETwAAAAAAAAAAAAAAAEBK4icAAAAAAAAAAAAAAAAgJfETAAAAAAAAAAAAAAAAkJL4CQAAAAAAAAAAAAAAAEhJ/AQAAAAAAAAAAAAAAACkJH4CAAAAAAAAAAAAAAAAUhI/AQAAAAAAAAAAAAAAACmJnwAAAAAAAAAAAAAAAICUxE8AAAAAAAAAAAAAAABASuInAAAAAAAAAAAAAAAAICXxEwAAAAAAAAAAAAAAAJCS+AkAAAAAAAAAAAAAAABISfwEAAAAAAAAAAAAAAAApCR+AgAAAAAAAAAAAAAAAFISPwEAAAAAAAAAAAAAAAApiZ8AAAAAAAAAAAAAAACAlMRPAAAAAAAAAAAAAAAAQEpXlHsAAAAAAAAA4J+rr68vfv3115Ktv2TJkrj55ptLtj4AAAAAAFBaFcVisVjuIQAAAAAAAIDLU0tLSxQKhbLt/8orr8S6devKtj8AAAAAAPD3VJZ7AAAAAAAAAAAAAAAAAIC/In4CAAAAAAAAAAAAAAAAUhI/AQAAAAAAAAAAAAAAACmJnwAAAAAAAAAAAAAAAICUxE8AAAAAAAAAAAAAAABASleUewAAAAAAAADgn2vr1q2xatWqco8BAAAAAAAk5clPAAAAAAAAAAAAAAAAQEriJwAAAAAAAAAAAAAAACAl8RMAAAAAAAAAAAAAAACQkvgJAAAAAAAAAAAAAAAASEn8BAAAAAAAAAAAAAAAAKQkfgIAAAAAAAAAAAAAAABSEj8BAAAAAAAAAAAAAAAAKYmfAAAAAAAAAAAAAAAAgJTETwAAAAAAAAAAAAAAAEBK4icAAAAAAAAAAAAAAAAgJfETAAAAAAAAAAAAAAAAkJL4CQAAAAAAAAAAAAAAAEhJ/AQAAAAAAAAAAAAAAACkJH4CAAAAAAAAAAAAAAAAUhI/AQAAAAAAAAAAAAAAACmJnwAAAAAAAAAAAAAAAICUxE8AAAAAAAAAAAAAAABASuInAAAAAAAAAAAAAAAAICXxEwAAAAAAAAAAAAAAAJCS+AkAAAAAAAAAAAAAAABISfwEAAAAAAAAAAAAAAAApCR+AgAAAAAAAAAAAAAAAFISPwEAAAAAAAAAAAAAAAApiZ8AAAAAAAAAAAAAAACAlMRPAAAAAAAAAAAAAAAAQEriJwAAAAAAAAAAAAAAACAl8RMAAAAAAAAAAAAAAACQkvgJAAAAAAAAAAAAAAAASKmiWCwWyz0EAAAAAAAAAAAAAAAAwJ958hMAAAAAAAAAAAAAAACQkvgJAAAAAAAAAAAAAAAASEn8BAAAAAAAAAAAAAAAAKQkfgIAAAAAAAAAAAAAAABSEj8BAAAAAAAAAAAAAAAAKYmfAAAAAAAAAAAAAAAAgJTETwAAAAAAAAAAAAAAAEBK4icAAAAAAAAAAAAAAAAgJfETAAAAAAAAAAAAAAAAkJL4CQAAAAAAAAAAAAAAAEhJ/AQAAAAAAAAAAAAAAACkJH4CAAAAAAAAAAAAAAAAUhI/AQAAAAAAAAAAAAAAACmJnwAAAAAAAAAAAAAAAICUxE8AAAAAAAAAAAAAAABASuInAAAAAAAAAAAAAAAAICXxEwAAAAAAAAAAAAAAAJCS+AkAAAAAAAAAAAAAAABISfwEAAAAAAAAAAAAAAAApCR+AgAAAAAAAAAAAAAAAFISPwEAAAAAAAAAAAAAAAApiZ8AAAAAAAAAAAAAAACAlMRPAAAAAAAAAAAAAAAAQEriJwAAAAAAAAAAAAAAACAl8RMAAAAAAAAAAAAAAACQkvgJAAAAAAAAAAAAAAAASEn8BAAAAAAAAAAAAAAAAKQkfgIAAAAAAAAAAAAAAABSEj8BAAAAAAAAAAAAAAAAKYmfAAAAAAAAAAAAAAAAgJTETwAAAAAAAAAAAAAAAEBK4icAAAAAAAAAAAAAAAAgJfETAAAAAAAAAAAAAAAAkJL4CQAAAAAAAAAAAAAAAEhJ/AQAAAAAAAAAAAAAAACkJH4CAAAAAAAAAAAAAAAAUhI/AQAAAAAAAAAAAAAAACmJnwAAAAAAAAAAAAAAAICUxE8AAAAAAAAAAAAAAABASuInAAAAAAAAAAAAAAAAICXxEwAAAAAAAAAAAAAAAJCS+AkAAAAAAAAAAAAAAABISfwEAAAAAAAAAAAAAAAApCR+AgAAAAAAAAAAAAAAAFISPwEAAAAAAAAAAAAAAAApiZ8AAAAAAAAAAAAAAACAlMRPAAAAAAAAAAAAAAAAQEriJwAAAAAAAAAAAAAAACAl8RMAAAAAAAAAAAAAAACQkvgJAAAAAAAAAAAAAAAASEn8BAAAAAAAAAAAAAAAAKQkfgIAAAAAAAAAAAAAAABSEj8BAAAAAAAAAAAAAAAAKYmfAAAAAAAAAAAAAAAAgJTETwAAAAAAAAAAAAAAAEBK4icAAAAAAAAAAAAAAAAgJfETAAAAAAAAAAAAAAAAkJL4CQAAAAAAAAAAAAAAAEhJ/AQAAAAAAAAAAAAAAACkJH4CAAAAAAAAAAAAAAAAUhI/AQAAAAAAAAAAAAAAACmJnwAAAAAAAAAAAAAAAICUxE8AAAAAAAAAAAAAAABASuInAAAAAAAAAAAAAAAAICXxEwAAAAAAAAAAAAAAAJCS+AkAAAAAAAAAAAAAAABISfwEAAAAAAAAAAAAAAAApCR+AgAAAAAAAAAAAAAAAFISPwEAAAAAAAAAAAAAAAApiZ8AAAAAAAAAAAAAAACAlMRPAAAAAAAAAAAAAAAAQEriJwAAAAAAAAAAAAAAACAl8RMAAAAAAAAAAAAAAACQkvgJAAAAAAAAAAAAAAAASEn8BAAAAAAAAAAAAAAAAKQkfgIAAAAAAAAAAAAAAABS+hdp/uChAAj0lwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 3840x2880 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "t_p = model(t_un,*params) \n",
    "\n",
    "fig = plt.figure(dpi = 600)\n",
    "plt.xlabel(\"F\")\n",
    "plt.ylabel(\"C\")\n",
    "\n",
    "plt.plot(t_u.numpy(),t_p.detach().numpy())\n",
    "plt.plot(t_u.numpy(),t_c.numpy(),'o')\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0dce7b0df2f1b46d847510d5f66d601db3fe6d7287ec3d6ad0521fbc0159973"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
