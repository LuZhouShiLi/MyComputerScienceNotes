{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m t_batch \u001b[38;5;241m=\u001b[39m t_train[batch_mask]\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m## 计算梯度\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumerical_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mt_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m## 更新参数\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW2\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb2\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32md:\\Learn\\Notes\\MachineLearning\\ch03\\two_layer_net.py:48\u001b[0m, in \u001b[0;36mTwoLayerNet.numerical_gradient\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     45\u001b[0m loss_W \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m W: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(x, t)\n\u001b[0;32m     47\u001b[0m grads \u001b[39m=\u001b[39m {}\n\u001b[1;32m---> 48\u001b[0m grads[\u001b[39m'\u001b[39m\u001b[39mW1\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m numerical_gradient(loss_W, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mW1\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     49\u001b[0m grads[\u001b[39m'\u001b[39m\u001b[39mb1\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m numerical_gradient(loss_W, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mb1\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     50\u001b[0m grads[\u001b[39m'\u001b[39m\u001b[39mW2\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m numerical_gradient(loss_W, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mW2\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32md:\\Learn\\Notes\\MachineLearning\\ch03\\..\\common\\gradient.py:46\u001b[0m, in \u001b[0;36mnumerical_gradient\u001b[1;34m(f, x)\u001b[0m\n\u001b[0;32m     43\u001b[0m fxh1 \u001b[39m=\u001b[39m f(x) \u001b[39m# f(x+h)\u001b[39;00m\n\u001b[0;32m     45\u001b[0m x[idx] \u001b[39m=\u001b[39m tmp_val \u001b[39m-\u001b[39m h \n\u001b[1;32m---> 46\u001b[0m fxh2 \u001b[39m=\u001b[39m f(x) \u001b[39m# f(x-h)\u001b[39;00m\n\u001b[0;32m     47\u001b[0m grad[idx] \u001b[39m=\u001b[39m (fxh1 \u001b[39m-\u001b[39m fxh2) \u001b[39m/\u001b[39m (\u001b[39m2\u001b[39m\u001b[39m*\u001b[39mh)\n\u001b[0;32m     49\u001b[0m x[idx] \u001b[39m=\u001b[39m tmp_val \u001b[39m# 还原值\u001b[39;00m\n",
      "File \u001b[1;32md:\\Learn\\Notes\\MachineLearning\\ch03\\two_layer_net.py:45\u001b[0m, in \u001b[0;36mTwoLayerNet.numerical_gradient.<locals>.<lambda>\u001b[1;34m(W)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnumerical_gradient\u001b[39m(\u001b[39mself\u001b[39m, x, t):\n\u001b[1;32m---> 45\u001b[0m     loss_W \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m W: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss(x, t)\n\u001b[0;32m     47\u001b[0m     grads \u001b[39m=\u001b[39m {}\n\u001b[0;32m     48\u001b[0m     grads[\u001b[39m'\u001b[39m\u001b[39mW1\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m numerical_gradient(loss_W, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mW1\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32md:\\Learn\\Notes\\MachineLearning\\ch03\\two_layer_net.py:31\u001b[0m, in \u001b[0;36mTwoLayerNet.loss\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss\u001b[39m(\u001b[39mself\u001b[39m, x, t):\n\u001b[1;32m---> 31\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(x)\n\u001b[0;32m     33\u001b[0m     \u001b[39mreturn\u001b[39;00m cross_entropy_error(y, t)\n",
      "File \u001b[1;32md:\\Learn\\Notes\\MachineLearning\\ch03\\two_layer_net.py:22\u001b[0m, in \u001b[0;36mTwoLayerNet.predict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m W1, W2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mW1\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mW2\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     20\u001b[0m b1, b2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mb1\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mb2\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> 22\u001b[0m a1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(x, W1) \u001b[39m+\u001b[39m b1\n\u001b[0;32m     23\u001b[0m z1 \u001b[39m=\u001b[39m sigmoid(a1)\n\u001b[0;32m     24\u001b[0m a2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(z1, W2) \u001b[39m+\u001b[39m b2\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys,os\n",
    "sys.path.append(os.pardir)\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "(x_train,t_train),(x_test,t_test) = load_mnist(normalize=True,one_hot_label=True)\n",
    "\n",
    "train_loss_list = []\n",
    "\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 超参数\n",
    "\n",
    "iters_num = 10  ## 梯度下降迭代次数\n",
    "train_size = x_train.shape[0]  ## 计算训练数据样本个数\n",
    "batch_size = 100## 批处理大小\n",
    "learning_rate = 0.1  ## 学习率\n",
    "\n",
    "# 平均每一个epoch的重复次数\n",
    "iter_per_epoch = max(train_size / batch_size,1)\n",
    "\n",
    "network = TwoLayerNet(input_size=784,hidden_size=50,output_size=10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    ## 获取mini_batch\n",
    "    batch_mask = np.random.choice(train_size,batch_size)\n",
    "\n",
    "    ## 批量获取数据\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    ## 计算梯度\n",
    "    grad = network.numerical_gradient(x_batch,t_batch)\n",
    "\n",
    "    ## 更新参数\n",
    "    for key in ('W1','b1','W2','b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "\n",
    "    # 记录学习过程\n",
    "    loss = network.loss(x_batch,t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "\n",
    "    ## 计算每一个epoch的识别精度  100次\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train,t_train)\n",
    "        test_acc = network.accuracy(x_test,t_test)\n",
    "\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "\n",
    "        print(\"train acc, test acc |\" + str(train_acc) + \",\" + str(test_acc))\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0dce7b0df2f1b46d847510d5f66d601db3fe6d7287ec3d6ad0521fbc0159973"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
