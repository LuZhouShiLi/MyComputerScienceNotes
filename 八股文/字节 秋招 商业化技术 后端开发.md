# 字节 秋招 商业化技术 后端开发


## ConcurrentHashMap


* ConcurrentHashMap 是 Java Collections Framework 提供的线程安全的哈希表实现。它通过使用分段锁（Segment）的方式来保证线程安全性。ConcurrentHashMap 将整个哈希表分为多个段（Segment），每个段相当于一个小的哈希表，这样不同的段可以被不同的线程同时访问，从而提高并发性能。

以下是 ConcurrentHashMap 如何保证线程安全的主要机制：

* 分段锁机制：

    * ConcurrentHashMap 内部维护了一个数组，每个数组元素是一个段，每个段维护一个小的哈希表。在对哈希表的操作时，锁的粒度被缩小到段的级别。这样，在并发访问时，不同的线程可以同时访问不同的段，提高了并发性能。


* 线程安全的操作：ConcurrentHashMap 提供了一系列的线程安全的操作，例如 putIfAbsent(), replace(), remove() 等，这些操作是原子的，不需要额外的同步措施。



## HashMap和CoonCurrentHashMap

### 线程安全性：
* HashMap：HashMap 是非线程安全的。在多线程环境中，如果有多个线程同时修改 HashMap，可能会导致不一致的结果，甚至导致死锁。
* ConcurrentHashMap：concurrentHashMap 是线程安全的。它通过分段锁的机制，在对哈希表进行操作时，只需要锁住特定的段而不是整个哈希表，从而允许多个线程同时对不同的段进行操作。这提高了并发性能，同时保证了线程安全。

### 锁的粒度：
HashMap：

HashMap 在多线程环境中，如果有线程对其进行修改操作，需要额外的同步措施，例如使用 Collections.synchronizedMap 来包装 HashMap。
ConcurrentHashMap：

ConcurrentHashMap 使用分段锁的方式，每个段都有一个独立的锁，因此可以在多线程环境中实现更细粒度的锁控制。这样，不同的线程可以同时对不同的段进行操作，提高了并发度。

### 效率和性能

* HashMap：HashMap 在单线程环境下的性能可能更高，因为不需要额外的同步开销。


* ConcurrentHashMap：ConcurrentHashMap 在多线程环境下的性能可能更好，因为它允许多个线程同时访问不同的段。


### 初始容量和负载因子
* 在创建 HashMap 时需要指定初始容量和负载因子。负载因子过高可能导致频繁的扩容，影响性能。
* ConcurrentHashMap 在构造时也需要指定初始容量和负载因子，但相对于 HashMap，它的默认负载因子更高，可以更好地支持高并发。

* ConcurrentHashMap 在多线程环境下提供了更好的性能和线程安全性，适用于高并发的场景。而 HashMap 更适合在单线程环境或者是不需要考虑并发安全性的场景。

## synchronized上锁解锁流程

### synchronized 上锁流程：


* 获取锁：当线程执行到 synchronized 块的时候，首先尝试获取锁。如果锁没有被其他线程占用，该线程获得锁，并继续执行 synchronized 块中的代码。
* 锁的状态：当线程获取到锁时，锁的状态为"锁定"。此时，其他线程尝试获取同一把锁时会被阻塞，直到当前线程释放锁。
* 执行 synchronized 块：获取到锁的线程执行 synchronized 块中的代码。在这个阶段，线程可以安全地访问共享资源。

### synchronized 解锁流程


* 执行完 synchronized 块：当线程执行完 synchronized 块中的代码，或者在 synchronized 块中发生异常而退出时，线程会释放锁。
* 锁的状态变为"未锁定"：一旦线程释放锁，锁的状态变为"未锁定"。此时，其他线程可以尝试获取该锁。
* 唤醒等待线程：如果有其他线程在等待获取相同的锁，其中一个等待线程（通常是等待时间最长的线程）将被唤醒，它会尝试获取锁，获取成功后继续执行。

* synchronized 可以用在方法上，也可以用在代码块上。对于方法而言，整个方法都被视为临界区。

* 对于 synchronized 代码块，需要指定一个对象作为锁，当线程想要执行 synchronized 代码块时，需要先获得指定对象的锁。

* 当线程获得锁后，其他线程对同一把锁的请求将会被阻塞，直到持有锁的线程释放锁。

synchronized 提供了一种简单而有效的机制来实现线程同步，但在一些复杂的情况下，可能需要使用更高级的并发工具，如 java.util.concurrent 包提供的类



### synchronized为什么设计为可重入锁

* 避免死锁：可重入性解决了死锁的一个重要问题。如果 synchronized 不是可重入的，那么当一个线程持有锁并尝试再次获取这个锁的时候，就会发生死锁。可重入锁允许一个线程在持有锁的情况下继续获取这个锁，因此避免了死锁的发生。

* 可重入性使得同一线程能够多次获得同一把锁，从而可以方便地进行嵌套调用
* 对于递归函数或者调用链上的嵌套方法，可重入锁允许同一线程在递归调用过程中多次获取相同的锁，而不会产生死锁或其他问题。

## 微信朋友圈设计

```
A发送朋友圈（客户端）：

A打开微信客户端，点击发布朋友圈。
A选择要分享的内容，可以包括文字、图片、视频等。
A点击发布按钮，触发发送朋友圈的操作。
A发送朋友圈（服务端）：

微信客户端将A的朋友圈内容上传到微信服务器。
服务器接收到A的朋友圈内容后，进行相关的校验，确保内容合法、符合规定。
服务器将合法的朋友圈内容存储到数据库中，同时生成一个唯一的朋友圈ID。
B接收朋友圈（客户端）：

B打开微信客户端，刷新朋友圈页面或者接收到新消息的通知。
客户端向微信服务器发送请求，获取最新的朋友圈列表。
B接收朋友圈（服务端）：

微信服务器接收到B的请求，查询数据库获取最新的朋友圈列表数据。
服务器将朋友圈数据打包成响应，发送给B的客户端。
B展示朋友圈（客户端）：

客户端接收到服务器响应的朋友圈数据。
客户端解析数据，并在界面上展示朋友圈的内容，包括文字、图片、视频等。

```

&emsp;这个流程涉及到客户端的用户交互和展示，以及服务端的数据存储和传输。客户端负责用户的输入、界面展示和与用户的交互，而服务端负责数据的存储、处理和传输。这样的架构使得用户可以方便地分享和查看朋友圈，而服务器则负责协调和管理这些数据的流动。

### 假如A在一个小时内发了5条朋友圈，对于某个时刻，A的好友怎么拿到自己最新的朋友圈（比如B能看到A发的3条，C能看到A发的5条）
A的好友应该和A维护一个什么状态，才能拿到最新的信息

* 轮询方式：

A的好友（比如B）定期向服务器发送请求，查询A最近发表的朋友圈。
服务器返回A最近发表的朋友圈列表，B更新本地的朋友圈显示。

* 订阅方式：

A的好友（比如B）在登录或者应用启动时，向服务器注册一个订阅，表明他想要接收A的朋友圈更新通知。
当A发表新的朋友圈时，服务器向所有订阅了A的好友发送通知。
B收到通知后，向服务器发起请求获取最新的朋友圈数据。
服务器返回A最新的朋友圈列表，B更新本地的朋友圈显示。


* A的好友需要维护一个状态，**以记录上一次获取朋友圈的时间戳或者已经获取到的最新朋友圈ID**。这个状态可以帮助服务器确定应该返回哪些朋友圈信息给好友。**服务器会根据好友的状态和A发表的朋友圈列表的时间戳进行筛选，确保好友获取到最新的未读朋友圈信息。**


## IO模型


* 阻塞式 I/O 模型（Blocking I/O）：

当应用程序发起 I/O 操作时，程序会被阻塞（暂停执行），直到操作完成。
阻塞式 I/O 是最传统的模型，适用于很多简单的应用，但当有大量的 I/O 操作需要处理时，可能导致性能瓶颈。


* 非阻塞式 I/O 模型（Non-blocking I/O）：

当应用程序发起 I/O 操作时，程序可以继续执行其他任务而不被阻塞，随后通过轮询或其他手段来检查操作是否完成。
非阻塞式 I/O 可以提高并发性，但需要不断轮询，可能会导致 CPU 资源的浪费。


* 事件驱动（异步）I/O 模型（Event-Driven I/O）：

当应用程序发起 I/O 操作时，程序可以继续执行其他任务，而不需要轮询。操作完成后，通过回调或事件通知的方式通知应用程序。
事件驱动 I/O 模型通常使用异步 I/O 操作，提供高度的并发性和性能，适用于处理大量并发连接的服务器应用。



## 设计应用层协议


```java

报文格式（Message Format）：

定义了在通信中传输的数据的结构和格式。报文格式包括消息头和消息体，消息头通常包含元数据，如消息长度、协议版本等。
数据编码（Data Encoding）：

定义了在报文中如何对数据进行编码和解码。常见的编码方式有 JSON、XML、二进制编码等。选择合适的编码方式可以根据应用的需求和性能要求。
协议操作码（Opcode）：

定义了不同种类的操作或请求的标识符。这些操作码用于识别报文的目的，例如请求数据、发送命令等。
会话管理（Session Management）：

如果协议需要建立和维护会话，那么会话管理部分需要定义会话的建立、维护和结束的过程。这可能包括用户身份验证、会话密钥生成等。
错误处理（Error Handling）：

定义了如何处理错误情况，包括报文格式错误、请求不合法等。协议应该提供清晰的错误码和描述，以便通信的各方能够理解和适当地处理错误。
安全性（Security）：

如果通信需要安全性，协议可能包括加密、身份验证、数字签名等机制。这有助于确保数据的保密性和完整性。
流程控制（Flow Control）：

定义了在通信中如何进行流程控制，以防止发送方过快地发送数据导致接收方无法处理。这可能涉及到确认机制、滑动窗口等。
应用层协议交互（Application Layer Protocol Interaction）：

如果协议需要与其他应用层协议交互，需要定义这种交互的方式和规则。这可以包括握手、协商协议选项等。
时间处理（Timing Issues）：

定义了定时、超时、重传等时间相关的处理机制，以确保通信的及时性和可靠性。
协议版本（Protocol Versioning）：

考虑到协议可能升级或变更，需要定义协议版本号和处理不同版本的兼容性机制。

```

## 线程池


### 基本组件


任务队列（Task Queue）： 用于存放需要执行的任务。线程池中的线程会从任务队列中取出任务并执行。

线程池管理器： 负责创建、销毁和管理线程池中的线程。它还负责监控任务队列，以便及时分配任务给可用的线程。

工作线程（Worker Thread）： 实际执行任务的线程。线程池中会有多个工作线程，它们会从任务队列中获取任务并执行。

任务（Task）： 要执行的具体工作单元。可以是一个函数、一个方法或者一个类的实例，封装了需要执行的操作。


### 线程池的基本实现步骤：


初始化线程池： 创建一个任务队列和一定数量的工作线程。

提交任务： 将任务提交到任务队列中。

工作线程执行： 工作线程从任务队列中取出任务，并执行任务中定义的操作。

任务完成： 工作线程执行完任务后，将线程返回到线程池，等待下一个任务。

销毁线程池： 在不需要线程池时，应当销毁线程池。这包括停止接受新任务，等待所有任务完成，并释放资源。


### 线程安全的阻塞队列


在实现线程安全的阻塞队列时，为了减小锁的竞争，可以考虑使用两个锁，一个用于控制队列的入队操作，另一个用于控制队列的出队操作。这种方式被称为"双锁队列"（Double-Checked Locking）。


## 大文件找到出现次数最多的字符串 TopK问题

* 遍历文件，使用哈希表记录每个字符串的出现次数：逐行读取大文件，将每个字符串作为键，记录其出现的次数。
* 使用最小堆来维护TopK：

维护一个大小为K的最小堆，其中元素为（字符串，出现次数）的键值对。
对于哈希表中的每个记录，将其插入到最小堆中。
如果堆的大小超过K，弹出堆顶元素。
* 遍历哈希表完成后，堆中剩余的就是TopK：

堆中剩余的元素就是出现次数最多的TopK字符串




